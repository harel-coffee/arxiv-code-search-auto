{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/tim/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"production, wake topology, and propulsive performance of a pitching and rolling wing. Although our numerical values do not fully match those from the original study Li and Dong5, we obtain the same trends and thus consider this replication attempt to be successful. A CFD solver typically outputs the solution of primary variables. For example, PetIBM outputs the pressure and velocity fields, as well as the body forces. We often use multiple post-processing scripts to generate the final data and figures reported and analyzed in the manuscript; it involves computing secondary data, such as the vorticity field, the aerodynamic power and forces. If the code is not made available, readers cannot inspect what has been done to produce these data; bugs introduced in these post-processing steps would go undetected. If no code is available, we cannot explain discrepancies observed between our replication and the original study. As Donoho and coworkers14 once said: “The only way we’d ever get to the bottom of such a discrepancy is if we both worked reproducibly and studied detailed differences between code and data.” We made our best efforts to ensure that our replication study is reproducible. Our computational application makes use of fully open-source tools, and we created a GitHub repository6 for this study. The repository contains the source code of the PetIBM application, as well as all input files of the simulations reported here, and pre- and postprocessing Python scripts. We adopted a reproducible workflow to run computational simulations; it makes use of Docker images and Singularity recipes to capture the computational environment. With Singularity, we ran container-based jobs on our universitymanaged HPC cluster. The GitHub repository also contains the job-submission scripts that were use to run the simulations on our cluster; they can be adapted to run on other platforms if readers are interested in reproducing our results. Admittedly, not everyone has access to an HPC cluster with GPU nodes and with Singularity installed. Lacking those resources, it becomes difficult to fully reproduce our workflow. However, we made the effort to deposit on Zenodo7 the primary data (directly output from our CFD solver) and post-processing scripts needed to reproduce the figures of the present manuscript. Once the Zenodo repository is downloaded, readers should be able to spin up a Docker container and run a Bash script to compute the secondary data and generate the figures, or generate different figures to explore the data in new ways. The Docker images produced and used for this study are stored on DockerHub8, under a basic free subscription. In the event Docker adopts a policy to automatically purge inactive images (those who have not been recently downloaded) from the Hub, the Dockerfiles are version-controlled on the GitHub repository and can be used to rebuild the images. We spent time engineering a transparent and reproducible workflow to produce the artifacts of this replication study. Surely, we cannot assert our steps will be fully reproducible in years from now; the software stack could very well become obsolete with new hardware generations. While the likelihood of the study being reproducible may decrease with the years, the transparency of the steps we took to generate the data shall remain constant.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "590\n"
     ]
    }
   ],
   "source": [
    "token_count = len(nltk.word_tokenize(text))\n",
    "print(token_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['production, wake topology, and propulsive performance of a pitching and rolling wing.',\n",
       " 'Although our numerical values do not fully match those from the original study Li and Dong5, we obtain the same trends and thus consider this replication attempt to be successful.',\n",
       " 'A CFD solver typically outputs the solution of primary variables.',\n",
       " 'For example, PetIBM outputs the pressure and velocity fields, as well as the body forces.',\n",
       " 'We often use multiple post-processing scripts to generate the final data and figures reported and analyzed in the manuscript; it involves computing secondary data, such as the vorticity field, the aerodynamic power and forces.',\n",
       " 'If the code is not made available, readers cannot inspect what has been done to produce these data; bugs introduced in these post-processing steps would go undetected.',\n",
       " 'If no code is available, we cannot explain discrepancies observed between our replication and the original study.',\n",
       " 'As Donoho and coworkers14 once said: “The only way we’d ever get to the bottom of such a discrepancy is if we both worked reproducibly and studied detailed differences between code and data.” We made our best efforts to ensure that our replication study is reproducible.',\n",
       " 'Our computational application makes use of fully open-source tools, and we created a GitHub repository6 for this study.',\n",
       " 'The repository contains the source code of the PetIBM application, as well as all input files of the simulations reported here, and pre- and postprocessing Python scripts.',\n",
       " 'We adopted a reproducible workflow to run computational simulations; it makes use of Docker images and Singularity recipes to capture the computational environment.',\n",
       " 'With Singularity, we ran container-based jobs on our universitymanaged HPC cluster.',\n",
       " 'The GitHub repository also contains the job-submission scripts that were use to run the simulations on our cluster; they can be adapted to run on other platforms if readers are interested in reproducing our results.',\n",
       " 'Admittedly, not everyone has access to an HPC cluster with GPU nodes and with Singularity installed.',\n",
       " 'Lacking those resources, it becomes difficult to fully reproduce our workflow.',\n",
       " 'However, we made the effort to deposit on Zenodo7 the primary data (directly output from our CFD solver) and post-processing scripts needed to reproduce the figures of the present manuscript.',\n",
       " 'Once the Zenodo repository is downloaded, readers should be able to spin up a Docker container and run a Bash script to compute the secondary data and generate the figures, or generate different figures to explore the data in new ways.',\n",
       " 'The Docker images produced and used for this study are stored on DockerHub8, under a basic free subscription.',\n",
       " 'In the event Docker adopts a policy to automatically purge inactive images (those who have not been recently downloaded) from the Hub, the Dockerfiles are version-controlled on the GitHub repository and can be used to rebuild the images.',\n",
       " 'We spent time engineering a transparent and reproducible workflow to produce the artifacts of this replication study.',\n",
       " 'Surely, we cannot assert our steps will be fully reproducible in years from now; the software stack could very well become obsolete with new hardware generations.',\n",
       " 'While the likelihood of the study being reproducible may decrease with the years, the transparency of the steps we took to generate the data shall remain constant.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['While the likelihood of the study being reproducible may decrease with the years, the transparency of the steps we took to generate the data shall remain constant.',\n",
       " 'Surely, we cannot assert our steps will be fully reproducible in years from now; the software stack could very well become obsolete with new hardware generations.',\n",
       " 'We spent time engineering a transparent and reproducible workflow to produce the artifacts of this replication study.',\n",
       " 'In the event Docker adopts a policy to automatically purge inactive images (those who have not been recently downloaded) from the Hub, the Dockerfiles are version-controlled on the GitHub repository and can be used to rebuild the images.',\n",
       " 'The Docker images produced and used for this study are stored on DockerHub8, under a basic free subscription.',\n",
       " 'Once the Zenodo repository is downloaded, readers should be able to spin up a Docker container and run a Bash script to compute the secondary data and generate the figures, or generate different figures to explore the data in new ways.',\n",
       " 'However, we made the effort to deposit on Zenodo7 the primary data (directly output from our CFD solver) and post-processing scripts needed to reproduce the figures of the present manuscript.',\n",
       " 'Lacking those resources, it becomes difficult to fully reproduce our workflow.',\n",
       " 'Admittedly, not everyone has access to an HPC cluster with GPU nodes and with Singularity installed.',\n",
       " 'The GitHub repository also contains the job-submission scripts that were use to run the simulations on our cluster; they can be adapted to run on other platforms if readers are interested in reproducing our results.',\n",
       " 'With Singularity, we ran container-based jobs on our universitymanaged HPC cluster.',\n",
       " 'We adopted a reproducible workflow to run computational simulations; it makes use of Docker images and Singularity recipes to capture the computational environment.',\n",
       " 'The repository contains the source code of the PetIBM application, as well as all input files of the simulations reported here, and pre- and postprocessing Python scripts.',\n",
       " 'Our computational application makes use of fully open-source tools, and we created a GitHub repository6 for this study.',\n",
       " 'As Donoho and coworkers14 once said: “The only way we’d ever get to the bottom of such a discrepancy is if we both worked reproducibly and studied detailed differences between code and data.” We made our best efforts to ensure that our replication study is reproducible.',\n",
       " 'If no code is available, we cannot explain discrepancies observed between our replication and the original study.',\n",
       " 'If the code is not made available, readers cannot inspect what has been done to produce these data; bugs introduced in these post-processing steps would go undetected.',\n",
       " 'We often use multiple post-processing scripts to generate the final data and figures reported and analyzed in the manuscript; it involves computing secondary data, such as the vorticity field, the aerodynamic power and forces.',\n",
       " 'For example, PetIBM outputs the pressure and velocity fields, as well as the body forces.',\n",
       " 'A CFD solver typically outputs the solution of primary variables.',\n",
       " 'Although our numerical values do not fully match those from the original study Li and Dong5, we obtain the same trends and thus consider this replication attempt to be successful.',\n",
       " 'production, wake topology, and propulsive performance of a pitching and rolling wing.']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.sent_tokenize(text)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if token_count > 512, then break up into two chunks, using sentences\n",
    "if token_count > 500 and token_count < 1000:\n",
    "    \n",
    "    # split into two chunks, one starting from the front, and one starting from the back\n",
    "    chunk1 = \"\"\n",
    "    for sent in nltk.sent_tokenize(text):\n",
    "        # add sentence to chunk1 with a space inbetween sentences\n",
    "        chunk1 += sent + \" \"\n",
    "        len_chunk = len(nltk.word_tokenize(chunk1))\n",
    "        if len_chunk > 500:\n",
    "            break\n",
    "        # print(len_chunk)\n",
    "\n",
    "    chunk2 = \"\"\n",
    "    for sent in nltk.sent_tokenize(text)[::-1]:\n",
    "        # add sentence to chunk2 with a space inbetween sentences\n",
    "        chunk2 = sent + \" \" + chunk2\n",
    "        len_chunk = len(nltk.word_tokenize(chunk2))\n",
    "        if len_chunk > 500:\n",
    "            break\n",
    "        # print(len_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_large_para(text, max_token_count=500):\n",
    "    # split into two chunks, one starting from the front, and one starting from the back\n",
    "    chunk1 = \"\"\n",
    "    for sent in nltk.sent_tokenize(text):\n",
    "        # add sentence to chunk1 with a space inbetween sentences\n",
    "        chunk1 += sent + \" \"\n",
    "        len_chunk = len(nltk.word_tokenize(chunk1))\n",
    "        if len_chunk > max_token_count:\n",
    "            break\n",
    "        # print(len_chunk)\n",
    "\n",
    "    chunk2 = \"\"\n",
    "    for sent in nltk.sent_tokenize(text)[::-1]:\n",
    "        # add sentence to chunk2 with a space inbetween sentences\n",
    "        chunk2 = sent + \" \" + chunk2\n",
    "        len_chunk = len(nltk.word_tokenize(chunk2))\n",
    "        if len_chunk > max_token_count:\n",
    "            break\n",
    "        \n",
    "    return chunk1, chunk2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk1, chunk2 = split_large_para(text*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'production, wake topology, and propulsive performance of a pitching and rolling wing. Although our numerical values do not fully match those from the original study Li and Dong5, we obtain the same trends and thus consider this replication attempt to be successful. A CFD solver typically outputs the solution of primary variables. For example, PetIBM outputs the pressure and velocity fields, as well as the body forces. We often use multiple post-processing scripts to generate the final data and figures reported and analyzed in the manuscript; it involves computing secondary data, such as the vorticity field, the aerodynamic power and forces. If the code is not made available, readers cannot inspect what has been done to produce these data; bugs introduced in these post-processing steps would go undetected. If no code is available, we cannot explain discrepancies observed between our replication and the original study. As Donoho and coworkers14 once said: “The only way we’d ever get to the bottom of such a discrepancy is if we both worked reproducibly and studied detailed differences between code and data.” We made our best efforts to ensure that our replication study is reproducible. Our computational application makes use of fully open-source tools, and we created a GitHub repository6 for this study. The repository contains the source code of the PetIBM application, as well as all input files of the simulations reported here, and pre- and postprocessing Python scripts. We adopted a reproducible workflow to run computational simulations; it makes use of Docker images and Singularity recipes to capture the computational environment. With Singularity, we ran container-based jobs on our universitymanaged HPC cluster. The GitHub repository also contains the job-submission scripts that were use to run the simulations on our cluster; they can be adapted to run on other platforms if readers are interested in reproducing our results. Admittedly, not everyone has access to an HPC cluster with GPU nodes and with Singularity installed. Lacking those resources, it becomes difficult to fully reproduce our workflow. However, we made the effort to deposit on Zenodo7 the primary data (directly output from our CFD solver) and post-processing scripts needed to reproduce the figures of the present manuscript. Once the Zenodo repository is downloaded, readers should be able to spin up a Docker container and run a Bash script to compute the secondary data and generate the figures, or generate different figures to explore the data in new ways. The Docker images produced and used for this study are stored on DockerHub8, under a basic free subscription. In the event Docker adopts a policy to automatically purge inactive images (those who have not been recently downloaded) from the Hub, the Dockerfiles are version-controlled on the GitHub repository and can be used to rebuild the images. '"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if token_count > 500 and token_count < 1000:\n",
    "    # start at the beginning of the text and take the first ~500 tokens\n",
    "    # based on full sentences\n",
    "    chunk1 = nltk.word_tokenize(text)[:500]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print(\"Too many tokens\")\n",
    "    # sentences = nltk.sent_tokenize(text)\n",
    "    # token_count = 0\n",
    "    # for sentence in sentences:\n",
    "    #     token_count += len(nltk.word_tokenize(sentence))\n",
    "    # print(token_count)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "17e082919eb97a8b1648db68459a0548143f50884a45122adabc4767e3d2dece"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('arxiv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
