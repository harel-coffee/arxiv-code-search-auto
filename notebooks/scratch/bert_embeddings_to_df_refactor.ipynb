{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup, BertForSequenceClassification\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from torchmetrics import PrecisionRecallCurve\n",
    "from transformers import AutoModel\n",
    "import pickle\n",
    "from src.models.utils import create_data_loader\n",
    "from src.features.make_bert_embeddings import create_single_embedding\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "device count: 1\n",
      "device name: NVIDIA GeForce GTX 980M\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"device count:\", torch.cuda.device_count())\n",
    "print(\"device name:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/code/colinlagator/pytorch-bert-multi-label/notebook\n",
    "\n",
    "https://discuss.huggingface.co/t/download-models-for-local-loading/1963\n",
    "\n",
    "Much of notebook is from: https://colab.research.google.com/drive/1PHv-IRLPCtv7oTcIGbsgZHqrB5LPvB7S#scrollTo=-FWG7kBm372V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(31090, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('allenai/scibert_scivocab_uncased')\n",
    "\n",
    "# for hpc (need to manually download model)\n",
    "model = AutoModel.from_pretrained('allenai/scibert_scivocab_uncased')\n",
    "\n",
    "# send model to gpu\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data_folder = Path().cwd().parent.parent / \"data\"\n",
    "path_interim_folder = path_data_folder / \"interim\"\n",
    "path_label_folder = path_data_folder / \"processed\" / \"labels\" / \"labels_complete\"\n",
    "proj_dir = Path().cwd().parent.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batch_embeddings(df, model, tokenizer, device=None, max_len=512, batch_size=20, label_column=\"label\"):\n",
    "    \"\"\"Create batch embeddings for a given dataframe.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        Dataframe with text and labels.\n",
    "    model : BertModel\n",
    "        Model to use for embedding.\n",
    "    tokenizer : BertTokenizer\n",
    "        Tokenizer to use for embedding.\n",
    "    data_loader : DataLoader\n",
    "        Pytorch DataLoader to get the text from the df.\n",
    "    device : torch.device, optional\n",
    "        Device to use for embedding. If \"none\" is specified, the system will look for a GPU, else will use the CPU.\n",
    "    max_len : int, optional\n",
    "        Maximum length of the text. The default is 512.\n",
    "    batch_size : int, optional\n",
    "        Batch size for embedding. The default is 20.\n",
    "    label_column : str, optional\n",
    "        Column name for the label. The default is \"label\".\n",
    "    \"\"\"\n",
    "\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # create copy of df\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    df_copy[\"para\"] = df_copy[\"para\"].str.lower()\n",
    "    df_copy[\"label\"] = df_copy[\"label\"].apply(lambda x: 1 if x > 0 else 0)  # binary labels\n",
    "\n",
    "    # loop through label data and create embeddings\n",
    "    data_loader = create_data_loader(df_copy, tokenizer, max_len, batch_size)\n",
    "\n",
    "    features_list = []\n",
    "    for i, data in enumerate(data_loader):\n",
    "        if i % 5 == 0:\n",
    "            print(f\"No. para: {batch_size * i}\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # print(data[\"input_ids\"].shape)\n",
    "            # from https://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/\n",
    "            last_hidden_states = model(\n",
    "                data[\"input_ids\"].to(device),\n",
    "                attention_mask=data[\"attention_masks\"].to(device),\n",
    "            )\n",
    "\n",
    "            features = (\n",
    "                last_hidden_states[0][:, 0, :].cpu().numpy()\n",
    "            )\n",
    "\n",
    "            features_list.append(features)  \n",
    "\n",
    "    return np.vstack(features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pattern</th>\n",
       "      <th>token_count</th>\n",
       "      <th>update_date</th>\n",
       "      <th>label</th>\n",
       "      <th>para</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1602.06797</td>\n",
       "      <td>data</td>\n",
       "      <td>6</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>of data with given labels.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1602.06797</td>\n",
       "      <td>data</td>\n",
       "      <td>9</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Guan. sparse co-occurrence data. Computer Soci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1602.06797</td>\n",
       "      <td>data</td>\n",
       "      <td>14</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Figure 5: Inﬂuence of labeled data, where the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1602.06797</td>\n",
       "      <td>data</td>\n",
       "      <td>20</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>In other words, µk is equal to the mean of all...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1602.06797</td>\n",
       "      <td>data</td>\n",
       "      <td>25</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>metric-learn-ave-vec also uses the metric lear...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id pattern  token_count update_date  label  \\\n",
       "0  1602.06797    data            6         NaT    0.0   \n",
       "1  1602.06797    data            9         NaT    0.0   \n",
       "2  1602.06797    data           14         NaT    0.0   \n",
       "3  1602.06797    data           20         NaT    0.0   \n",
       "4  1602.06797    data           25         NaT    0.0   \n",
       "\n",
       "                                                para  \n",
       "0                         of data with given labels.  \n",
       "1  Guan. sparse co-occurrence data. Computer Soci...  \n",
       "2  Figure 5: Inﬂuence of labeled data, where the ...  \n",
       "3  In other words, µk is equal to the mean of all...  \n",
       "4  metric-learn-ave-vec also uses the metric lear...  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\n",
    "    path_interim_folder / \"labels_to_not_include_in_final\" / \"labels_3.ods\",\n",
    "    parse_dates=[\"update_date\"],\n",
    "    engine=\"odf\",\n",
    "    dtype={\"id\": str},\n",
    "    )\n",
    "\n",
    "df = df[:133]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. para: 0\n",
      "No. para: 100\n"
     ]
    }
   ],
   "source": [
    "features_array = create_batch_embeddings(df, model, tokenizer, device=None, max_len=512, batch_size=20, label_column=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"h\"] = features_array.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pattern</th>\n",
       "      <th>token_count</th>\n",
       "      <th>update_date</th>\n",
       "      <th>label</th>\n",
       "      <th>para</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1602.06797</td>\n",
       "      <td>data</td>\n",
       "      <td>6</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>of data with given labels.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1602.06797</td>\n",
       "      <td>data</td>\n",
       "      <td>9</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Guan. sparse co-occurrence data. Computer Soci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1602.06797</td>\n",
       "      <td>data</td>\n",
       "      <td>14</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Figure 5: Inﬂuence of labeled data, where the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1602.06797</td>\n",
       "      <td>data</td>\n",
       "      <td>20</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>In other words, µk is equal to the mean of all...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1602.06797</td>\n",
       "      <td>data</td>\n",
       "      <td>25</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>metric-learn-ave-vec also uses the metric lear...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id pattern  token_count update_date  label  \\\n",
       "0  1602.06797    data            6         NaT    0.0   \n",
       "1  1602.06797    data            9         NaT    0.0   \n",
       "2  1602.06797    data           14         NaT    0.0   \n",
       "3  1602.06797    data           20         NaT    0.0   \n",
       "4  1602.06797    data           25         NaT    0.0   \n",
       "\n",
       "                                                para  \n",
       "0                         of data with given labels.  \n",
       "1  Guan. sparse co-occurrence data. Computer Soci...  \n",
       "2  Figure 5: Inﬂuence of labeled data, where the ...  \n",
       "3  In other words, µk is equal to the mean of all...  \n",
       "4  metric-learn-ave-vec also uses the metric lear...  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn any NaNs in the label column to \"\"\n",
    "df[\"label\"] = df[\"label\"].fillna(\"\")\n",
    "\n",
    "# turn any ints in the label column to strings\n",
    "# df[\"label\"] = df[\"label\"].apply(lambda x: str(int(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df as a csv\n",
    "df.to_csv(\"labels_3.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-9.92010653e-01, -1.91837735e-02,  2.07604140e-01,\n",
       "        -1.12113722e-01, -1.12709597e-01, -5.32972574e-01,\n",
       "         1.42638400e-01, -8.51180136e-01, -4.15681273e-01,\n",
       "        -4.63594139e-01, -2.79437631e-01,  1.89075261e-01,\n",
       "         1.11612177e+00, -4.21413295e-02,  1.73815876e-01,\n",
       "        -1.63513690e-01, -2.60987306e+00,  2.78270066e-01,\n",
       "         1.41929626e+00, -9.68841314e-01, -3.80713716e-02,\n",
       "        -6.73436642e-01, -1.10868111e-01,  2.36259982e-01,\n",
       "         1.11386263e+00,  5.30296206e-01,  1.46613657e-01,\n",
       "         8.06532651e-02, -1.00784516e+00,  3.47145349e-01,\n",
       "        -4.89346951e-01, -1.80431700e+00, -1.58109531e-01,\n",
       "        -6.44086421e-01,  1.90137282e-01, -5.63873112e-01,\n",
       "         5.05904078e-01, -5.91572702e-01, -1.06918417e-01,\n",
       "         2.45699119e-02, -2.89581984e-01,  1.04430199e+00,\n",
       "         5.51848888e-01, -2.86946237e-01, -4.10252362e-01,\n",
       "        -1.42275944e-01, -3.74744117e-01,  5.45941927e-02,\n",
       "        -3.12141068e-02, -2.99590290e-01,  9.94830847e-01,\n",
       "        -6.20567203e-01,  1.15189165e-01,  6.16108894e-01,\n",
       "        -1.72904357e-01,  6.99957371e-01, -1.20755398e+00,\n",
       "        -1.05573595e+00,  1.33034259e-01,  3.88531625e-01,\n",
       "        -3.20137143e-01, -3.09499800e-01, -4.12073165e-01,\n",
       "         2.33229339e-01,  8.34619164e-01,  2.60047615e-01,\n",
       "         1.40664947e+00,  3.84362489e-02,  2.62225032e-01,\n",
       "         1.83952999e+00,  4.10705507e-01,  1.64005712e-01,\n",
       "         2.14501470e-01, -1.76849127e-01,  7.61535764e-01,\n",
       "         9.84355450e-01, -4.17369455e-01,  6.70191824e-01,\n",
       "        -2.74664670e-01, -1.83830306e-01,  6.87821090e-01,\n",
       "        -3.46685350e-01, -2.83442855e-01, -7.90113986e-01,\n",
       "        -5.54349601e-01,  6.67166173e-01,  5.10999799e-01,\n",
       "         9.25588369e-01,  3.56148273e-01,  3.81159186e-01,\n",
       "         3.54338020e-01,  1.47649720e-01, -2.08233491e-01,\n",
       "         7.66644120e-01,  5.45711160e-01,  2.18653470e-01,\n",
       "        -6.23657346e-01, -1.06070019e-01, -2.52092957e-01,\n",
       "         1.51608324e+00, -4.51565951e-01,  4.17497844e-01,\n",
       "        -1.07457399e+00,  7.62197435e-01,  7.24421382e-01,\n",
       "         2.76559163e-02, -1.74572505e-02, -9.68764722e-01,\n",
       "         7.38557726e-02,  8.44931304e-02, -1.06008112e+00,\n",
       "        -4.25716102e-01, -3.21020931e-01, -9.11489069e-01,\n",
       "         2.78569102e-01,  1.71351116e-02, -6.14368856e-01,\n",
       "        -4.95362461e-01, -1.39413774e+00,  9.97084498e-01,\n",
       "         8.99128020e-01,  1.06993127e+00,  1.69538140e-01,\n",
       "        -1.21544816e-01,  1.86260378e+00,  1.40802979e+00,\n",
       "         3.10750417e-02,  5.56634307e-01, -2.86389828e-01,\n",
       "        -2.26325202e+00, -5.32487929e-01, -9.86440897e-01,\n",
       "         5.49079061e-01, -1.43598080e-01,  7.66377151e-01,\n",
       "         4.54744607e-01,  4.51228023e-01,  4.84681696e-01,\n",
       "        -4.99564826e-01, -4.54004347e-01, -2.91129798e-01,\n",
       "         2.60976553e-01,  2.94287324e-01,  5.79267263e-01,\n",
       "         2.93375701e-01,  3.40118371e-02, -5.84759533e-01,\n",
       "        -1.22380328e+00,  3.91871035e-01, -4.62364376e-01,\n",
       "        -2.47775838e-01,  3.91891301e-02, -4.99113709e-01,\n",
       "         3.77398240e-03, -4.58027840e-01, -5.09657681e-01,\n",
       "         7.84691572e-01, -1.24754503e-01, -7.36638784e-01,\n",
       "         2.79543221e-01, -2.99562544e-01, -7.53704488e-01,\n",
       "         9.47023273e-01,  7.18916595e-01, -1.53512621e+00,\n",
       "        -3.09206694e-01,  1.39393523e-01,  2.97156870e-01,\n",
       "         1.87161759e-01, -5.02190650e-01,  2.65772939e-01,\n",
       "        -5.02772510e-01, -6.32651567e-01,  1.13091862e+00,\n",
       "         1.54931581e+00,  1.18777610e-01,  4.01494980e-01,\n",
       "         2.68488973e-01,  5.67465961e-01,  1.00665951e+00,\n",
       "        -1.25051570e+00,  6.94456339e-01, -5.66533267e-01,\n",
       "        -5.36821425e-01,  4.19749796e-01, -4.00743842e-01,\n",
       "         4.60098088e-01, -3.46883297e-01, -7.71459579e-01,\n",
       "        -1.29240561e+00,  7.18385518e-01, -3.12262148e-01,\n",
       "         8.50599408e-01, -6.82139099e-02,  3.44666131e-02,\n",
       "        -5.37077427e-01, -5.37736952e-01, -3.97390485e-01,\n",
       "        -1.25814247e+00, -3.12704235e-01, -3.22463453e-01,\n",
       "         2.07984243e-02, -2.56803811e-01, -1.66434026e+00,\n",
       "        -1.10138667e+00, -7.98077822e-01,  5.13046503e-01,\n",
       "        -1.09393740e+00,  7.44123578e-01,  5.58860064e-01,\n",
       "        -2.78055996e-01, -8.48249257e-01, -1.32831967e+00,\n",
       "         5.93760312e-01, -1.15345943e+00, -3.31468345e-03,\n",
       "        -8.55488539e-01, -7.67405480e-02, -3.79700303e-01,\n",
       "         1.35534513e+00,  2.00345039e-01, -6.89517021e-01,\n",
       "         6.40155494e-01, -1.07314491e+00, -1.68624580e-01,\n",
       "         8.86796236e-01,  6.95475876e-01,  7.09436178e-01,\n",
       "        -4.18684125e-01,  2.44840477e-02, -7.70713449e-01,\n",
       "        -8.07861090e-01, -1.21152895e-02,  1.43471733e-01,\n",
       "        -1.18554398e-01, -2.13012889e-01, -7.32025087e-01,\n",
       "        -5.21029413e-01, -7.08739460e-01,  1.24989331e+00,\n",
       "         3.43637854e-01,  8.73423278e-01,  1.24983780e-01,\n",
       "        -3.92569363e-01,  2.35788137e-01, -3.57679099e-01,\n",
       "         6.90960050e-01,  6.13144636e-01,  1.91894162e+00,\n",
       "         7.54754245e-01, -8.64778876e-01,  9.47608948e-01,\n",
       "        -5.44787049e-01, -1.23458348e-01, -2.40135878e-01,\n",
       "         3.73202958e-03, -2.65227735e-01, -8.66575092e-02,\n",
       "        -1.89922601e-01, -7.52212703e-01, -4.82561827e-01,\n",
       "        -1.27173233e+00,  6.16431594e-01,  1.51100743e+00,\n",
       "        -6.23917487e-03, -5.04552603e-01, -3.77453506e-01,\n",
       "        -6.66784525e-01,  4.93266881e-01,  1.05039513e+00,\n",
       "        -2.31325384e-02,  4.47999030e-01,  1.41549585e-02,\n",
       "        -1.79454315e+00,  5.60552664e-02, -6.28637671e-02,\n",
       "         1.44362807e-01, -2.94526130e-01, -4.94417012e-01,\n",
       "        -1.60376236e-01, -1.48414612e-01,  2.43250087e-01,\n",
       "        -5.45675270e-02,  2.14725494e-01, -6.23702407e-01,\n",
       "        -5.35485387e-01,  9.63044763e-01, -4.78673160e-01,\n",
       "        -6.26223803e-01,  1.29803091e-01,  1.18051612e+00,\n",
       "        -2.77962126e-02,  5.66469133e-01, -6.72956228e-01,\n",
       "        -1.25947043e-01, -5.67184031e-01, -5.39810002e-01,\n",
       "         1.16575217e+00, -9.08617899e-02,  6.46763921e-01,\n",
       "         7.32282400e-01,  8.99675936e-02,  3.58722329e-01,\n",
       "         1.43618560e+00, -1.60095394e-01,  1.01211643e+00,\n",
       "        -3.77369314e-01, -3.22372168e-02, -2.14939594e-01,\n",
       "         2.64946252e-01,  8.35083246e-01, -8.84663999e-01,\n",
       "         2.31435895e-01, -1.00930169e-01,  1.50487095e-01,\n",
       "        -4.21779275e-01, -3.78266811e-01,  1.24570870e+00,\n",
       "        -3.52455646e-01, -4.32542771e-01, -1.23284452e-01,\n",
       "         5.94758809e-01, -4.69611466e-01, -6.86011255e-01,\n",
       "        -5.24288118e-02, -2.30647460e-01,  2.38357633e-01,\n",
       "         1.05901194e+00,  6.00009263e-01,  8.21661055e-02,\n",
       "        -1.50038511e-01, -4.65188920e-01,  1.00109506e+00,\n",
       "         2.63360739e-01, -3.07519287e-02, -6.27186477e-01,\n",
       "        -2.70555288e-01, -3.29540700e-01, -8.72479901e-02,\n",
       "         1.82188198e-01, -3.98376673e-01,  1.02800978e-02,\n",
       "         7.61597157e-01, -9.80525762e-02,  6.43637255e-02,\n",
       "        -8.03060830e-01, -5.41784406e-01, -7.11409152e-01,\n",
       "        -5.56235850e-01,  6.98589236e-02,  2.30698094e-01,\n",
       "         2.89667934e-01, -9.91597250e-02, -7.28781462e-01,\n",
       "        -7.07716644e-01,  9.43103611e-01, -6.24130785e-01,\n",
       "        -7.37264276e-01,  9.09995958e-02, -1.96158849e-02,\n",
       "        -9.88737047e-02, -3.30898076e-01, -2.20708713e-01,\n",
       "         3.78472582e-02,  1.37989962e+00, -1.04722512e+00,\n",
       "         3.29646438e-01, -4.56801206e-01,  2.30569497e-01,\n",
       "        -3.82340103e-01, -6.36953115e-02,  6.99812353e-01,\n",
       "         6.50805414e-01, -7.98024684e-02,  2.78717935e-01,\n",
       "        -8.05215612e-02, -1.39149979e-01, -1.08318830e+00,\n",
       "         6.83885872e-01,  4.77446973e-01,  4.12764877e-01,\n",
       "         1.12182617e-01, -5.94993412e-01,  1.86561435e-01,\n",
       "         2.61210442e-01, -7.96420336e-01,  1.33959091e+00,\n",
       "         1.50214452e-02,  9.10684347e-01,  6.64991319e-01,\n",
       "         1.18842848e-01,  9.03034508e-01,  1.93087444e-01,\n",
       "         9.12605878e-03, -5.61658621e-01, -4.37399149e-01,\n",
       "         3.35539967e-01, -1.11122936e-01,  4.07019079e-01,\n",
       "         1.60810924e+00,  5.46437800e-01,  6.62403032e-02,\n",
       "        -4.56255257e-01, -9.97567952e-01, -9.72915828e-01,\n",
       "        -1.33257818e+00,  7.06819713e-01, -3.14683050e-01,\n",
       "         1.67324340e+00,  3.06035757e-01, -1.11502635e+00,\n",
       "        -2.12874070e-01, -4.61620390e-01,  5.70114493e-01,\n",
       "        -6.60419166e-01, -7.55775034e-01,  3.26322734e-01,\n",
       "        -3.21196675e-01,  1.10523686e-01,  1.41542459e+00,\n",
       "        -1.83230847e-01,  1.11950946e+00,  1.40364323e+01,\n",
       "        -4.14455503e-01,  1.19985759e-01,  2.76374519e-01,\n",
       "        -8.82957280e-02,  5.36264062e-01, -3.04217041e-01,\n",
       "         6.32560670e-01, -4.32380319e-01, -1.21660054e+00,\n",
       "        -6.56789422e-01, -8.92491281e-01,  4.94108051e-01,\n",
       "         1.09612298e+00, -6.32787287e-01, -1.67041823e-01,\n",
       "        -1.68333113e+00,  2.34245539e-01,  7.82148600e-01,\n",
       "        -1.30325186e+00,  5.18336535e-01,  3.92401487e-01,\n",
       "        -2.60968469e-02,  5.63907385e-01,  1.06528610e-01,\n",
       "         3.87206048e-01, -4.53546017e-01, -6.76525831e-01,\n",
       "        -2.28804834e-02, -8.33109856e-01,  5.58353961e-01,\n",
       "        -7.51362026e-01,  2.87869781e-01,  6.44994855e-01,\n",
       "        -1.02013826e+00, -4.61133301e-01,  1.54300168e-01,\n",
       "         2.78600324e-02,  1.97999299e-01, -3.63142639e-01,\n",
       "        -7.70280778e-01, -2.65664995e-01,  1.97696471e+00,\n",
       "         1.52073348e+00,  2.00325400e-01,  3.86282027e-01,\n",
       "        -8.23391303e-02,  6.89307928e-01,  8.75163555e-01,\n",
       "         8.75585303e-02,  4.98920262e-01, -2.23487914e-01,\n",
       "         3.81087512e-01,  8.03230643e-01,  4.98236299e-01,\n",
       "        -4.00731415e-01,  8.06802988e-01, -4.55173790e-01,\n",
       "        -3.67489904e-01,  6.65625930e-01, -5.42649508e-01,\n",
       "        -2.84013867e-01,  2.46021464e-01,  1.80708840e-01,\n",
       "         7.09200501e-01, -2.98357546e-01, -9.57217515e-01,\n",
       "         1.29768491e-01,  1.84843540e-01,  3.56935531e-01,\n",
       "        -1.74621612e-01,  3.60774606e-01,  3.33839148e-01,\n",
       "         8.01130384e-02, -8.84315431e-01, -2.59105444e-01,\n",
       "        -6.25593603e-01, -2.52039731e-01, -9.87986743e-01,\n",
       "        -7.63730586e-01,  1.90073282e-01,  6.99861467e-01,\n",
       "        -1.53483123e-01,  7.31229246e-01, -1.63376406e-01,\n",
       "        -6.87422574e-01,  2.70674944e-01, -8.76141246e-03,\n",
       "         7.44579792e-01,  1.32152498e-01, -5.01355648e-01,\n",
       "         2.48615667e-01, -1.54163569e-01,  8.05201590e-01,\n",
       "         1.57708421e-01, -3.91294837e-01,  4.44207847e-01,\n",
       "        -1.10266767e-01, -2.64711827e-01,  9.90884244e-01,\n",
       "        -2.15540349e-01,  3.84533763e-01,  6.95086300e-01,\n",
       "        -8.77326965e-01,  1.31262934e+00,  4.23779637e-02,\n",
       "         5.31794071e-01, -2.22625792e-01, -5.05768180e-01,\n",
       "         5.52074015e-02,  7.13830769e-01, -7.18197942e-01,\n",
       "        -8.94265771e-01, -1.17963409e+00,  2.75058359e-01,\n",
       "        -7.24053502e-01,  1.76042885e-01,  4.70430136e-01,\n",
       "         5.02722204e-01, -3.28527421e-01,  8.37921262e-01,\n",
       "         5.71490288e-01, -1.23898253e-01, -4.09391433e-01,\n",
       "        -2.86039919e-01, -4.42927152e-01,  8.24546278e-01,\n",
       "         3.70779544e-01,  8.32364261e-02,  2.93612778e-02,\n",
       "         1.66716039e-01, -2.77295321e-01, -2.81807959e-01,\n",
       "         5.44613242e-01,  2.87345022e-01,  3.13219696e-01,\n",
       "         6.28966510e-01,  6.76523745e-02,  1.15405750e+00,\n",
       "         1.48559734e-01, -5.84112883e-01, -1.12643051e+00,\n",
       "        -4.70295131e-01,  4.19819087e-01, -2.90933996e-01,\n",
       "        -1.13403045e-01, -3.34987134e-01, -1.22216329e-01,\n",
       "         6.37318313e-01,  1.57985166e-01,  4.81691092e-01,\n",
       "        -1.48509622e+00,  4.39912438e-01, -9.16731894e-01,\n",
       "         6.27405167e-01,  2.66445279e-01,  7.19926894e-01,\n",
       "         1.41143227e+00, -7.39209652e-01, -2.75384873e-01,\n",
       "         1.32346094e+00, -9.53122258e-01,  2.52438962e-01,\n",
       "        -9.35421824e-01,  8.40444207e-01, -3.02319467e-01,\n",
       "        -7.36077189e-01,  3.22062850e-01,  5.21697819e-01,\n",
       "        -1.01443446e+00, -7.18961835e-01, -7.15892494e-01,\n",
       "        -4.28901702e-01,  5.51378965e-01, -5.95336556e-01,\n",
       "         2.56630331e-01, -5.37679791e-01,  1.27966964e+00,\n",
       "         6.39489144e-02,  5.16544342e-01,  6.37076616e-01,\n",
       "        -2.67708093e-01,  1.53422207e-01,  3.69004041e-01,\n",
       "         9.58798289e-01, -5.79128027e-01, -1.16111124e+00,\n",
       "        -5.63543200e-01, -2.10822076e-01,  6.89547837e-01,\n",
       "         3.43497604e-01, -2.59139407e-02, -7.52791643e-01,\n",
       "        -1.37177908e+00, -4.49184388e-01, -4.72702712e-01,\n",
       "        -2.23833799e-01, -7.68344939e-01,  3.83026242e-01,\n",
       "         9.71862897e-02,  5.49769700e-01, -5.73807418e-01,\n",
       "        -8.07343423e-01,  1.10010779e+00, -3.98773462e-01,\n",
       "        -9.95441914e-01, -5.87085843e-01,  2.74862885e-01,\n",
       "        -1.16150305e-01, -7.36106634e-01, -2.76267976e-01,\n",
       "         1.16217756e+00,  1.84640676e-01, -3.97860199e-01,\n",
       "        -7.29927480e-01,  4.00690973e-01,  3.30196559e-01,\n",
       "         1.99157059e-01, -6.23393469e-02, -3.29513937e-01,\n",
       "        -1.03521025e+00, -5.40384531e-01,  3.64485681e-01,\n",
       "         1.02138363e-01,  1.66938111e-01,  8.17749560e-01,\n",
       "         3.19873750e-01, -1.12489820e+00, -9.07571137e-01,\n",
       "        -2.97710840e-02,  5.29931523e-02, -3.44426364e-01,\n",
       "        -4.22090054e-01, -2.48580366e-01,  3.01051497e-01,\n",
       "        -1.42333806e+00,  6.07430220e-01, -7.64611781e-01,\n",
       "         5.45501672e-02, -4.43122070e-03,  9.69361126e-01,\n",
       "        -1.07820845e+00,  5.52134216e-01,  4.84275877e-01,\n",
       "        -5.62730491e-01, -5.34095287e-01, -1.17804691e-01,\n",
       "        -5.71587980e-01, -7.54168451e-01,  3.05143774e-01,\n",
       "         1.07951725e+00,  1.29389083e+00, -4.28703189e-01,\n",
       "        -2.08148703e-01, -6.88070893e-01, -2.87735403e-01,\n",
       "        -2.40397036e-01, -7.80660868e-01,  3.15061152e-01,\n",
       "         3.90679747e-01, -3.08921874e-01,  2.79787540e-01,\n",
       "         8.49507570e-01,  1.48635745e-01, -3.24050426e-01,\n",
       "        -3.17352891e-01, -1.00667822e+00,  1.52420327e-01,\n",
       "         5.26068509e-01, -2.11186092e-02, -1.01775646e+00,\n",
       "         9.91789579e-01,  4.27384883e-01, -3.50230217e-01,\n",
       "        -4.48477477e-01, -8.81663710e-03,  4.48767632e-01,\n",
       "         6.37403250e-01,  4.13547337e-01, -1.33243454e+00,\n",
       "         3.75133425e-01,  9.84267950e-01,  4.73694116e-01,\n",
       "        -4.21704620e-01, -3.18312973e-01, -4.36110049e-01,\n",
       "        -6.06065392e-01, -3.74160856e-02,  6.95133805e-01,\n",
       "         5.16879201e-01,  2.39261165e-01, -1.35349393e-01,\n",
       "        -4.45497804e-04,  2.02199534e-01, -9.54164863e-01,\n",
       "        -4.07445103e-01,  8.79528940e-01,  4.71249036e-02,\n",
       "         8.13859403e-01,  7.48376176e-02, -5.28789163e-01,\n",
       "         6.07114255e-01, -6.49700165e-01,  1.98384583e-01,\n",
       "         4.42695707e-01,  1.17114484e+00,  6.98736787e-01,\n",
       "         7.71274388e-01,  1.73680708e-01,  1.29858696e+00,\n",
       "        -5.06537557e-01,  2.06873342e-01,  4.94539917e-01,\n",
       "         5.61498880e-01, -3.63877177e-01,  6.37340069e-01,\n",
       "         4.21591341e-01, -4.22056019e-01,  2.96948045e-01,\n",
       "         1.08375597e+00, -2.33448431e-01, -6.44028902e-01,\n",
       "        -8.37379813e-01, -1.03844047e+00, -1.69583559e-01,\n",
       "        -1.57313383e+00,  2.72748142e-01, -2.85192490e-01,\n",
       "        -9.52626646e-01,  3.02605599e-01, -2.08691955e-01,\n",
       "         4.90560144e-01,  4.58073288e-01,  5.27369797e-01,\n",
       "         2.00807840e-01,  2.36778378e-01,  4.26678419e-01,\n",
       "        -6.94211304e-01, -2.34509563e+00, -9.03547525e-01,\n",
       "         4.33876514e-01,  5.63815773e-01,  1.35374948e-01,\n",
       "         2.94941813e-01, -5.85159957e-01, -5.36608756e-01]], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = create_single_embedding(df.iloc[4]['para'], model, tokenizer)\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dfh.pickle\n",
    "with open(proj_dir / \"data/processed/embeddings\" / \"df_embeddings_2.pkl\", \"rb\") as f:\n",
    "    df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>para</th>\n",
       "      <th>h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1710.02907</td>\n",
       "      <td>0</td>\n",
       "      <td>Experiment 2: In this set of experiments, we e...</td>\n",
       "      <td>[-0.7371358871459961, -1.4070982933044434, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1811.11012</td>\n",
       "      <td>0</td>\n",
       "      <td>This section of the technical report is focuse...</td>\n",
       "      <td>[-0.3564741313457489, 0.018136806786060333, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1811.11012</td>\n",
       "      <td>0</td>\n",
       "      <td>volunteers’ vehicles were mounted with BSM-bro...</td>\n",
       "      <td>[-0.7548128366470337, -0.35174882411956787, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1912.09582</td>\n",
       "      <td>0</td>\n",
       "      <td>for small datasets–a case with Dutch book revi...</td>\n",
       "      <td>[-1.4487942457199097, -0.013197386637330055, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1912.09582</td>\n",
       "      <td>1</td>\n",
       "      <td>Table 4: Sentiment Analysis accuracy scores on...</td>\n",
       "      <td>[-0.8141533136367798, 0.016403447836637497, -0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  label                                               para  \\\n",
       "0  1710.02907      0  Experiment 2: In this set of experiments, we e...   \n",
       "1  1811.11012      0  This section of the technical report is focuse...   \n",
       "2  1811.11012      0  volunteers’ vehicles were mounted with BSM-bro...   \n",
       "3  1912.09582      0  for small datasets–a case with Dutch book revi...   \n",
       "4  1912.09582      1  Table 4: Sentiment Analysis accuracy scores on...   \n",
       "\n",
       "                                                   h  \n",
       "0  [-0.7371358871459961, -1.4070982933044434, -0....  \n",
       "1  [-0.3564741313457489, 0.018136806786060333, -0...  \n",
       "2  [-0.7548128366470337, -0.35174882411956787, -0...  \n",
       "3  [-1.4487942457199097, -0.013197386637330055, 0...  \n",
       "4  [-0.8141533136367798, 0.016403447836637497, -0...  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "1 columns passed, passed data had 768 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/arxiv/lib/python3.8/site-packages/pandas/core/internals/construction.py:982\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[0;34m(content, columns, dtype)\u001b[0m\n\u001b[1;32m    981\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 982\u001b[0m     columns \u001b[39m=\u001b[39m _validate_or_indexify_columns(contents, columns)\n\u001b[1;32m    983\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    984\u001b[0m     \u001b[39m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/arxiv/lib/python3.8/site-packages/pandas/core/internals/construction.py:1030\u001b[0m, in \u001b[0;36m_validate_or_indexify_columns\u001b[0;34m(content, columns)\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_mi_list \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(columns) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(content):  \u001b[39m# pragma: no cover\u001b[39;00m\n\u001b[1;32m   1029\u001b[0m     \u001b[39m# caller's responsibility to check for this...\u001b[39;00m\n\u001b[0;32m-> 1030\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\n\u001b[1;32m   1031\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(columns)\u001b[39m}\u001b[39;00m\u001b[39m columns passed, passed data had \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1032\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(content)\u001b[39m}\u001b[39;00m\u001b[39m columns\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1033\u001b[0m     )\n\u001b[1;32m   1034\u001b[0m \u001b[39melif\u001b[39;00m is_mi_list:\n\u001b[1;32m   1035\u001b[0m \n\u001b[1;32m   1036\u001b[0m     \u001b[39m# check if nested list column, length of each sub-list should be equal\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: 1 columns passed, passed data had 768 columns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/tim/Documents/arxiv-code-search/notebooks/scratch/bert_embeddings_to_df_refactor.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/tim/Documents/arxiv-code-search/notebooks/scratch/bert_embeddings_to_df_refactor.ipynb#ch0000099?line=0'>1</a>\u001b[0m df_h \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame(features_array\u001b[39m.\u001b[39;49mtolist(), columns\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mh\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tim/Documents/arxiv-code-search/notebooks/scratch/bert_embeddings_to_df_refactor.ipynb#ch0000099?line=1'>2</a>\u001b[0m df_h\n",
      "File \u001b[0;32m~/miniconda3/envs/arxiv/lib/python3.8/site-packages/pandas/core/frame.py:721\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    716\u001b[0m     \u001b[39mif\u001b[39;00m columns \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    717\u001b[0m         \u001b[39m# error: Argument 1 to \"ensure_index\" has incompatible type\u001b[39;00m\n\u001b[1;32m    718\u001b[0m         \u001b[39m# \"Collection[Any]\"; expected \"Union[Union[Union[ExtensionArray,\u001b[39;00m\n\u001b[1;32m    719\u001b[0m         \u001b[39m# ndarray], Index, Series], Sequence[Any]]\"\u001b[39;00m\n\u001b[1;32m    720\u001b[0m         columns \u001b[39m=\u001b[39m ensure_index(columns)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m--> 721\u001b[0m     arrays, columns, index \u001b[39m=\u001b[39m nested_data_to_arrays(\n\u001b[1;32m    722\u001b[0m         \u001b[39m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[39;49;00m\n\u001b[1;32m    723\u001b[0m         \u001b[39m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[39;49;00m\n\u001b[1;32m    724\u001b[0m         data,\n\u001b[1;32m    725\u001b[0m         columns,\n\u001b[1;32m    726\u001b[0m         index,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    727\u001b[0m         dtype,\n\u001b[1;32m    728\u001b[0m     )\n\u001b[1;32m    729\u001b[0m     mgr \u001b[39m=\u001b[39m arrays_to_mgr(\n\u001b[1;32m    730\u001b[0m         arrays,\n\u001b[1;32m    731\u001b[0m         columns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    734\u001b[0m         typ\u001b[39m=\u001b[39mmanager,\n\u001b[1;32m    735\u001b[0m     )\n\u001b[1;32m    736\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/arxiv/lib/python3.8/site-packages/pandas/core/internals/construction.py:519\u001b[0m, in \u001b[0;36mnested_data_to_arrays\u001b[0;34m(data, columns, index, dtype)\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[39mif\u001b[39;00m is_named_tuple(data[\u001b[39m0\u001b[39m]) \u001b[39mand\u001b[39;00m columns \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    517\u001b[0m     columns \u001b[39m=\u001b[39m ensure_index(data[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39m_fields)\n\u001b[0;32m--> 519\u001b[0m arrays, columns \u001b[39m=\u001b[39m to_arrays(data, columns, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m    520\u001b[0m columns \u001b[39m=\u001b[39m ensure_index(columns)\n\u001b[1;32m    522\u001b[0m \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/arxiv/lib/python3.8/site-packages/pandas/core/internals/construction.py:883\u001b[0m, in \u001b[0;36mto_arrays\u001b[0;34m(data, columns, dtype)\u001b[0m\n\u001b[1;32m    880\u001b[0m     data \u001b[39m=\u001b[39m [\u001b[39mtuple\u001b[39m(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m data]\n\u001b[1;32m    881\u001b[0m     arr \u001b[39m=\u001b[39m _list_to_arrays(data)\n\u001b[0;32m--> 883\u001b[0m content, columns \u001b[39m=\u001b[39m _finalize_columns_and_data(arr, columns, dtype)\n\u001b[1;32m    884\u001b[0m \u001b[39mreturn\u001b[39;00m content, columns\n",
      "File \u001b[0;32m~/miniconda3/envs/arxiv/lib/python3.8/site-packages/pandas/core/internals/construction.py:985\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[0;34m(content, columns, dtype)\u001b[0m\n\u001b[1;32m    982\u001b[0m     columns \u001b[39m=\u001b[39m _validate_or_indexify_columns(contents, columns)\n\u001b[1;32m    983\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    984\u001b[0m     \u001b[39m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n\u001b[0;32m--> 985\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(err) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m    987\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(contents) \u001b[39mand\u001b[39;00m contents[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mobject_:\n\u001b[1;32m    988\u001b[0m     contents \u001b[39m=\u001b[39m _convert_object_array(contents, dtype\u001b[39m=\u001b[39mdtype)\n",
      "\u001b[0;31mValueError\u001b[0m: 1 columns passed, passed data had 768 columns"
     ]
    }
   ],
   "source": [
    "df_h = pd.DataFrame(features_array.tolist(), columns=[\"h\"])\n",
    "df_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133, 768)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack(features_list).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data_folder = Path().cwd().parent.parent / \"data\"\n",
    "path_interim_folder = path_data_folder / \"interim\"\n",
    "path_label_folder = path_data_folder / \"processed\" / \"labels\" / \"labels_complete\"\n",
    "\n",
    "# load the labels.csv from the path_label_folder\n",
    "df = pd.read_csv(path_label_folder / \"labels.csv\", dtype={\"id\": str})\n",
    "df[\"para\"] = df[\"para\"].str.lower()\n",
    "df[\"label\"] = df[\"label\"].apply(lambda x: 1 if x > 0 else 0) # binary labels\n",
    "print(df.shape)\n",
    "print(df[\"label\"].unique())\n",
    "\n",
    "\n",
    "# loop\n",
    "train_data_loader = create_data_loader(df, tokenizer, 512, 20)\n",
    "\n",
    "dfh_list = []\n",
    "for i, data in enumerate(train_data_loader):\n",
    "\n",
    "  labels = data['labels']\n",
    "  with torch.no_grad():\n",
    "    last_hidden_states = model(data[\"input_ids\"].to(DEVICE), attention_mask=data[\"attention_masks\"].to(DEVICE))\n",
    "    features = last_hidden_states[0][:,0,:].cpu().numpy() # from https://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/\n",
    "    df_h = pd.DataFrame(labels, columns=[\"label\"])\n",
    "    df_h[\"para\"] = data[\"texts_orig\"]\n",
    "    df_h[\"h\"] = features.tolist()\n",
    "    df_h['h'] = df_h['h'].apply(lambda x: np.array(x))\n",
    "    dfh_list.append(df_h)\n",
    "  \n",
    "  if i % 5 == 0:\n",
    "    print(i*20)\n",
    "\n",
    "dfh = pd.concat(dfh_list)\n",
    "# save dfh as a pickle file\n",
    "with open(path_interim_folder / \"dfh.pkl\", \"wb\") as f:\n",
    "  pickle.dump(dfh, f)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dfh.pickle\n",
    "with open(path_interim_folder / \"dfh.pkl\", \"rb\") as f:\n",
    "  dfh = pickle.load(f)\n",
    "dfh.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dfh\n",
    "Load dfh in pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "      <th>para</th>\n",
       "      <th>h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1710.02907</td>\n",
       "      <td>experiment 2: in this set of experiments, we e...</td>\n",
       "      <td>[-0.7371358871459961, -1.4070982933044434, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1811.11012</td>\n",
       "      <td>this section of the technical report is focuse...</td>\n",
       "      <td>[-0.3564741313457489, 0.018136806786060333, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1811.11012</td>\n",
       "      <td>volunteers’ vehicles were mounted with bsm-bro...</td>\n",
       "      <td>[-0.7548128366470337, -0.35174882411956787, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1912.09582</td>\n",
       "      <td>for small datasets–a case with dutch book revi...</td>\n",
       "      <td>[-1.4487942457199097, -0.013197386637330055, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1912.09582</td>\n",
       "      <td>table 4: sentiment analysis accuracy scores on...</td>\n",
       "      <td>[-0.8141533136367798, 0.016403447836637497, -0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label          id                                               para  \\\n",
       "0      0  1710.02907  experiment 2: in this set of experiments, we e...   \n",
       "1      0  1811.11012  this section of the technical report is focuse...   \n",
       "2      0  1811.11012  volunteers’ vehicles were mounted with bsm-bro...   \n",
       "3      0  1912.09582  for small datasets–a case with dutch book revi...   \n",
       "4      1  1912.09582  table 4: sentiment analysis accuracy scores on...   \n",
       "\n",
       "                                                   h  \n",
       "0  [-0.7371358871459961, -1.4070982933044434, -0....  \n",
       "1  [-0.3564741313457489, 0.018136806786060333, -0...  \n",
       "2  [-0.7548128366470337, -0.35174882411956787, -0...  \n",
       "3  [-1.4487942457199097, -0.013197386637330055, 0...  \n",
       "4  [-0.8141533136367798, 0.016403447836637497, -0...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_data_dir = Path().cwd().parent.parent / \"data\"\n",
    "embeddings_dir = path_data_dir / \"processed/embeddings\"\n",
    "\n",
    "# load dfh.pickle\n",
    "with open(embeddings_dir / \"df_embeddings.pkl\", \"rb\") as f:\n",
    "    df = pickle.load(f)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the case study used for testing the methodology was chosen from the commercial reference buildings database [26] of the us department of energy (doe). a secondary school located in san francisco (california) and constructed after the year of 1980 was selected. data about the energy load demands (whose hourly values are shown in figure 4) were calculated by means of energyplus simulation software [27] and then imported and processed in matlab. hourly temperatures of the typical meteorological year of san francisco, which are shown in figure 5, were considered.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"label\"] == 1].iloc[9][\"para\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([i for i in dfh[\"h\"].values])\n",
    "x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([i for i in dfh[\"h\"].values])\n",
    "y = dfh['label'].values\n",
    "\n",
    "# split into train and test\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb_clf = GaussianNB()\n",
    "gnb_clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8316326530612245"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb_clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tim/miniconda3/envs/arxiv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train a naive bayes classifier\n",
    "gnb = GaussianNB()\n",
    "y_train = dfh[\"label\"].values\n",
    "\n",
    "gnb.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "x_test = np.array([i for i in dfh[\"h\"].values])\n",
    "x_test.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>para</th>\n",
       "      <th>h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>experiment 2: in this set of experiments, we e...</td>\n",
       "      <td>[-0.7371358871459961, -1.4070982933044434, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>this section of the technical report is focuse...</td>\n",
       "      <td>[-0.3564741313457489, 0.018136806786060333, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>volunteers’ vehicles were mounted with bsm-bro...</td>\n",
       "      <td>[-0.7548128366470337, -0.35174882411956787, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>for small datasets–a case with dutch book revi...</td>\n",
       "      <td>[-1.4487942457199097, -0.013197386637330055, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>table 4: sentiment analysis accuracy scores on...</td>\n",
       "      <td>[-0.8141533136367798, 0.016403447836637497, -0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               para  \\\n",
       "0      0  experiment 2: in this set of experiments, we e...   \n",
       "1      0  this section of the technical report is focuse...   \n",
       "2      0  volunteers’ vehicles were mounted with bsm-bro...   \n",
       "3      0  for small datasets–a case with dutch book revi...   \n",
       "4      1  table 4: sentiment analysis accuracy scores on...   \n",
       "\n",
       "                                                   h  \n",
       "0  [-0.7371358871459961, -1.4070982933044434, -0....  \n",
       "1  [-0.3564741313457489, 0.018136806786060333, -0...  \n",
       "2  [-0.7548128366470337, -0.35174882411956787, -0...  \n",
       "3  [-1.4487942457199097, -0.013197386637330055, 0...  \n",
       "4  [-0.8141533136367798, 0.016403447836637497, -0...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_embeddings = pd.read_pickle(embeddings_dir / \"dfh.pkl\")\n",
    "df_embeddings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_embeddings[\"h\"].values[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = np.array([i for i in a])\n",
    "l.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "for i in a:\n",
    "    l.append(int(i.shape[0]))\n",
    "\n",
    "# only keep unique values in l\n",
    "l = list(set(l))\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.reshape(a, (-1, a.shape[0]))\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.reshape(-1, a.shape[-1])\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfh[\"h\"].to_numpy()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df_h['h'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(a[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test creation of embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data_folder = Path().cwd().parent.parent / \"data\"\n",
    "path_interim_folder = path_data_folder / \"interim\"\n",
    "path_label_folder = path_data_folder / \"processed\" / \"labels\" / \"labels_complete\"\n",
    "\n",
    "# load the labels.csv from the path_label_folder\n",
    "df = pd.read_csv(path_label_folder / \"labels.csv\", dtype={\"id\": str})\n",
    "# lowercase \"para\" column in df\n",
    "df[\"para\"] = df[\"para\"].str.lower()\n",
    "\n",
    "\n",
    "df[\"label\"] = df[\"label\"].apply(lambda x: 1 if x > 0 else 0) # binary labels\n",
    "# df = df.drop(columns=[\"label\"])\n",
    "print(df.shape)\n",
    "print(df[\"label\"].unique())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('allenai/scibert_scivocab_uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArxivDataset(Dataset):\n",
    "\n",
    "  def __init__(self, texts, labels, tokenizer, max_len):\n",
    "    self.texts = texts\n",
    "    self.labels = labels\n",
    "    self.tokenizer = tokenizer\n",
    "    self.max_len = max_len\n",
    "  \n",
    "  def __len__(self):\n",
    "    return len(self.texts)\n",
    "  \n",
    "  def __getitem__(self, item):\n",
    "    text = str(self.texts[item]).lower()\n",
    "    text_orig = str(self.texts[item])\n",
    "    label = self.labels[item]\n",
    "\n",
    "    encoding = self.tokenizer.encode_plus(\n",
    "      text,\n",
    "      add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
    "      max_length=self.max_len,\n",
    "      return_token_type_ids=False,\n",
    "      padding='max_length',\n",
    "      return_attention_mask=True,\n",
    "      truncation=True,\n",
    "      return_tensors='pt', # Return PyTorch tensors\n",
    "    )\n",
    "\n",
    "    return {\n",
    "      'texts': text,\n",
    "      'texts_orig': text_orig,\n",
    "      'input_ids': encoding['input_ids'].flatten(),\n",
    "      'attention_masks': encoding['attention_mask'].flatten(),\n",
    "      'labels': torch.tensor(label, dtype=torch.long)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
    "  ds = ArxivDataset(\n",
    "    texts=df.para.to_numpy(),\n",
    "    labels=df.label.to_numpy(),\n",
    "    tokenizer=tokenizer,\n",
    "    max_len=max_len\n",
    "  )\n",
    "\n",
    "  return DataLoader(\n",
    "    ds,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=4\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = create_data_loader(df, tokenizer, 512, 2)\n",
    "\n",
    "data = next(iter(train_data_loader))\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for hpc (need to manually download model)\n",
    "model = AutoModel.from_pretrained('allenai/scibert_scivocab_uncased')\n",
    "\n",
    "# send model to gpu\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put h into a dataframe with the labels\n",
    "df_h = pd.DataFrame(labels, columns=[\"label\"])\n",
    "df_h[\"para\"] = data[\"texts_orig\"]\n",
    "df_h[\"h\"] = h.tolist()\n",
    "df_h['h'] = df_h['h'].apply(lambda x: np.array(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put it all together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data_folder = Path().cwd().parent.parent / \"data\"\n",
    "path_interim_folder = path_data_folder / \"interim\"\n",
    "path_label_folder = path_data_folder / \"processed\" / \"labels\" / \"labels_complete\"\n",
    "\n",
    "# load the labels.csv from the path_label_folder\n",
    "df = pd.read_csv(path_label_folder / \"labels.csv\", dtype={\"id\": str})\n",
    "# lowercase \"para\" column in df\n",
    "df[\"para\"] = df[\"para\"].str.lower()\n",
    "\n",
    "df[\"label\"] = df[\"label\"].apply(lambda x: 1 if x > 0 else 0) # binary labels\n",
    "# df = df.drop(columns=[\"label\"])\n",
    "print(df.shape)\n",
    "print(df[\"label\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"para\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = df[\"para\"].apply((lambda x: tokenizer.encode(\n",
    "    x,\n",
    "    add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
    "    max_length=512,\n",
    "    # return_token_type_ids=False,\n",
    "    padding='max_length',\n",
    "    return_attention_mask=True,\n",
    "    truncation=True,\n",
    "    )))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "# for hpc (need to manually download model)\n",
    "model = AutoModel.from_pretrained('allenai/scibert_scivocab_uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 512\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data loader -- inspired by https://curiousily.com/posts/sentiment-analysis-with-bert-and-hugging-face-using-pytorch-and-python/\n",
    "class ArxivDataset(Dataset):\n",
    "\n",
    "  def __init__(self, texts, labels, tokenizer, max_len):\n",
    "    self.texts = texts\n",
    "    self.labels = labels\n",
    "    self.tokenizer = tokenizer\n",
    "    self.max_len = max_len\n",
    "  \n",
    "  def __len__(self):\n",
    "    return len(self.texts)\n",
    "  \n",
    "  def __getitem__(self, item):\n",
    "    text = str(self.texts[item]).lower()\n",
    "    label = self.labels[item]\n",
    "\n",
    "    encoding = self.tokenizer.encode_plus(\n",
    "      text,\n",
    "      add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
    "      max_length=self.max_len,\n",
    "      return_token_type_ids=False,\n",
    "      padding='max_length',\n",
    "      return_attention_mask=True,\n",
    "      truncation=True,\n",
    "      return_tensors='pt', # Return PyTorch tensors\n",
    "    )\n",
    "\n",
    "    return {\n",
    "      'texts': text,\n",
    "      'input_ids': encoding['input_ids'].flatten(),\n",
    "      'attention_mask': encoding['attention_mask'].flatten(),\n",
    "      'labels': torch.tensor(label, dtype=torch.long)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val = train_test_split(df, test_size=0.1, random_state=12)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
    "  ds = ArxivDataset(\n",
    "    texts=df.para.to_numpy(),\n",
    "    labels=df.label.to_numpy(),\n",
    "    tokenizer=tokenizer,\n",
    "    max_len=max_len\n",
    "  )\n",
    "\n",
    "  return DataLoader(\n",
    "    ds,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=4\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('allenai/scibert_scivocab_uncased')  # local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 512\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(train_data_loader))\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['input_ids'].shape)\n",
    "print(data['attention_mask'].shape)\n",
    "print(data['labels'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_TRAINED_MODEL_NAME = 'allenai/scibert_scivocab_uncased'\n",
    "\n",
    "MAX_LEN = 512\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArxivClassifier(nn.Module):\n",
    "    def __init__(self, n_classes, pre_trained_model_name):\n",
    "        super(ArxivClassifier, self).__init__()\n",
    "        self.encoder = BertModel.from_pretrained(pre_trained_model_name)\n",
    "\n",
    "        self.dense_1 = torch.nn.Linear(768, 768)\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.dense_2 = torch.nn.Linear(768, n_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output_1 = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_state = output_1[0]\n",
    "        pooled_output = hidden_state[:, 0]\n",
    "        pooled_output = self.dense_1(pooled_output)\n",
    "        pooled_output = torch.nn.ReLU()(pooled_output)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        output = self.dense_2(pooled_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ArxivClassifier(4)\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best_model_state.bin pytorch model\n",
    "model.load_state_dict(torch.load(\"best_model_state.bin\"))\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(train_data_loader))\n",
    "input_ids = data['input_ids'].to(DEVICE)\n",
    "attention_mask = data['attention_mask'].to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = F.softmax(model(input_ids, attention_mask), dim=1)\n",
    "labels = data['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try pr-auc curve with torchmetrics\n",
    "# https://torchmetrics.readthedocs.io/en/v0.8.2/classification/precision_recall_curve.html\n",
    "# https://torchmetrics.readthedocs.io/en/v0.8.2/classification/binned_precision_recall_curve.html\n",
    "\n",
    "pr_curve = PrecisionRecallCurve(num_classes=4)\n",
    "precision, recall, thresholds = pr_curve(pred.cpu(), labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
    "total_steps = len(train_data_loader) * EPOCHS\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "  optimizer,\n",
    "  num_warmup_steps=0,\n",
    "  num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "  model, \n",
    "  data_loader, \n",
    "  loss_fn, \n",
    "  optimizer, \n",
    "  device, \n",
    "  scheduler, \n",
    "  n_examples\n",
    "):\n",
    "  model = model.train()\n",
    "\n",
    "  losses = []\n",
    "  correct_predictions = 0\n",
    "  \n",
    "  for d in data_loader:\n",
    "    input_ids = d[\"input_ids\"].to(device)\n",
    "    attention_mask = d[\"attention_mask\"].to(device)\n",
    "    labels = d[\"labels\"].to(device)\n",
    "\n",
    "    outputs = model(\n",
    "      input_ids=input_ids,\n",
    "      attention_mask=attention_mask\n",
    "    )\n",
    "\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    loss = loss_fn(outputs, labels)\n",
    "\n",
    "    correct_predictions += torch.sum(preds == labels)\n",
    "    losses.append(loss.item())\n",
    "\n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "  return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "  model = model.eval()\n",
    "\n",
    "  losses = []\n",
    "  correct_predictions = 0\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for d in data_loader:\n",
    "      input_ids = d[\"input_ids\"].to(device)\n",
    "      attention_mask = d[\"attention_mask\"].to(device)\n",
    "      labels = d[\"labels\"].to(device)\n",
    "\n",
    "      outputs = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask\n",
    "      )\n",
    "      _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "      loss = loss_fn(outputs, labels)\n",
    "\n",
    "      correct_predictions += torch.sum(preds == labels)\n",
    "      losses.append(loss.item())\n",
    "\n",
    "  return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "history = defaultdict(list)\n",
    "best_accuracy = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "  print('-' * 10)\n",
    "\n",
    "  train_acc, train_loss = train_epoch(\n",
    "    model,\n",
    "    train_data_loader,    \n",
    "    loss_fn, \n",
    "    optimizer, \n",
    "    DEVICE, \n",
    "    scheduler, \n",
    "    len(df_train)\n",
    "  )\n",
    "\n",
    "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "\n",
    "  val_acc, val_loss = eval_model(\n",
    "    model,\n",
    "    val_data_loader,\n",
    "    loss_fn, \n",
    "    DEVICE, \n",
    "    len(df_val)\n",
    "  )\n",
    "\n",
    "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
    "  print()\n",
    "\n",
    "  history['train_acc'].append(train_acc)\n",
    "  history['train_loss'].append(train_loss)\n",
    "  history['val_acc'].append(val_acc)\n",
    "  history['val_loss'].append(val_loss)\n",
    "\n",
    "  if val_acc > best_accuracy:\n",
    "    torch.save(model.state_dict(), 'best_model_state.bin')\n",
    "    best_accuracy = val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(history['train_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(torch.tensor(history['train_acc']), label='train accuracy')\n",
    "plt.plot(torch.tensor(history['val_acc']), label='validation accuracy')\n",
    "\n",
    "plt.title('Training history')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.ylim([0, 1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"So we can solve the dual comparison problem (18) using any eﬃcient SVM solver, such as libsvm (Chang & Lin 2011). We used the R interface in the kernlab package (Karatzoglou et al. 2004), and our code is available in the rankSVMcompare package on Github.\"\n",
    "\n",
    "print(text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = BertTokenizer.from_pretrained('/home/tvhahn/scibert_scivocab_uncased') # hpc\n",
    "tokenizer = BertTokenizer.from_pretrained('allenai/scibert_scivocab_uncased')  # local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text = tokenizer.tokenize(text)\n",
    "print(len(tokenized_text))\n",
    "print(tokenized_text)\n",
    "\n",
    "token_ids = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "print(token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tokenizer.encode_plus(\n",
    "  text,\n",
    "  max_length=512,\n",
    "  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
    "  return_token_type_ids=False,\n",
    "  padding='max_length',\n",
    "  return_attention_mask=True,\n",
    "  truncation=True,\n",
    "  return_tensors='pt',  # Return PyTorch tensors\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(encoding['input_ids'][0]))\n",
    "# encoding['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.convert_ids_to_tokens(encoding['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "# for hpc (need to manually download model)\n",
    "model = AutoModel.from_pretrained('/home/tvhahn/scibert_scivocab_uncased')\n",
    "\n",
    "# for local computer\n",
    "# model = AutoModel.from_pretrained('/home/tvhahn/scibert_scivocab_uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text = tokenizer.tokenize(text)\n",
    "print(len(tokenized_text))\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stop words, etc\n",
    "stop = stopwords.words('english')\n",
    "text_tokens = word_tokenize(text)\n",
    "tokens_without_sw = [word for word in text_tokens if not word in stop]\n",
    "\n",
    "# text = text.lower()\n",
    "# text = text.apply(lambda x: x.split(' '))\n",
    "# text = text.apply(lambda x: [item for item in x if item not in stop])\n",
    "# text = text.apply(lambda x: ' '.join(x))\n",
    "# text = text.apply(lambda x: re.sub('[^A-Za-z\\s]+', ' ', x))\n",
    "# text = text.apply(lambda x: re.sub('\\n', ' ', x))\n",
    "# text = text.apply(lambda x: re.sub(r'\\s+', ' ', x))\n",
    "# text = text.apply(lambda x: re.sub(r'^\\s', '', x))\n",
    "# text = text.apply(lambda x: re.sub(r'\\s$', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_sentence = (\" \").join(tokens_without_sw)\n",
    "filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text = tokenizer.tokenize(text)\n",
    "print(len(tokenized_text))\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tokens = tokenizer.batch_encode_plus(text, pad_to_max_length=True, max_length=512, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tokens['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "17e082919eb97a8b1648db68459a0548143f50884a45122adabc4767e3d2dece"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
