{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from multiprocessing import Pool\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from io import StringIO\n",
    "import os\n",
    "import numpy as np\n",
    "import argparse\n",
    "import tqdm\n",
    "import re\n",
    "import unicodedata\n",
    "from pdfminer import high_level\n",
    "import pdftotext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pdf_to_txt(path):\n",
    "    try:\n",
    "        save_name = path.stem + \".txt\"\n",
    "        text = high_level.extract_text(path)\n",
    "        # text = text.replace(\"-\\n\", \"\")\n",
    "        text = unicodedata.normalize(\"NFC\", text)\n",
    "\n",
    "        text_lower = text.lower()\n",
    "\n",
    "        # get the .txt save name\n",
    "        save_name = path.stem + \".txt\"\n",
    "    \n",
    "    # save full traceback in exception\n",
    "    except Exception as e:\n",
    "        text = \"error in converting pdf to txt \\n\" + str(e)\n",
    "        save_name = path.stem + \"_error.txt\"\n",
    "\n",
    "    return {save_name: text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_name = \"1702.03196.pdf\"\n",
    "with open(pdf_name, \"rb\") as f:\n",
    "    pdf = pdftotext.PDF(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Universal Semantic Parsing\n",
      "Siva Reddy†∗ Oscar Täckström‡\n",
      "\n",
      "Slav Petrov‡ Mark Steedman†† Mirella Lapata††\n",
      "† Stanford University\n",
      "‡ Google Inc.\n",
      "†† University of Edinburgh\n",
      "sivar@stanford.edu, {oscart, slav}@google.com, {steedman, mlap}@inf.ed.ac.uk\n",
      "\n",
      "arXiv:1702.03196v4 [cs.CL] 28 Aug 2017\n",
      "\n",
      "Abstract\n",
      "Universal Dependencies (UD) offer a uniform cross-lingual syntactic representation,\n",
      "with the aim of advancing multilingual applications. Recent work shows that semantic parsing can be accomplished by\n",
      "transforming syntactic dependencies to logical forms. However, this work is limited to English, and cannot process dependency graphs, which allow handling\n",
      "complex phenomena such as control. In\n",
      "this work, we introduce UD EP L AMBDA,\n",
      "a semantic interface for UD, which maps\n",
      "natural language to logical forms in an\n",
      "almost language-independent fashion and\n",
      "can process dependency graphs. We perform experiments on question answering\n",
      "against Freebase and provide German and\n",
      "Spanish translations of the WebQuestions\n",
      "and GraphQuestions datasets to facilitate\n",
      "multilingual evaluation. Results show that\n",
      "UD EP L AMBDA outperforms strong baselines across languages and datasets. For\n",
      "English, it achieves a 4.9 F1 point improvement over the state-of-the-art on GraphQuestions.\n",
      "\n",
      "1\n",
      "\n",
      "Introduction\n",
      "\n",
      "The Universal Dependencies (UD) initiative seeks\n",
      "to develop cross-linguistically consistent annotation guidelines as well as a large number of uniformly annotated treebanks for many languages\n",
      "(Nivre et al., 2016). Such resources could advance\n",
      "multilingual applications of parsing, improve comparability of evaluation results, enable cross-lingual\n",
      "learning, and more generally support natural language understanding.\n",
      "∗ Work done at the University of Edinburgh\n",
      "\n",
      "Seeking to exploit the benefits of UD for natural language understanding, we introduce UD EP L AMBDA, a semantic interface for UD that maps\n",
      "natural language to logical forms, representing underlying predicate-argument structures, in an almost language-independent manner. Our framework is based on D EP L AMBDA (Reddy et al.,\n",
      "2016) a recently developed method that converts\n",
      "English Stanford Dependencies (SD) to logical\n",
      "forms. The conversion process is illustrated in\n",
      "Figure 1 and discussed in more detail in Section 2.\n",
      "Whereas D EP L AMBDA works only for English, UD EP L AMBDA applies to any language for which\n",
      "UD annotations are available.1 Moreover, D EP L AMBDA can only process tree-structured inputs\n",
      "whereas UD EP L AMBDA can also process dependency graphs, which allow to handle complex constructions such as control. The different treatments\n",
      "of various linguistic constructions in UD compared\n",
      "to SD also require different handling in UD EP L AMBDA (Section 3.3).\n",
      "Our experiments focus on Freebase semantic\n",
      "parsing as a testbed for evaluating the framework’s\n",
      "multilingual appeal. We convert natural language\n",
      "to logical forms which in turn are converted to machine interpretable formal meaning representations\n",
      "for retrieving answers to questions from Freebase.\n",
      "To facilitate multilingual evaluation, we provide\n",
      "translations of the English WebQuestions (Berant\n",
      "et al., 2013) and GraphQuestions (Su et al., 2016)\n",
      "datasets to German and Spanish. We demonstrate\n",
      "that UD EP L AMBDA can be used to derive logical\n",
      "forms for these languages using a minimal amount\n",
      "of language-specific knowledge. Aside from developing the first multilingual semantic parsing tool\n",
      "for Freebase, we also experimentally show that UD EP L AMBDA outperforms strong baselines across\n",
      "1 As of v1.3, UD annotations are available for 47 languages\n",
      "at http://universaldependencies.org.\n",
      "\n",
      "\f\n",
      "\n",
      "languages and datasets. For English, it achieves the\n",
      "strongest result to date on GraphQuestions, with\n",
      "competitive results on WebQuestions. Our implementation and translated datasets are publicly available at https://github.com/sivareddyg/udeplambda.\n",
      "\n",
      "2\n",
      "\n",
      "D EP L AMBDA\n",
      "\n",
      "Before describing UD EP L AMBDA, we provide an\n",
      "overview of D EP L AMBDA (Reddy et al., 2016)\n",
      "on which our approach is based. D EP L AMBDA\n",
      "converts a dependency tree to its logical form in\n",
      "three steps: binarization, substitution, and composition, each of which is briefly outlined below.\n",
      "Algorithm 1 describes the steps of D EP L AMBDA\n",
      "in lines 4-6, whereas lines 2 and 3 are specific to\n",
      "UD EP L AMBDA.\n",
      "Binarization A dependency tree is first mapped\n",
      "to a Lisp-style s-expression indicating the order\n",
      "of semantic composition. Figure 1(b) shows the\n",
      "s-expression for the sentence Disney won an Oscar for the movie Frozen, derived from the dependency tree in Figure 1(a). Here, the sub-expression\n",
      "(dobj won (det Oscar an)) indicates that the logical form of the phrase won an Oscar is derived by\n",
      "composing the logical form of the label dobj with\n",
      "the logical form of the word won and the logical\n",
      "form of the phrase an Oscar, derived analogously.\n",
      "The s-expression can also be interpreted as a binarized tree with the dependency label as the root\n",
      "node, and the left and right expressions as subtrees.\n",
      "A composition hierarchy is employed to impose\n",
      "a strict traversal ordering on the modifiers to each\n",
      "head in the dependency tree. As an example, won\n",
      "has three modifiers in Figure 1(a), which according\n",
      "to the composition hierarchy are composed in the\n",
      "order dobj > nmod > nsubj. In constructions like\n",
      "coordination, this ordering is crucial to arrive at\n",
      "the correct semantics. Lines 7-17 in Algorithm 1\n",
      "describe the binarization step.\n",
      "Substitution Each symbol in the s-expressions\n",
      "is substituted for a lambda expression encoding\n",
      "its semantics. Words and dependency labels are\n",
      "assigned different types of expressions. In general,\n",
      "words have expressions of the following kind:\n",
      "ENTITY\n",
      "⇒ λx. word(xa ); e.g. Oscar ⇒ λx. Oscar(xa )\n",
      "EVENT\n",
      "⇒ λx. word(xe ); e.g. won ⇒ λx. won(xe )\n",
      "FUNCTIONAL ⇒ λx. TRUE ; e.g. an ⇒ λx. TRUE\n",
      "\n",
      "Here, the subscripts ·a and ·e denote the types\n",
      "of individuals (Ind) and events (Event), respectively, whereas x denotes a paired variable (xa , xe )\n",
      "\n",
      "root\n",
      "nmod\n",
      "case\n",
      "dobj\n",
      "nsubj\n",
      "\n",
      "Disney won\n",
      "\n",
      "det\n",
      "\n",
      "det\n",
      "compound\n",
      "\n",
      "an Oscar for the movie\n",
      "\n",
      "Frozen\n",
      "\n",
      "propn verb det propn adp det noun\n",
      "\n",
      "propn\n",
      "\n",
      "(a) The dependency tree for Disney won an Oscar for the\n",
      "movie Frozen in the Universal Dependencies formalism.\n",
      "(nsubj (nmod (dobj won (det Oscar an))\n",
      "(case (det (comp. Frozen movie) the) for)) Disney)\n",
      "(b) The binarized s-expression for the dependency tree.\n",
      "λx. ∃yzw. won(xe ) ∧ Disney(ya ) ∧ Oscar(za )\n",
      "∧ Frozen(wa ) ∧ movie(wa )\n",
      "∧ arg1 (xe , ya ) ∧ arg2 (xe , za ) ∧ nmod.for(xe , wa )\n",
      "(c) The composed lambda-calculus expression.\n",
      "\n",
      "Figure 1: The mapping of a dependency tree to its\n",
      "logical form with the intermediate s-expression.\n",
      "of type Ind × Event. Roughly speaking, proper\n",
      "nouns and adjectives invoke ENTITY expressions,\n",
      "verbs and adverbs invoke EVENT expressions, and\n",
      "common nouns invoke both ENTITY and EVENT expressions (see Section 3.3), while remaining words\n",
      "invoke FUNCTIONAL expressions. D EP L AMBDA\n",
      "enforces the constraint that every s-expression is of\n",
      "the type η = Ind × Event → Bool, which simplifies the type system considerably.\n",
      "Expressions for dependency labels glue the\n",
      "semantics of heads and modifiers to articulate\n",
      "predicate-argument structure. These expressions in\n",
      "general take one of the following forms:\n",
      "COPY\n",
      "⇒ λ f gx. ∃y. f (x) ∧ g(y) ∧ rel(x, y)\n",
      "e.g. nsubj, dobj, nmod, advmod\n",
      "INVERT\n",
      "⇒ λ f gx. ∃y. f (x) ∧ g(y) ∧ reli (y, x)\n",
      "e.g. amod, acl\n",
      "MERGE\n",
      "⇒ λ f gx. f (x) ∧ g(x)\n",
      "e.g. compound, appos, amod, acl\n",
      "HEAD\n",
      "⇒ λ f gx. f (x)\n",
      "e.g. case, punct, aux, mark .\n",
      "\n",
      "As an example of COPY, consider the lambda\n",
      "expression for dobj in (dobj won (det Oscar an)):\n",
      "λ f gx. ∃y. f (x) ∧ g(y) ∧ arg2 (xe , ya ). This expression takes two functions f and g as input, where\n",
      "f represents the logical form of won and g represents the logical form of an Oscar. The predicateargument structure arg2 (xe , ya ) indicates that the\n",
      "arg2 of the event xe , i.e. won, is the individual ya ,\n",
      "i.e. the entity Oscar. Since arg2 (xe , ya ) mimics the\n",
      "dependency structure dobj(won, Oscar), we refer\n",
      "to the expression kind evoked by dobj as COPY.\n",
      "\n",
      "\f\n",
      "\n",
      "Expressions that invert the dependency direction are referred to as INVERT (e.g. amod in running horse); expressions that merge two subexpressions without introducing any relation predicates\n",
      "are referred to as MERGE (e.g. compound in movie\n",
      "Frozen); and expressions that simply return the parent expression semantics are referred to as HEAD\n",
      "(e.g. case in for Frozen). While this generalization\n",
      "applies to most dependency labels, several labels\n",
      "take a different logical form not listed here, some\n",
      "of which are discussed in Section 3.3. Sometimes\n",
      "the mapping of dependency label to lambda expression may depend on surrounding part-of-speech\n",
      "tags or dependency labels. For example, amod acts\n",
      "as INVERT when the modifier is a verb (e.g. in running horse), and as MERGE when the modifier is\n",
      "an adjective (e.g. in beautiful horse).2 Lines 26-32\n",
      "in Algorithm 1 describe the substitution procedure.\n",
      "Composition The final logical form is computed\n",
      "by beta-reduction, treating expressions of the form\n",
      "(f x y) as the function f applied to the arguments\n",
      "x and y. For example, (dobj won (det Oscar an))\n",
      "results in λx. ∃z. won(xe ) ∧ Oscar(za ) ∧ arg2 (xe , za )\n",
      "when the expression for dobj is applied to those\n",
      "for won and (det Oscar an). Figure 1(c) shows the\n",
      "logical form for the s-expression in Figure 1(b).\n",
      "The binarized s-expression is recursively converted\n",
      "to a logical form as described in lines 18-25 in\n",
      "Algorithm 1.\n",
      "\n",
      "3\n",
      "\n",
      "UD EP L AMBDA\n",
      "\n",
      "We now introduce UD EP L AMBDA, a semantic interface for Universal Dependencies.3 Whereas\n",
      "D EP L AMBDA only applies to English Stanford Dependencies, UD EP L AMBDA takes advantage of the\n",
      "cross-lingual nature of UD to facilitate an (almost)\n",
      "language independent semantic interface. This is\n",
      "accomplished by restricting the binarization, substitution, and composition steps described above\n",
      "to rely solely on information encoded in the UD\n",
      "representation. As shown in Algorithm 1, lines\n",
      "4-6 are common to both D EP L AMBDA and UD EP L AMBDA, whereas lines 2 and 3 applies only to\n",
      "UD EP L AMBDA. Importantly, UD EP L AMBDA is\n",
      "designed to not rely on lexical forms in a language\n",
      "2 We use Tregex (Levy and Andrew, 2006) for substitution mappings and Cornell SPF (Artzi, 2013) as the lambdacalculus implementation. For example, in running horse, the\n",
      "tregex /label:amod/=target < /postag:verb/ matches amod to\n",
      "its INVERT expression λ f gx. ∃y. f (x) ∧ g(y) ∧ amodi (ye , xa ).\n",
      "3 In what follows, all references to UD are to UD v1.3.\n",
      "\n",
      "Algorithm 1: UD EP L AMBDA Steps\n",
      "Function UDepLambda(depTree):\n",
      "depGraph = Enhancement (depTree)\n",
      "#See Figure 2(a) for a depGraph.\n",
      "3\n",
      "bindedTree = SplitLongDistance (depGraph)\n",
      "#See Figure 2(b) for a bindedTree.\n",
      "4\n",
      "binarizedTree = Binarization (bindedTree)\n",
      "#See Figure 1(b) for a binarizedTree.\n",
      "5\n",
      "logicalForm = Composition (binarizedTree)\n",
      "6\n",
      "return logicalForm\n",
      "1\n",
      "\n",
      "2\n",
      "\n",
      "Function Binarization (tree):\n",
      "parent = GetRootNode (tree);\n",
      "9\n",
      "{(label1, child1), (label2, child2) . . .}\n",
      "= GetChildNodes (parent)\n",
      "10\n",
      "sortedChildren = SortUsingLabelHierarchy\n",
      "({(label1, child1), (label2, child2) . . .})\n",
      "11\n",
      "binarziedTree.root = parent\n",
      "12\n",
      "for label, child ∈ sortedChildren:\n",
      "13\n",
      "temp.root = label\n",
      "14\n",
      "temp.le f t = binarziedTree\n",
      "15\n",
      "temp.right = Binarization(child)\n",
      "16\n",
      "binarziedTree = temp\n",
      "17\n",
      "return binarizedTree\n",
      "7\n",
      "\n",
      "8\n",
      "\n",
      "Function Composition (binarizedTree):\n",
      "mainLF = Substitution (binarizedTree.root)\n",
      "20\n",
      "if binarziedTree has left and right children:\n",
      "21\n",
      "le f tLF = Composition (binarziedTree.le f t)\n",
      "22\n",
      "rightLF = Composition(binarziedTree.right)\n",
      "23\n",
      "mainLF = BetaReduce (mainLF, le f tLF)\n",
      "24\n",
      "mainLF = BetaReduce (mainLF, rightLF)\n",
      "25\n",
      "return mainLF\n",
      "18\n",
      "\n",
      "19\n",
      "\n",
      "Function Substitution (node):\n",
      "logicalForms = [ ]\n",
      "28\n",
      "for tregexRule, template ∈ substitutionRules:\n",
      "29\n",
      "if tregexRule.match(node):\n",
      "30\n",
      "l f = GenLambdaExp (node, template)\n",
      "31\n",
      "logicalForms.add(l f )\n",
      "32\n",
      "return logicalForms\n",
      "26\n",
      "\n",
      "27\n",
      "\n",
      "to assign lambda expressions, but only on information contained in dependency labels and postags.\n",
      "However, some linguistic phenomena are language specific (e.g. pronoun-dropping) or lexicalized (e.g. every and the in English have different\n",
      "semantics, despite being both determiners) and are\n",
      "not encoded in the UD schema. Furthermore, some\n",
      "cross-linguistic phenomena, such as long-distance\n",
      "dependencies, are not part of the core UD representation. To circumvent this limitation, a simple enhancement step enriches the original UD representation before binarization takes place (Section 3.1).\n",
      "This step adds to the dependency tree missing syntactic information and long-distance dependencies,\n",
      "thereby creating a graph. Whereas D EP L AMBDA\n",
      "is not able to handle graph-structured input, UD EP -\n",
      "\n",
      "\f\n",
      "\n",
      "L AMBDA is designed to work with dependency\n",
      "graphs as well (Section 3.2). Finally, several constructions differ in structure between UD and SD,\n",
      "which requires different handling in the semantic\n",
      "interface (Section 3.3).\n",
      "\n",
      "xcomp\n",
      "nsubj\n",
      "\n",
      "Anna\n",
      "\n",
      "3.2 Graph Structures and B IND\n",
      "To handle graph structures that may result from the\n",
      "enhancement step, such as those in Figure 2(a), we\n",
      "propose a variable-binding mechanism that differs\n",
      "\n",
      "wants\n",
      "\n",
      "to\n",
      "\n",
      "dobj\n",
      "\n",
      "marry\n",
      "\n",
      "Kristoff\n",
      "\n",
      "nsubj\n",
      "\n",
      "(a) With long-distance dependency.\n",
      "\n",
      "3.1 Enhancement\n",
      "Both Schuster and Manning (2016) and Nivre et al.\n",
      "(2016) note the necessity of an enhanced UD representation to enable semantic applications. However, such enhancements are currently only available for a subset of languages in UD. Instead, we\n",
      "rely on a small number of enhancements for our\n",
      "main application—semantic parsing for questionanswering—with the hope that this step can be replaced by an enhanced UD representation in the future. Specifically, we define three kinds of enhancements: (1) long-distance dependencies; (2) types\n",
      "of coordination; and (3) refined question word tags.\n",
      "These correspond to line 2 in Algorithm 1.\n",
      "First, we identify long-distance dependencies in\n",
      "relative clauses and control constructions. We follow Schuster and Manning (2016) and find these\n",
      "using the labels acl (relative) and xcomp (control).\n",
      "Figure 2(a) shows the long-distance dependency in\n",
      "the sentence Anna wants to marry Kristoff. Here,\n",
      "marry is provided with its missing nsubj (dashed\n",
      "arc). Second, UD conflates all coordinating constructions to a single dependency label, conj. To\n",
      "obtain the correct coordination scope, we refine\n",
      "conj to conj:verb, conj:vp, conj:sentence,\n",
      "conj:np, and conj:adj, similar to Reddy et al.\n",
      "(2016). Finally, unlike the PTB tags (Marcus et al.,\n",
      "1993) used by SD, the UD part-of-speech tags do\n",
      "not distinguish question words. Since these are crucial to question-answering, we use a small lexicon\n",
      "to refine the tags for determiners (DET), adverbs\n",
      "(ADV) and pronouns (PRON) to DET: WH, ADV: WH\n",
      "and PRON : WH, respectively. Specifically, we use\n",
      "a list of 12 (English), 14 (Spanish) and 35 (German) words, respectively. This is the only part\n",
      "of UD EP L AMBDA that relies on language-specific\n",
      "information. We hope that, as the coverage of morphological features in UD improves, this refinement can be replaced by relying on morphological\n",
      "features, such as the interrogative feature (INT).\n",
      "\n",
      "mark\n",
      "\n",
      "xcomp\n",
      "nsubj\n",
      "\n",
      "Anna\n",
      "\n",
      "mark\n",
      "\n",
      "wants\n",
      "\n",
      "bin\n",
      "\n",
      "d\n",
      "\n",
      "Ω Ω\n",
      "\n",
      "to\n",
      "\n",
      "dobj\n",
      "\n",
      "marry\n",
      "\n",
      "Kristoff\n",
      "\n",
      "nsub j\n",
      "\n",
      "(b) With variable binding.\n",
      "\n",
      "Figure 2: The original and enhanced dependency\n",
      "trees for Anna wants to marry Kristoff.\n",
      "from that of D EP L AMBDA. This is indicated in\n",
      "line 3 of Algorithm 1. First, each long-distance\n",
      "dependency is split into independent arcs as shown\n",
      "in Figure 2(b). Here, Ω is a placeholder for the subject of marry, which in turn corresponds to Anna as\n",
      "indicated by the binding of Ω via the pseudo-label\n",
      "BIND . We treat BIND like an ordinary dependency\n",
      "label with semantics MERGE and process the resulting tree as usual, via the s-expression:\n",
      "(nsubj (xcomp wants (nsubj (mark\n",
      "(dobj marry Kristoff) to) Ω) (BIND Anna Ω)) ,\n",
      "\n",
      "with the lambda-expression substitutions:\n",
      "wants, marry ∈ EVENT; to ∈ FUNCTIONAL;\n",
      "Anna, Kristoff ∈ ENTITY;\n",
      "mark ∈ HEAD; BIND ∈ MERGE;\n",
      "xcomp = λ f gx. ∃y. f (x) ∧ g(y) ∧ xcomp(xe , ye ) .\n",
      "\n",
      "These substitutions are based solely on unlexicalized context. For example, the part-of-speech\n",
      "tag PROPN of Anna invokes an ENTITY expression.\n",
      "The placeholder Ω has semantics λx.EQ(x, ω),\n",
      "where EQ(u, ω) is true iff u and ω are equal (have\n",
      "the same denotation), which unifies the subject variable of wants with the subject variable of marry.\n",
      "After substitution and composition, we get:\n",
      "λz. ∃xywv. wants(ze ) ∧ Anna(xa ) ∧ arg1 (ze , xa ) ∧ EQ(x, ω)\n",
      "∧ marry(ye ) ∧ xcomp(ze , ye ) ∧ arg1 (ye , va ) ∧ EQ(v, ω)\n",
      "∧ Kristoff(wa ) ∧ arg2 (ye , wa ) ,\n",
      "\n",
      "This expression may be simplified further by\n",
      "replacing all occurrences of v with x and removing\n",
      "the unification predicates EQ, which results in:\n",
      "λz. ∃xyw. wants(ze ) ∧ Anna(xa ) ∧ arg1 (ze , xa )\n",
      "∧ marry(ye ) ∧ xcomp(ze , ye ) ∧ arg1 (ye , xa )\n",
      "∧ Kristoff(wa ) ∧ arg2 (ye , wa ) .\n",
      "\n",
      "\f\n",
      "\n",
      "This expression encodes the fact that Anna is the\n",
      "arg1 of the marry event, as desired. D EP L AMBDA,\n",
      "in contrast, cannot handle graph-structured input,\n",
      "since it lacks a principled way of generating sexpressions from graphs. Even given the above\n",
      "s-expression, BIND in D EP L AMBDA is defined in\n",
      "a way such that the composition fails to unify v\n",
      "and x, which is crucial for the correct semantics.\n",
      "Moreover, the definition of BIND in D EP L AMBDA\n",
      "does not have a formal interpretation within the\n",
      "lambda calculus, unlike ours.\n",
      "3.3 Linguistic Constructions\n",
      "Below, we highlight the most pertinent differences\n",
      "between UD EP L AMBDA and D EP L AMBDA, stemming from the different treatment of various linguistic constructions in UD versus SD.\n",
      "Prepositional Phrases UD uses a content-head\n",
      "analysis, in contrast to SD, which treats function\n",
      "words as heads of prepositional phrases, Accordingly, the s-expression for the phrase president\n",
      "in 2009 is (nmod president (case 2009 in)) in UD EP L AMBDA and (prep president (pobj in 2009))\n",
      "in D EP L AMBDA. To achieve the desired semantics,\n",
      "λx. ∃y. president(xa ) ∧ president event(xe ) ∧\n",
      "arg1 (xe , xa ) ∧ 2009(ya ) ∧ prep.in(xe , ya ) ,\n",
      "\n",
      "D EP L AMBDA relies on an intermediate logical\n",
      "form that requires some post-processing, whereas\n",
      "UD EP L AMBDA obtains the desired logical form\n",
      "directly through the following entries:\n",
      "in ∈ FUNCTIONAL; 2009 ∈ ENTITY; case ∈ HEAD;\n",
      "president = λx. president(xa ) ∧ president event(xe )\n",
      "∧ arg1 (xe , xa ) ;\n",
      "nmod = λ f gx. ∃y. f (x) ∧ g(y) ∧ nmod.in(xe , ya ) .\n",
      "\n",
      "Other nmod constructions, such as possessives\n",
      "(nmod:poss), temporal modifiers (nmod:tmod)\n",
      "and adverbial modifiers (nmod:npmod), are handled similarly. Note how the common noun president, evokes both entity and event predicates above.\n",
      "Passives D EP L AMBDA gives special treatment\n",
      "to passive verbs, identified by the fine-grained partof-speech tags in the PTB tag together with dependency context. For example, An Oscar was\n",
      "won is analyzed as λx. won.pass(xe ) ∧ Oscar(ya ) ∧\n",
      "arg1 (xe , ya ), where won.pass represents a passive\n",
      "event. However, UD does not distinguish between active and passive forms.4 While the labels\n",
      "4 UD encodes voice as a morphological feature, but most\n",
      "syntactic analyzers do not produce this information yet.\n",
      "\n",
      "nsubjpass or auxpass indicate passive constructions, such clues are sometimes missing, such as in\n",
      "reduced relatives. We therefore opt to not have separate entries for passives, but aim to produce identical logical forms for active and passive forms when\n",
      "possible (for example, by treating nsubjpass as\n",
      "direct object). With the following entries,\n",
      "won ∈ EVENT; an, was ∈ FUNCTIONAL; auxpass ∈ HEAD;\n",
      "nsubjpass = λ f gx. ∃y. f (x) ∧ g(y) ∧ arg2 (xe , ya ) ,\n",
      "\n",
      "the lambda expression for An Oscar was won becomes λx. won(xe ) ∧ Oscar(ya ) ∧ arg2 (xe , ya ), identical to that of its active form. However, not having\n",
      "a special entry for passive verbs may have undesirable side-effects. For example, in the reducedrelative construction Pixar claimed the Oscar won\n",
      "for Frozen, the phrase the Oscar won ... will\n",
      "receive the semantics λx. Oscar(ya ) ∧ won(xe ) ∧\n",
      "arg1 (xe , ya ), which differs from that of an Oscar\n",
      "was won. We leave it to the target application to\n",
      "disambiguate the interpretation in such cases.\n",
      "Long-Distance Dependencies As discussed in\n",
      "Section 3.2, we handle long-distance dependencies evoked by clausal modifiers (acl) and control verbs (xcomp) with the BIND mechanism,\n",
      "whereas D EP L AMBDA cannot handle control constructions. For xcomp, as seen earlier, we use the\n",
      "mapping λ f gx. ∃y. f (x)∧g(y)∧xcomp(xe , ye ). For\n",
      "acl we use λ f gx. ∃y. f (x) ∧ g(y), to conjoin the\n",
      "main clause and the modifier clause. However, not\n",
      "all acl clauses evoke long-distance dependencies,\n",
      "e.g. in the news that Disney won an Oscar, the\n",
      "clause that Disney won an Oscar is a subordinating\n",
      "conjunction of news. In such cases, we instead\n",
      "assign acl the INVERT semantics.\n",
      "Questions Question words are marked with the\n",
      "enhanced part-of-speech tags DET: WH, ADV: WH\n",
      "and PRON : WH, which are all assigned the semantics λx. ${word}(xa ) ∧ TARGET(xa ). The predicate\n",
      "TARGET indicates that xa represents the variable of\n",
      "interest, that is the answer to the question.\n",
      "3.4\n",
      "\n",
      "Limitations\n",
      "\n",
      "In order to achieve language independence, UD EP L AMBDA has to sacrifice semantic specificity, since\n",
      "in many cases the semantics is carried by lexical\n",
      "information. Consider the sentences John broke\n",
      "the window and The window broke. Although it is\n",
      "the window that broke in both cases, our inferred\n",
      "logical forms do not canonicalize the relation between broke and window. To achieve this, we\n",
      "\n",
      "\f\n",
      "\n",
      "language\n",
      "\n",
      "sprache\n",
      "\n",
      "people\n",
      "\n",
      "target\n",
      "\n",
      "e2\n",
      "people\n",
      ".arg1\n",
      "\n",
      "people\n",
      ".nmod.in\n",
      "\n",
      "Ghana\n",
      "\n",
      "e1\n",
      "\n",
      "x\n",
      "gesprochen\n",
      ".arg2\n",
      "\n",
      "(a) English\n",
      "\n",
      "gesprochen\n",
      ".nmod.in\n",
      "\n",
      "Ghana\n",
      "\n",
      "(b) German\n",
      "\n",
      "target\n",
      "\n",
      "type\n",
      "\n",
      "y\n",
      "speak\n",
      ".arg1\n",
      "\n",
      "type\n",
      "\n",
      "type\n",
      "\n",
      "type\n",
      "\n",
      "type\n",
      "speak\n",
      ".arg2\n",
      "\n",
      "target\n",
      "language\n",
      ".human language\n",
      "\n",
      "e1\n",
      "\n",
      "x\n",
      "\n",
      "lengua\n",
      "\n",
      "target\n",
      "\n",
      "e1\n",
      "\n",
      "x\n",
      "lengua\n",
      ".arg1\n",
      "\n",
      "lengua\n",
      ".nmod.de\n",
      "\n",
      "(c) Spanish\n",
      "\n",
      "Ghana\n",
      "\n",
      "x\n",
      "\n",
      "m\n",
      "location.country\n",
      ".official language.2\n",
      "\n",
      "location.country\n",
      ".official language.1\n",
      "\n",
      "Ghana\n",
      "\n",
      "(d) Freebase\n",
      "\n",
      "Figure 3: The ungrounded graphs for What language do the people in Ghana speak?, Welche Sprache\n",
      "wird in Ghana gesprochen? and Cuál es la lengua de Ghana?, and the corresponding grounded graph.\n",
      "would have to make the substitution of nsubj depend on lexical context, such that when window\n",
      "occurs as nsubj with broke, the predicate arg2 is\n",
      "invoked rather than arg1 . UD EP L AMBDA does\n",
      "not address this problem, and leave it to the target application to infer context-sensitive semantics\n",
      "of arg1 and arg2 . To measure the impact of this\n",
      "limitation, we present UD EP L AMBDA SRL in Section 4.4 which addresses this problem by relying on\n",
      "semantic roles from semantic role labeling (Palmer\n",
      "et al., 2010).\n",
      "Other constructions that require lexical information are quantifiers like every, some and most, negation markers like no and not, and intentional verbs\n",
      "like believe and said. UD does not have special\n",
      "labels to indicate these. We discuss how to handle\n",
      "quantifiers in this framework in the supplementary\n",
      "material.\n",
      "Although in the current setup UD EP L AMBDA\n",
      "rules are hand-coded, the number of rules are only\n",
      "proportional to the number of UD labels, making rule-writing manageable.5 Moreover, we view\n",
      "UD EP L AMBDA as a first step towards learning\n",
      "rules for converting UD to richer semantic representations such as PropBank, AMR, or the Parallel Meaning Bank (Palmer et al., 2005; Banarescu\n",
      "et al., 2013; Abzianidze et al., 2017)..\n",
      "\n",
      "4\n",
      "\n",
      "Cross-lingual Semantic Parsing\n",
      "\n",
      "To study the multilingual nature of UD EP L AMBDA,\n",
      "we conduct an empirical evaluation on question\n",
      "answering against Freebase in three different languages: English, Spanish, and German. Before\n",
      "discussing the details of this experiment, we briefly\n",
      "outline the semantic parsing framework employed.\n",
      "5 UD v1.3 has 40 dependency labels, and the number of\n",
      "substitution rules in UD EP L AMBDA are 61, with some labels\n",
      "having multiple rules, and some representing lexical semantics.\n",
      "\n",
      "4.1\n",
      "\n",
      "Semantic Parsing as Graph Matching\n",
      "\n",
      "UD EP L AMBDA generates ungrounded logical\n",
      "forms that are independent of any knowledge base,\n",
      "such as Freebase. We use G RAPH PARSER (Reddy\n",
      "et al., 2016) to map these logical forms to their\n",
      "grounded Freebase graphs, via corresponding ungrounded graphs. Figures 3(a) to 3(c) show the\n",
      "ungrounded graphs corresponding to logical forms\n",
      "from UD EP L AMBDA, each grounded to the same\n",
      "Freebase graph in Figure 3(d). Here, rectangles denote entities, circles denote events, rounded rectangles denote entity types, and edges between events\n",
      "and entities denote predicates or Freebase relations.\n",
      "Finally, the TARGET node represents the set of values of x that are consistent with the Freebase graph,\n",
      "that is the answer to the question.\n",
      "G RAPH PARSER treats semantic parsing as a\n",
      "graph-matching problem with the goal of finding\n",
      "the Freebase graphs that are structurally isomorphic\n",
      "to an ungrounded graph and rank them according\n",
      "to a model. To account for structural mismatches,\n",
      "G RAPH PARSER uses two graph transformations:\n",
      "CONTRACT and EXPAND . In Figure 3(a) there are\n",
      "two edges between x and Ghana. CONTRACT collapses one of these edges to create a graph isomorphic to Freebase. EXPAND, in contrast, adds edges\n",
      "to connect the graph in the case of disconnected\n",
      "components. The search space is explored by beam\n",
      "search and model parameters are estimated with\n",
      "the averaged structured perceptron (Collins, 2002)\n",
      "from training data consisting of question-answer\n",
      "pairs, using answer F1 -score as the objective.\n",
      "4.2\n",
      "\n",
      "Datasets\n",
      "\n",
      "We evaluate our approach on two public benchmarks of question answering against Freebase:\n",
      "WebQuestions (Berant et al., 2013), a widely used\n",
      "benchmark consisting of English questions and\n",
      "their answers, and GraphQuestions (Su et al., 2016),\n",
      "a recently released dataset of English questions\n",
      "with both their answers and grounded logical forms.\n",
      "\n",
      "\f\n",
      "\n",
      "While WebQuestions is dominated by simple entityattribute questions, GraphQuestions contains a\n",
      "large number of compositional questions involving\n",
      "aggregation (e.g. How many children of Eddard\n",
      "Stark were born in Winterfell? ) and comparison\n",
      "(e.g. In which month does the average rainfall of\n",
      "New York City exceed 86 mm? ). The number of\n",
      "training, development and test questions is 2644,\n",
      "1134, and 2032, respectively, for WebQuestions\n",
      "and 1794, 764, and 2608 for GraphQuestions.\n",
      "To support multilingual evaluation, we created\n",
      "translations of WebQuestions and GraphQuestions\n",
      "to German and Spanish. For WebQuestions two\n",
      "professional annotators were hired per language,\n",
      "while for GraphQuestions we used a trusted pool of\n",
      "20 annotators per language (with a single annotator\n",
      "per question). Examples of the original questions\n",
      "and their translations are provided in Table 1.\n",
      "4.3 Implementation Details\n",
      "\n",
      "WebQuestions\n",
      "en\n",
      "de\n",
      "es\n",
      "\n",
      "What language do the people in Ghana speak?\n",
      "Welche Sprache wird in Ghana gesprochen?\n",
      "¿Cuál es la lengua de Ghana?\n",
      "\n",
      "en\n",
      "de\n",
      "es\n",
      "\n",
      "Who was Vincent van Gogh inspired by?\n",
      "Von wem wurde Vincent van Gogh inspiriert?\n",
      "¿Qué inspiró a Van Gogh?\n",
      "GraphQuestions\n",
      "\n",
      "en\n",
      "de\n",
      "es\n",
      "\n",
      "NASA has how many launch sites?\n",
      "Wie viele Abschussbasen besitzt NASA?\n",
      "¿Cuántos sitios de despegue tiene NASA?\n",
      "\n",
      "en\n",
      "de\n",
      "es\n",
      "\n",
      "Which loudspeakers are heavier than 82.0 kg?\n",
      "Welche Lautsprecher sind schwerer als 82.0 kg?\n",
      "¿Qué altavoces pesan más de 82.0 kg?\n",
      "\n",
      "Table 1: Example questions and their translations.\n",
      "k\n",
      "1\n",
      "10\n",
      "\n",
      "en\n",
      "\n",
      "WebQuestions\n",
      "de\n",
      "es\n",
      "\n",
      "GraphQuestions\n",
      "en\n",
      "de\n",
      "es\n",
      "\n",
      "89.6\n",
      "95.7\n",
      "\n",
      "82.8\n",
      "91.2\n",
      "\n",
      "47.2\n",
      "56.9\n",
      "\n",
      "86.7\n",
      "94.0\n",
      "\n",
      "39.9\n",
      "48.4\n",
      "\n",
      "39.5\n",
      "51.6\n",
      "\n",
      "Here we provide details on the syntactic analyzers\n",
      "employed, our entity resolution algorithm, and the\n",
      "features used by the grounding model.\n",
      "\n",
      "Table 2: Structured perceptron k-best entity linking\n",
      "accuracies on the development sets.\n",
      "\n",
      "Dependency Parsing The English, Spanish, and\n",
      "German Universal Dependencies (UD) treebanks\n",
      "(v1.3; Nivre et al 2016) were used to train part of\n",
      "speech taggers and dependency parsers. We used a\n",
      "bidirectional LSTM tagger (Plank et al., 2016) and\n",
      "a bidirectional LSTM shift-reduce parser (Kiperwasser and Goldberg, 2016). Both the tagger and\n",
      "parser require word embeddings. For English, we\n",
      "used GloVe embeddings (Pennington et al., 2014)\n",
      "trained on Wikipedia and the Gigaword corpus.\n",
      "For German and Spanish, we used SENNA embeddings (Collobert et al., 2011; Al-Rfou et al.,\n",
      "2013) trained on Wikipedia corpora (589M words\n",
      "German; 397M words Spanish).6 Measured on the\n",
      "UD test sets, the tagger accuracies are 94.5 (English), 92.2 (German), and 95.7 (Spanish), with\n",
      "corresponding labeled attachment parser scores of\n",
      "81.8, 74.7, and 82.2.\n",
      "\n",
      "input to G RAPH PARSER, leaving the final disambiguation to the semantic parsing problem. Table 2\n",
      "shows the 1-best and 10-best entity disambiguation\n",
      "F1 -scores for each language and dataset.\n",
      "\n",
      "Entity Resolution We follow Reddy et al. (2016)\n",
      "and resolve entities in three steps: (1) potential entity spans are identified using seven handcrafted\n",
      "part-of-speech patterns; (2) each span is associated\n",
      "with potential Freebase entities according to the\n",
      "Freebase/KG API; and (3) the 10-best entity linking lattices, scored by a structured perceptron, are\n",
      "6 https://sites.google.com/site/rmyeid/projects/polyglot.\n",
      "\n",
      "Features We use features similar to Reddy et al.\n",
      "(2016): basic features of words and Freebase relations, and graph features crossing ungrounded\n",
      "events with grounded relations, ungrounded types\n",
      "with grounded relations, and ungrounded answer\n",
      "type crossed with a binary feature indicating if the\n",
      "answer is a number. In addition, we add features\n",
      "encoding the semantic similarity of ungrounded\n",
      "events and Freebase relations. Specifically, we used\n",
      "the cosine similarity of the translation-invariant embeddings of Huang et al. (2015).7\n",
      "4.4\n",
      "\n",
      "Comparison Systems\n",
      "\n",
      "We compared UD EP L AMBDA to four versions of\n",
      "G RAPH PARSER that operate on different representations, in addition to prior work.\n",
      "S INGLE E VENT This model resembles the\n",
      "learning-to-rank model of Bast and Haussmann\n",
      "(2015). An ungrounded graph is generated by connecting all entities in the question with the TARGET\n",
      "node, representing a single event. Note that this\n",
      "7 http://128.2.220.95/multilingual/data/.\n",
      "\n",
      "\f\n",
      "\n",
      "Method\n",
      "\n",
      "WebQuestions\n",
      "en de es\n",
      "\n",
      "GraphQuestions\n",
      "en de\n",
      "es\n",
      "\n",
      "S INGLE E VENT\n",
      "D EP T REE\n",
      "CCGG RAPH\n",
      "UD EP L AMBDA\n",
      "UD EP L AMBDA SRL\n",
      "\n",
      "48.5 45.6 46.3\n",
      "48.8 45.9 46.4\n",
      "49.5 –\n",
      "–\n",
      "49.5 46.1 47.5\n",
      "49.8 46.2 47.0\n",
      "\n",
      "15.9 8.8\n",
      "16.0 8.3\n",
      "15.9 –\n",
      "17.7 9.5\n",
      "17.7 9.1\n",
      "\n",
      "11.4\n",
      "11.3\n",
      "–\n",
      "12.8\n",
      "12.7\n",
      "\n",
      "Table 3: F1 -scores on the test data.\n",
      "baseline cannot handle compositional questions, or\n",
      "those with aggregation or comparison.\n",
      "D EP T REE An ungrounded graph is obtained directly from the original dependency tree. An event\n",
      "is created for each parent and its dependents in the\n",
      "tree. Each dependent is linked to this event with an\n",
      "edge labeled with its dependency relation, while the\n",
      "parent is linked to the event with an edge labeled\n",
      "arg0 . If a word is a question word, an additional\n",
      "TARGET predicate is attached to its entity node.\n",
      "CCGG RAPH This is the CCG-based semantic\n",
      "representation of Reddy et al. (2014). Note that\n",
      "this baseline exists only for English.\n",
      "UD EP L AMBDA SRL This is similar to UD EP L AMBDA except that instead of assuming nsubj,\n",
      "dobj and nsubjpass correspond to arg1 , arg2 and\n",
      "arg2 , we employ semantic role labeling to identify\n",
      "the correct interpretation. We used the systems of\n",
      "Roth and Woodsend (2014) for English and German and Bjrkelund et al. (2009) for Spanish trained\n",
      "on the CoNLL-2009 dataset (Haji et al., 2009).8\n",
      "4.5 Results\n",
      "Table 3 shows the performance of G RAPH PARSER\n",
      "with these different representations. Here and in\n",
      "what follows, we use average F1 -score of predicted\n",
      "answers (Berant et al., 2013) as the evaluation metric. We first observe that UD EP L AMBDA consistently outperforms the S INGLE E VENT and D EP T REE representations in all languages.\n",
      "For English, performance is on par with CCGG RAPH, which suggests that UD EP L AMBDA does\n",
      "not sacrifice too much specificity for universality. With both datasets, results are lower for German compared to Spanish. This agrees with the\n",
      "lower performance of the syntactic parser on the\n",
      "German portion of the UD treebank. While UD EP L AMBDA SRL performs better than UD EP 8 The parser accuracies (%) are 87.33, 81.38 and 79.91for\n",
      "English, German and Spanish respectively.\n",
      "\n",
      "Method\n",
      "\n",
      "GraphQ. WebQ.\n",
      "\n",
      "S EMPRE (Berant et al., 2013)\n",
      "10.8 35.7\n",
      "JACANA (Yao and Van Durme, 2014)\n",
      "5.1 33.0\n",
      "PARA S EMPRE (Berant and Liang, 2014) 12.8 39.9\n",
      "QA (Yao, 2015)\n",
      "–\n",
      "44.3\n",
      "AQQU (Bast and Haussmann, 2015)\n",
      "–\n",
      "49.4\n",
      "AGENDA IL (Berant and Liang, 2015)\n",
      "–\n",
      "49.7\n",
      "D EP L AMBDA (Reddy et al., 2016)\n",
      "–\n",
      "50.3\n",
      "STAGG (Yih et al., 2015)\n",
      "B I LSTM (Türe and Jojic, 2016)\n",
      "MCNN (Xu et al., 2016)\n",
      "AGENDA IL-R ANK (Yavuz et al., 2016)\n",
      "\n",
      "–\n",
      "–\n",
      "–\n",
      "–\n",
      "\n",
      "48.4 (52.5)\n",
      "24.9 (52.2)\n",
      "47.0 (53.3)\n",
      "51.6 (52.6)\n",
      "\n",
      "UD EP L AMBDA\n",
      "\n",
      "17.7 49.5\n",
      "\n",
      "Table 4: F1 -scores on the English GraphQuestions\n",
      "and WebQuestions test sets (results with additional\n",
      "task-specific resources in parentheses).\n",
      "\n",
      "L AMBDA on WebQuestions for English, we do not\n",
      "see large performance gaps in other settings, suggesting that G RAPH PARSER is either able to learn\n",
      "context-sensitive semantics of ungrounded predicates or that the datasets do not contain ambiguous\n",
      "nsubj, dobj and nsubjpass mappings. Finally,\n",
      "while these results confirm that GraphQuestions is\n",
      "much harder compared to WebQuestions, we note\n",
      "that both datasets predominantly contain single-hop\n",
      "questions, as indicated by the competitive performance of S INGLE E VENT on both datasets.\n",
      "Table 4 compares UD EP L AMBDA with previously published models which exist only for English and have been mainly evaluated on WebQuestions. These are either symbolic like ours (first\n",
      "block) or employ neural networks (second block).\n",
      "Results for models using additional task-specific\n",
      "training resources, such as ClueWeb09, Wikipedia,\n",
      "or SimpleQuestions (Bordes et al., 2015) are shown\n",
      "in parentheses. On GraphQuestions, we achieve\n",
      "a new state-of-the-art result with a gain of 4.8 F1 points over the previously reported best result. On\n",
      "WebQuestions we are 2.1 points below the best\n",
      "model using comparable resources, and 3.8 points\n",
      "below the state of the art. Most related to our\n",
      "work is the English-specific system of Reddy et al.\n",
      "(2016). We attribute the 0.8 point difference in F1 score to their use of the more fine-grained PTB tag\n",
      "set and Stanford Dependencies.\n",
      "\n",
      "5\n",
      "\n",
      "Related Work\n",
      "\n",
      "Our work continues the long tradition of building\n",
      "logical forms from syntactic representations initiated by Montague (1973). The literature is rife with\n",
      "\n",
      "\f\n",
      "\n",
      "attempts to develop semantic interfaces for HPSG\n",
      "(Copestake et al., 2005), LFG (Kaplan and Bresnan,\n",
      "1982; Dalrymple et al., 1995; Crouch and King,\n",
      "2006), TAG (Kallmeyer and Joshi, 2003; Gardent\n",
      "and Kallmeyer, 2003; Nesson and Shieber, 2006),\n",
      "and CCG (Baldridge and Kruijff, 2002; Bos et al.,\n",
      "2004; Artzi et al., 2015). Unlike existing semantic\n",
      "interfaces, UD EP L AMBDA uses dependency syntax, a widely available syntactic resource.\n",
      "A common trend in previous work on semantic interfaces is the reliance on rich typed feature\n",
      "structures or semantic types coupled with strong\n",
      "type constraints, which can be very informative\n",
      "but unavoidably language specific. Instead, UD EP L AMBDA relies on generic unlexicalized information present in dependency treebanks and uses a\n",
      "simple type system (one type for dependency labels,\n",
      "and one for words) along with a combinatory mechanism, which avoids type collisions. Earlier attempts at extracting semantic representations from\n",
      "dependencies have mainly focused on languagespecific dependency representations (Spreyer and\n",
      "Frank, 2005; Simov and Osenova, 2011; Hahn and\n",
      "Meurers, 2011; Reddy et al., 2016; Falke et al.,\n",
      "2016; Beltagy, 2016), and multi-layered dependency annotations (Jakob et al., 2010; Bédaride\n",
      "and Gardent, 2011). In contrast, UD EP L AMBDA\n",
      "derives semantic representations for multiple languages in a common schema directly from Universal Dependencies. This work parallels a growing\n",
      "interest in creating other forms of multilingual semantic representations (Akbik et al., 2015; Vanderwende et al., 2015; White et al., 2016; Evang and\n",
      "Bos, 2016).\n",
      "We evaluate UD EP L AMBDA on semantic parsing for question answering against a knowledge\n",
      "base. Here, the literature offers two main modeling\n",
      "paradigms: (1) learning of task-specific grammars\n",
      "that directly parse language to a grounded representation (Zelle and Mooney, 1996; Zettlemoyer\n",
      "and Collins, 2005; Berant et al., 2013; Flanigan\n",
      "et al., 2014; Pasupat and Liang, 2015; Groschwitz\n",
      "et al., 2015); and (2) converting language to a linguistically motivated task-independent representation that is then mapped to a grounded representation (Kwiatkowski et al., 2013; Reddy et al., 2014;\n",
      "Krishnamurthy and Mitchell, 2015; Gardner and\n",
      "Krishnamurthy, 2017). Our work belongs to the\n",
      "latter paradigm, as we map natural language to\n",
      "Freebase indirectly via logical forms. Capitalizing\n",
      "on natural-language syntax affords interpretability,\n",
      "\n",
      "scalability, and reduced duplication of effort across\n",
      "applications (Bender et al., 2015). Our work also relates to literature on parsing multiple languages to a\n",
      "common executable representation (Cimiano et al.,\n",
      "2013; Haas and Riezler, 2016). However, existing\n",
      "approaches still map to the target meaning representations (more or less) directly (Kwiatkowksi et al.,\n",
      "2010; Jones et al., 2012; Jie and Lu, 2014).\n",
      "\n",
      "6\n",
      "\n",
      "Conclusions\n",
      "\n",
      "We introduced UD EP L AMBDA, a semantic interface for Universal Dependencies, and showed that\n",
      "the resulting semantic representation can be used\n",
      "for question-answering against a knowledge base\n",
      "in multiple languages. We provided translations of\n",
      "benchmark datasets in German and Spanish, in the\n",
      "hope to stimulate further multilingual research on\n",
      "semantic parsing and question answering in general. We have only scratched the surface when it\n",
      "comes to applying UD EP L AMBDA to natural language understanding tasks. In the future, we would\n",
      "like to explore how this framework can benefit applications such as summarization (Liu et al., 2015)\n",
      "and machine reading (Sachan and Xing, 2016).\n",
      "\n",
      "Acknowledgements\n",
      "This work greatly benefited from discussions with\n",
      "Michael Collins, Dipanjan Das, Federico Fancellu,\n",
      "Julia Hockenmaier, Tom Kwiatkowski, Adam\n",
      "Lopez, Valeria de Paiva, Martha Palmer, Fernando\n",
      "Pereira, Emily Pitler, Vijay Saraswat, Nathan\n",
      "Schneider, Bonnie Webber, Luke Zettlemoyer, and\n",
      "the members of ILCC Edinburgh University, the\n",
      "Microsoft Research Redmond NLP group, the Stanford NLP group, and the UW NLP and Linguistics\n",
      "group. We thank Reviewer 2 for useful feedback.\n",
      "The authors would also like to thank the Universal Dependencies community for the treebanks and\n",
      "documentation. This research is supported by a\n",
      "Google PhD Fellowship to the first author. We acknowledge the financial support of the European\n",
      "Research Council (Lapata; award number 681760).\n",
      "\n",
      "References\n",
      "Lasha Abzianidze, Johannes Bjerva, Kilian Evang,\n",
      "Hessel Haagsma, Rik van Noord, Pierre Ludmann,\n",
      "Duc-Duy Nguyen, and Johan Bos. 2017. The Parallel Meaning Bank: Towards a Multilingual Corpus of Translations Annotated with Compositional\n",
      "Meaning Representations. In Proceedings of the\n",
      "\n",
      "\f\n",
      "\n",
      "European Chapter of the Association for Computational Linguistics. Association for Computational\n",
      "Linguistics, Valencia, Spain, pages 242–247.\n",
      "Alan Akbik, laura chiticariu, Marina Danilevsky, Yunyao Li, Shivakumar Vaithyanathan, and Huaiyu Zhu.\n",
      "2015. Generating High Quality Proposition Banks\n",
      "for Multilingual Semantic Role Labeling. In Proceedings of the Association for Computational Linguistics and the International Joint Conference on\n",
      "Natural Language Processing. Association for Computational Linguistics, Beijing, China, pages 397–\n",
      "407.\n",
      "Rami Al-Rfou, Bryan Perozzi, and Steven Skiena.\n",
      "2013. Polyglot: Distributed Word Representations\n",
      "for Multilingual NLP. In Proceedings of the Computational Natural Language Learning. Sofia, Bulgaria, pages 183–192.\n",
      "\n",
      "Jonathan Berant, Andrew Chou, Roy Frostig, and Percy\n",
      "Liang. 2013. Semantic Parsing on Freebase from\n",
      "Question-Answer Pairs. In Proceedings of the Empirical Methods on Natural Language Processing.\n",
      "pages 1533–1544.\n",
      "Jonathan Berant and Percy Liang. 2014. Semantic Parsing via Paraphrasing. In Proceedings of the Association for Computational Linguistics. pages 1415–\n",
      "1425.\n",
      "Jonathan Berant and Percy Liang. 2015. Imitation\n",
      "Learning of Agenda-Based Semantic Parsers. Transactions of the Association for Computational Linguistics 3:545–558.\n",
      "\n",
      "Yoav Artzi. 2013. Cornell SPF: Cornell Semantic Parsing Framework. arXiv:1311.3011 [cs.CL] .\n",
      "\n",
      "Anders Bjrkelund, Love Hafdell, and Pierre Nugues.\n",
      "2009. Multilingual Semantic Role Labeling. In\n",
      "Proceedings of Computational Natural Language\n",
      "Learning (CoNLL 2009): Shared Task. Association\n",
      "for Computational Linguistics, Boulder, Colorado,\n",
      "pages 43–48.\n",
      "\n",
      "Yoav Artzi, Kenton Lee, and Luke Zettlemoyer. 2015.\n",
      "Broad-coverage CCG Semantic Parsing with AMR.\n",
      "In Proceedings of the Empirical Methods on Natural\n",
      "Language Processing. pages 1699–1710.\n",
      "\n",
      "Antoine Bordes, Nicolas Usunier, Sumit Chopra, and\n",
      "Jason Weston. 2015. Large-scale simple question answering with memory networks. CoRR\n",
      "abs/1506.02075.\n",
      "\n",
      "Jason Baldridge and Geert-Jan Kruijff. 2002. Coupling\n",
      "CCG and Hybrid Logic Dependency Semantics. In\n",
      "Proceedings of the Association for Computational\n",
      "Linguistics. pages 319–326.\n",
      "\n",
      "Johan Bos, Stephen Clark, Mark Steedman, James R.\n",
      "Curran, and Julia Hockenmaier. 2004.\n",
      "WideCoverage Semantic Representations from a CCG\n",
      "Parser. In Proceedings of the Conference on Computational Linguistics. pages 1240–1246.\n",
      "\n",
      "Laura Banarescu, Claire Bonial, Shu Cai, Madalina\n",
      "Georgescu, Kira Griffitt, Ulf Hermjakob, Kevin\n",
      "Knight, Philipp Koehn, Martha Palmer, and Nathan\n",
      "Schneider. 2013. Abstract Meaning Representation\n",
      "for Sembanking. In Linguistic Annotation Workshop\n",
      "and Interoperability with Discourse. Sofia, Bulgaria,\n",
      "pages 178–186.\n",
      "Hannah Bast and Elmar Haussmann. 2015. More Accurate Question Answering on Freebase. In Proceedings of ACM International Conference on Information and Knowledge Management. pages 1431–\n",
      "1440.\n",
      "Paul Bédaride and Claire Gardent. 2011. Deep Semantics for Dependency Structures. In Proceedings of\n",
      "Conference on Intelligent Text Processing and Computational Linguistics. pages 277–288.\n",
      "Islam Beltagy. 2016. Natural Language Semantics Using Probabilistic Logic. Ph.D. thesis, Department\n",
      "of Computer Science, The University of Texas at\n",
      "Austin.\n",
      "Emily M. Bender, Dan Flickinger, Stephan Oepen,\n",
      "Woodley Packard, and Ann Copestake. 2015. Layers of Interpretation: On Grammar and Compositionality. In Proceedings of the International Conference on Computational Semantics. Association for\n",
      "Computational Linguistics, London, UK, pages 239–\n",
      "249.\n",
      "\n",
      "Philipp Cimiano, Vanessa Lopez, Christina Unger,\n",
      "Elena Cabrio, Axel-Cyrille Ngonga Ngomo, and\n",
      "Sebastian Walter. 2013. Multilingual question answering over linked data (QALD-3): Lab overview.\n",
      "In Information Access Evaluation. Multilinguality,\n",
      "Multimodality, and Visualization. Springer, Valencia,\n",
      "Spain, volume 8138.\n",
      "Michael Collins. 2002. Discriminative Training Methods for Hidden Markov Models: Theory and Experiments with Perceptron Algorithms. In Proceedings\n",
      "of the Empirical Methods on Natural Language Processing. pages 1–8.\n",
      "Ronan Collobert, Jason Weston, Leon Bottou, Michael\n",
      "Karlen, Koray Kavukcuoglu, and Pavel Kuks. 2011.\n",
      "Natural language processing (almost) from scratch.\n",
      "Journal of Machine Learning Research 12:2493–\n",
      "2537.\n",
      "Ann Copestake, Dan Flickinger, Carl Pollard, and\n",
      "Ivan A. Sag. 2005. Minimal Recursion Semantics:\n",
      "An Introduction. Research on Language and Computation 3(2-3):281–332.\n",
      "Dick Crouch and Tracy Holloway King. 2006. Semantics via f-structure rewriting. In Proceedings of the\n",
      "LFG’06 Conference. CSLI Publications, page 145.\n",
      "Mary Dalrymple, John Lamping, Fernando C. N.\n",
      "Pereira, and Vijay A. Saraswat. 1995. Linear Logic\n",
      "for Meaning Assembly. In Proceedings of Computational Logic for Natural Language Processing.\n",
      "\n",
      "\f\n",
      "\n",
      "Kilian Evang and Johan Bos. 2016. Cross-lingual\n",
      "Learning of an Open-domain Semantic Parser. In\n",
      "Proceedings of the Conference on Computational\n",
      "Linguistics. The COLING 2016 Organizing Committee, Osaka, Japan, pages 579–588.\n",
      "Tobias Falke, Gabriel Stanovsky, Iryna Gurevych, and\n",
      "Ido Dagan. 2016. Porting an Open Information Extraction System from English to German. In Proceedings of the Empirical Methods in Natural Language Processing. Association for Computational\n",
      "Linguistics, Austin, Texas, pages 892–898.\n",
      "Jeffrey Flanigan, Sam Thomson, Jaime Carbonell,\n",
      "Chris Dyer, and Noah A. Smith. 2014. A Discriminative Graph-Based Parser for the Abstract Meaning\n",
      "Representation. In Proceedings of the Association\n",
      "for Computational Linguistics. pages 1426–1436.\n",
      "Claire Gardent and Laura Kallmeyer. 2003. Semantic\n",
      "Construction in Feature-based TAG. In Proceedings\n",
      "of European Chapter of the Association for Computational Linguistics. pages 123–130.\n",
      "Matt Gardner and Jayant Krishnamurthy. 2017. OpenVocabulary Semantic Parsing with both Distributional Statistics and Formal Knowledge. In Proceedings of Association for the Advancement of Artificial\n",
      "Intelligence.\n",
      "\n",
      "Translation Invariant Word Embeddings. In Proceedings of the Empirical Methods in Natural Language Processing. Lisbon, Portugal, pages 1084–\n",
      "1088.\n",
      "Max Jakob, Markéta Lopatková, and Valia Kordoni.\n",
      "2010. Mapping between Dependency Structures and\n",
      "Compositional Semantic Representations. In Proceedings of the Fifth International Conference on\n",
      "Language Resources and Evaluation.\n",
      "Zhanming Jie and Wei Lu. 2014. Multilingual Semantic Parsing : Parsing Multiple Languages into Semantic Representations. In Proceedings of the Conference on Computational Linguistics. Dublin City\n",
      "University and Association for Computational Linguistics, Dublin, Ireland, pages 1291–1301.\n",
      "Bevan Keeley Jones, Mark Johnson, and Sharon Goldwater. 2012. Semantic Parsing with Bayesian Tree\n",
      "Transducers. In Proceedings of the Association for\n",
      "Computational Linguistics. Association for Computational Linguistics, Stroudsburg, PA, USA, pages\n",
      "488–496.\n",
      "Laura Kallmeyer and Aravind Joshi. 2003. Factoring predicate argument and scope semantics: Underspecified semantics with LTAG. Research on Language and Computation 1(1-2):3–58.\n",
      "\n",
      "Jonas Groschwitz, Alexander Koller, and Christoph Teichmann. 2015. Graph parsing with s-graph grammars. In Proceedings of the Association for Computational Linguistics. pages 1481–1490.\n",
      "\n",
      "Ronald M Kaplan and Joan Bresnan. 1982. Lexicalfunctional grammar: A formal system for grammatical representation. Formal Issues in LexicalFunctional Grammar pages 29–130.\n",
      "\n",
      "Carolin Haas and Stefan Riezler. 2016. A Corpus and\n",
      "Semantic Parser for Multilingual Natural Language\n",
      "Querying of OpenStreetMap. In Proceedings of\n",
      "the North American Chapter of the Association for\n",
      "Computational Linguistics: Human Language Technologies. Association for Computational Linguistics,\n",
      "San Diego, California, pages 740–750.\n",
      "\n",
      "Eliyahu Kiperwasser and Yoav Goldberg. 2016. Simple and Accurate Dependency Parsing Using Bidirectional LSTM Feature Representations. Transactions of the Association for Computational Linguistics 4:313–327.\n",
      "\n",
      "Michael Hahn and Detmar Meurers. 2011. On deriving semantic representations from dependencies: A\n",
      "practical approach for evaluating meaning in learner\n",
      "corpora. In Proceedings of the Int. Conference on\n",
      "Dependency Linguistics (Depling 2011). Barcelona,\n",
      "pages 94–103.\n",
      "Jan Haji, Massimiliano Ciaramita, Richard Johansson, Daisuke Kawahara, Maria Antnia Mart, Llus\n",
      "Mrquez, Adam Meyers, Joakim Nivre, Sebastian\n",
      "Pad, Jan tpnek, and others. 2009. The CoNLL-2009\n",
      "shared task: Syntactic and semantic dependencies in\n",
      "multiple languages. In Proceedings of the Computational Natural Language Learning: Shared Task.\n",
      "Association for Computational Linguistics, pages 1–\n",
      "18.\n",
      "Kejun Huang, Matt Gardner, Evangelos Papalexakis, Christos Faloutsos, Nikos Sidiropoulos, Tom\n",
      "Mitchell, Partha P. Talukdar, and Xiao Fu. 2015.\n",
      "\n",
      "Jayant Krishnamurthy and Tom M. Mitchell. 2015.\n",
      "Learning a Compositional Semantics for Freebase\n",
      "with an Open Predicate Vocabulary. Transactions\n",
      "of the Association for Computational Linguistics\n",
      "3:257–270.\n",
      "Tom Kwiatkowksi, Luke Zettlemoyer, Sharon Goldwater, and Mark Steedman. 2010. Inducing Probabilistic CCG Grammars from Logical Form with HigherOrder Unification. In Proceedings of the Empirical Methods on Natural Language Processing. pages\n",
      "1223–1233.\n",
      "Tom Kwiatkowski, Eunsol Choi, Yoav Artzi, and Luke\n",
      "Zettlemoyer. 2013. Scaling Semantic Parsers with\n",
      "On-the-Fly Ontology Matching. In Proceedings of\n",
      "the Empirical Methods on Natural Language Processing. pages 1545–1556.\n",
      "Roger Levy and Galen Andrew. 2006. Tregex and tsurgeon: tools for querying and manipulating tree data\n",
      "structures. In Proceedings of LREC. pages 2231–\n",
      "2234.\n",
      "\n",
      "\f\n",
      "\n",
      "Fei Liu, Jeffrey Flanigan, Sam Thomson, Norman\n",
      "Sadeh, and Noah A. Smith. 2015. Toward Abstractive Summarization Using Semantic Representations. In Proceedings of North American Chapter of the Association for Computational Linguistics.\n",
      "pages 1077–1086.\n",
      "\n",
      "Siva Reddy, Mirella Lapata, and Mark Steedman. 2014.\n",
      "Large-scale Semantic Parsing without QuestionAnswer Pairs. Transactions of the Association for\n",
      "Computational Linguistics 2:377–392.\n",
      "\n",
      "Mitchell P. Marcus, Mary Ann Marcinkiewicz, and\n",
      "Beatrice Santorini. 1993. Building a large annotated\n",
      "corpus of English: The Penn Treebank. Computational linguistics 19(2):313–330.\n",
      "\n",
      "Siva Reddy, Oscar Täckström, Michael Collins, Tom\n",
      "Kwiatkowski, Dipanjan Das, Mark Steedman, and\n",
      "Mirella Lapata. 2016. Transforming Dependency\n",
      "Structures to Logical Forms for Semantic Parsing.\n",
      "Transactions of the Association for Computational\n",
      "Linguistics 4:127–140.\n",
      "\n",
      "Richard Montague. 1973. The Proper Treatment of\n",
      "Quantification in Ordinary English. In K.J.J. Hintikka, J.M.E. Moravcsik, and P. Suppes, editors,\n",
      "Approaches to Natural Language, Springer Netherlands, volume 49 of Synthese Library, pages 221–\n",
      "242.\n",
      "\n",
      "Michael Roth and Kristian Woodsend. 2014. Composition of Word Representations Improves Semantic\n",
      "Role Labelling. In Proceedings of the Empirical\n",
      "Methods in Natural Language Processing (EMNLP).\n",
      "Association for Computational Linguistics, Doha,\n",
      "Qatar, pages 407–413.\n",
      "\n",
      "Rebecca Nesson and Stuart M. Shieber. 2006. Simpler\n",
      "TAG Semantics Through Synchronization. In Proceedings of the 11th Conference on Formal Grammar. Center for the Study of Language and Information, Malaga, Spain, pages 129–142.\n",
      "\n",
      "Mrinmaya Sachan and Eric Xing. 2016. Machine Comprehension using Rich Semantic Representations. In\n",
      "Proceedings of the Association for Computational\n",
      "Linguistics. Association for Computational Linguistics, Berlin, Germany, pages 486–492.\n",
      "\n",
      "Joakim Nivre, Marie-Catherine de Marneffe, Filip Ginter, Yoav Goldberg, Jan Hajic, Christopher D. Manning, Ryan McDonald, Slav Petrov, Sampo Pyysalo,\n",
      "Natalia Silveira, Reut Tsarfaty, and Daniel Zeman.\n",
      "2016. Universal Dependencies v1: A Multilingual\n",
      "Treebank Collection. In Proceedings of the Tenth International Conference on Language Resources and\n",
      "Evaluation. European Language Resources Association (ELRA), Paris, France.\n",
      "\n",
      "Sebastian Schuster and Christopher D. Manning. 2016.\n",
      "Enhanced English Universal Dependencies: An Improved Representation for Natural Language Understanding Tasks. In Proceedings of the Tenth International Conference on Language Resources and Evaluation. European Language Resources Association\n",
      "(ELRA), Paris, France.\n",
      "\n",
      "Joakim Nivre et al. 2016. Universal dependencies 1.3.\n",
      "LINDAT/CLARIN digital library at the Institute of\n",
      "Formal and Applied Linguistics, Charles University\n",
      "in Prague.\n",
      "Martha Palmer, Daniel Gildea, and Paul Kingsbury.\n",
      "2005. The proposition bank: An annotated corpus of\n",
      "semantic roles. Computational linguistics 31(1):71–\n",
      "106.\n",
      "Martha Palmer, Daniel Gildea, and Nianwen Xue. 2010.\n",
      "Semantic role labeling. Synthesis Lectures on Human Language Technologies 3(1):1–103.\n",
      "Panupong Pasupat and Percy Liang. 2015. Compositional Semantic Parsing on Semi-Structured Tables.\n",
      "In Proceedings of the Association for Computational\n",
      "Linguistics. pages 1470–1480.\n",
      "Jeffrey Pennington, Richard Socher, and Christopher\n",
      "Manning. 2014. Glove: Global Vectors for Word\n",
      "Representation. In Proceedings of the Empirical\n",
      "Methods in Natural Language Processing. Association for Computational Linguistics, Doha, Qatar,\n",
      "pages 1532–1543.\n",
      "Barbara Plank, Anders Søgaard, and Yoav Goldberg.\n",
      "2016. Multilingual Part-of-Speech Tagging with\n",
      "Bidirectional Long Short-Term Memory Models and\n",
      "Auxiliary Loss. In Proceedings of the Annual Meeting of the Association for Computational Linguistics.\n",
      "Berlin, Germany, pages 412–418.\n",
      "\n",
      "Kiril Simov and Petya Osenova. 2011. Towards Minimal Recursion Semantics over Bulgarian Dependency Parsing. In Proceedings of the International\n",
      "Conference Recent Advances in Natural Language\n",
      "Processing 2011. RANLP 2011 Organising Committee, Hissar, Bulgaria, pages 471–478.\n",
      "Kathrin Spreyer and Anette Frank. 2005. Projecting\n",
      "RMRS from TIGER Dependencies. In Proceedings\n",
      "of the HPSG 2005 Conference. CSLI Publications.\n",
      "Yu Su, Huan Sun, Brian Sadler, Mudhakar Srivatsa,\n",
      "Izzeddin Gur, Zenghui Yan, and Xifeng Yan. 2016.\n",
      "On Generating Characteristic-rich Question Sets for\n",
      "QA Evaluation. In Proceedings of the Empirical\n",
      "Methods in Natural Language Processing. Austin,\n",
      "Texas, pages 562–572.\n",
      "Ferhan Türe and Oliver Jojic. 2016. Simple and Effective Question Answering with Recurrent Neural\n",
      "Networks. CoRR abs/1606.05029.\n",
      "Lucy Vanderwende, Arul Menezes, and Chris Quirk.\n",
      "2015. An AMR parser for English, French, German,\n",
      "Spanish and Japanese and a new AMR-annotated\n",
      "corpus. In Proceedings of the North American Chapter of the Association for Computational Linguistics:\n",
      "Demonstrations. Association for Computational Linguistics, Denver, Colorado, pages 26–30.\n",
      "\n",
      "\f\n",
      "\n",
      "Aaron Steven White, Drew Reisinger, Keisuke Sakaguchi, Tim Vieira, Sheng Zhang, Rachel Rudinger,\n",
      "Kyle Rawlins, and Benjamin Van Durme. 2016. Universal Decompositional Semantics on Universal Dependencies. In Proceedings of the Empirical Methods in Natural Language Processing. Association\n",
      "for Computational Linguistics, Austin, Texas, pages\n",
      "1713–1723.\n",
      "Kun Xu, Siva Reddy, Yansong Feng, Songfang Huang,\n",
      "and Dongyan Zhao. 2016. Question Answering on\n",
      "Freebase via Relation Extraction and Textual Evidence. In Proceedings of the Association for Computational Linguistics. Association for Computational\n",
      "Linguistics, Berlin, Germany, pages 2326–2336.\n",
      "Xuchen Yao. 2015. Lean Question Answering over\n",
      "Freebase from Scratch. In Proceedings of North\n",
      "American Chapter of the Association for Computational Linguistics. pages 66–70.\n",
      "Xuchen Yao and Benjamin Van Durme. 2014. Information Extraction over Structured Data: Question\n",
      "Answering with Freebase. In Proceedings of the Association for Computational Linguistics. pages 956–\n",
      "966.\n",
      "\n",
      "Semih Yavuz, Izzeddin Gur, Yu Su, Mudhakar Srivatsa,\n",
      "and Xifeng Yan. 2016. Improving Semantic Parsing\n",
      "via Answer Type Inference. In Proceedings of the\n",
      "Empirical Methods in Natural Language Processing.\n",
      "Association for Computational Linguistics, Austin,\n",
      "Texas, pages 149–159.\n",
      "Wen-tau Yih, Ming-Wei Chang, Xiaodong He, and\n",
      "Jianfeng Gao. 2015. Semantic Parsing via Staged\n",
      "Query Graph Generation: Question Answering with\n",
      "Knowledge Base. In Proceedings of the Association\n",
      "for Computational Linguistics. pages 1321–1331.\n",
      "John M. Zelle and Raymond J. Mooney. 1996. Learning to Parse Database Queries Using Inductive Logic\n",
      "Programming. In Proceedings of Association for the\n",
      "Advancement of Artificial Intelligence. pages 1050–\n",
      "1055.\n",
      "Luke S. Zettlemoyer and Michael Collins. 2005. Learning to Map Sentences to Logical Form: Structured\n",
      "Classification with Probabilistic Categorial Grammars. In Proceedings of Uncertainty in Artificial Intelligence. pages 658–666.\n",
      "\n",
      "\f\n",
      "\n",
      "Universal Semantic Parsing: Supplementary Material\n",
      "Siva Reddy†\n",
      "\n",
      "Oscar Täckström‡\n",
      "\n",
      "Slav Petrov‡ Mark Steedman†† Mirella Lapata††\n",
      "† Stanford University\n",
      "‡ Google Inc.\n",
      "†† University of Edinburgh\n",
      "sivar@stanford.edu, {oscart, slav}@google.com, {steedman, mlap}@inf.ed.ac.uk\n",
      "\n",
      "Abstract\n",
      "This supplementary material to the main\n",
      "paper, provides an outline of how quantification can be incorporated in the UD EP L AMBDA framework.\n",
      "\n",
      "root\n",
      "xcomp\n",
      "nsubj\n",
      "\n",
      "dobj\n",
      "\n",
      "mark\n",
      "\n",
      "Everybody wants to\n",
      "\n",
      "det\n",
      "\n",
      "buy\n",
      "\n",
      "a\n",
      "\n",
      "house\n",
      "\n",
      "(a) Original dependency tree.\n",
      "root\n",
      "\n",
      "1\n",
      "\n",
      "Universal Quantification\n",
      "\n",
      "Consider the sentence Everybody wants to buy a\n",
      "house,1 whose dependency tree in the Universal\n",
      "Dependencies (UD) formalism is shown in Figure 1(a). This sentence has two possible readings:\n",
      "either (1) every person wants to buy a different\n",
      "house; or (2) every person wants to buy the same\n",
      "house. The two interpretations correspond to the\n",
      "following logical forms:\n",
      "(1) ∀x. person(xa ) →\n",
      "[∃zyw. wants(ze ) ∧ arg1 (ze , xa ) ∧ buy(ye ) ∧ xcomp(ze , ye )∧\n",
      "house(wa ) ∧ arg1 (ze , xa ) ∧ arg2 (ze , wa )] ;\n",
      "\n",
      "(2) ∃w. house(wa ) ∧ (∀x. person(xa ) →\n",
      "[∃zy. wants(ze ) ∧ arg1 (ze , xa ) ∧ buy(ye ) ∧ xcomp(ze , ye )∧\n",
      "arg1 (ze , xa ) ∧ arg2 (ze , wa )]) .\n",
      "\n",
      "In (1), the existential variable w is in the scope of\n",
      "the universal variable x (i.e. the house is dependent\n",
      "on the person). This reading is commonly referred\n",
      "to as the surface reading. Conversely, in (2) the\n",
      "universal variable x is in the scope of the existential\n",
      "variable w (i.e. the house is independent of the\n",
      "person). This reading is also called inverse reading.\n",
      "Our goal is to obtain the surface reading logical\n",
      "form in (1) with UD EP L AMBDA. We do not aim to\n",
      "obtain the inverse reading, although this is possible\n",
      "with the use of Skolemization (Steedman, 2012).\n",
      "In UD EP L AMBDA, lambda expressions for\n",
      "words, phrases and sentences are all of the\n",
      "form λx. . . .. But from (1), it is clear that we need\n",
      "to express variables bound by quantifiers, e.g. ∀x,\n",
      "while still providing access to x for composition.\n",
      "This demands a change in the type system since the\n",
      "1 Example borrowed from Schuster and Manning (2016).\n",
      "\n",
      "xcomp\n",
      "nsubj\n",
      "\n",
      "Everybody wants to\n",
      "bind\n",
      "\n",
      "dobj\n",
      "\n",
      "mark\n",
      "\n",
      "det\n",
      "\n",
      "buy\n",
      "\n",
      "a\n",
      "\n",
      "house\n",
      "\n",
      "nsub j\n",
      "\n",
      "Ω Ω\n",
      "\n",
      "(b) Enhanced dependency tree.\n",
      "root\n",
      "xcomp\n",
      "nsubj:univ\n",
      "\n",
      "Everybody wants to\n",
      "bind\n",
      "\n",
      "dobj\n",
      "\n",
      "mark\n",
      "\n",
      "Ω Ω\n",
      "\n",
      "det\n",
      "\n",
      "buy\n",
      "\n",
      "a\n",
      "\n",
      "house\n",
      "\n",
      "nsub j\n",
      "\n",
      "(c) Enhanced dependency tree with universal quantification.\n",
      "\n",
      "Figure 1: The dependency tree for Everybody\n",
      "wants to buy a house and its enhanced variants.\n",
      "same variable cannot be lambda bound and quantifier bound—that is we cannot have formulas of the\n",
      "form λx . . . ∀x . . .. In this material, we first derive\n",
      "the logical form for the example sentence using\n",
      "the type system from our main paper (Section 1.1)\n",
      "and show that it fails to handle universal quantification. We then modify the type system slightly\n",
      "to allow derivation of the desired surface reading\n",
      "logical form (Section 1.2). This modified type system is a strict generalization of the original type\n",
      "system.2 Fancellu et al. (2017) present an elaborate\n",
      "discussion on the modified type system, and how it\n",
      "can handle negation scope and its interaction with\n",
      "universal quantifiers.\n",
      "2 Note that this treatment has yet to be added to our\n",
      "\n",
      "implementation, which can be found at https://github.com/\n",
      "sivareddyg/udeplambda.\n",
      "\n",
      "\f\n",
      "\n",
      "1.1 With Original Type System\n",
      "We will first attempt to derive the logical form in (1)\n",
      "using the default type system of UD EP L AMBDA.\n",
      "Figure 1(b) shows the enhanced dependency tree\n",
      "for the sentence, where BIND has been introduced\n",
      "to connect the implied nsubj of buy (BIND is explained in the main paper in Section 3.2). The\n",
      "s-expression corresponding to the enhanced tree is:\n",
      "(nsubj (xcomp wants (mark\n",
      "(nsubj (dobj buy (det house a)) Ω) to))\n",
      "(BIND everybody Ω)) .\n",
      "\n",
      "With the following substitution entries,\n",
      "wants, buy ∈ EVENT;\n",
      "everybody, house ∈ ENTITY;\n",
      "a, to ∈ FUNCTIONAL;\n",
      "Ω = λx. EQ(x, ω);\n",
      "nsubj = λ f gx. ∃y. f (x) ∧ g(y) ∧ arg1 (xe , ya );\n",
      "dobj = λ f gx. ∃y. f (x) ∧ g(y) ∧ arg2 (xe , ya );\n",
      "xcomp = λ f gx. ∃y. f (x) ∧ g(y) ∧ xcomp(xe , ya );\n",
      "mark ∈ HEAD;\n",
      "BIND ∈ MERGE ,\n",
      "\n",
      "the lambda expression after composition becomes:\n",
      "λz. ∃xywv. wants(ze ) ∧ everybody(xa ) ∧ arg1 (ze , xa )\n",
      "∧ EQ(x, ω) ∧ buy(ye ) ∧ xcomp(ze , ye ) ∧ arg1 (ye , va )\n",
      "∧ EQ(v, ω) ∧ arg1 (xe , ya ) ∧ house(wa ) ∧ arg2 (ye , wa ) .\n",
      "\n",
      "This expression encodes the fact that x and v are\n",
      "in unification, and can thus be further simplified to:\n",
      "(3) λz. ∃xyw. wants(ze ) ∧ everybody(xa ) ∧ arg1 (ze , xa )\n",
      "∧ buy(ye ) ∧ xcomp(ze , ye ) ∧ arg1 (ye , xa )\n",
      "∧ arg1 (xe , ya ) ∧ house(wa ) ∧ arg2 (ye , wa ) .\n",
      "\n",
      "However, the logical form (3) differs from the\n",
      "desired form (1). As noted above, UD EP L AMBDA\n",
      "with its default type, where each s-expression must\n",
      "have the type η = Ind × Event → Bool, cannot\n",
      "handle quantifier scoping.\n",
      "1.2 With Higher-order Type System\n",
      "Following Champollion (2010), we make a slight\n",
      "modification to the type system. Instead of using\n",
      "expressions of the form λx. . . . for words, we use\n",
      "either λ f . ∃x. . . . or λ f . ∀x. . . ., where f has type η.\n",
      "As argued by Champollion, this higher-order form\n",
      "makes quantification and negation handling sound\n",
      "and simpler in Neo-Davidsonian event semantics.\n",
      "Following this change, we assign the following\n",
      "lambda expressions to the words in our example\n",
      "sentence:\n",
      "everybody = λ f . ∀x. person(x) → f (x) ;\n",
      "wants = λ f . ∃x. wants(xe ) ∧ f (x) ;\n",
      "to = λ f . TRUE ;\n",
      "buy = λ f . ∃x. buy(xe ) ∧ f (x) ;\n",
      "a = λ f . TRUE ;\n",
      "house = λ f . ∃x. house(xa ) ∧ f (x) ;\n",
      "Ω = λ f . f (ω) .\n",
      "\n",
      "Here everybody is assigned universal quantifier\n",
      "semantics. Since the UD representation does not\n",
      "distinguish quantifiers, we need to rely on a small\n",
      "(language-specific) lexicon to identify these. To\n",
      "encode quantification scope, we enhance the label nsubj to nsubj:univ, which indicates that\n",
      "the subject argument of wants contains a universal\n",
      "quantifier, as shown in Figure 1(c).\n",
      "This change of semantic type for words and sexpressions forces us to also modify the semantic type of dependency labels, in order to obey\n",
      "the single-type constraint of D EP L AMBDA (Reddy\n",
      "et al., 2016). Thus, dependency labels will now\n",
      "take the form λPQ f . . . ., where P is the parent expression, Q is the child expression, and the return\n",
      "expression is of the form λ f . . . .. Following this\n",
      "change, we assign the following lambda expressions to dependency labels:\n",
      "nsubj:univ = λPQ f . Q(λy. P(λx. f (x) ∧ arg1 (xe , ya ))) ;\n",
      "nsubj = λP Q f . P(λx. f (x) ∧ Q(λy. arg1 (xe , ya ))) ;\n",
      "dobj = λP Q f . P(λx. f (x) ∧ Q(λy. arg2 (xe , ya ))) ;\n",
      "xcomp = λP Q f . P(λx. f (x) ∧ Q(λy. xcomp(xe , ya ))) ;\n",
      "det, mark = λPQ f . P( f ) ;\n",
      "BIND = λPQ f . P(λx. f (x) ∧ Q(λy. EQ (y, x))) .\n",
      "\n",
      "Notice that the lambda expression of\n",
      "nsubj:univ differs from nsubj. In the former, the lambda variables inside Q have wider\n",
      "scope over the variables in P (i.e. the universal\n",
      "quantifier variable of everybody has scope over the\n",
      "event variable of wants) contrary to the latter.\n",
      "The new s-expression for Figure 1(c) is\n",
      "(nsubj:univ (xcomp wants (mark\n",
      "(nsubj (dobj buy (det house a)) Ω) to))\n",
      "(BIND everybody Ω)) .\n",
      "\n",
      "Substituting with the modified expressions, and\n",
      "performing composition and simplification leads to\n",
      "the expression:\n",
      "(6) λ f . ∀x . person(xa ) →\n",
      "[∃zyw. f (z) ∧ wants(ze ) ∧ arg1 (ze , xa ) ∧ buy(ye )\n",
      "∧ xcomp(ze , ye ) ∧ house(wa )\n",
      "∧ arg1 (ze , xa ) ∧ arg2 (ze , wa )] .\n",
      "\n",
      "This expression is identical to (1) except for the\n",
      "outermost term λ f . By applying (6) to λx.TRUE,\n",
      "we obtain (1), which completes the treatment of\n",
      "universal quantification in UD EP L AMBDA.\n",
      "\n",
      "References\n",
      "Lucas Champollion. 2010. Quantification and negation\n",
      "in event semantics. Baltic International Yearbook of\n",
      "Cognition, Logic and Communication 6(1):3.\n",
      "Federico Fancellu, Siva Reddy, Adam Lopez, and Bonnie Webber. 2017. Universal Dependencies to Logical Forms with Negation Scope. arXiv Preprint .\n",
      "\n",
      "\f\n",
      "\n",
      "Siva Reddy, Oscar Täckström, Michael Collins, Tom\n",
      "Kwiatkowski, Dipanjan Das, Mark Steedman, and\n",
      "Mirella Lapata. 2016. Transforming Dependency\n",
      "Structures to Logical Forms for Semantic Parsing.\n",
      "Transactions of the Association for Computational\n",
      "Linguistics 4:127–140.\n",
      "Sebastian Schuster and Christopher D. Manning. 2016.\n",
      "Enhanced English Universal Dependencies: An Im-\n",
      "\n",
      "proved Representation for Natural Language Understanding Tasks. In Proceedings of the Tenth International Conference on Language Resources and Evaluation. European Language Resources Association\n",
      "(ELRA), Paris, France.\n",
      "Mark Steedman. 2012. Taking Scope - The Natural Semantics of Quantifiers. MIT Press.\n",
      "\n",
      "\f\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n\".join(pdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1702.03196.txt': '7\\n1\\n0\\n2\\n\\ng\\nu\\nA\\n8\\n2\\n\\n]\\nL\\nC\\n.\\ns\\nc\\n[\\n\\n4\\nv\\n6\\n9\\n1\\n3\\n0\\n.\\n2\\n0\\n7\\n1\\n:\\nv\\ni\\nX\\nr\\na\\n\\nUniversalSemanticParsingSivaReddy†∗OscarT¨ackstr¨om‡SlavPetrov‡MarkSteedman††MirellaLapata†††StanfordUniversity‡GoogleInc.††UniversityofEdinburghsivar@stanford.edu,{oscart,slav}@google.com,{steedman,mlap}@inf.ed.ac.ukAbstractUniversalDependencies(UD)offerauni-formcross-lingualsyntacticrepresentation,withtheaimofadvancingmultilingualap-plications.Recentworkshowsthatse-manticparsingcanbeaccomplishedbytransformingsyntacticdependenciestolog-icalforms.However,thisworkislim-itedtoEnglish,andcannotprocessde-pendencygraphs,whichallowhandlingcomplexphenomenasuchascontrol.Inthiswork,weintroduceUDEPLAMBDA,asemanticinterfaceforUD,whichmapsnaturallanguagetologicalformsinanalmostlanguage-independentfashionandcanprocessdependencygraphs.Weper-formexperimentsonquestionansweringagainstFreebaseandprovideGermanandSpanishtranslationsoftheWebQuestionsandGraphQuestionsdatasetstofacilitatemultilingualevaluation.ResultsshowthatUDEPLAMBDAoutperformsstrongbase-linesacrosslanguagesanddatasets.ForEnglish,itachievesa4.9F1pointimprove-mentoverthestate-of-the-artonGraph-Questions.1IntroductionTheUniversalDependencies(UD)initiativeseekstodevelopcross-linguisticallyconsistentannota-tionguidelinesaswellasalargenumberofuni-formlyannotatedtreebanksformanylanguages(Nivreetal.,2016).Suchresourcescouldadvancemultilingualapplicationsofparsing,improvecom-parabilityofevaluationresults,enablecross-linguallearning,andmoregenerallysupportnaturallan-guageunderstanding.∗WorkdoneattheUniversityofEdinburghSeekingtoexploitthebeneﬁtsofUDfornatu-rallanguageunderstanding,weintroduceUDEP-LAMBDA,asemanticinterfaceforUDthatmapsnaturallanguagetologicalforms,representingun-derlyingpredicate-argumentstructures,inanal-mostlanguage-independentmanner.Ourframe-workisbasedonDEPLAMBDA(Reddyetal.,2016)arecentlydevelopedmethodthatconvertsEnglishStanfordDependencies(SD)tologicalforms.TheconversionprocessisillustratedinFigure1anddiscussedinmoredetailinSection2.WhereasDEPLAMBDAworksonlyforEnglish,U-DEPLAMBDAappliestoanylanguageforwhichUDannotationsareavailable.1Moreover,DEP-LAMBDAcanonlyprocesstree-structuredinputswhereasUDEPLAMBDAcanalsoprocessdepen-dencygraphs,whichallowtohandlecomplexcon-structionssuchascontrol.ThedifferenttreatmentsofvariouslinguisticconstructionsinUDcomparedtoSDalsorequiredifferenthandlinginUDEP-LAMBDA(Section3.3).OurexperimentsfocusonFreebasesemanticparsingasatestbedforevaluatingtheframework’smultilingualappeal.Weconvertnaturallanguagetologicalformswhichinturnareconvertedtoma-chineinterpretableformalmeaningrepresentationsforretrievinganswerstoquestionsfromFreebase.Tofacilitatemultilingualevaluation,weprovidetranslationsoftheEnglishWebQuestions(Berantetal.,2013)andGraphQuestions(Suetal.,2016)datasetstoGermanandSpanish.WedemonstratethatUDEPLAMBDAcanbeusedtoderivelogicalformsfortheselanguagesusingaminimalamountoflanguage-speciﬁcknowledge.Asidefromdevel-opingtheﬁrstmultilingualsemanticparsingtoolforFreebase,wealsoexperimentallyshowthatU-DEPLAMBDAoutperformsstrongbaselinesacross1Asofv1.3,UDannotationsareavailablefor47languagesathttp://universaldependencies.org. \\n \\n \\n \\n \\n \\n\\x0clanguagesanddatasets.ForEnglish,itachievesthestrongestresulttodateonGraphQuestions,withcompetitiveresultsonWebQuestions.Ourimple-mentationandtranslateddatasetsarepubliclyavail-ableathttps://github.com/sivareddyg/udeplambda.2DEPLAMBDABeforedescribingUDEPLAMBDA,weprovideanoverviewofDEPLAMBDA(Reddyetal.,2016)onwhichourapproachisbased.DEPLAMBDAconvertsadependencytreetoitslogicalforminthreesteps:binarization,substitution,andcom-position,eachofwhichisbrieﬂyoutlinedbelow.Algorithm1describesthestepsofDEPLAMBDAinlines4-6,whereaslines2and3arespeciﬁctoUDEPLAMBDA.BinarizationAdependencytreeisﬁrstmappedtoaLisp-styles-expressionindicatingtheorderofsemanticcomposition.Figure1(b)showsthes-expressionforthesentenceDisneywonanOs-carforthemovieFrozen,derivedfromthedepen-dencytreeinFigure1(a).Here,thesub-expression(dobjwon(detOscaran))indicatesthatthelogi-calformofthephrasewonanOscarisderivedbycomposingthelogicalformofthelabeldobjwiththelogicalformofthewordwonandthelogicalformofthephraseanOscar,derivedanalogously.Thes-expressioncanalsobeinterpretedasabi-narizedtreewiththedependencylabelastherootnode,andtheleftandrightexpressionsassubtrees.Acompositionhierarchyisemployedtoimposeastricttraversalorderingonthemodiﬁerstoeachheadinthedependencytree.Asanexample,wonhasthreemodiﬁersinFigure1(a),whichaccordingtothecompositionhierarchyarecomposedintheorderdobj>nmod>nsubj.Inconstructionslikecoordination,thisorderingiscrucialtoarriveatthecorrectsemantics.Lines7-17inAlgorithm1describethebinarizationstep.SubstitutionEachsymbolinthes-expressionsissubstitutedforalambdaexpressionencodingitssemantics.Wordsanddependencylabelsareassigneddifferenttypesofexpressions.Ingeneral,wordshaveexpressionsofthefollowingkind:ENTITY⇒λx.word(xa);e.g.Oscar⇒λx.Oscar(xa)EVENT⇒λx.word(xe);e.g.won⇒λx.won(xe)FUNCTIONAL⇒λx.TRUE;e.g.an⇒λx.TRUEHere,thesubscripts·aand·edenotethetypesofindividuals(Ind)andevents(Event),respec-tively,whereasxdenotesapairedvariable(xa,xe)DisneywonanOscarforthemovieFrozenpropnverbdetpropnadpdetnounpropnnsubjdobjnmoddetcasedetcompoundroot(a)ThedependencytreeforDisneywonanOscarforthemovieFrozenintheUniversalDependenciesformalism.(nsubj(nmod(dobjwon(detOscaran))(case(det(comp.Frozenmovie)the)for))Disney)(b)Thebinarizeds-expressionforthedependencytree.λx.∃yzw.won(xe)∧Disney(ya)∧Oscar(za)∧Frozen(wa)∧movie(wa)∧arg1(xe,ya)∧arg2(xe,za)∧nmod.for(xe,wa)(c)Thecomposedlambda-calculusexpression.Figure1:Themappingofadependencytreetoitslogicalformwiththeintermediates-expression.oftypeInd×Event.Roughlyspeaking,propernounsandadjectivesinvokeENTITYexpressions,verbsandadverbsinvokeEVENTexpressions,andcommonnounsinvokebothENTITYandEVENTex-pressions(seeSection3.3),whileremainingwordsinvokeFUNCTIONALexpressions.DEPLAMBDAenforcestheconstraintthateverys-expressionisofthetypeη=Ind×Event→Bool,whichsimpli-ﬁesthetypesystemconsiderably.Expressionsfordependencylabelsgluethesemanticsofheadsandmodiﬁerstoarticulatepredicate-argumentstructure.Theseexpressionsingeneraltakeoneofthefollowingforms:COPY⇒λfgx.∃y.f(x)∧g(y)∧rel(x,y)e.g.nsubj,dobj,nmod,advmodINVERT⇒λfgx.∃y.f(x)∧g(y)∧reli(y,x)e.g.amod,aclMERGE⇒λfgx.f(x)∧g(x)e.g.compound,appos,amod,aclHEAD⇒λfgx.f(x)e.g.case,punct,aux,mark.AsanexampleofCOPY,considerthelambdaexpressionfordobjin(dobjwon(detOscaran)):λfgx.∃y.f(x)∧g(y)∧arg2(xe,ya).Thisexpres-siontakestwofunctionsfandgasinput,wherefrepresentsthelogicalformofwonandgrepre-sentsthelogicalformofanOscar.Thepredicate-argumentstructurearg2(xe,ya)indicatesthatthearg2oftheeventxe,i.e.won,istheindividualya,i.e.theentityOscar.Sincearg2(xe,ya)mimicsthedependencystructuredobj(won,Oscar),werefertotheexpressionkindevokedbydobjasCOPY.\\x0cExpressionsthatinvertthedependencydirec-tionarereferredtoasINVERT(e.g.amodinrun-ninghorse);expressionsthatmergetwosubexpres-sionswithoutintroducinganyrelationpredicatesarereferredtoasMERGE(e.g.compoundinmovieFrozen);andexpressionsthatsimplyreturnthepar-entexpressionsemanticsarereferredtoasHEAD(e.g.caseinforFrozen).Whilethisgeneralizationappliestomostdependencylabels,severallabelstakeadifferentlogicalformnotlistedhere,someofwhicharediscussedinSection3.3.Sometimesthemappingofdependencylabeltolambdaexpres-sionmaydependonsurroundingpart-of-speechtagsordependencylabels.Forexample,amodactsasINVERTwhenthemodiﬁerisaverb(e.g.inrun-ninghorse),andasMERGEwhenthemodiﬁerisanadjective(e.g.inbeautifulhorse).2Lines26-32inAlgorithm1describethesubstitutionprocedure.CompositionTheﬁnallogicalformiscomputedbybeta-reduction,treatingexpressionsoftheform(fxy)asthefunctionfappliedtotheargumentsxandy.Forexample,(dobjwon(detOscaran))resultsinλx.∃z.won(xe)∧Oscar(za)∧arg2(xe,za)whentheexpressionfordobjisappliedtothoseforwonand(detOscaran).Figure1(c)showsthelogicalformforthes-expressioninFigure1(b).Thebinarizeds-expressionisrecursivelyconvertedtoalogicalformasdescribedinlines18-25inAlgorithm1.3UDEPLAMBDAWenowintroduceUDEPLAMBDA,asemanticin-terfaceforUniversalDependencies.3WhereasDEPLAMBDAonlyappliestoEnglishStanfordDe-pendencies,UDEPLAMBDAtakesadvantageofthecross-lingualnatureofUDtofacilitatean(almost)languageindependentsemanticinterface.Thisisaccomplishedbyrestrictingthebinarization,sub-stitution,andcompositionstepsdescribedabovetorelysolelyoninformationencodedintheUDrepresentation.AsshowninAlgorithm1,lines4-6arecommontobothDEPLAMBDAandUDEP-LAMBDA,whereaslines2and3appliesonlytoUDEPLAMBDA.Importantly,UDEPLAMBDAisdesignedtonotrelyonlexicalformsinalanguage2WeuseTregex(LevyandAndrew,2006)forsubstitu-tionmappingsandCornellSPF(Artzi,2013)asthelambda-calculusimplementation.Forexample,inrunninghorse,thetregex/label:amod/=target</postag:verb/matchesamodtoitsINVERTexpressionλfgx.∃y.f(x)∧g(y)∧amodi(ye,xa).3Inwhatfollows,allreferencestoUDaretoUDv1.3.Algorithm1:UDEPLAMBDASteps1FunctionUDepLambda(depTree):2depGraph=Enhancement(depTree)#SeeFigure2(a)foradepGraph.3bindedTree=SplitLongDistance(depGraph)#SeeFigure2(b)forabindedTree.4binarizedTree=Binarization(bindedTree)#SeeFigure1(b)forabinarizedTree.5logicalForm=Composition(binarizedTree)6returnlogicalForm7FunctionBinarization(tree):8parent=GetRootNode(tree);9{(label1,child1),(label2,child2)...}=GetChildNodes(parent)10sortedChildren=SortUsingLabelHierarchy({(label1,child1),(label2,child2)...})11binarziedTree.root=parent12forlabel,child∈sortedChildren:13temp.root=label14temp.left=binarziedTree15temp.right=Binarization(child)16binarziedTree=temp17returnbinarizedTree18FunctionComposition(binarizedTree):19mainLF=Substitution(binarizedTree.root)20ifbinarziedTreehasleftandrightchildren:21leftLF=Composition(binarziedTree.left)22rightLF=Composition(binarziedTree.right)23mainLF=BetaReduce(mainLF,leftLF)24mainLF=BetaReduce(mainLF,rightLF)25returnmainLF26FunctionSubstitution(node):27logicalForms=[]28fortregexRule,template∈substitutionRules:29iftregexRule.match(node):30lf=GenLambdaExp(node,template)31logicalForms.add(lf)32returnlogicalFormstoassignlambdaexpressions,butonlyoninforma-tioncontainedindependencylabelsandpostags.However,somelinguisticphenomenaarelan-guagespeciﬁc(e.g.pronoun-dropping)orlexical-ized(e.g.everyandtheinEnglishhavedifferentsemantics,despitebeingbothdeterminers)andarenotencodedintheUDschema.Furthermore,somecross-linguisticphenomena,suchaslong-distancedependencies,arenotpartofthecoreUDrepresen-tation.Tocircumventthislimitation,asimpleen-hancementstepenrichestheoriginalUDrepresen-tationbeforebinarizationtakesplace(Section3.1).Thisstepaddstothedependencytreemissingsyn-tacticinformationandlong-distancedependencies,therebycreatingagraph.WhereasDEPLAMBDAisnotabletohandlegraph-structuredinput,UDEP-\\x0cLAMBDAisdesignedtoworkwithdependencygraphsaswell(Section3.2).Finally,severalcon-structionsdifferinstructurebetweenUDandSD,whichrequiresdifferenthandlinginthesemanticinterface(Section3.3).3.1EnhancementBothSchusterandManning(2016)andNivreetal.(2016)notethenecessityofanenhancedUDrep-resentationtoenablesemanticapplications.How-ever,suchenhancementsarecurrentlyonlyavail-ableforasubsetoflanguagesinUD.Instead,werelyonasmallnumberofenhancementsforourmainapplication—semanticparsingforquestion-answering—withthehopethatthisstepcanbere-placedbyanenhancedUDrepresentationinthefu-ture.Speciﬁcally,wedeﬁnethreekindsofenhance-ments:(1)long-distancedependencies;(2)typesofcoordination;and(3)reﬁnedquestionwordtags.Thesecorrespondtoline2inAlgorithm1.First,weidentifylong-distancedependenciesinrelativeclausesandcontrolconstructions.Wefol-lowSchusterandManning(2016)andﬁndtheseusingthelabelsacl(relative)andxcomp(control).Figure2(a)showsthelong-distancedependencyinthesentenceAnnawantstomarryKristoff.Here,marryisprovidedwithitsmissingnsubj(dashedarc).Second,UDconﬂatesallcoordinatingcon-structionstoasingledependencylabel,conj.Toobtainthecorrectcoordinationscope,wereﬁneconjtoconj:verb,conj:vp,conj:sentence,conj:np,andconj:adj,similartoReddyetal.(2016).Finally,unlikethePTBtags(Marcusetal.,1993)usedbySD,theUDpart-of-speechtagsdonotdistinguishquestionwords.Sincethesearecru-cialtoquestion-answering,weuseasmalllexicontoreﬁnethetagsfordeterminers(DET),adverbs(ADV)andpronouns(PRON)toDET:WH,ADV:WHandPRON:WH,respectively.Speciﬁcally,weusealistof12(English),14(Spanish)and35(Ger-man)words,respectively.ThisistheonlypartofUDEPLAMBDAthatreliesonlanguage-speciﬁcinformation.Wehopethat,asthecoverageofmor-phologicalfeaturesinUDimproves,thisreﬁne-mentcanbereplacedbyrelyingonmorphologicalfeatures,suchastheinterrogativefeature(INT).3.2GraphStructuresandBINDTohandlegraphstructuresthatmayresultfromtheenhancementstep,suchasthoseinFigure2(a),weproposeavariable-bindingmechanismthatdiffersAnnawantstomarryKristoﬀnsubjxcompmarkdobjnsubj(a)Withlong-distancedependency.AnnawantstomarryKristoﬀΩΩnsubjxcompmarkdobjbindnsubj(b)Withvariablebinding.Figure2:TheoriginalandenhanceddependencytreesforAnnawantstomarryKristoff.fromthatofDEPLAMBDA.Thisisindicatedinline3ofAlgorithm1.First,eachlong-distancedependencyissplitintoindependentarcsasshowninFigure2(b).Here,Ωisaplaceholderforthesub-jectofmarry,whichinturncorrespondstoAnnaasindicatedbythebindingofΩviathepseudo-labelBIND.WetreatBINDlikeanordinarydependencylabelwithsemanticsMERGEandprocesstheresult-ingtreeasusual,viathes-expression:(nsubj(xcompwants(nsubj(mark(dobjmarryKristoff)to)Ω)(BINDAnnaΩ)),withthelambda-expressionsubstitutions:wants,marry∈EVENT;to∈FUNCTIONAL;Anna,Kristoff∈ENTITY;mark∈HEAD;BIND∈MERGE;xcomp=λfgx.∃y.f(x)∧g(y)∧xcomp(xe,ye).Thesesubstitutionsarebasedsolelyonunlexi-calizedcontext.Forexample,thepart-of-speechtagPROPNofAnnainvokesanENTITYexpression.TheplaceholderΩhassemanticsλx.EQ(x,ω),whereEQ(u,ω)istrueiffuandωareequal(havethesamedenotation),whichuniﬁesthesubjectvari-ableofwantswiththesubjectvariableofmarry.Aftersubstitutionandcomposition,weget:λz.∃xywv.wants(ze)∧Anna(xa)∧arg1(ze,xa)∧EQ(x,ω)∧marry(ye)∧xcomp(ze,ye)∧arg1(ye,va)∧EQ(v,ω)∧Kristoff(wa)∧arg2(ye,wa),ThisexpressionmaybesimpliﬁedfurtherbyreplacingalloccurrencesofvwithxandremovingtheuniﬁcationpredicatesEQ,whichresultsin:λz.∃xyw.wants(ze)∧Anna(xa)∧arg1(ze,xa)∧marry(ye)∧xcomp(ze,ye)∧arg1(ye,xa)∧Kristoff(wa)∧arg2(ye,wa).\\x0cThisexpressionencodesthefactthatAnnaisthearg1ofthemarryevent,asdesired.DEPLAMBDA,incontrast,cannothandlegraph-structuredinput,sinceitlacksaprincipledwayofgeneratings-expressionsfromgraphs.Evengiventheaboves-expression,BINDinDEPLAMBDAisdeﬁnedinawaysuchthatthecompositionfailstounifyvandx,whichiscrucialforthecorrectsemantics.Moreover,thedeﬁnitionofBINDinDEPLAMBDAdoesnothaveaformalinterpretationwithinthelambdacalculus,unlikeours.3.3LinguisticConstructionsBelow,wehighlightthemostpertinentdifferencesbetweenUDEPLAMBDAandDEPLAMBDA,stem-mingfromthedifferenttreatmentofvariouslin-guisticconstructionsinUDversusSD.PrepositionalPhrasesUDusesacontent-headanalysis,incontrasttoSD,whichtreatsfunctionwordsasheadsofprepositionalphrases,Accord-ingly,thes-expressionforthephrasepresidentin2009is(nmodpresident(case2009in))inU-DEPLAMBDAand(preppresident(pobjin2009))inDEPLAMBDA.Toachievethedesiredsemantics,λx.∃y.president(xa)∧presidentevent(xe)∧arg1(xe,xa)∧2009(ya)∧prep.in(xe,ya),DEPLAMBDAreliesonanintermediatelogicalformthatrequiressomepost-processing,whereasUDEPLAMBDAobtainsthedesiredlogicalformdirectlythroughthefollowingentries:in∈FUNCTIONAL;2009∈ENTITY;case∈HEAD;president=λx.president(xa)∧presidentevent(xe)∧arg1(xe,xa);nmod=λfgx.∃y.f(x)∧g(y)∧nmod.in(xe,ya).Othernmodconstructions,suchaspossessives(nmod:poss),temporalmodiﬁers(nmod:tmod)andadverbialmodiﬁers(nmod:npmod),arehan-dledsimilarly.Notehowthecommonnounpresi-dent,evokesbothentityandeventpredicatesabove.PassivesDEPLAMBDAgivesspecialtreatmenttopassiveverbs,identiﬁedbytheﬁne-grainedpart-of-speechtagsinthePTBtagtogetherwithde-pendencycontext.Forexample,AnOscarwaswonisanalyzedasλx.won.pass(xe)∧Oscar(ya)∧arg1(xe,ya),wherewon.passrepresentsapassiveevent.However,UDdoesnotdistinguishbe-tweenactiveandpassiveforms.4Whilethelabels4UDencodesvoiceasamorphologicalfeature,butmostsyntacticanalyzersdonotproducethisinformationyet.nsubjpassorauxpassindicatepassiveconstruc-tions,suchcluesaresometimesmissing,suchasinreducedrelatives.Wethereforeopttonothavesep-arateentriesforpassives,butaimtoproduceidenti-callogicalformsforactiveandpassiveformswhenpossible(forexample,bytreatingnsubjpassasdirectobject).Withthefollowingentries,won∈EVENT;an,was∈FUNCTIONAL;auxpass∈HEAD;nsubjpass=λfgx.∃y.f(x)∧g(y)∧arg2(xe,ya),thelambdaexpressionforAnOscarwaswonbe-comesλx.won(xe)∧Oscar(ya)∧arg2(xe,ya),iden-ticaltothatofitsactiveform.However,nothavingaspecialentryforpassiveverbsmayhaveunde-sirableside-effects.Forexample,inthereduced-relativeconstructionPixarclaimedtheOscarwonforFrozen,thephrasetheOscarwon...willreceivethesemanticsλx.Oscar(ya)∧won(xe)∧arg1(xe,ya),whichdiffersfromthatofanOscarwaswon.Weleaveittothetargetapplicationtodisambiguatetheinterpretationinsuchcases.Long-DistanceDependenciesAsdiscussedinSection3.2,wehandlelong-distancedependen-ciesevokedbyclausalmodiﬁers(acl)andcon-trolverbs(xcomp)withtheBINDmechanism,whereasDEPLAMBDAcannothandlecontrolcon-structions.Forxcomp,asseenearlier,weusethemappingλfgx.∃y.f(x)∧g(y)∧xcomp(xe,ye).Foraclweuseλfgx.∃y.f(x)∧g(y),toconjointhemainclauseandthemodiﬁerclause.However,notallaclclausesevokelong-distancedependencies,e.g.inthenewsthatDisneywonanOscar,theclausethatDisneywonanOscarisasubordinatingconjunctionofnews.Insuchcases,weinsteadassignacltheINVERTsemantics.QuestionsQuestionwordsaremarkedwiththeenhancedpart-of-speechtagsDET:WH,ADV:WHandPRON:WH,whichareallassignedtheseman-ticsλx.${word}(xa)∧TARGET(xa).ThepredicateTARGETindicatesthatxarepresentsthevariableofinterest,thatistheanswertothequestion.3.4LimitationsInordertoachievelanguageindependence,UDEP-LAMBDAhastosacriﬁcesemanticspeciﬁcity,sinceinmanycasesthesemanticsiscarriedbylexicalinformation.ConsiderthesentencesJohnbrokethewindowandThewindowbroke.Althoughitisthewindowthatbrokeinbothcases,ourinferredlogicalformsdonotcanonicalizetherelationbe-tweenbrokeandwindow.Toachievethis,we\\x0clanguagetargetpeoplexe1ye2Ghanaspeak.arg2speak.arg1people.arg1people.nmod.intypetype(a)Englishsprachetargetxe1Ghanagesprochen.arg2gesprochen.nmod.intype(b)Germanlenguatargetxe1Ghanalengua.arg1lengua.nmod.detype(c)Spanishlanguage.humanlanguagetargetxmGhanalocation.country.oﬃciallanguage.2location.country.oﬃciallanguage.1type(d)FreebaseFigure3:TheungroundedgraphsforWhatlanguagedothepeopleinGhanaspeak?,WelcheSprachewirdinGhanagesprochen?andCu´aleslalenguadeGhana?,andthecorrespondinggroundedgraph.wouldhavetomakethesubstitutionofnsubjde-pendonlexicalcontext,suchthatwhenwindowoccursasnsubjwithbroke,thepredicatearg2isinvokedratherthanarg1.UDEPLAMBDAdoesnotaddressthisproblem,andleaveittothetar-getapplicationtoinfercontext-sensitivesemanticsofarg1andarg2.Tomeasuretheimpactofthislimitation,wepresentUDEPLAMBDASRLinSec-tion4.4whichaddressesthisproblembyrelyingonsemanticrolesfromsemanticrolelabeling(Palmeretal.,2010).Otherconstructionsthatrequirelexicalinforma-tionarequantiﬁerslikeevery,someandmost,nega-tionmarkerslikenoandnot,andintentionalverbslikebelieveandsaid.UDdoesnothavespeciallabelstoindicatethese.Wediscusshowtohandlequantiﬁersinthisframeworkinthesupplementarymaterial.AlthoughinthecurrentsetupUDEPLAMBDArulesarehand-coded,thenumberofrulesareonlyproportionaltothenumberofUDlabels,mak-ingrule-writingmanageable.5Moreover,weviewUDEPLAMBDAasaﬁrststeptowardslearningrulesforconvertingUDtorichersemanticrepre-sentationssuchasPropBank,AMR,ortheParal-lelMeaningBank(Palmeretal.,2005;Banarescuetal.,2013;Abzianidzeetal.,2017)..4Cross-lingualSemanticParsingTostudythemultilingualnatureofUDEPLAMBDA,weconductanempiricalevaluationonquestionansweringagainstFreebaseinthreedifferentlan-guages:English,Spanish,andGerman.Beforediscussingthedetailsofthisexperiment,webrieﬂyoutlinethesemanticparsingframeworkemployed.5UDv1.3has40dependencylabels,andthenumberofsubstitutionrulesinUDEPLAMBDAare61,withsomelabelshavingmultiplerules,andsomerepresentinglexicalseman-tics.4.1SemanticParsingasGraphMatchingUDEPLAMBDAgeneratesungroundedlogicalformsthatareindependentofanyknowledgebase,suchasFreebase.WeuseGRAPHPARSER(Reddyetal.,2016)tomaptheselogicalformstotheirgroundedFreebasegraphs,viacorrespondingun-groundedgraphs.Figures3(a)to3(c)showtheungroundedgraphscorrespondingtologicalformsfromUDEPLAMBDA,eachgroundedtothesameFreebasegraphinFigure3(d).Here,rectanglesde-noteentities,circlesdenoteevents,roundedrectan-glesdenoteentitytypes,andedgesbetweeneventsandentitiesdenotepredicatesorFreebaserelations.Finally,theTARGETnoderepresentsthesetofval-uesofxthatareconsistentwiththeFreebasegraph,thatistheanswertothequestion.GRAPHPARSERtreatssemanticparsingasagraph-matchingproblemwiththegoalofﬁndingtheFreebasegraphsthatarestructurallyisomorphictoanungroundedgraphandrankthemaccordingtoamodel.Toaccountforstructuralmismatches,GRAPHPARSERusestwographtransformations:CONTRACTandEXPAND.InFigure3(a)therearetwoedgesbetweenxandGhana.CONTRACTcol-lapsesoneoftheseedgestocreateagraphisomor-phictoFreebase.EXPAND,incontrast,addsedgestoconnectthegraphinthecaseofdisconnectedcomponents.Thesearchspaceisexploredbybeamsearchandmodelparametersareestimatedwiththeaveragedstructuredperceptron(Collins,2002)fromtrainingdataconsistingofquestion-answerpairs,usinganswerF1-scoreastheobjective.4.2DatasetsWeevaluateourapproachontwopublicbench-marksofquestionansweringagainstFreebase:WebQuestions(Berantetal.,2013),awidelyusedbenchmarkconsistingofEnglishquestionsandtheiranswers,andGraphQuestions(Suetal.,2016),arecentlyreleaseddatasetofEnglishquestionswithboththeiranswersandgroundedlogicalforms.\\x0cWhileWebQuestionsisdominatedbysimpleentity-attributequestions,GraphQuestionscontainsalargenumberofcompositionalquestionsinvolvingaggregation(e.g.HowmanychildrenofEddardStarkwereborninWinterfell?)andcomparison(e.g.InwhichmonthdoestheaveragerainfallofNewYorkCityexceed86mm?).Thenumberoftraining,developmentandtestquestionsis2644,1134,and2032,respectively,forWebQuestionsand1794,764,and2608forGraphQuestions.Tosupportmultilingualevaluation,wecreatedtranslationsofWebQuestionsandGraphQuestionstoGermanandSpanish.ForWebQuestionstwoprofessionalannotatorswerehiredperlanguage,whileforGraphQuestionsweusedatrustedpoolof20annotatorsperlanguage(withasingleannotatorperquestion).ExamplesoftheoriginalquestionsandtheirtranslationsareprovidedinTable1.4.3ImplementationDetailsHereweprovidedetailsonthesyntacticanalyzersemployed,ourentityresolutionalgorithm,andthefeaturesusedbythegroundingmodel.DependencyParsingTheEnglish,Spanish,andGermanUniversalDependencies(UD)treebanks(v1.3;Nivreetal2016)wereusedtotrainpartofspeechtaggersanddependencyparsers.WeusedabidirectionalLSTMtagger(Planketal.,2016)andabidirectionalLSTMshift-reduceparser(Kiper-wasserandGoldberg,2016).Boththetaggerandparserrequirewordembeddings.ForEnglish,weusedGloVeembeddings(Penningtonetal.,2014)trainedonWikipediaandtheGigawordcorpus.ForGermanandSpanish,weusedSENNAem-beddings(Collobertetal.,2011;Al-Rfouetal.,2013)trainedonWikipediacorpora(589MwordsGerman;397MwordsSpanish).6MeasuredontheUDtestsets,thetaggeraccuraciesare94.5(En-glish),92.2(German),and95.7(Spanish),withcorrespondinglabeledattachmentparserscoresof81.8,74.7,and82.2.EntityResolutionWefollowReddyetal.(2016)andresolveentitiesinthreesteps:(1)potentialen-tityspansareidentiﬁedusingsevenhandcraftedpart-of-speechpatterns;(2)eachspanisassociatedwithpotentialFreebaseentitiesaccordingtotheFreebase/KGAPI;and(3)the10-bestentitylink-inglattices,scoredbyastructuredperceptron,are6https://sites.google.com/site/rmyeid/projects/polyglot.WebQuestionsenWhatlanguagedothepeopleinGhanaspeak?deWelcheSprachewirdinGhanagesprochen?es¿Cu´aleslalenguadeGhana?enWhowasVincentvanGoghinspiredby?deVonwemwurdeVincentvanGoghinspiriert?es¿Qu´einspir´oaVanGogh?GraphQuestionsenNASAhashowmanylaunchsites?deWievieleAbschussbasenbesitztNASA?es¿Cu´antossitiosdedespeguetieneNASA?enWhichloudspeakersareheavierthan82.0kg?deWelcheLautsprechersindschwererals82.0kg?es¿Qu´ealtavocespesanm´asde82.0kg?Table1:Examplequestionsandtheirtranslations.kWebQuestionsGraphQuestionsendeesendees189.682.886.747.239.939.51095.791.294.056.948.451.6Table2:Structuredperceptronk-bestentitylinkingaccuraciesonthedevelopmentsets.inputtoGRAPHPARSER,leavingtheﬁnaldisam-biguationtothesemanticparsingproblem.Table2showsthe1-bestand10-bestentitydisambiguationF1-scoresforeachlanguageanddataset.FeaturesWeusefeaturessimilartoReddyetal.(2016):basicfeaturesofwordsandFreebasere-lations,andgraphfeaturescrossingungroundedeventswithgroundedrelations,ungroundedtypeswithgroundedrelations,andungroundedanswertypecrossedwithabinaryfeatureindicatingiftheanswerisanumber.Inaddition,weaddfeaturesencodingthesemanticsimilarityofungroundedeventsandFreebaserelations.Speciﬁcally,weusedthecosinesimilarityofthetranslation-invariantem-beddingsofHuangetal.(2015).74.4ComparisonSystemsWecomparedUDEPLAMBDAtofourversionsofGRAPHPARSERthatoperateondifferentrepresen-tations,inadditiontopriorwork.SINGLEEVENTThismodelresemblesthelearning-to-rankmodelofBastandHaussmann(2015).Anungroundedgraphisgeneratedbycon-nectingallentitiesinthequestionwiththeTARGETnode,representingasingleevent.Notethatthis7http://128.2.220.95/multilingual/data/.\\x0cWebQuestionsGraphQuestionsMethodendeesendeesSINGLEEVENT48.545.646.315.98.811.4DEPTREE48.845.946.416.08.311.3CCGGRAPH49.5––15.9––UDEPLAMBDA49.546.147.517.79.512.8UDEPLAMBDASRL49.846.247.017.79.112.7Table3:F1-scoresonthetestdata.baselinecannothandlecompositionalquestions,orthosewithaggregationorcomparison.DEPTREEAnungroundedgraphisobtaineddi-rectlyfromtheoriginaldependencytree.Aneventiscreatedforeachparentanditsdependentsinthetree.Eachdependentislinkedtothiseventwithanedgelabeledwithitsdependencyrelation,whiletheparentislinkedtotheeventwithanedgelabeledarg0.Ifawordisaquestionword,anadditionalTARGETpredicateisattachedtoitsentitynode.CCGGRAPHThisistheCCG-basedsemanticrepresentationofReddyetal.(2014).NotethatthisbaselineexistsonlyforEnglish.UDEPLAMBDASRLThisissimilartoUDEP-LAMBDAexceptthatinsteadofassumingnsubj,dobjandnsubjpasscorrespondtoarg1,arg2andarg2,weemploysemanticrolelabelingtoidentifythecorrectinterpretation.WeusedthesystemsofRothandWoodsend(2014)forEnglishandGer-manandBjrkelundetal.(2009)forSpanishtrainedontheCoNLL-2009dataset(Hajietal.,2009).84.5ResultsTable3showstheperformanceofGRAPHPARSERwiththesedifferentrepresentations.Hereandinwhatfollows,weuseaverageF1-scoreofpredictedanswers(Berantetal.,2013)astheevaluationmet-ric.WeﬁrstobservethatUDEPLAMBDAconsis-tentlyoutperformstheSINGLEEVENTandDEP-TREErepresentationsinalllanguages.ForEnglish,performanceisonparwithCCG-GRAPH,whichsuggeststhatUDEPLAMBDAdoesnotsacriﬁcetoomuchspeciﬁcityforuniversal-ity.Withbothdatasets,resultsarelowerforGer-mancomparedtoSpanish.ThisagreeswiththelowerperformanceofthesyntacticparserontheGermanportionoftheUDtreebank.WhileU-DEPLAMBDASRLperformsbetterthanUDEP-8Theparseraccuracies(%)are87.33,81.38and79.91forEnglish,GermanandSpanishrespectively.MethodGraphQ.WebQ.SEMPRE(Berantetal.,2013)10.835.7JACANA(YaoandVanDurme,2014)5.133.0PARASEMPRE(BerantandLiang,2014)12.839.9QA(Yao,2015)–44.3AQQU(BastandHaussmann,2015)–49.4AGENDAIL(BerantandLiang,2015)–49.7DEPLAMBDA(Reddyetal.,2016)–50.3STAGG(Yihetal.,2015)–48.4(52.5)BILSTM(T¨ureandJojic,2016)–24.9(52.2)MCNN(Xuetal.,2016)–47.0(53.3)AGENDAIL-RANK(Yavuzetal.,2016)–51.6(52.6)UDEPLAMBDA17.749.5Table4:F1-scoresontheEnglishGraphQuestionsandWebQuestionstestsets(resultswithadditionaltask-speciﬁcresourcesinparentheses).LAMBDAonWebQuestionsforEnglish,wedonotseelargeperformancegapsinothersettings,sug-gestingthatGRAPHPARSERiseitherabletolearncontext-sensitivesemanticsofungroundedpredi-catesorthatthedatasetsdonotcontainambiguousnsubj,dobjandnsubjpassmappings.Finally,whiletheseresultsconﬁrmthatGraphQuestionsismuchhardercomparedtoWebQuestions,wenotethatbothdatasetspredominantlycontainsingle-hopquestions,asindicatedbythecompetitiveperfor-manceofSINGLEEVENTonbothdatasets.Table4comparesUDEPLAMBDAwithprevi-ouslypublishedmodelswhichexistonlyforEn-glishandhavebeenmainlyevaluatedonWeb-Questions.Theseareeithersymboliclikeours(ﬁrstblock)oremployneuralnetworks(secondblock).Resultsformodelsusingadditionaltask-speciﬁctrainingresources,suchasClueWeb09,Wikipedia,orSimpleQuestions(Bordesetal.,2015)areshowninparentheses.OnGraphQuestions,weachieveanewstate-of-the-artresultwithagainof4.8F1-pointsoverthepreviouslyreportedbestresult.OnWebQuestionsweare2.1pointsbelowthebestmodelusingcomparableresources,and3.8pointsbelowthestateoftheart.MostrelatedtoourworkistheEnglish-speciﬁcsystemofReddyetal.(2016).Weattributethe0.8pointdifferenceinF1-scoretotheiruseofthemoreﬁne-grainedPTBtagsetandStanfordDependencies.5RelatedWorkOurworkcontinuesthelongtraditionofbuildinglogicalformsfromsyntacticrepresentationsiniti-atedbyMontague(1973).Theliteratureisrifewith\\x0cattemptstodevelopsemanticinterfacesforHPSG(Copestakeetal.,2005),LFG(KaplanandBresnan,1982;Dalrympleetal.,1995;CrouchandKing,2006),TAG(KallmeyerandJoshi,2003;GardentandKallmeyer,2003;NessonandShieber,2006),andCCG(BaldridgeandKruijff,2002;Bosetal.,2004;Artzietal.,2015).Unlikeexistingsemanticinterfaces,UDEPLAMBDAusesdependencysyn-tax,awidelyavailablesyntacticresource.Acommontrendinpreviousworkonseman-ticinterfacesistherelianceonrichtypedfeaturestructuresorsemantictypescoupledwithstrongtypeconstraints,whichcanbeveryinformativebutunavoidablylanguagespeciﬁc.Instead,UDEP-LAMBDAreliesongenericunlexicalizedinforma-tionpresentindependencytreebanksandusesasimpletypesystem(onetypefordependencylabels,andoneforwords)alongwithacombinatorymech-anism,whichavoidstypecollisions.Earlierat-temptsatextractingsemanticrepresentationsfromdependencieshavemainlyfocusedonlanguage-speciﬁcdependencyrepresentations(SpreyerandFrank,2005;SimovandOsenova,2011;HahnandMeurers,2011;Reddyetal.,2016;Falkeetal.,2016;Beltagy,2016),andmulti-layereddepen-dencyannotations(Jakobetal.,2010;B´edarideandGardent,2011).Incontrast,UDEPLAMBDAderivessemanticrepresentationsformultiplelan-guagesinacommonschemadirectlyfromUniver-salDependencies.Thisworkparallelsagrowinginterestincreatingotherformsofmultilingualse-manticrepresentations(Akbiketal.,2015;Vander-wendeetal.,2015;Whiteetal.,2016;EvangandBos,2016).WeevaluateUDEPLAMBDAonsemanticpars-ingforquestionansweringagainstaknowledgebase.Here,theliteratureofferstwomainmodelingparadigms:(1)learningoftask-speciﬁcgrammarsthatdirectlyparselanguagetoagroundedrepre-sentation(ZelleandMooney,1996;ZettlemoyerandCollins,2005;Berantetal.,2013;Flaniganetal.,2014;PasupatandLiang,2015;Groschwitzetal.,2015);and(2)convertinglanguagetoalin-guisticallymotivatedtask-independentrepresenta-tionthatisthenmappedtoagroundedrepresenta-tion(Kwiatkowskietal.,2013;Reddyetal.,2014;KrishnamurthyandMitchell,2015;GardnerandKrishnamurthy,2017).Ourworkbelongstothelatterparadigm,aswemapnaturallanguagetoFreebaseindirectlyvialogicalforms.Capitalizingonnatural-languagesyntaxaffordsinterpretability,scalability,andreducedduplicationofeffortacrossapplications(Benderetal.,2015).Ourworkalsore-latestoliteratureonparsingmultiplelanguagestoacommonexecutablerepresentation(Cimianoetal.,2013;HaasandRiezler,2016).However,existingapproachesstillmaptothetargetmeaningrepresen-tations(moreorless)directly(Kwiatkowksietal.,2010;Jonesetal.,2012;JieandLu,2014).6ConclusionsWeintroducedUDEPLAMBDA,asemanticinter-faceforUniversalDependencies,andshowedthattheresultingsemanticrepresentationcanbeusedforquestion-answeringagainstaknowledgebaseinmultiplelanguages.WeprovidedtranslationsofbenchmarkdatasetsinGermanandSpanish,inthehopetostimulatefurthermultilingualresearchonsemanticparsingandquestionansweringingen-eral.WehaveonlyscratchedthesurfacewhenitcomestoapplyingUDEPLAMBDAtonaturallan-guageunderstandingtasks.Inthefuture,wewouldliketoexplorehowthisframeworkcanbeneﬁtap-plicationssuchassummarization(Liuetal.,2015)andmachinereading(SachanandXing,2016).AcknowledgementsThisworkgreatlybeneﬁtedfromdiscussionswithMichaelCollins,DipanjanDas,FedericoFancellu,JuliaHockenmaier,TomKwiatkowski,AdamLopez,ValeriadePaiva,MarthaPalmer,FernandoPereira,EmilyPitler,VijaySaraswat,NathanSchneider,BonnieWebber,LukeZettlemoyer,andthemembersofILCCEdinburghUniversity,theMicrosoftResearchRedmondNLPgroup,theStan-fordNLPgroup,andtheUWNLPandLinguisticsgroup.WethankReviewer2forusefulfeedback.TheauthorswouldalsoliketothanktheUniver-salDependenciescommunityforthetreebanksanddocumentation.ThisresearchissupportedbyaGooglePhDFellowshiptotheﬁrstauthor.Weac-knowledgetheﬁnancialsupportoftheEuropeanResearchCouncil(Lapata;awardnumber681760).ReferencesLashaAbzianidze,JohannesBjerva,KilianEvang,HesselHaagsma,RikvanNoord,PierreLudmann,Duc-DuyNguyen,andJohanBos.2017.ThePar-allelMeaningBank:TowardsaMultilingualCor-pusofTranslationsAnnotatedwithCompositionalMeaningRepresentations.InProceedingsofthe\\x0cEuropeanChapteroftheAssociationforCompu-tationalLinguistics.AssociationforComputationalLinguistics,Valencia,Spain,pages242–247.AlanAkbik,laurachiticariu,MarinaDanilevsky,Yun-yaoLi,ShivakumarVaithyanathan,andHuaiyuZhu.2015.GeneratingHighQualityPropositionBanksforMultilingualSemanticRoleLabeling.InPro-ceedingsoftheAssociationforComputationalLin-guisticsandtheInternationalJointConferenceonNaturalLanguageProcessing.AssociationforCom-putationalLinguistics,Beijing,China,pages397–407.RamiAl-Rfou,BryanPerozzi,andStevenSkiena.2013.Polyglot:DistributedWordRepresentationsforMultilingualNLP.InProceedingsoftheCom-putationalNaturalLanguageLearning.Soﬁa,Bul-garia,pages183–192.YoavArtzi.2013.CornellSPF:CornellSemanticPars-ingFramework.arXiv:1311.3011[cs.CL].YoavArtzi,KentonLee,andLukeZettlemoyer.2015.Broad-coverageCCGSemanticParsingwithAMR.InProceedingsoftheEmpiricalMethodsonNaturalLanguageProcessing.pages1699–1710.JasonBaldridgeandGeert-JanKruijff.2002.CouplingCCGandHybridLogicDependencySemantics.InProceedingsoftheAssociationforComputationalLinguistics.pages319–326.LauraBanarescu,ClaireBonial,ShuCai,MadalinaGeorgescu,KiraGrifﬁtt,UlfHermjakob,KevinKnight,PhilippKoehn,MarthaPalmer,andNathanSchneider.2013.AbstractMeaningRepresentationforSembanking.InLinguisticAnnotationWorkshopandInteroperabilitywithDiscourse.Soﬁa,Bulgaria,pages178–186.HannahBastandElmarHaussmann.2015.MoreAc-curateQuestionAnsweringonFreebase.InPro-ceedingsofACMInternationalConferenceonInfor-mationandKnowledgeManagement.pages1431–1440.PaulB´edarideandClaireGardent.2011.DeepSeman-ticsforDependencyStructures.InProceedingsofConferenceonIntelligentTextProcessingandCom-putationalLinguistics.pages277–288.IslamBeltagy.2016.NaturalLanguageSemanticsUs-ingProbabilisticLogic.Ph.D.thesis,DepartmentofComputerScience,TheUniversityofTexasatAustin.EmilyM.Bender,DanFlickinger,StephanOepen,WoodleyPackard,andAnnCopestake.2015.Lay-ersofInterpretation:OnGrammarandComposition-ality.InProceedingsoftheInternationalConfer-enceonComputationalSemantics.AssociationforComputationalLinguistics,London,UK,pages239–249.JonathanBerant,AndrewChou,RoyFrostig,andPercyLiang.2013.SemanticParsingonFreebasefromQuestion-AnswerPairs.InProceedingsoftheEm-piricalMethodsonNaturalLanguageProcessing.pages1533–1544.JonathanBerantandPercyLiang.2014.SemanticPars-ingviaParaphrasing.InProceedingsoftheAsso-ciationforComputationalLinguistics.pages1415–1425.JonathanBerantandPercyLiang.2015.ImitationLearningofAgenda-BasedSemanticParsers.Trans-actionsoftheAssociationforComputationalLin-guistics3:545–558.AndersBjrkelund,LoveHafdell,andPierreNugues.2009.MultilingualSemanticRoleLabeling.InProceedingsofComputationalNaturalLanguageLearning(CoNLL2009):SharedTask.AssociationforComputationalLinguistics,Boulder,Colorado,pages43–48.AntoineBordes,NicolasUsunier,SumitChopra,andJasonWeston.2015.Large-scalesimpleques-tionansweringwithmemorynetworks.CoRRabs/1506.02075.JohanBos,StephenClark,MarkSteedman,JamesR.Curran,andJuliaHockenmaier.2004.Wide-CoverageSemanticRepresentationsfromaCCGParser.InProceedingsoftheConferenceonCom-putationalLinguistics.pages1240–1246.PhilippCimiano,VanessaLopez,ChristinaUnger,ElenaCabrio,Axel-CyrilleNgongaNgomo,andSebastianWalter.2013.Multilingualquestionan-sweringoverlinkeddata(QALD-3):Laboverview.InInformationAccessEvaluation.Multilinguality,Multimodality,andVisualization.Springer,Valencia,Spain,volume8138.MichaelCollins.2002.DiscriminativeTrainingMeth-odsforHiddenMarkovModels:TheoryandExper-imentswithPerceptronAlgorithms.InProceedingsoftheEmpiricalMethodsonNaturalLanguagePro-cessing.pages1–8.RonanCollobert,JasonWeston,LeonBottou,MichaelKarlen,KorayKavukcuoglu,andPavelKuks.2011.Naturallanguageprocessing(almost)fromscratch.JournalofMachineLearningResearch12:2493–2537.AnnCopestake,DanFlickinger,CarlPollard,andIvanA.Sag.2005.MinimalRecursionSemantics:AnIntroduction.ResearchonLanguageandCom-putation3(2-3):281–332.DickCrouchandTracyHollowayKing.2006.Seman-ticsviaf-structurerewriting.InProceedingsoftheLFG’06Conference.CSLIPublications,page145.MaryDalrymple,JohnLamping,FernandoC.N.Pereira,andVijayA.Saraswat.1995.LinearLogicforMeaningAssembly.InProceedingsofComputa-tionalLogicforNaturalLanguageProcessing.\\x0cKilianEvangandJohanBos.2016.Cross-lingualLearningofanOpen-domainSemanticParser.InProceedingsoftheConferenceonComputationalLinguistics.TheCOLING2016OrganizingCom-mittee,Osaka,Japan,pages579–588.TobiasFalke,GabrielStanovsky,IrynaGurevych,andIdoDagan.2016.PortinganOpenInformationEx-tractionSystemfromEnglishtoGerman.InPro-ceedingsoftheEmpiricalMethodsinNaturalLan-guageProcessing.AssociationforComputationalLinguistics,Austin,Texas,pages892–898.JeffreyFlanigan,SamThomson,JaimeCarbonell,ChrisDyer,andNoahA.Smith.2014.ADiscrimi-nativeGraph-BasedParserfortheAbstractMeaningRepresentation.InProceedingsoftheAssociationforComputationalLinguistics.pages1426–1436.ClaireGardentandLauraKallmeyer.2003.SemanticConstructioninFeature-basedTAG.InProceedingsofEuropeanChapteroftheAssociationforCompu-tationalLinguistics.pages123–130.MattGardnerandJayantKrishnamurthy.2017.Open-VocabularySemanticParsingwithbothDistribu-tionalStatisticsandFormalKnowledge.InProceed-ingsofAssociationfortheAdvancementofArtiﬁcialIntelligence.JonasGroschwitz,AlexanderKoller,andChristophTe-ichmann.2015.Graphparsingwiths-graphgram-mars.InProceedingsoftheAssociationforCompu-tationalLinguistics.pages1481–1490.CarolinHaasandStefanRiezler.2016.ACorpusandSemanticParserforMultilingualNaturalLanguageQueryingofOpenStreetMap.InProceedingsoftheNorthAmericanChapteroftheAssociationforComputationalLinguistics:HumanLanguageTech-nologies.AssociationforComputationalLinguistics,SanDiego,California,pages740–750.MichaelHahnandDetmarMeurers.2011.Onderiv-ingsemanticrepresentationsfromdependencies:Apracticalapproachforevaluatingmeaninginlearnercorpora.InProceedingsoftheInt.ConferenceonDependencyLinguistics(Depling2011).Barcelona,pages94–103.JanHaji,MassimilianoCiaramita,RichardJohans-son,DaisukeKawahara,MariaAntniaMart,LlusMrquez,AdamMeyers,JoakimNivre,SebastianPad,Jantpnek,andothers.2009.TheCoNLL-2009sharedtask:Syntacticandsemanticdependenciesinmultiplelanguages.InProceedingsoftheCompu-tationalNaturalLanguageLearning:SharedTask.AssociationforComputationalLinguistics,pages1–18.KejunHuang,MattGardner,EvangelosPapalex-akis,ChristosFaloutsos,NikosSidiropoulos,TomMitchell,ParthaP.Talukdar,andXiaoFu.2015.TranslationInvariantWordEmbeddings.InPro-ceedingsoftheEmpiricalMethodsinNaturalLan-guageProcessing.Lisbon,Portugal,pages1084–1088.MaxJakob,Mark´etaLopatkov´a,andValiaKordoni.2010.MappingbetweenDependencyStructuresandCompositionalSemanticRepresentations.InPro-ceedingsoftheFifthInternationalConferenceonLanguageResourcesandEvaluation.ZhanmingJieandWeiLu.2014.MultilingualSeman-ticParsing:ParsingMultipleLanguagesintoSe-manticRepresentations.InProceedingsoftheCon-ferenceonComputationalLinguistics.DublinCityUniversityandAssociationforComputationalLin-guistics,Dublin,Ireland,pages1291–1301.BevanKeeleyJones,MarkJohnson,andSharonGold-water.2012.SemanticParsingwithBayesianTreeTransducers.InProceedingsoftheAssociationforComputationalLinguistics.AssociationforCompu-tationalLinguistics,Stroudsburg,PA,USA,pages488–496.LauraKallmeyerandAravindJoshi.2003.Factor-ingpredicateargumentandscopesemantics:Under-speciﬁedsemanticswithLTAG.ResearchonLan-guageandComputation1(1-2):3–58.RonaldMKaplanandJoanBresnan.1982.Lexical-functionalgrammar:Aformalsystemforgram-maticalrepresentation.FormalIssuesinLexical-FunctionalGrammarpages29–130.EliyahuKiperwasserandYoavGoldberg.2016.Sim-pleandAccurateDependencyParsingUsingBidi-rectionalLSTMFeatureRepresentations.Transac-tionsoftheAssociationforComputationalLinguis-tics4:313–327.JayantKrishnamurthyandTomM.Mitchell.2015.LearningaCompositionalSemanticsforFreebasewithanOpenPredicateVocabulary.TransactionsoftheAssociationforComputationalLinguistics3:257–270.TomKwiatkowksi,LukeZettlemoyer,SharonGoldwa-ter,andMarkSteedman.2010.InducingProbabilis-ticCCGGrammarsfromLogicalFormwithHigher-OrderUniﬁcation.InProceedingsoftheEmpiri-calMethodsonNaturalLanguageProcessing.pages1223–1233.TomKwiatkowski,EunsolChoi,YoavArtzi,andLukeZettlemoyer.2013.ScalingSemanticParserswithOn-the-FlyOntologyMatching.InProceedingsoftheEmpiricalMethodsonNaturalLanguagePro-cessing.pages1545–1556.RogerLevyandGalenAndrew.2006.Tregexandtsur-geon:toolsforqueryingandmanipulatingtreedatastructures.InProceedingsofLREC.pages2231–2234.\\x0cFeiLiu,JeffreyFlanigan,SamThomson,NormanSadeh,andNoahA.Smith.2015.TowardAb-stractiveSummarizationUsingSemanticRepresen-tations.InProceedingsofNorthAmericanChap-teroftheAssociationforComputationalLinguistics.pages1077–1086.MitchellP.Marcus,MaryAnnMarcinkiewicz,andBeatriceSantorini.1993.BuildingalargeannotatedcorpusofEnglish:ThePennTreebank.Computa-tionallinguistics19(2):313–330.RichardMontague.1973.TheProperTreatmentofQuantiﬁcationinOrdinaryEnglish.InK.J.J.Hin-tikka,J.M.E.Moravcsik,andP.Suppes,editors,ApproachestoNaturalLanguage,SpringerNether-lands,volume49ofSyntheseLibrary,pages221–242.RebeccaNessonandStuartM.Shieber.2006.SimplerTAGSemanticsThroughSynchronization.InPro-ceedingsofthe11thConferenceonFormalGram-mar.CenterfortheStudyofLanguageandInforma-tion,Malaga,Spain,pages129–142.JoakimNivre,Marie-CatherinedeMarneffe,FilipGin-ter,YoavGoldberg,JanHajic,ChristopherD.Man-ning,RyanMcDonald,SlavPetrov,SampoPyysalo,NataliaSilveira,ReutTsarfaty,andDanielZeman.2016.UniversalDependenciesv1:AMultilingualTreebankCollection.InProceedingsoftheTenthIn-ternationalConferenceonLanguageResourcesandEvaluation.EuropeanLanguageResourcesAssocia-tion(ELRA),Paris,France.JoakimNivreetal.2016.Universaldependencies1.3.LINDAT/CLARINdigitallibraryattheInstituteofFormalandAppliedLinguistics,CharlesUniversityinPrague.MarthaPalmer,DanielGildea,andPaulKingsbury.2005.Thepropositionbank:Anannotatedcorpusofsemanticroles.Computationallinguistics31(1):71–106.MarthaPalmer,DanielGildea,andNianwenXue.2010.Semanticrolelabeling.SynthesisLecturesonHu-manLanguageTechnologies3(1):1–103.PanupongPasupatandPercyLiang.2015.Composi-tionalSemanticParsingonSemi-StructuredTables.InProceedingsoftheAssociationforComputationalLinguistics.pages1470–1480.JeffreyPennington,RichardSocher,andChristopherManning.2014.Glove:GlobalVectorsforWordRepresentation.InProceedingsoftheEmpiricalMethodsinNaturalLanguageProcessing.Associ-ationforComputationalLinguistics,Doha,Qatar,pages1532–1543.BarbaraPlank,AndersSøgaard,andYoavGoldberg.2016.MultilingualPart-of-SpeechTaggingwithBidirectionalLongShort-TermMemoryModelsandAuxiliaryLoss.InProceedingsoftheAnnualMeet-ingoftheAssociationforComputationalLinguistics.Berlin,Germany,pages412–418.SivaReddy,MirellaLapata,andMarkSteedman.2014.Large-scaleSemanticParsingwithoutQuestion-AnswerPairs.TransactionsoftheAssociationforComputationalLinguistics2:377–392.SivaReddy,OscarT¨ackstr¨om,MichaelCollins,TomKwiatkowski,DipanjanDas,MarkSteedman,andMirellaLapata.2016.TransformingDependencyStructurestoLogicalFormsforSemanticParsing.TransactionsoftheAssociationforComputationalLinguistics4:127–140.MichaelRothandKristianWoodsend.2014.Compo-sitionofWordRepresentationsImprovesSemanticRoleLabelling.InProceedingsoftheEmpiricalMethodsinNaturalLanguageProcessing(EMNLP).AssociationforComputationalLinguistics,Doha,Qatar,pages407–413.MrinmayaSachanandEricXing.2016.MachineCom-prehensionusingRichSemanticRepresentations.InProceedingsoftheAssociationforComputationalLinguistics.AssociationforComputationalLinguis-tics,Berlin,Germany,pages486–492.SebastianSchusterandChristopherD.Manning.2016.EnhancedEnglishUniversalDependencies:AnIm-provedRepresentationforNaturalLanguageUnder-standingTasks.InProceedingsoftheTenthInterna-tionalConferenceonLanguageResourcesandEval-uation.EuropeanLanguageResourcesAssociation(ELRA),Paris,France.KirilSimovandPetyaOsenova.2011.TowardsMin-imalRecursionSemanticsoverBulgarianDepen-dencyParsing.InProceedingsoftheInternationalConferenceRecentAdvancesinNaturalLanguageProcessing2011.RANLP2011OrganisingCommit-tee,Hissar,Bulgaria,pages471–478.KathrinSpreyerandAnetteFrank.2005.ProjectingRMRSfromTIGERDependencies.InProceedingsoftheHPSG2005Conference.CSLIPublications.YuSu,HuanSun,BrianSadler,MudhakarSrivatsa,IzzeddinGur,ZenghuiYan,andXifengYan.2016.OnGeneratingCharacteristic-richQuestionSetsforQAEvaluation.InProceedingsoftheEmpiricalMethodsinNaturalLanguageProcessing.Austin,Texas,pages562–572.FerhanT¨ureandOliverJojic.2016.SimpleandEf-fectiveQuestionAnsweringwithRecurrentNeuralNetworks.CoRRabs/1606.05029.LucyVanderwende,ArulMenezes,andChrisQuirk.2015.AnAMRparserforEnglish,French,German,SpanishandJapaneseandanewAMR-annotatedcorpus.InProceedingsoftheNorthAmericanChap-teroftheAssociationforComputationalLinguistics:Demonstrations.AssociationforComputationalLin-guistics,Denver,Colorado,pages26–30.\\x0cAaronStevenWhite,DrewReisinger,KeisukeSak-aguchi,TimVieira,ShengZhang,RachelRudinger,KyleRawlins,andBenjaminVanDurme.2016.Uni-versalDecompositionalSemanticsonUniversalDe-pendencies.InProceedingsoftheEmpiricalMeth-odsinNaturalLanguageProcessing.AssociationforComputationalLinguistics,Austin,Texas,pages1713–1723.KunXu,SivaReddy,YansongFeng,SongfangHuang,andDongyanZhao.2016.QuestionAnsweringonFreebaseviaRelationExtractionandTextualEvi-dence.InProceedingsoftheAssociationforCompu-tationalLinguistics.AssociationforComputationalLinguistics,Berlin,Germany,pages2326–2336.XuchenYao.2015.LeanQuestionAnsweringoverFreebasefromScratch.InProceedingsofNorthAmericanChapteroftheAssociationforComputa-tionalLinguistics.pages66–70.XuchenYaoandBenjaminVanDurme.2014.Infor-mationExtractionoverStructuredData:QuestionAnsweringwithFreebase.InProceedingsoftheAs-sociationforComputationalLinguistics.pages956–966.SemihYavuz,IzzeddinGur,YuSu,MudhakarSrivatsa,andXifengYan.2016.ImprovingSemanticParsingviaAnswerTypeInference.InProceedingsoftheEmpiricalMethodsinNaturalLanguageProcessing.AssociationforComputationalLinguistics,Austin,Texas,pages149–159.Wen-tauYih,Ming-WeiChang,XiaodongHe,andJianfengGao.2015.SemanticParsingviaStagedQueryGraphGeneration:QuestionAnsweringwithKnowledgeBase.InProceedingsoftheAssociationforComputationalLinguistics.pages1321–1331.JohnM.ZelleandRaymondJ.Mooney.1996.Learn-ingtoParseDatabaseQueriesUsingInductiveLogicProgramming.InProceedingsofAssociationfortheAdvancementofArtiﬁcialIntelligence.pages1050–1055.LukeS.ZettlemoyerandMichaelCollins.2005.Learn-ingtoMapSentencestoLogicalForm:StructuredClassiﬁcationwithProbabilisticCategorialGram-mars.InProceedingsofUncertaintyinArtiﬁcialIn-telligence.pages658–666.\\x0cUniversalSemanticParsing:SupplementaryMaterialSivaReddy†OscarT¨ackstr¨om‡SlavPetrov‡MarkSteedman††MirellaLapata†††StanfordUniversity‡GoogleInc.††UniversityofEdinburghsivar@stanford.edu,{oscart,slav}@google.com,{steedman,mlap}@inf.ed.ac.ukAbstractThissupplementarymaterialtothemainpaper,providesanoutlineofhowquantiﬁ-cationcanbeincorporatedintheUDEP-LAMBDAframework.1UniversalQuantiﬁcationConsiderthesentenceEverybodywantstobuyahouse,1whosedependencytreeintheUniversalDependencies(UD)formalismisshowninFig-ure1(a).Thissentencehastwopossiblereadings:either(1)everypersonwantstobuyadifferenthouse;or(2)everypersonwantstobuythesamehouse.Thetwointerpretationscorrespondtothefollowinglogicalforms:(1)∀x.person(xa)→[∃zyw.wants(ze)∧arg1(ze,xa)∧buy(ye)∧xcomp(ze,ye)∧house(wa)∧arg1(ze,xa)∧arg2(ze,wa)];(2)∃w.house(wa)∧(∀x.person(xa)→[∃zy.wants(ze)∧arg1(ze,xa)∧buy(ye)∧xcomp(ze,ye)∧arg1(ze,xa)∧arg2(ze,wa)]).In(1),theexistentialvariablewisinthescopeoftheuniversalvariablex(i.e.thehouseisdependentontheperson).Thisreadingiscommonlyreferredtoasthesurfacereading.Conversely,in(2)theuniversalvariablexisinthescopeoftheexistentialvariablew(i.e.thehouseisindependentoftheperson).Thisreadingisalsocalledinversereading.Ourgoalistoobtainthesurfacereadinglogicalformin(1)withUDEPLAMBDA.Wedonotaimtoobtaintheinversereading,althoughthisispossiblewiththeuseofSkolemization(Steedman,2012).InUDEPLAMBDA,lambdaexpressionsforwords,phrasesandsentencesarealloftheformλx.....Butfrom(1),itisclearthatweneedtoexpressvariablesboundbyquantiﬁers,e.g.∀x,whilestillprovidingaccesstoxforcomposition.Thisdemandsachangeinthetypesystemsincethe1ExampleborrowedfromSchusterandManning(2016).Everybodywantstobuyahousensubjxcompdobjdetmarkroot(a)Originaldependencytree.EverybodywantstobuyahousensubjxcompdobjdetmarkrootΩΩbindnsubj(b)Enhanceddependencytree.Everybodywantstobuyahousensubj:univxcompdobjdetmarkrootΩΩbindnsubj(c)Enhanceddependencytreewithuniversalquantiﬁcation.Figure1:ThedependencytreeforEverybodywantstobuyahouseanditsenhancedvariants.samevariablecannotbelambdaboundandquanti-ﬁerbound—thatiswecannothaveformulasoftheformλx...∀x....Inthismaterial,weﬁrstderivethelogicalformfortheexamplesentenceusingthetypesystemfromourmainpaper(Section1.1)andshowthatitfailstohandleuniversalquantiﬁ-cation.Wethenmodifythetypesystemslightlytoallowderivationofthedesiredsurfacereadinglogicalform(Section1.2).Thismodiﬁedtypesys-temisastrictgeneralizationoftheoriginaltypesystem.2Fancelluetal.(2017)presentanelaboratediscussiononthemodiﬁedtypesystem,andhowitcanhandlenegationscopeanditsinteractionwithuniversalquantiﬁers.2Notethatthistreatmenthasyettobeaddedtoourimplementation,whichcanbefoundathttps://github.com/sivareddyg/udeplambda.\\x0c1.1WithOriginalTypeSystemWewillﬁrstattempttoderivethelogicalformin(1)usingthedefaulttypesystemofUDEPLAMBDA.Figure1(b)showstheenhanceddependencytreeforthesentence,whereBINDhasbeenintroducedtoconnecttheimpliednsubjofbuy(BINDisex-plainedinthemainpaperinSection3.2).Thes-expressioncorrespondingtotheenhancedtreeis:(nsubj(xcompwants(mark(nsubj(dobjbuy(dethousea))Ω)to))(BINDeverybodyΩ)).Withthefollowingsubstitutionentries,wants,buy∈EVENT;everybody,house∈ENTITY;a,to∈FUNCTIONAL;Ω=λx.EQ(x,ω);nsubj=λfgx.∃y.f(x)∧g(y)∧arg1(xe,ya);dobj=λfgx.∃y.f(x)∧g(y)∧arg2(xe,ya);xcomp=λfgx.∃y.f(x)∧g(y)∧xcomp(xe,ya);mark∈HEAD;BIND∈MERGE,thelambdaexpressionaftercompositionbecomes:λz.∃xywv.wants(ze)∧everybody(xa)∧arg1(ze,xa)∧EQ(x,ω)∧buy(ye)∧xcomp(ze,ye)∧arg1(ye,va)∧EQ(v,ω)∧arg1(xe,ya)∧house(wa)∧arg2(ye,wa).Thisexpressionencodesthefactthatxandvareinuniﬁcation,andcanthusbefurthersimpliﬁedto:(3)λz.∃xyw.wants(ze)∧everybody(xa)∧arg1(ze,xa)∧buy(ye)∧xcomp(ze,ye)∧arg1(ye,xa)∧arg1(xe,ya)∧house(wa)∧arg2(ye,wa).However,thelogicalform(3)differsfromthedesiredform(1).Asnotedabove,UDEPLAMBDAwithitsdefaulttype,whereeachs-expressionmusthavethetypeη=Ind×Event→Bool,cannothandlequantiﬁerscoping.1.2WithHigher-orderTypeSystemFollowingChampollion(2010),wemakeaslightmodiﬁcationtothetypesystem.Insteadofusingexpressionsoftheformλx....forwords,weuseeitherλf.∃x....orλf.∀x....,wherefhastypeη.AsarguedbyChampollion,thishigher-orderformmakesquantiﬁcationandnegationhandlingsoundandsimplerinNeo-Davidsonianeventsemantics.Followingthischange,weassignthefollowinglambdaexpressionstothewordsinourexamplesentence:everybody=λf.∀x.person(x)→f(x);wants=λf.∃x.wants(xe)∧f(x);to=λf.TRUE;buy=λf.∃x.buy(xe)∧f(x);a=λf.TRUE;house=λf.∃x.house(xa)∧f(x);Ω=λf.f(ω).Hereeverybodyisassigneduniversalquantiﬁersemantics.SincetheUDrepresentationdoesnotdistinguishquantiﬁers,weneedtorelyonasmall(language-speciﬁc)lexicontoidentifythese.Toencodequantiﬁcationscope,weenhancethela-belnsubjtonsubj:univ,whichindicatesthatthesubjectargumentofwantscontainsauniversalquantiﬁer,asshowninFigure1(c).Thischangeofsemantictypeforwordsands-expressionsforcesustoalsomodifytheseman-tictypeofdependencylabels,inordertoobeythesingle-typeconstraintofDEPLAMBDA(Reddyetal.,2016).Thus,dependencylabelswillnowtaketheformλPQf....,wherePistheparentex-pression,Qisthechildexpression,andthereturnexpressionisoftheformλf.....Followingthischange,weassignthefollowinglambdaexpres-sionstodependencylabels:nsubj:univ=λPQf.Q(λy.P(λx.f(x)∧arg1(xe,ya)));nsubj=λPQf.P(λx.f(x)∧Q(λy.arg1(xe,ya)));dobj=λPQf.P(λx.f(x)∧Q(λy.arg2(xe,ya)));xcomp=λPQf.P(λx.f(x)∧Q(λy.xcomp(xe,ya)));det,mark=λPQf.P(f);BIND=λPQf.P(λx.f(x)∧Q(λy.EQ(y,x))).Noticethatthelambdaexpressionofnsubj:univdiffersfromnsubj.Inthefor-mer,thelambdavariablesinsideQhavewiderscopeoverthevariablesinP(i.e.theuniversalquantiﬁervariableofeverybodyhasscopeovertheeventvariableofwants)contrarytothelatter.Thenews-expressionforFigure1(c)is(nsubj:univ(xcompwants(mark(nsubj(dobjbuy(dethousea))Ω)to))(BINDeverybodyΩ)).Substitutingwiththemodiﬁedexpressions,andperformingcompositionandsimpliﬁcationleadstotheexpression:(6)λf.∀x.person(xa)→[∃zyw.f(z)∧wants(ze)∧arg1(ze,xa)∧buy(ye)∧xcomp(ze,ye)∧house(wa)∧arg1(ze,xa)∧arg2(ze,wa)].Thisexpressionisidenticalto(1)exceptfortheoutermosttermλf.Byapplying(6)toλx.TRUE,weobtain(1),whichcompletesthetreatmentofuniversalquantiﬁcationinUDEPLAMBDA.ReferencesLucasChampollion.2010.Quantiﬁcationandnegationineventsemantics.BalticInternationalYearbookofCognition,LogicandCommunication6(1):3.FedericoFancellu,SivaReddy,AdamLopez,andBon-nieWebber.2017.UniversalDependenciestoLogi-calFormswithNegationScope.arXivPreprint.\\x0cSivaReddy,OscarT¨ackstr¨om,MichaelCollins,TomKwiatkowski,DipanjanDas,MarkSteedman,andMirellaLapata.2016.TransformingDependencyStructurestoLogicalFormsforSemanticParsing.TransactionsoftheAssociationforComputationalLinguistics4:127–140.SebastianSchusterandChristopherD.Manning.2016.EnhancedEnglishUniversalDependencies:AnIm-provedRepresentationforNaturalLanguageUnder-standingTasks.InProceedingsoftheTenthInterna-tionalConferenceonLanguageResourcesandEval-uation.EuropeanLanguageResourcesAssociation(ELRA),Paris,France.MarkSteedman.2012.TakingScope-TheNaturalSe-manticsofQuantiﬁers.MITPress.\\x0c'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_name = \"1702.03196.pdf\"\n",
    "d = convert_pdf_to_txt(Path(pdf_name))\n",
    "d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1702.03196.txt': '7\\n1\\n0\\n2\\n\\ng\\nu\\nA\\n8\\n2\\n\\n]\\nL\\nC\\n.\\ns\\nc\\n[\\n\\n4\\nv\\n6\\n9\\n1\\n3\\n0\\n.\\n2\\n0\\n7\\n1\\n:\\nv\\ni\\nX\\nr\\na\\n\\nUniversalSemanticParsingSivaReddy†∗OscarT¨ackstr¨om‡SlavPetrov‡MarkSteedman††MirellaLapata†††StanfordUniversity‡GoogleInc.††UniversityofEdinburghsivar@stanford.edu,{oscart,slav}@google.com,{steedman,mlap}@inf.ed.ac.ukAbstractUniversalDependencies(UD)offerauni-formcross-lingualsyntacticrepresentation,withtheaimofadvancingmultilingualap-plications.Recentworkshowsthatse-manticparsingcanbeaccomplishedbytransformingsyntacticdependenciestolog-icalforms.However,thisworkislim-itedtoEnglish,andcannotprocessde-pendencygraphs,whichallowhandlingcomplexphenomenasuchascontrol.Inthiswork,weintroduceUDEPLAMBDA,asemanticinterfaceforUD,whichmapsnaturallanguagetologicalformsinanalmostlanguage-independentfashionandcanprocessdependencygraphs.Weper-formexperimentsonquestionansweringagainstFreebaseandprovideGermanandSpanishtranslationsoftheWebQuestionsandGraphQuestionsdatasetstofacilitatemultilingualevaluation.ResultsshowthatUDEPLAMBDAoutperformsstrongbase-linesacrosslanguagesanddatasets.ForEnglish,itachievesa4.9F1pointimprove-mentoverthestate-of-the-artonGraph-Questions.1IntroductionTheUniversalDependencies(UD)initiativeseekstodevelopcross-linguisticallyconsistentannota-tionguidelinesaswellasalargenumberofuni-formlyannotatedtreebanksformanylanguages(Nivreetal.,2016).Suchresourcescouldadvancemultilingualapplicationsofparsing,improvecom-parabilityofevaluationresults,enablecross-linguallearning,andmoregenerallysupportnaturallan-guageunderstanding.∗WorkdoneattheUniversityofEdinburghSeekingtoexploitthebeneﬁtsofUDfornatu-rallanguageunderstanding,weintroduceUDEP-LAMBDA,asemanticinterfaceforUDthatmapsnaturallanguagetologicalforms,representingun-derlyingpredicate-argumentstructures,inanal-mostlanguage-independentmanner.Ourframe-workisbasedonDEPLAMBDA(Reddyetal.,2016)arecentlydevelopedmethodthatconvertsEnglishStanfordDependencies(SD)tologicalforms.TheconversionprocessisillustratedinFigure1anddiscussedinmoredetailinSection2.WhereasDEPLAMBDAworksonlyforEnglish,U-DEPLAMBDAappliestoanylanguageforwhichUDannotationsareavailable.1Moreover,DEP-LAMBDAcanonlyprocesstree-structuredinputswhereasUDEPLAMBDAcanalsoprocessdepen-dencygraphs,whichallowtohandlecomplexcon-structionssuchascontrol.ThedifferenttreatmentsofvariouslinguisticconstructionsinUDcomparedtoSDalsorequiredifferenthandlinginUDEP-LAMBDA(Section3.3).OurexperimentsfocusonFreebasesemanticparsingasatestbedforevaluatingtheframework’smultilingualappeal.Weconvertnaturallanguagetologicalformswhichinturnareconvertedtoma-chineinterpretableformalmeaningrepresentationsforretrievinganswerstoquestionsfromFreebase.Tofacilitatemultilingualevaluation,weprovidetranslationsoftheEnglishWebQuestions(Berantetal.,2013)andGraphQuestions(Suetal.,2016)datasetstoGermanandSpanish.WedemonstratethatUDEPLAMBDAcanbeusedtoderivelogicalformsfortheselanguagesusingaminimalamountoflanguage-speciﬁcknowledge.Asidefromdevel-opingtheﬁrstmultilingualsemanticparsingtoolforFreebase,wealsoexperimentallyshowthatU-DEPLAMBDAoutperformsstrongbaselinesacross1Asofv1.3,UDannotationsareavailablefor47languagesathttp://universaldependencies.org. \\n \\n \\n \\n \\n \\n\\x0clanguagesanddatasets.ForEnglish,itachievesthestrongestresulttodateonGraphQuestions,withcompetitiveresultsonWebQuestions.Ourimple-mentationandtranslateddatasetsarepubliclyavail-ableathttps://github.com/sivareddyg/udeplambda.2DEPLAMBDABeforedescribingUDEPLAMBDA,weprovideanoverviewofDEPLAMBDA(Reddyetal.,2016)onwhichourapproachisbased.DEPLAMBDAconvertsadependencytreetoitslogicalforminthreesteps:binarization,substitution,andcom-position,eachofwhichisbrieﬂyoutlinedbelow.Algorithm1describesthestepsofDEPLAMBDAinlines4-6,whereaslines2and3arespeciﬁctoUDEPLAMBDA.BinarizationAdependencytreeisﬁrstmappedtoaLisp-styles-expressionindicatingtheorderofsemanticcomposition.Figure1(b)showsthes-expressionforthesentenceDisneywonanOs-carforthemovieFrozen,derivedfromthedepen-dencytreeinFigure1(a).Here,thesub-expression(dobjwon(detOscaran))indicatesthatthelogi-calformofthephrasewonanOscarisderivedbycomposingthelogicalformofthelabeldobjwiththelogicalformofthewordwonandthelogicalformofthephraseanOscar,derivedanalogously.Thes-expressioncanalsobeinterpretedasabi-narizedtreewiththedependencylabelastherootnode,andtheleftandrightexpressionsassubtrees.Acompositionhierarchyisemployedtoimposeastricttraversalorderingonthemodiﬁerstoeachheadinthedependencytree.Asanexample,wonhasthreemodiﬁersinFigure1(a),whichaccordingtothecompositionhierarchyarecomposedintheorderdobj>nmod>nsubj.Inconstructionslikecoordination,thisorderingiscrucialtoarriveatthecorrectsemantics.Lines7-17inAlgorithm1describethebinarizationstep.SubstitutionEachsymbolinthes-expressionsissubstitutedforalambdaexpressionencodingitssemantics.Wordsanddependencylabelsareassigneddifferenttypesofexpressions.Ingeneral,wordshaveexpressionsofthefollowingkind:ENTITY⇒λx.word(xa);e.g.Oscar⇒λx.Oscar(xa)EVENT⇒λx.word(xe);e.g.won⇒λx.won(xe)FUNCTIONAL⇒λx.TRUE;e.g.an⇒λx.TRUEHere,thesubscripts·aand·edenotethetypesofindividuals(Ind)andevents(Event),respec-tively,whereasxdenotesapairedvariable(xa,xe)DisneywonanOscarforthemovieFrozenpropnverbdetpropnadpdetnounpropnnsubjdobjnmoddetcasedetcompoundroot(a)ThedependencytreeforDisneywonanOscarforthemovieFrozenintheUniversalDependenciesformalism.(nsubj(nmod(dobjwon(detOscaran))(case(det(comp.Frozenmovie)the)for))Disney)(b)Thebinarizeds-expressionforthedependencytree.λx.∃yzw.won(xe)∧Disney(ya)∧Oscar(za)∧Frozen(wa)∧movie(wa)∧arg1(xe,ya)∧arg2(xe,za)∧nmod.for(xe,wa)(c)Thecomposedlambda-calculusexpression.Figure1:Themappingofadependencytreetoitslogicalformwiththeintermediates-expression.oftypeInd×Event.Roughlyspeaking,propernounsandadjectivesinvokeENTITYexpressions,verbsandadverbsinvokeEVENTexpressions,andcommonnounsinvokebothENTITYandEVENTex-pressions(seeSection3.3),whileremainingwordsinvokeFUNCTIONALexpressions.DEPLAMBDAenforcestheconstraintthateverys-expressionisofthetypeη=Ind×Event→Bool,whichsimpli-ﬁesthetypesystemconsiderably.Expressionsfordependencylabelsgluethesemanticsofheadsandmodiﬁerstoarticulatepredicate-argumentstructure.Theseexpressionsingeneraltakeoneofthefollowingforms:COPY⇒λfgx.∃y.f(x)∧g(y)∧rel(x,y)e.g.nsubj,dobj,nmod,advmodINVERT⇒λfgx.∃y.f(x)∧g(y)∧reli(y,x)e.g.amod,aclMERGE⇒λfgx.f(x)∧g(x)e.g.compound,appos,amod,aclHEAD⇒λfgx.f(x)e.g.case,punct,aux,mark.AsanexampleofCOPY,considerthelambdaexpressionfordobjin(dobjwon(detOscaran)):λfgx.∃y.f(x)∧g(y)∧arg2(xe,ya).Thisexpres-siontakestwofunctionsfandgasinput,wherefrepresentsthelogicalformofwonandgrepre-sentsthelogicalformofanOscar.Thepredicate-argumentstructurearg2(xe,ya)indicatesthatthearg2oftheeventxe,i.e.won,istheindividualya,i.e.theentityOscar.Sincearg2(xe,ya)mimicsthedependencystructuredobj(won,Oscar),werefertotheexpressionkindevokedbydobjasCOPY.\\x0cExpressionsthatinvertthedependencydirec-tionarereferredtoasINVERT(e.g.amodinrun-ninghorse);expressionsthatmergetwosubexpres-sionswithoutintroducinganyrelationpredicatesarereferredtoasMERGE(e.g.compoundinmovieFrozen);andexpressionsthatsimplyreturnthepar-entexpressionsemanticsarereferredtoasHEAD(e.g.caseinforFrozen).Whilethisgeneralizationappliestomostdependencylabels,severallabelstakeadifferentlogicalformnotlistedhere,someofwhicharediscussedinSection3.3.Sometimesthemappingofdependencylabeltolambdaexpres-sionmaydependonsurroundingpart-of-speechtagsordependencylabels.Forexample,amodactsasINVERTwhenthemodiﬁerisaverb(e.g.inrun-ninghorse),andasMERGEwhenthemodiﬁerisanadjective(e.g.inbeautifulhorse).2Lines26-32inAlgorithm1describethesubstitutionprocedure.CompositionTheﬁnallogicalformiscomputedbybeta-reduction,treatingexpressionsoftheform(fxy)asthefunctionfappliedtotheargumentsxandy.Forexample,(dobjwon(detOscaran))resultsinλx.∃z.won(xe)∧Oscar(za)∧arg2(xe,za)whentheexpressionfordobjisappliedtothoseforwonand(detOscaran).Figure1(c)showsthelogicalformforthes-expressioninFigure1(b).Thebinarizeds-expressionisrecursivelyconvertedtoalogicalformasdescribedinlines18-25inAlgorithm1.3UDEPLAMBDAWenowintroduceUDEPLAMBDA,asemanticin-terfaceforUniversalDependencies.3WhereasDEPLAMBDAonlyappliestoEnglishStanfordDe-pendencies,UDEPLAMBDAtakesadvantageofthecross-lingualnatureofUDtofacilitatean(almost)languageindependentsemanticinterface.Thisisaccomplishedbyrestrictingthebinarization,sub-stitution,andcompositionstepsdescribedabovetorelysolelyoninformationencodedintheUDrepresentation.AsshowninAlgorithm1,lines4-6arecommontobothDEPLAMBDAandUDEP-LAMBDA,whereaslines2and3appliesonlytoUDEPLAMBDA.Importantly,UDEPLAMBDAisdesignedtonotrelyonlexicalformsinalanguage2WeuseTregex(LevyandAndrew,2006)forsubstitu-tionmappingsandCornellSPF(Artzi,2013)asthelambda-calculusimplementation.Forexample,inrunninghorse,thetregex/label:amod/=target</postag:verb/matchesamodtoitsINVERTexpressionλfgx.∃y.f(x)∧g(y)∧amodi(ye,xa).3Inwhatfollows,allreferencestoUDaretoUDv1.3.Algorithm1:UDEPLAMBDASteps1FunctionUDepLambda(depTree):2depGraph=Enhancement(depTree)#SeeFigure2(a)foradepGraph.3bindedTree=SplitLongDistance(depGraph)#SeeFigure2(b)forabindedTree.4binarizedTree=Binarization(bindedTree)#SeeFigure1(b)forabinarizedTree.5logicalForm=Composition(binarizedTree)6returnlogicalForm7FunctionBinarization(tree):8parent=GetRootNode(tree);9{(label1,child1),(label2,child2)...}=GetChildNodes(parent)10sortedChildren=SortUsingLabelHierarchy({(label1,child1),(label2,child2)...})11binarziedTree.root=parent12forlabel,child∈sortedChildren:13temp.root=label14temp.left=binarziedTree15temp.right=Binarization(child)16binarziedTree=temp17returnbinarizedTree18FunctionComposition(binarizedTree):19mainLF=Substitution(binarizedTree.root)20ifbinarziedTreehasleftandrightchildren:21leftLF=Composition(binarziedTree.left)22rightLF=Composition(binarziedTree.right)23mainLF=BetaReduce(mainLF,leftLF)24mainLF=BetaReduce(mainLF,rightLF)25returnmainLF26FunctionSubstitution(node):27logicalForms=[]28fortregexRule,template∈substitutionRules:29iftregexRule.match(node):30lf=GenLambdaExp(node,template)31logicalForms.add(lf)32returnlogicalFormstoassignlambdaexpressions,butonlyoninforma-tioncontainedindependencylabelsandpostags.However,somelinguisticphenomenaarelan-guagespeciﬁc(e.g.pronoun-dropping)orlexical-ized(e.g.everyandtheinEnglishhavedifferentsemantics,despitebeingbothdeterminers)andarenotencodedintheUDschema.Furthermore,somecross-linguisticphenomena,suchaslong-distancedependencies,arenotpartofthecoreUDrepresen-tation.Tocircumventthislimitation,asimpleen-hancementstepenrichestheoriginalUDrepresen-tationbeforebinarizationtakesplace(Section3.1).Thisstepaddstothedependencytreemissingsyn-tacticinformationandlong-distancedependencies,therebycreatingagraph.WhereasDEPLAMBDAisnotabletohandlegraph-structuredinput,UDEP-\\x0cLAMBDAisdesignedtoworkwithdependencygraphsaswell(Section3.2).Finally,severalcon-structionsdifferinstructurebetweenUDandSD,whichrequiresdifferenthandlinginthesemanticinterface(Section3.3).3.1EnhancementBothSchusterandManning(2016)andNivreetal.(2016)notethenecessityofanenhancedUDrep-resentationtoenablesemanticapplications.How-ever,suchenhancementsarecurrentlyonlyavail-ableforasubsetoflanguagesinUD.Instead,werelyonasmallnumberofenhancementsforourmainapplication—semanticparsingforquestion-answering—withthehopethatthisstepcanbere-placedbyanenhancedUDrepresentationinthefu-ture.Speciﬁcally,wedeﬁnethreekindsofenhance-ments:(1)long-distancedependencies;(2)typesofcoordination;and(3)reﬁnedquestionwordtags.Thesecorrespondtoline2inAlgorithm1.First,weidentifylong-distancedependenciesinrelativeclausesandcontrolconstructions.Wefol-lowSchusterandManning(2016)andﬁndtheseusingthelabelsacl(relative)andxcomp(control).Figure2(a)showsthelong-distancedependencyinthesentenceAnnawantstomarryKristoff.Here,marryisprovidedwithitsmissingnsubj(dashedarc).Second,UDconﬂatesallcoordinatingcon-structionstoasingledependencylabel,conj.Toobtainthecorrectcoordinationscope,wereﬁneconjtoconj:verb,conj:vp,conj:sentence,conj:np,andconj:adj,similartoReddyetal.(2016).Finally,unlikethePTBtags(Marcusetal.,1993)usedbySD,theUDpart-of-speechtagsdonotdistinguishquestionwords.Sincethesearecru-cialtoquestion-answering,weuseasmalllexicontoreﬁnethetagsfordeterminers(DET),adverbs(ADV)andpronouns(PRON)toDET:WH,ADV:WHandPRON:WH,respectively.Speciﬁcally,weusealistof12(English),14(Spanish)and35(Ger-man)words,respectively.ThisistheonlypartofUDEPLAMBDAthatreliesonlanguage-speciﬁcinformation.Wehopethat,asthecoverageofmor-phologicalfeaturesinUDimproves,thisreﬁne-mentcanbereplacedbyrelyingonmorphologicalfeatures,suchastheinterrogativefeature(INT).3.2GraphStructuresandBINDTohandlegraphstructuresthatmayresultfromtheenhancementstep,suchasthoseinFigure2(a),weproposeavariable-bindingmechanismthatdiffersAnnawantstomarryKristoﬀnsubjxcompmarkdobjnsubj(a)Withlong-distancedependency.AnnawantstomarryKristoﬀΩΩnsubjxcompmarkdobjbindnsubj(b)Withvariablebinding.Figure2:TheoriginalandenhanceddependencytreesforAnnawantstomarryKristoff.fromthatofDEPLAMBDA.Thisisindicatedinline3ofAlgorithm1.First,eachlong-distancedependencyissplitintoindependentarcsasshowninFigure2(b).Here,Ωisaplaceholderforthesub-jectofmarry,whichinturncorrespondstoAnnaasindicatedbythebindingofΩviathepseudo-labelBIND.WetreatBINDlikeanordinarydependencylabelwithsemanticsMERGEandprocesstheresult-ingtreeasusual,viathes-expression:(nsubj(xcompwants(nsubj(mark(dobjmarryKristoff)to)Ω)(BINDAnnaΩ)),withthelambda-expressionsubstitutions:wants,marry∈EVENT;to∈FUNCTIONAL;Anna,Kristoff∈ENTITY;mark∈HEAD;BIND∈MERGE;xcomp=λfgx.∃y.f(x)∧g(y)∧xcomp(xe,ye).Thesesubstitutionsarebasedsolelyonunlexi-calizedcontext.Forexample,thepart-of-speechtagPROPNofAnnainvokesanENTITYexpression.TheplaceholderΩhassemanticsλx.EQ(x,ω),whereEQ(u,ω)istrueiffuandωareequal(havethesamedenotation),whichuniﬁesthesubjectvari-ableofwantswiththesubjectvariableofmarry.Aftersubstitutionandcomposition,weget:λz.∃xywv.wants(ze)∧Anna(xa)∧arg1(ze,xa)∧EQ(x,ω)∧marry(ye)∧xcomp(ze,ye)∧arg1(ye,va)∧EQ(v,ω)∧Kristoff(wa)∧arg2(ye,wa),ThisexpressionmaybesimpliﬁedfurtherbyreplacingalloccurrencesofvwithxandremovingtheuniﬁcationpredicatesEQ,whichresultsin:λz.∃xyw.wants(ze)∧Anna(xa)∧arg1(ze,xa)∧marry(ye)∧xcomp(ze,ye)∧arg1(ye,xa)∧Kristoff(wa)∧arg2(ye,wa).\\x0cThisexpressionencodesthefactthatAnnaisthearg1ofthemarryevent,asdesired.DEPLAMBDA,incontrast,cannothandlegraph-structuredinput,sinceitlacksaprincipledwayofgeneratings-expressionsfromgraphs.Evengiventheaboves-expression,BINDinDEPLAMBDAisdeﬁnedinawaysuchthatthecompositionfailstounifyvandx,whichiscrucialforthecorrectsemantics.Moreover,thedeﬁnitionofBINDinDEPLAMBDAdoesnothaveaformalinterpretationwithinthelambdacalculus,unlikeours.3.3LinguisticConstructionsBelow,wehighlightthemostpertinentdifferencesbetweenUDEPLAMBDAandDEPLAMBDA,stem-mingfromthedifferenttreatmentofvariouslin-guisticconstructionsinUDversusSD.PrepositionalPhrasesUDusesacontent-headanalysis,incontrasttoSD,whichtreatsfunctionwordsasheadsofprepositionalphrases,Accord-ingly,thes-expressionforthephrasepresidentin2009is(nmodpresident(case2009in))inU-DEPLAMBDAand(preppresident(pobjin2009))inDEPLAMBDA.Toachievethedesiredsemantics,λx.∃y.president(xa)∧presidentevent(xe)∧arg1(xe,xa)∧2009(ya)∧prep.in(xe,ya),DEPLAMBDAreliesonanintermediatelogicalformthatrequiressomepost-processing,whereasUDEPLAMBDAobtainsthedesiredlogicalformdirectlythroughthefollowingentries:in∈FUNCTIONAL;2009∈ENTITY;case∈HEAD;president=λx.president(xa)∧presidentevent(xe)∧arg1(xe,xa);nmod=λfgx.∃y.f(x)∧g(y)∧nmod.in(xe,ya).Othernmodconstructions,suchaspossessives(nmod:poss),temporalmodiﬁers(nmod:tmod)andadverbialmodiﬁers(nmod:npmod),arehan-dledsimilarly.Notehowthecommonnounpresi-dent,evokesbothentityandeventpredicatesabove.PassivesDEPLAMBDAgivesspecialtreatmenttopassiveverbs,identiﬁedbytheﬁne-grainedpart-of-speechtagsinthePTBtagtogetherwithde-pendencycontext.Forexample,AnOscarwaswonisanalyzedasλx.won.pass(xe)∧Oscar(ya)∧arg1(xe,ya),wherewon.passrepresentsapassiveevent.However,UDdoesnotdistinguishbe-tweenactiveandpassiveforms.4Whilethelabels4UDencodesvoiceasamorphologicalfeature,butmostsyntacticanalyzersdonotproducethisinformationyet.nsubjpassorauxpassindicatepassiveconstruc-tions,suchcluesaresometimesmissing,suchasinreducedrelatives.Wethereforeopttonothavesep-arateentriesforpassives,butaimtoproduceidenti-callogicalformsforactiveandpassiveformswhenpossible(forexample,bytreatingnsubjpassasdirectobject).Withthefollowingentries,won∈EVENT;an,was∈FUNCTIONAL;auxpass∈HEAD;nsubjpass=λfgx.∃y.f(x)∧g(y)∧arg2(xe,ya),thelambdaexpressionforAnOscarwaswonbe-comesλx.won(xe)∧Oscar(ya)∧arg2(xe,ya),iden-ticaltothatofitsactiveform.However,nothavingaspecialentryforpassiveverbsmayhaveunde-sirableside-effects.Forexample,inthereduced-relativeconstructionPixarclaimedtheOscarwonforFrozen,thephrasetheOscarwon...willreceivethesemanticsλx.Oscar(ya)∧won(xe)∧arg1(xe,ya),whichdiffersfromthatofanOscarwaswon.Weleaveittothetargetapplicationtodisambiguatetheinterpretationinsuchcases.Long-DistanceDependenciesAsdiscussedinSection3.2,wehandlelong-distancedependen-ciesevokedbyclausalmodiﬁers(acl)andcon-trolverbs(xcomp)withtheBINDmechanism,whereasDEPLAMBDAcannothandlecontrolcon-structions.Forxcomp,asseenearlier,weusethemappingλfgx.∃y.f(x)∧g(y)∧xcomp(xe,ye).Foraclweuseλfgx.∃y.f(x)∧g(y),toconjointhemainclauseandthemodiﬁerclause.However,notallaclclausesevokelong-distancedependencies,e.g.inthenewsthatDisneywonanOscar,theclausethatDisneywonanOscarisasubordinatingconjunctionofnews.Insuchcases,weinsteadassignacltheINVERTsemantics.QuestionsQuestionwordsaremarkedwiththeenhancedpart-of-speechtagsDET:WH,ADV:WHandPRON:WH,whichareallassignedtheseman-ticsλx.${word}(xa)∧TARGET(xa).ThepredicateTARGETindicatesthatxarepresentsthevariableofinterest,thatistheanswertothequestion.3.4LimitationsInordertoachievelanguageindependence,UDEP-LAMBDAhastosacriﬁcesemanticspeciﬁcity,sinceinmanycasesthesemanticsiscarriedbylexicalinformation.ConsiderthesentencesJohnbrokethewindowandThewindowbroke.Althoughitisthewindowthatbrokeinbothcases,ourinferredlogicalformsdonotcanonicalizetherelationbe-tweenbrokeandwindow.Toachievethis,we\\x0clanguagetargetpeoplexe1ye2Ghanaspeak.arg2speak.arg1people.arg1people.nmod.intypetype(a)Englishsprachetargetxe1Ghanagesprochen.arg2gesprochen.nmod.intype(b)Germanlenguatargetxe1Ghanalengua.arg1lengua.nmod.detype(c)Spanishlanguage.humanlanguagetargetxmGhanalocation.country.oﬃciallanguage.2location.country.oﬃciallanguage.1type(d)FreebaseFigure3:TheungroundedgraphsforWhatlanguagedothepeopleinGhanaspeak?,WelcheSprachewirdinGhanagesprochen?andCu´aleslalenguadeGhana?,andthecorrespondinggroundedgraph.wouldhavetomakethesubstitutionofnsubjde-pendonlexicalcontext,suchthatwhenwindowoccursasnsubjwithbroke,thepredicatearg2isinvokedratherthanarg1.UDEPLAMBDAdoesnotaddressthisproblem,andleaveittothetar-getapplicationtoinfercontext-sensitivesemanticsofarg1andarg2.Tomeasuretheimpactofthislimitation,wepresentUDEPLAMBDASRLinSec-tion4.4whichaddressesthisproblembyrelyingonsemanticrolesfromsemanticrolelabeling(Palmeretal.,2010).Otherconstructionsthatrequirelexicalinforma-tionarequantiﬁerslikeevery,someandmost,nega-tionmarkerslikenoandnot,andintentionalverbslikebelieveandsaid.UDdoesnothavespeciallabelstoindicatethese.Wediscusshowtohandlequantiﬁersinthisframeworkinthesupplementarymaterial.AlthoughinthecurrentsetupUDEPLAMBDArulesarehand-coded,thenumberofrulesareonlyproportionaltothenumberofUDlabels,mak-ingrule-writingmanageable.5Moreover,weviewUDEPLAMBDAasaﬁrststeptowardslearningrulesforconvertingUDtorichersemanticrepre-sentationssuchasPropBank,AMR,ortheParal-lelMeaningBank(Palmeretal.,2005;Banarescuetal.,2013;Abzianidzeetal.,2017)..4Cross-lingualSemanticParsingTostudythemultilingualnatureofUDEPLAMBDA,weconductanempiricalevaluationonquestionansweringagainstFreebaseinthreedifferentlan-guages:English,Spanish,andGerman.Beforediscussingthedetailsofthisexperiment,webrieﬂyoutlinethesemanticparsingframeworkemployed.5UDv1.3has40dependencylabels,andthenumberofsubstitutionrulesinUDEPLAMBDAare61,withsomelabelshavingmultiplerules,andsomerepresentinglexicalseman-tics.4.1SemanticParsingasGraphMatchingUDEPLAMBDAgeneratesungroundedlogicalformsthatareindependentofanyknowledgebase,suchasFreebase.WeuseGRAPHPARSER(Reddyetal.,2016)tomaptheselogicalformstotheirgroundedFreebasegraphs,viacorrespondingun-groundedgraphs.Figures3(a)to3(c)showtheungroundedgraphscorrespondingtologicalformsfromUDEPLAMBDA,eachgroundedtothesameFreebasegraphinFigure3(d).Here,rectanglesde-noteentities,circlesdenoteevents,roundedrectan-glesdenoteentitytypes,andedgesbetweeneventsandentitiesdenotepredicatesorFreebaserelations.Finally,theTARGETnoderepresentsthesetofval-uesofxthatareconsistentwiththeFreebasegraph,thatistheanswertothequestion.GRAPHPARSERtreatssemanticparsingasagraph-matchingproblemwiththegoalofﬁndingtheFreebasegraphsthatarestructurallyisomorphictoanungroundedgraphandrankthemaccordingtoamodel.Toaccountforstructuralmismatches,GRAPHPARSERusestwographtransformations:CONTRACTandEXPAND.InFigure3(a)therearetwoedgesbetweenxandGhana.CONTRACTcol-lapsesoneoftheseedgestocreateagraphisomor-phictoFreebase.EXPAND,incontrast,addsedgestoconnectthegraphinthecaseofdisconnectedcomponents.Thesearchspaceisexploredbybeamsearchandmodelparametersareestimatedwiththeaveragedstructuredperceptron(Collins,2002)fromtrainingdataconsistingofquestion-answerpairs,usinganswerF1-scoreastheobjective.4.2DatasetsWeevaluateourapproachontwopublicbench-marksofquestionansweringagainstFreebase:WebQuestions(Berantetal.,2013),awidelyusedbenchmarkconsistingofEnglishquestionsandtheiranswers,andGraphQuestions(Suetal.,2016),arecentlyreleaseddatasetofEnglishquestionswithboththeiranswersandgroundedlogicalforms.\\x0cWhileWebQuestionsisdominatedbysimpleentity-attributequestions,GraphQuestionscontainsalargenumberofcompositionalquestionsinvolvingaggregation(e.g.HowmanychildrenofEddardStarkwereborninWinterfell?)andcomparison(e.g.InwhichmonthdoestheaveragerainfallofNewYorkCityexceed86mm?).Thenumberoftraining,developmentandtestquestionsis2644,1134,and2032,respectively,forWebQuestionsand1794,764,and2608forGraphQuestions.Tosupportmultilingualevaluation,wecreatedtranslationsofWebQuestionsandGraphQuestionstoGermanandSpanish.ForWebQuestionstwoprofessionalannotatorswerehiredperlanguage,whileforGraphQuestionsweusedatrustedpoolof20annotatorsperlanguage(withasingleannotatorperquestion).ExamplesoftheoriginalquestionsandtheirtranslationsareprovidedinTable1.4.3ImplementationDetailsHereweprovidedetailsonthesyntacticanalyzersemployed,ourentityresolutionalgorithm,andthefeaturesusedbythegroundingmodel.DependencyParsingTheEnglish,Spanish,andGermanUniversalDependencies(UD)treebanks(v1.3;Nivreetal2016)wereusedtotrainpartofspeechtaggersanddependencyparsers.WeusedabidirectionalLSTMtagger(Planketal.,2016)andabidirectionalLSTMshift-reduceparser(Kiper-wasserandGoldberg,2016).Boththetaggerandparserrequirewordembeddings.ForEnglish,weusedGloVeembeddings(Penningtonetal.,2014)trainedonWikipediaandtheGigawordcorpus.ForGermanandSpanish,weusedSENNAem-beddings(Collobertetal.,2011;Al-Rfouetal.,2013)trainedonWikipediacorpora(589MwordsGerman;397MwordsSpanish).6MeasuredontheUDtestsets,thetaggeraccuraciesare94.5(En-glish),92.2(German),and95.7(Spanish),withcorrespondinglabeledattachmentparserscoresof81.8,74.7,and82.2.EntityResolutionWefollowReddyetal.(2016)andresolveentitiesinthreesteps:(1)potentialen-tityspansareidentiﬁedusingsevenhandcraftedpart-of-speechpatterns;(2)eachspanisassociatedwithpotentialFreebaseentitiesaccordingtotheFreebase/KGAPI;and(3)the10-bestentitylink-inglattices,scoredbyastructuredperceptron,are6https://sites.google.com/site/rmyeid/projects/polyglot.WebQuestionsenWhatlanguagedothepeopleinGhanaspeak?deWelcheSprachewirdinGhanagesprochen?es¿Cu´aleslalenguadeGhana?enWhowasVincentvanGoghinspiredby?deVonwemwurdeVincentvanGoghinspiriert?es¿Qu´einspir´oaVanGogh?GraphQuestionsenNASAhashowmanylaunchsites?deWievieleAbschussbasenbesitztNASA?es¿Cu´antossitiosdedespeguetieneNASA?enWhichloudspeakersareheavierthan82.0kg?deWelcheLautsprechersindschwererals82.0kg?es¿Qu´ealtavocespesanm´asde82.0kg?Table1:Examplequestionsandtheirtranslations.kWebQuestionsGraphQuestionsendeesendees189.682.886.747.239.939.51095.791.294.056.948.451.6Table2:Structuredperceptronk-bestentitylinkingaccuraciesonthedevelopmentsets.inputtoGRAPHPARSER,leavingtheﬁnaldisam-biguationtothesemanticparsingproblem.Table2showsthe1-bestand10-bestentitydisambiguationF1-scoresforeachlanguageanddataset.FeaturesWeusefeaturessimilartoReddyetal.(2016):basicfeaturesofwordsandFreebasere-lations,andgraphfeaturescrossingungroundedeventswithgroundedrelations,ungroundedtypeswithgroundedrelations,andungroundedanswertypecrossedwithabinaryfeatureindicatingiftheanswerisanumber.Inaddition,weaddfeaturesencodingthesemanticsimilarityofungroundedeventsandFreebaserelations.Speciﬁcally,weusedthecosinesimilarityofthetranslation-invariantem-beddingsofHuangetal.(2015).74.4ComparisonSystemsWecomparedUDEPLAMBDAtofourversionsofGRAPHPARSERthatoperateondifferentrepresen-tations,inadditiontopriorwork.SINGLEEVENTThismodelresemblesthelearning-to-rankmodelofBastandHaussmann(2015).Anungroundedgraphisgeneratedbycon-nectingallentitiesinthequestionwiththeTARGETnode,representingasingleevent.Notethatthis7http://128.2.220.95/multilingual/data/.\\x0cWebQuestionsGraphQuestionsMethodendeesendeesSINGLEEVENT48.545.646.315.98.811.4DEPTREE48.845.946.416.08.311.3CCGGRAPH49.5––15.9––UDEPLAMBDA49.546.147.517.79.512.8UDEPLAMBDASRL49.846.247.017.79.112.7Table3:F1-scoresonthetestdata.baselinecannothandlecompositionalquestions,orthosewithaggregationorcomparison.DEPTREEAnungroundedgraphisobtaineddi-rectlyfromtheoriginaldependencytree.Aneventiscreatedforeachparentanditsdependentsinthetree.Eachdependentislinkedtothiseventwithanedgelabeledwithitsdependencyrelation,whiletheparentislinkedtotheeventwithanedgelabeledarg0.Ifawordisaquestionword,anadditionalTARGETpredicateisattachedtoitsentitynode.CCGGRAPHThisistheCCG-basedsemanticrepresentationofReddyetal.(2014).NotethatthisbaselineexistsonlyforEnglish.UDEPLAMBDASRLThisissimilartoUDEP-LAMBDAexceptthatinsteadofassumingnsubj,dobjandnsubjpasscorrespondtoarg1,arg2andarg2,weemploysemanticrolelabelingtoidentifythecorrectinterpretation.WeusedthesystemsofRothandWoodsend(2014)forEnglishandGer-manandBjrkelundetal.(2009)forSpanishtrainedontheCoNLL-2009dataset(Hajietal.,2009).84.5ResultsTable3showstheperformanceofGRAPHPARSERwiththesedifferentrepresentations.Hereandinwhatfollows,weuseaverageF1-scoreofpredictedanswers(Berantetal.,2013)astheevaluationmet-ric.WeﬁrstobservethatUDEPLAMBDAconsis-tentlyoutperformstheSINGLEEVENTandDEP-TREErepresentationsinalllanguages.ForEnglish,performanceisonparwithCCG-GRAPH,whichsuggeststhatUDEPLAMBDAdoesnotsacriﬁcetoomuchspeciﬁcityforuniversal-ity.Withbothdatasets,resultsarelowerforGer-mancomparedtoSpanish.ThisagreeswiththelowerperformanceofthesyntacticparserontheGermanportionoftheUDtreebank.WhileU-DEPLAMBDASRLperformsbetterthanUDEP-8Theparseraccuracies(%)are87.33,81.38and79.91forEnglish,GermanandSpanishrespectively.MethodGraphQ.WebQ.SEMPRE(Berantetal.,2013)10.835.7JACANA(YaoandVanDurme,2014)5.133.0PARASEMPRE(BerantandLiang,2014)12.839.9QA(Yao,2015)–44.3AQQU(BastandHaussmann,2015)–49.4AGENDAIL(BerantandLiang,2015)–49.7DEPLAMBDA(Reddyetal.,2016)–50.3STAGG(Yihetal.,2015)–48.4(52.5)BILSTM(T¨ureandJojic,2016)–24.9(52.2)MCNN(Xuetal.,2016)–47.0(53.3)AGENDAIL-RANK(Yavuzetal.,2016)–51.6(52.6)UDEPLAMBDA17.749.5Table4:F1-scoresontheEnglishGraphQuestionsandWebQuestionstestsets(resultswithadditionaltask-speciﬁcresourcesinparentheses).LAMBDAonWebQuestionsforEnglish,wedonotseelargeperformancegapsinothersettings,sug-gestingthatGRAPHPARSERiseitherabletolearncontext-sensitivesemanticsofungroundedpredi-catesorthatthedatasetsdonotcontainambiguousnsubj,dobjandnsubjpassmappings.Finally,whiletheseresultsconﬁrmthatGraphQuestionsismuchhardercomparedtoWebQuestions,wenotethatbothdatasetspredominantlycontainsingle-hopquestions,asindicatedbythecompetitiveperfor-manceofSINGLEEVENTonbothdatasets.Table4comparesUDEPLAMBDAwithprevi-ouslypublishedmodelswhichexistonlyforEn-glishandhavebeenmainlyevaluatedonWeb-Questions.Theseareeithersymboliclikeours(ﬁrstblock)oremployneuralnetworks(secondblock).Resultsformodelsusingadditionaltask-speciﬁctrainingresources,suchasClueWeb09,Wikipedia,orSimpleQuestions(Bordesetal.,2015)areshowninparentheses.OnGraphQuestions,weachieveanewstate-of-the-artresultwithagainof4.8F1-pointsoverthepreviouslyreportedbestresult.OnWebQuestionsweare2.1pointsbelowthebestmodelusingcomparableresources,and3.8pointsbelowthestateoftheart.MostrelatedtoourworkistheEnglish-speciﬁcsystemofReddyetal.(2016).Weattributethe0.8pointdifferenceinF1-scoretotheiruseofthemoreﬁne-grainedPTBtagsetandStanfordDependencies.5RelatedWorkOurworkcontinuesthelongtraditionofbuildinglogicalformsfromsyntacticrepresentationsiniti-atedbyMontague(1973).Theliteratureisrifewith\\x0cattemptstodevelopsemanticinterfacesforHPSG(Copestakeetal.,2005),LFG(KaplanandBresnan,1982;Dalrympleetal.,1995;CrouchandKing,2006),TAG(KallmeyerandJoshi,2003;GardentandKallmeyer,2003;NessonandShieber,2006),andCCG(BaldridgeandKruijff,2002;Bosetal.,2004;Artzietal.,2015).Unlikeexistingsemanticinterfaces,UDEPLAMBDAusesdependencysyn-tax,awidelyavailablesyntacticresource.Acommontrendinpreviousworkonseman-ticinterfacesistherelianceonrichtypedfeaturestructuresorsemantictypescoupledwithstrongtypeconstraints,whichcanbeveryinformativebutunavoidablylanguagespeciﬁc.Instead,UDEP-LAMBDAreliesongenericunlexicalizedinforma-tionpresentindependencytreebanksandusesasimpletypesystem(onetypefordependencylabels,andoneforwords)alongwithacombinatorymech-anism,whichavoidstypecollisions.Earlierat-temptsatextractingsemanticrepresentationsfromdependencieshavemainlyfocusedonlanguage-speciﬁcdependencyrepresentations(SpreyerandFrank,2005;SimovandOsenova,2011;HahnandMeurers,2011;Reddyetal.,2016;Falkeetal.,2016;Beltagy,2016),andmulti-layereddepen-dencyannotations(Jakobetal.,2010;B´edarideandGardent,2011).Incontrast,UDEPLAMBDAderivessemanticrepresentationsformultiplelan-guagesinacommonschemadirectlyfromUniver-salDependencies.Thisworkparallelsagrowinginterestincreatingotherformsofmultilingualse-manticrepresentations(Akbiketal.,2015;Vander-wendeetal.,2015;Whiteetal.,2016;EvangandBos,2016).WeevaluateUDEPLAMBDAonsemanticpars-ingforquestionansweringagainstaknowledgebase.Here,theliteratureofferstwomainmodelingparadigms:(1)learningoftask-speciﬁcgrammarsthatdirectlyparselanguagetoagroundedrepre-sentation(ZelleandMooney,1996;ZettlemoyerandCollins,2005;Berantetal.,2013;Flaniganetal.,2014;PasupatandLiang,2015;Groschwitzetal.,2015);and(2)convertinglanguagetoalin-guisticallymotivatedtask-independentrepresenta-tionthatisthenmappedtoagroundedrepresenta-tion(Kwiatkowskietal.,2013;Reddyetal.,2014;KrishnamurthyandMitchell,2015;GardnerandKrishnamurthy,2017).Ourworkbelongstothelatterparadigm,aswemapnaturallanguagetoFreebaseindirectlyvialogicalforms.Capitalizingonnatural-languagesyntaxaffordsinterpretability,scalability,andreducedduplicationofeffortacrossapplications(Benderetal.,2015).Ourworkalsore-latestoliteratureonparsingmultiplelanguagestoacommonexecutablerepresentation(Cimianoetal.,2013;HaasandRiezler,2016).However,existingapproachesstillmaptothetargetmeaningrepresen-tations(moreorless)directly(Kwiatkowksietal.,2010;Jonesetal.,2012;JieandLu,2014).6ConclusionsWeintroducedUDEPLAMBDA,asemanticinter-faceforUniversalDependencies,andshowedthattheresultingsemanticrepresentationcanbeusedforquestion-answeringagainstaknowledgebaseinmultiplelanguages.WeprovidedtranslationsofbenchmarkdatasetsinGermanandSpanish,inthehopetostimulatefurthermultilingualresearchonsemanticparsingandquestionansweringingen-eral.WehaveonlyscratchedthesurfacewhenitcomestoapplyingUDEPLAMBDAtonaturallan-guageunderstandingtasks.Inthefuture,wewouldliketoexplorehowthisframeworkcanbeneﬁtap-plicationssuchassummarization(Liuetal.,2015)andmachinereading(SachanandXing,2016).AcknowledgementsThisworkgreatlybeneﬁtedfromdiscussionswithMichaelCollins,DipanjanDas,FedericoFancellu,JuliaHockenmaier,TomKwiatkowski,AdamLopez,ValeriadePaiva,MarthaPalmer,FernandoPereira,EmilyPitler,VijaySaraswat,NathanSchneider,BonnieWebber,LukeZettlemoyer,andthemembersofILCCEdinburghUniversity,theMicrosoftResearchRedmondNLPgroup,theStan-fordNLPgroup,andtheUWNLPandLinguisticsgroup.WethankReviewer2forusefulfeedback.TheauthorswouldalsoliketothanktheUniver-salDependenciescommunityforthetreebanksanddocumentation.ThisresearchissupportedbyaGooglePhDFellowshiptotheﬁrstauthor.Weac-knowledgetheﬁnancialsupportoftheEuropeanResearchCouncil(Lapata;awardnumber681760).ReferencesLashaAbzianidze,JohannesBjerva,KilianEvang,HesselHaagsma,RikvanNoord,PierreLudmann,Duc-DuyNguyen,andJohanBos.2017.ThePar-allelMeaningBank:TowardsaMultilingualCor-pusofTranslationsAnnotatedwithCompositionalMeaningRepresentations.InProceedingsofthe\\x0cEuropeanChapteroftheAssociationforCompu-tationalLinguistics.AssociationforComputationalLinguistics,Valencia,Spain,pages242–247.AlanAkbik,laurachiticariu,MarinaDanilevsky,Yun-yaoLi,ShivakumarVaithyanathan,andHuaiyuZhu.2015.GeneratingHighQualityPropositionBanksforMultilingualSemanticRoleLabeling.InPro-ceedingsoftheAssociationforComputationalLin-guisticsandtheInternationalJointConferenceonNaturalLanguageProcessing.AssociationforCom-putationalLinguistics,Beijing,China,pages397–407.RamiAl-Rfou,BryanPerozzi,andStevenSkiena.2013.Polyglot:DistributedWordRepresentationsforMultilingualNLP.InProceedingsoftheCom-putationalNaturalLanguageLearning.Soﬁa,Bul-garia,pages183–192.YoavArtzi.2013.CornellSPF:CornellSemanticPars-ingFramework.arXiv:1311.3011[cs.CL].YoavArtzi,KentonLee,andLukeZettlemoyer.2015.Broad-coverageCCGSemanticParsingwithAMR.InProceedingsoftheEmpiricalMethodsonNaturalLanguageProcessing.pages1699–1710.JasonBaldridgeandGeert-JanKruijff.2002.CouplingCCGandHybridLogicDependencySemantics.InProceedingsoftheAssociationforComputationalLinguistics.pages319–326.LauraBanarescu,ClaireBonial,ShuCai,MadalinaGeorgescu,KiraGrifﬁtt,UlfHermjakob,KevinKnight,PhilippKoehn,MarthaPalmer,andNathanSchneider.2013.AbstractMeaningRepresentationforSembanking.InLinguisticAnnotationWorkshopandInteroperabilitywithDiscourse.Soﬁa,Bulgaria,pages178–186.HannahBastandElmarHaussmann.2015.MoreAc-curateQuestionAnsweringonFreebase.InPro-ceedingsofACMInternationalConferenceonInfor-mationandKnowledgeManagement.pages1431–1440.PaulB´edarideandClaireGardent.2011.DeepSeman-ticsforDependencyStructures.InProceedingsofConferenceonIntelligentTextProcessingandCom-putationalLinguistics.pages277–288.IslamBeltagy.2016.NaturalLanguageSemanticsUs-ingProbabilisticLogic.Ph.D.thesis,DepartmentofComputerScience,TheUniversityofTexasatAustin.EmilyM.Bender,DanFlickinger,StephanOepen,WoodleyPackard,andAnnCopestake.2015.Lay-ersofInterpretation:OnGrammarandComposition-ality.InProceedingsoftheInternationalConfer-enceonComputationalSemantics.AssociationforComputationalLinguistics,London,UK,pages239–249.JonathanBerant,AndrewChou,RoyFrostig,andPercyLiang.2013.SemanticParsingonFreebasefromQuestion-AnswerPairs.InProceedingsoftheEm-piricalMethodsonNaturalLanguageProcessing.pages1533–1544.JonathanBerantandPercyLiang.2014.SemanticPars-ingviaParaphrasing.InProceedingsoftheAsso-ciationforComputationalLinguistics.pages1415–1425.JonathanBerantandPercyLiang.2015.ImitationLearningofAgenda-BasedSemanticParsers.Trans-actionsoftheAssociationforComputationalLin-guistics3:545–558.AndersBjrkelund,LoveHafdell,andPierreNugues.2009.MultilingualSemanticRoleLabeling.InProceedingsofComputationalNaturalLanguageLearning(CoNLL2009):SharedTask.AssociationforComputationalLinguistics,Boulder,Colorado,pages43–48.AntoineBordes,NicolasUsunier,SumitChopra,andJasonWeston.2015.Large-scalesimpleques-tionansweringwithmemorynetworks.CoRRabs/1506.02075.JohanBos,StephenClark,MarkSteedman,JamesR.Curran,andJuliaHockenmaier.2004.Wide-CoverageSemanticRepresentationsfromaCCGParser.InProceedingsoftheConferenceonCom-putationalLinguistics.pages1240–1246.PhilippCimiano,VanessaLopez,ChristinaUnger,ElenaCabrio,Axel-CyrilleNgongaNgomo,andSebastianWalter.2013.Multilingualquestionan-sweringoverlinkeddata(QALD-3):Laboverview.InInformationAccessEvaluation.Multilinguality,Multimodality,andVisualization.Springer,Valencia,Spain,volume8138.MichaelCollins.2002.DiscriminativeTrainingMeth-odsforHiddenMarkovModels:TheoryandExper-imentswithPerceptronAlgorithms.InProceedingsoftheEmpiricalMethodsonNaturalLanguagePro-cessing.pages1–8.RonanCollobert,JasonWeston,LeonBottou,MichaelKarlen,KorayKavukcuoglu,andPavelKuks.2011.Naturallanguageprocessing(almost)fromscratch.JournalofMachineLearningResearch12:2493–2537.AnnCopestake,DanFlickinger,CarlPollard,andIvanA.Sag.2005.MinimalRecursionSemantics:AnIntroduction.ResearchonLanguageandCom-putation3(2-3):281–332.DickCrouchandTracyHollowayKing.2006.Seman-ticsviaf-structurerewriting.InProceedingsoftheLFG’06Conference.CSLIPublications,page145.MaryDalrymple,JohnLamping,FernandoC.N.Pereira,andVijayA.Saraswat.1995.LinearLogicforMeaningAssembly.InProceedingsofComputa-tionalLogicforNaturalLanguageProcessing.\\x0cKilianEvangandJohanBos.2016.Cross-lingualLearningofanOpen-domainSemanticParser.InProceedingsoftheConferenceonComputationalLinguistics.TheCOLING2016OrganizingCom-mittee,Osaka,Japan,pages579–588.TobiasFalke,GabrielStanovsky,IrynaGurevych,andIdoDagan.2016.PortinganOpenInformationEx-tractionSystemfromEnglishtoGerman.InPro-ceedingsoftheEmpiricalMethodsinNaturalLan-guageProcessing.AssociationforComputationalLinguistics,Austin,Texas,pages892–898.JeffreyFlanigan,SamThomson,JaimeCarbonell,ChrisDyer,andNoahA.Smith.2014.ADiscrimi-nativeGraph-BasedParserfortheAbstractMeaningRepresentation.InProceedingsoftheAssociationforComputationalLinguistics.pages1426–1436.ClaireGardentandLauraKallmeyer.2003.SemanticConstructioninFeature-basedTAG.InProceedingsofEuropeanChapteroftheAssociationforCompu-tationalLinguistics.pages123–130.MattGardnerandJayantKrishnamurthy.2017.Open-VocabularySemanticParsingwithbothDistribu-tionalStatisticsandFormalKnowledge.InProceed-ingsofAssociationfortheAdvancementofArtiﬁcialIntelligence.JonasGroschwitz,AlexanderKoller,andChristophTe-ichmann.2015.Graphparsingwiths-graphgram-mars.InProceedingsoftheAssociationforCompu-tationalLinguistics.pages1481–1490.CarolinHaasandStefanRiezler.2016.ACorpusandSemanticParserforMultilingualNaturalLanguageQueryingofOpenStreetMap.InProceedingsoftheNorthAmericanChapteroftheAssociationforComputationalLinguistics:HumanLanguageTech-nologies.AssociationforComputationalLinguistics,SanDiego,California,pages740–750.MichaelHahnandDetmarMeurers.2011.Onderiv-ingsemanticrepresentationsfromdependencies:Apracticalapproachforevaluatingmeaninginlearnercorpora.InProceedingsoftheInt.ConferenceonDependencyLinguistics(Depling2011).Barcelona,pages94–103.JanHaji,MassimilianoCiaramita,RichardJohans-son,DaisukeKawahara,MariaAntniaMart,LlusMrquez,AdamMeyers,JoakimNivre,SebastianPad,Jantpnek,andothers.2009.TheCoNLL-2009sharedtask:Syntacticandsemanticdependenciesinmultiplelanguages.InProceedingsoftheCompu-tationalNaturalLanguageLearning:SharedTask.AssociationforComputationalLinguistics,pages1–18.KejunHuang,MattGardner,EvangelosPapalex-akis,ChristosFaloutsos,NikosSidiropoulos,TomMitchell,ParthaP.Talukdar,andXiaoFu.2015.TranslationInvariantWordEmbeddings.InPro-ceedingsoftheEmpiricalMethodsinNaturalLan-guageProcessing.Lisbon,Portugal,pages1084–1088.MaxJakob,Mark´etaLopatkov´a,andValiaKordoni.2010.MappingbetweenDependencyStructuresandCompositionalSemanticRepresentations.InPro-ceedingsoftheFifthInternationalConferenceonLanguageResourcesandEvaluation.ZhanmingJieandWeiLu.2014.MultilingualSeman-ticParsing:ParsingMultipleLanguagesintoSe-manticRepresentations.InProceedingsoftheCon-ferenceonComputationalLinguistics.DublinCityUniversityandAssociationforComputationalLin-guistics,Dublin,Ireland,pages1291–1301.BevanKeeleyJones,MarkJohnson,andSharonGold-water.2012.SemanticParsingwithBayesianTreeTransducers.InProceedingsoftheAssociationforComputationalLinguistics.AssociationforCompu-tationalLinguistics,Stroudsburg,PA,USA,pages488–496.LauraKallmeyerandAravindJoshi.2003.Factor-ingpredicateargumentandscopesemantics:Under-speciﬁedsemanticswithLTAG.ResearchonLan-guageandComputation1(1-2):3–58.RonaldMKaplanandJoanBresnan.1982.Lexical-functionalgrammar:Aformalsystemforgram-maticalrepresentation.FormalIssuesinLexical-FunctionalGrammarpages29–130.EliyahuKiperwasserandYoavGoldberg.2016.Sim-pleandAccurateDependencyParsingUsingBidi-rectionalLSTMFeatureRepresentations.Transac-tionsoftheAssociationforComputationalLinguis-tics4:313–327.JayantKrishnamurthyandTomM.Mitchell.2015.LearningaCompositionalSemanticsforFreebasewithanOpenPredicateVocabulary.TransactionsoftheAssociationforComputationalLinguistics3:257–270.TomKwiatkowksi,LukeZettlemoyer,SharonGoldwa-ter,andMarkSteedman.2010.InducingProbabilis-ticCCGGrammarsfromLogicalFormwithHigher-OrderUniﬁcation.InProceedingsoftheEmpiri-calMethodsonNaturalLanguageProcessing.pages1223–1233.TomKwiatkowski,EunsolChoi,YoavArtzi,andLukeZettlemoyer.2013.ScalingSemanticParserswithOn-the-FlyOntologyMatching.InProceedingsoftheEmpiricalMethodsonNaturalLanguagePro-cessing.pages1545–1556.RogerLevyandGalenAndrew.2006.Tregexandtsur-geon:toolsforqueryingandmanipulatingtreedatastructures.InProceedingsofLREC.pages2231–2234.\\x0cFeiLiu,JeffreyFlanigan,SamThomson,NormanSadeh,andNoahA.Smith.2015.TowardAb-stractiveSummarizationUsingSemanticRepresen-tations.InProceedingsofNorthAmericanChap-teroftheAssociationforComputationalLinguistics.pages1077–1086.MitchellP.Marcus,MaryAnnMarcinkiewicz,andBeatriceSantorini.1993.BuildingalargeannotatedcorpusofEnglish:ThePennTreebank.Computa-tionallinguistics19(2):313–330.RichardMontague.1973.TheProperTreatmentofQuantiﬁcationinOrdinaryEnglish.InK.J.J.Hin-tikka,J.M.E.Moravcsik,andP.Suppes,editors,ApproachestoNaturalLanguage,SpringerNether-lands,volume49ofSyntheseLibrary,pages221–242.RebeccaNessonandStuartM.Shieber.2006.SimplerTAGSemanticsThroughSynchronization.InPro-ceedingsofthe11thConferenceonFormalGram-mar.CenterfortheStudyofLanguageandInforma-tion,Malaga,Spain,pages129–142.JoakimNivre,Marie-CatherinedeMarneffe,FilipGin-ter,YoavGoldberg,JanHajic,ChristopherD.Man-ning,RyanMcDonald,SlavPetrov,SampoPyysalo,NataliaSilveira,ReutTsarfaty,andDanielZeman.2016.UniversalDependenciesv1:AMultilingualTreebankCollection.InProceedingsoftheTenthIn-ternationalConferenceonLanguageResourcesandEvaluation.EuropeanLanguageResourcesAssocia-tion(ELRA),Paris,France.JoakimNivreetal.2016.Universaldependencies1.3.LINDAT/CLARINdigitallibraryattheInstituteofFormalandAppliedLinguistics,CharlesUniversityinPrague.MarthaPalmer,DanielGildea,andPaulKingsbury.2005.Thepropositionbank:Anannotatedcorpusofsemanticroles.Computationallinguistics31(1):71–106.MarthaPalmer,DanielGildea,andNianwenXue.2010.Semanticrolelabeling.SynthesisLecturesonHu-manLanguageTechnologies3(1):1–103.PanupongPasupatandPercyLiang.2015.Composi-tionalSemanticParsingonSemi-StructuredTables.InProceedingsoftheAssociationforComputationalLinguistics.pages1470–1480.JeffreyPennington,RichardSocher,andChristopherManning.2014.Glove:GlobalVectorsforWordRepresentation.InProceedingsoftheEmpiricalMethodsinNaturalLanguageProcessing.Associ-ationforComputationalLinguistics,Doha,Qatar,pages1532–1543.BarbaraPlank,AndersSøgaard,andYoavGoldberg.2016.MultilingualPart-of-SpeechTaggingwithBidirectionalLongShort-TermMemoryModelsandAuxiliaryLoss.InProceedingsoftheAnnualMeet-ingoftheAssociationforComputationalLinguistics.Berlin,Germany,pages412–418.SivaReddy,MirellaLapata,andMarkSteedman.2014.Large-scaleSemanticParsingwithoutQuestion-AnswerPairs.TransactionsoftheAssociationforComputationalLinguistics2:377–392.SivaReddy,OscarT¨ackstr¨om,MichaelCollins,TomKwiatkowski,DipanjanDas,MarkSteedman,andMirellaLapata.2016.TransformingDependencyStructurestoLogicalFormsforSemanticParsing.TransactionsoftheAssociationforComputationalLinguistics4:127–140.MichaelRothandKristianWoodsend.2014.Compo-sitionofWordRepresentationsImprovesSemanticRoleLabelling.InProceedingsoftheEmpiricalMethodsinNaturalLanguageProcessing(EMNLP).AssociationforComputationalLinguistics,Doha,Qatar,pages407–413.MrinmayaSachanandEricXing.2016.MachineCom-prehensionusingRichSemanticRepresentations.InProceedingsoftheAssociationforComputationalLinguistics.AssociationforComputationalLinguis-tics,Berlin,Germany,pages486–492.SebastianSchusterandChristopherD.Manning.2016.EnhancedEnglishUniversalDependencies:AnIm-provedRepresentationforNaturalLanguageUnder-standingTasks.InProceedingsoftheTenthInterna-tionalConferenceonLanguageResourcesandEval-uation.EuropeanLanguageResourcesAssociation(ELRA),Paris,France.KirilSimovandPetyaOsenova.2011.TowardsMin-imalRecursionSemanticsoverBulgarianDepen-dencyParsing.InProceedingsoftheInternationalConferenceRecentAdvancesinNaturalLanguageProcessing2011.RANLP2011OrganisingCommit-tee,Hissar,Bulgaria,pages471–478.KathrinSpreyerandAnetteFrank.2005.ProjectingRMRSfromTIGERDependencies.InProceedingsoftheHPSG2005Conference.CSLIPublications.YuSu,HuanSun,BrianSadler,MudhakarSrivatsa,IzzeddinGur,ZenghuiYan,andXifengYan.2016.OnGeneratingCharacteristic-richQuestionSetsforQAEvaluation.InProceedingsoftheEmpiricalMethodsinNaturalLanguageProcessing.Austin,Texas,pages562–572.FerhanT¨ureandOliverJojic.2016.SimpleandEf-fectiveQuestionAnsweringwithRecurrentNeuralNetworks.CoRRabs/1606.05029.LucyVanderwende,ArulMenezes,andChrisQuirk.2015.AnAMRparserforEnglish,French,German,SpanishandJapaneseandanewAMR-annotatedcorpus.InProceedingsoftheNorthAmericanChap-teroftheAssociationforComputationalLinguistics:Demonstrations.AssociationforComputationalLin-guistics,Denver,Colorado,pages26–30.\\x0cAaronStevenWhite,DrewReisinger,KeisukeSak-aguchi,TimVieira,ShengZhang,RachelRudinger,KyleRawlins,andBenjaminVanDurme.2016.Uni-versalDecompositionalSemanticsonUniversalDe-pendencies.InProceedingsoftheEmpiricalMeth-odsinNaturalLanguageProcessing.AssociationforComputationalLinguistics,Austin,Texas,pages1713–1723.KunXu,SivaReddy,YansongFeng,SongfangHuang,andDongyanZhao.2016.QuestionAnsweringonFreebaseviaRelationExtractionandTextualEvi-dence.InProceedingsoftheAssociationforCompu-tationalLinguistics.AssociationforComputationalLinguistics,Berlin,Germany,pages2326–2336.XuchenYao.2015.LeanQuestionAnsweringoverFreebasefromScratch.InProceedingsofNorthAmericanChapteroftheAssociationforComputa-tionalLinguistics.pages66–70.XuchenYaoandBenjaminVanDurme.2014.Infor-mationExtractionoverStructuredData:QuestionAnsweringwithFreebase.InProceedingsoftheAs-sociationforComputationalLinguistics.pages956–966.SemihYavuz,IzzeddinGur,YuSu,MudhakarSrivatsa,andXifengYan.2016.ImprovingSemanticParsingviaAnswerTypeInference.InProceedingsoftheEmpiricalMethodsinNaturalLanguageProcessing.AssociationforComputationalLinguistics,Austin,Texas,pages149–159.Wen-tauYih,Ming-WeiChang,XiaodongHe,andJianfengGao.2015.SemanticParsingviaStagedQueryGraphGeneration:QuestionAnsweringwithKnowledgeBase.InProceedingsoftheAssociationforComputationalLinguistics.pages1321–1331.JohnM.ZelleandRaymondJ.Mooney.1996.Learn-ingtoParseDatabaseQueriesUsingInductiveLogicProgramming.InProceedingsofAssociationfortheAdvancementofArtiﬁcialIntelligence.pages1050–1055.LukeS.ZettlemoyerandMichaelCollins.2005.Learn-ingtoMapSentencestoLogicalForm:StructuredClassiﬁcationwithProbabilisticCategorialGram-mars.InProceedingsofUncertaintyinArtiﬁcialIn-telligence.pages658–666.\\x0cUniversalSemanticParsing:SupplementaryMaterialSivaReddy†OscarT¨ackstr¨om‡SlavPetrov‡MarkSteedman††MirellaLapata†††StanfordUniversity‡GoogleInc.††UniversityofEdinburghsivar@stanford.edu,{oscart,slav}@google.com,{steedman,mlap}@inf.ed.ac.ukAbstractThissupplementarymaterialtothemainpaper,providesanoutlineofhowquantiﬁ-cationcanbeincorporatedintheUDEP-LAMBDAframework.1UniversalQuantiﬁcationConsiderthesentenceEverybodywantstobuyahouse,1whosedependencytreeintheUniversalDependencies(UD)formalismisshowninFig-ure1(a).Thissentencehastwopossiblereadings:either(1)everypersonwantstobuyadifferenthouse;or(2)everypersonwantstobuythesamehouse.Thetwointerpretationscorrespondtothefollowinglogicalforms:(1)∀x.person(xa)→[∃zyw.wants(ze)∧arg1(ze,xa)∧buy(ye)∧xcomp(ze,ye)∧house(wa)∧arg1(ze,xa)∧arg2(ze,wa)];(2)∃w.house(wa)∧(∀x.person(xa)→[∃zy.wants(ze)∧arg1(ze,xa)∧buy(ye)∧xcomp(ze,ye)∧arg1(ze,xa)∧arg2(ze,wa)]).In(1),theexistentialvariablewisinthescopeoftheuniversalvariablex(i.e.thehouseisdependentontheperson).Thisreadingiscommonlyreferredtoasthesurfacereading.Conversely,in(2)theuniversalvariablexisinthescopeoftheexistentialvariablew(i.e.thehouseisindependentoftheperson).Thisreadingisalsocalledinversereading.Ourgoalistoobtainthesurfacereadinglogicalformin(1)withUDEPLAMBDA.Wedonotaimtoobtaintheinversereading,althoughthisispossiblewiththeuseofSkolemization(Steedman,2012).InUDEPLAMBDA,lambdaexpressionsforwords,phrasesandsentencesarealloftheformλx.....Butfrom(1),itisclearthatweneedtoexpressvariablesboundbyquantiﬁers,e.g.∀x,whilestillprovidingaccesstoxforcomposition.Thisdemandsachangeinthetypesystemsincethe1ExampleborrowedfromSchusterandManning(2016).Everybodywantstobuyahousensubjxcompdobjdetmarkroot(a)Originaldependencytree.EverybodywantstobuyahousensubjxcompdobjdetmarkrootΩΩbindnsubj(b)Enhanceddependencytree.Everybodywantstobuyahousensubj:univxcompdobjdetmarkrootΩΩbindnsubj(c)Enhanceddependencytreewithuniversalquantiﬁcation.Figure1:ThedependencytreeforEverybodywantstobuyahouseanditsenhancedvariants.samevariablecannotbelambdaboundandquanti-ﬁerbound—thatiswecannothaveformulasoftheformλx...∀x....Inthismaterial,weﬁrstderivethelogicalformfortheexamplesentenceusingthetypesystemfromourmainpaper(Section1.1)andshowthatitfailstohandleuniversalquantiﬁ-cation.Wethenmodifythetypesystemslightlytoallowderivationofthedesiredsurfacereadinglogicalform(Section1.2).Thismodiﬁedtypesys-temisastrictgeneralizationoftheoriginaltypesystem.2Fancelluetal.(2017)presentanelaboratediscussiononthemodiﬁedtypesystem,andhowitcanhandlenegationscopeanditsinteractionwithuniversalquantiﬁers.2Notethatthistreatmenthasyettobeaddedtoourimplementation,whichcanbefoundathttps://github.com/sivareddyg/udeplambda.\\x0c1.1WithOriginalTypeSystemWewillﬁrstattempttoderivethelogicalformin(1)usingthedefaulttypesystemofUDEPLAMBDA.Figure1(b)showstheenhanceddependencytreeforthesentence,whereBINDhasbeenintroducedtoconnecttheimpliednsubjofbuy(BINDisex-plainedinthemainpaperinSection3.2).Thes-expressioncorrespondingtotheenhancedtreeis:(nsubj(xcompwants(mark(nsubj(dobjbuy(dethousea))Ω)to))(BINDeverybodyΩ)).Withthefollowingsubstitutionentries,wants,buy∈EVENT;everybody,house∈ENTITY;a,to∈FUNCTIONAL;Ω=λx.EQ(x,ω);nsubj=λfgx.∃y.f(x)∧g(y)∧arg1(xe,ya);dobj=λfgx.∃y.f(x)∧g(y)∧arg2(xe,ya);xcomp=λfgx.∃y.f(x)∧g(y)∧xcomp(xe,ya);mark∈HEAD;BIND∈MERGE,thelambdaexpressionaftercompositionbecomes:λz.∃xywv.wants(ze)∧everybody(xa)∧arg1(ze,xa)∧EQ(x,ω)∧buy(ye)∧xcomp(ze,ye)∧arg1(ye,va)∧EQ(v,ω)∧arg1(xe,ya)∧house(wa)∧arg2(ye,wa).Thisexpressionencodesthefactthatxandvareinuniﬁcation,andcanthusbefurthersimpliﬁedto:(3)λz.∃xyw.wants(ze)∧everybody(xa)∧arg1(ze,xa)∧buy(ye)∧xcomp(ze,ye)∧arg1(ye,xa)∧arg1(xe,ya)∧house(wa)∧arg2(ye,wa).However,thelogicalform(3)differsfromthedesiredform(1).Asnotedabove,UDEPLAMBDAwithitsdefaulttype,whereeachs-expressionmusthavethetypeη=Ind×Event→Bool,cannothandlequantiﬁerscoping.1.2WithHigher-orderTypeSystemFollowingChampollion(2010),wemakeaslightmodiﬁcationtothetypesystem.Insteadofusingexpressionsoftheformλx....forwords,weuseeitherλf.∃x....orλf.∀x....,wherefhastypeη.AsarguedbyChampollion,thishigher-orderformmakesquantiﬁcationandnegationhandlingsoundandsimplerinNeo-Davidsonianeventsemantics.Followingthischange,weassignthefollowinglambdaexpressionstothewordsinourexamplesentence:everybody=λf.∀x.person(x)→f(x);wants=λf.∃x.wants(xe)∧f(x);to=λf.TRUE;buy=λf.∃x.buy(xe)∧f(x);a=λf.TRUE;house=λf.∃x.house(xa)∧f(x);Ω=λf.f(ω).Hereeverybodyisassigneduniversalquantiﬁersemantics.SincetheUDrepresentationdoesnotdistinguishquantiﬁers,weneedtorelyonasmall(language-speciﬁc)lexicontoidentifythese.Toencodequantiﬁcationscope,weenhancethela-belnsubjtonsubj:univ,whichindicatesthatthesubjectargumentofwantscontainsauniversalquantiﬁer,asshowninFigure1(c).Thischangeofsemantictypeforwordsands-expressionsforcesustoalsomodifytheseman-tictypeofdependencylabels,inordertoobeythesingle-typeconstraintofDEPLAMBDA(Reddyetal.,2016).Thus,dependencylabelswillnowtaketheformλPQf....,wherePistheparentex-pression,Qisthechildexpression,andthereturnexpressionisoftheformλf.....Followingthischange,weassignthefollowinglambdaexpres-sionstodependencylabels:nsubj:univ=λPQf.Q(λy.P(λx.f(x)∧arg1(xe,ya)));nsubj=λPQf.P(λx.f(x)∧Q(λy.arg1(xe,ya)));dobj=λPQf.P(λx.f(x)∧Q(λy.arg2(xe,ya)));xcomp=λPQf.P(λx.f(x)∧Q(λy.xcomp(xe,ya)));det,mark=λPQf.P(f);BIND=λPQf.P(λx.f(x)∧Q(λy.EQ(y,x))).Noticethatthelambdaexpressionofnsubj:univdiffersfromnsubj.Inthefor-mer,thelambdavariablesinsideQhavewiderscopeoverthevariablesinP(i.e.theuniversalquantiﬁervariableofeverybodyhasscopeovertheeventvariableofwants)contrarytothelatter.Thenews-expressionforFigure1(c)is(nsubj:univ(xcompwants(mark(nsubj(dobjbuy(dethousea))Ω)to))(BINDeverybodyΩ)).Substitutingwiththemodiﬁedexpressions,andperformingcompositionandsimpliﬁcationleadstotheexpression:(6)λf.∀x.person(xa)→[∃zyw.f(z)∧wants(ze)∧arg1(ze,xa)∧buy(ye)∧xcomp(ze,ye)∧house(wa)∧arg1(ze,xa)∧arg2(ze,wa)].Thisexpressionisidenticalto(1)exceptfortheoutermosttermλf.Byapplying(6)toλx.TRUE,weobtain(1),whichcompletesthetreatmentofuniversalquantiﬁcationinUDEPLAMBDA.ReferencesLucasChampollion.2010.Quantiﬁcationandnegationineventsemantics.BalticInternationalYearbookofCognition,LogicandCommunication6(1):3.FedericoFancellu,SivaReddy,AdamLopez,andBon-nieWebber.2017.UniversalDependenciestoLogi-calFormswithNegationScope.arXivPreprint.\\x0cSivaReddy,OscarT¨ackstr¨om,MichaelCollins,TomKwiatkowski,DipanjanDas,MarkSteedman,andMirellaLapata.2016.TransformingDependencyStructurestoLogicalFormsforSemanticParsing.TransactionsoftheAssociationforComputationalLinguistics4:127–140.SebastianSchusterandChristopherD.Manning.2016.EnhancedEnglishUniversalDependencies:AnIm-provedRepresentationforNaturalLanguageUnder-standingTasks.InProceedingsoftheTenthInterna-tionalConferenceonLanguageResourcesandEval-uation.EuropeanLanguageResourcesAssociation(ELRA),Paris,France.MarkSteedman.2012.TakingScope-TheNaturalSe-manticsofQuantiﬁers.MITPress.\\x0c'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "17e082919eb97a8b1648db68459a0548143f50884a45122adabc4767e3d2dece"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('arxiv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
