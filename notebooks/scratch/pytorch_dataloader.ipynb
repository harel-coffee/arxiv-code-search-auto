{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup, BertForSequenceClassification\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from torchmetrics import PrecisionRecallCurve\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "device count: 1\n",
      "device name: NVIDIA GeForce GTX 980M\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"device count:\", torch.cuda.device_count())\n",
    "print(\"device name:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/code/colinlagator/pytorch-bert-multi-label/notebook\n",
    "\n",
    "https://discuss.huggingface.co/t/download-models-for-local-loading/1963\n",
    "\n",
    "Much of notebook is from: https://colab.research.google.com/drive/1PHv-IRLPCtv7oTcIGbsgZHqrB5LPvB7S#scrollTo=-FWG7kBm372V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pattern</th>\n",
       "      <th>token_count</th>\n",
       "      <th>update_date</th>\n",
       "      <th>label</th>\n",
       "      <th>para</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1710.02907</td>\n",
       "      <td>data, dataset</td>\n",
       "      <td>280</td>\n",
       "      <td>2022-04-21</td>\n",
       "      <td>0</td>\n",
       "      <td>Experiment 2: In this set of experiments, we e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1811.11012</td>\n",
       "      <td>data</td>\n",
       "      <td>195</td>\n",
       "      <td>2022-04-21</td>\n",
       "      <td>0</td>\n",
       "      <td>This section of the technical report is focuse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1811.11012</td>\n",
       "      <td>data, dataset</td>\n",
       "      <td>70</td>\n",
       "      <td>2022-04-21</td>\n",
       "      <td>0</td>\n",
       "      <td>volunteers’ vehicles were mounted with BSM-bro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1912.09582</td>\n",
       "      <td>dataset</td>\n",
       "      <td>13</td>\n",
       "      <td>2022-04-21</td>\n",
       "      <td>0</td>\n",
       "      <td>for small datasets–a case with Dutch book revi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1912.09582</td>\n",
       "      <td>dataset</td>\n",
       "      <td>15</td>\n",
       "      <td>2022-04-21</td>\n",
       "      <td>1</td>\n",
       "      <td>Table 4: Sentiment Analysis accuracy scores on...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id        pattern  token_count update_date  label  \\\n",
       "0  1710.02907  data, dataset          280  2022-04-21      0   \n",
       "1  1811.11012           data          195  2022-04-21      0   \n",
       "2  1811.11012  data, dataset           70  2022-04-21      0   \n",
       "3  1912.09582        dataset           13  2022-04-21      0   \n",
       "4  1912.09582        dataset           15  2022-04-21      1   \n",
       "\n",
       "                                                para  \n",
       "0  Experiment 2: In this set of experiments, we e...  \n",
       "1  This section of the technical report is focuse...  \n",
       "2  volunteers’ vehicles were mounted with BSM-bro...  \n",
       "3  for small datasets–a case with Dutch book revi...  \n",
       "4  Table 4: Sentiment Analysis accuracy scores on...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_data_folder = Path().cwd().parent.parent / \"data\"\n",
    "path_interim_folder = path_data_folder / \"interim\"\n",
    "path_label_folder = path_data_folder / \"processed\" / \"labels\" / \"labels_complete\"\n",
    "\n",
    "# load the labels.csv from the path_label_folder\n",
    "df = pd.read_csv(path_label_folder / \"labels.csv\", dtype={\"id\": str})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data loader -- inspired by https://curiousily.com/posts/sentiment-analysis-with-bert-and-hugging-face-using-pytorch-and-python/\n",
    "class ArxivDataset(Dataset):\n",
    "\n",
    "  def __init__(self, texts, labels, tokenizer, max_len):\n",
    "    self.texts = texts\n",
    "    self.labels = labels\n",
    "    self.tokenizer = tokenizer\n",
    "    self.max_len = max_len\n",
    "  \n",
    "  def __len__(self):\n",
    "    return len(self.texts)\n",
    "  \n",
    "  def __getitem__(self, item):\n",
    "    text = str(self.texts[item]).lower()\n",
    "    label = self.labels[item]\n",
    "\n",
    "    encoding = self.tokenizer.encode_plus(\n",
    "      text,\n",
    "      add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
    "      max_length=self.max_len,\n",
    "      return_token_type_ids=False,\n",
    "      padding='max_length',\n",
    "      return_attention_mask=True,\n",
    "      truncation=True,\n",
    "      return_tensors='pt', # Return PyTorch tensors\n",
    "    )\n",
    "\n",
    "    return {\n",
    "      'texts': text,\n",
    "      'input_ids': encoding['input_ids'].flatten(),\n",
    "      'attention_mask': encoding['attention_mask'].flatten(),\n",
    "      'labels': torch.tensor(label, dtype=torch.long)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pattern</th>\n",
       "      <th>token_count</th>\n",
       "      <th>update_date</th>\n",
       "      <th>label</th>\n",
       "      <th>para</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2011.05411</td>\n",
       "      <td>dataset</td>\n",
       "      <td>89</td>\n",
       "      <td>2022-04-21</td>\n",
       "      <td>0</td>\n",
       "      <td>2. Local Computation: Once receiving the globa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>2011.00242</td>\n",
       "      <td>python</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-04-21</td>\n",
       "      <td>0</td>\n",
       "      <td>PHP Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2108.02756</td>\n",
       "      <td>dataset</td>\n",
       "      <td>140</td>\n",
       "      <td>2022-04-21</td>\n",
       "      <td>0</td>\n",
       "      <td>Inspired by the defense mechanism presented in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2101.00522</td>\n",
       "      <td>dataset</td>\n",
       "      <td>104</td>\n",
       "      <td>2022-04-21</td>\n",
       "      <td>0</td>\n",
       "      <td>Table 3: The percentage of shift in pixel labe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2104.09994</td>\n",
       "      <td>publicly available, dataset</td>\n",
       "      <td>7</td>\n",
       "      <td>2022-04-21</td>\n",
       "      <td>0</td>\n",
       "      <td>Table 1 Public IoT network datasets.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                      pattern  token_count update_date  label  \\\n",
       "99  2011.05411                      dataset           89  2022-04-21      0   \n",
       "85  2011.00242                       python            2  2022-04-21      0   \n",
       "31  2108.02756                      dataset          140  2022-04-21      0   \n",
       "14  2101.00522                      dataset          104  2022-04-21      0   \n",
       "21  2104.09994  publicly available, dataset            7  2022-04-21      0   \n",
       "\n",
       "                                                 para  \n",
       "99  2. Local Computation: Once receiving the globa...  \n",
       "85                                         PHP Python  \n",
       "31  Inspired by the defense mechanism presented in...  \n",
       "14  Table 3: The percentage of shift in pixel labe...  \n",
       "21               Table 1 Public IoT network datasets.  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train, df_val = train_test_split(df, test_size=0.1, random_state=12)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
    "  ds = ArxivDataset(\n",
    "    texts=df.para.to_numpy(),\n",
    "    labels=df.label.to_numpy(),\n",
    "    tokenizer=tokenizer,\n",
    "    max_len=max_len\n",
    "  )\n",
    "\n",
    "  return DataLoader(\n",
    "    ds,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=4\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('allenai/scibert_scivocab_uncased')  # local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 512\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['texts', 'input_ids', 'attention_mask', 'labels'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = next(iter(train_data_loader))\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 512])\n",
      "torch.Size([2, 512])\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "print(data['input_ids'].shape)\n",
    "print(data['attention_mask'].shape)\n",
    "print(data['labels'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'texts': ['2. local computation: once receiving the global ml model from the server, the participants updates its current local ml model and then trains the updated model using the local dataset resided in the device. this step is operated at local nodes, and it requires end-users’ devices to install an fl client program to perform training algorithms such as federatedsgd and federated averaging, as well as to receive the global model updates and send the local ml model parameters from/to the server.',\n",
       "  'php python'],\n",
       " 'input_ids': tensor([[  102,   170,   205,  ...,     0,     0,     0],\n",
       "         [  102,   375, 30121,  ...,     0,     0,     0]]),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " 'labels': tensor([0, 0])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_TRAINED_MODEL_NAME = 'allenai/scibert_scivocab_uncased'\n",
    "\n",
    "MAX_LEN = 512\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArxivClassifier(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(ArxivClassifier, self).__init__()\n",
    "        self.encoder = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "\n",
    "        self.dense_1 = torch.nn.Linear(768, 768)\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.dense_2 = torch.nn.Linear(768, n_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output_1 = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_state = output_1[0]\n",
    "        pooled_output = hidden_state[:, 0]\n",
    "        pooled_output = self.dense_1(pooled_output)\n",
    "        pooled_output = torch.nn.ReLU()(pooled_output)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        output = self.dense_2(pooled_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = ArxivClassifier(4)\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(train_data_loader))\n",
    "input_ids = data['input_ids'].to(DEVICE)\n",
    "attention_mask = data['attention_mask'].to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1839, 0.2563, 0.3243, 0.2355],\n",
       "        [0.2188, 0.2299, 0.3073, 0.2440],\n",
       "        [0.2307, 0.2060, 0.3563, 0.2071],\n",
       "        [0.2220, 0.2747, 0.2932, 0.2101]], device='cuda:0',\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(model(input_ids, attention_mask), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try pr-auc curve with torchmetrics\n",
    "# https://torchmetrics.readthedocs.io/en/v0.8.2/classification/precision_recall_curve.html\n",
    "# https://torchmetrics.readthedocs.io/en/v0.8.2/classification/binned_precision_recall_curve.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tim/miniconda3/envs/arxiv/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
    "total_steps = len(train_data_loader) * EPOCHS\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "  optimizer,\n",
    "  num_warmup_steps=0,\n",
    "  num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "  model, \n",
    "  data_loader, \n",
    "  loss_fn, \n",
    "  optimizer, \n",
    "  device, \n",
    "  scheduler, \n",
    "  n_examples\n",
    "):\n",
    "  model = model.train()\n",
    "\n",
    "  losses = []\n",
    "  correct_predictions = 0\n",
    "  \n",
    "  for d in data_loader:\n",
    "    input_ids = d[\"input_ids\"].to(device)\n",
    "    attention_mask = d[\"attention_mask\"].to(device)\n",
    "    labels = d[\"labels\"].to(device)\n",
    "\n",
    "    outputs = model(\n",
    "      input_ids=input_ids,\n",
    "      attention_mask=attention_mask\n",
    "    )\n",
    "\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    loss = loss_fn(outputs, labels)\n",
    "\n",
    "    correct_predictions += torch.sum(preds == labels)\n",
    "    losses.append(loss.item())\n",
    "\n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "  return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "  model = model.eval()\n",
    "\n",
    "  losses = []\n",
    "  correct_predictions = 0\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for d in data_loader:\n",
    "      input_ids = d[\"input_ids\"].to(device)\n",
    "      attention_mask = d[\"attention_mask\"].to(device)\n",
    "      labels = d[\"labels\"].to(device)\n",
    "\n",
    "      outputs = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask\n",
    "      )\n",
    "      _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "      loss = loss_fn(outputs, labels)\n",
    "\n",
    "      correct_predictions += torch.sum(preds == labels)\n",
    "      losses.append(loss.item())\n",
    "\n",
    "  return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n",
      "Train loss 0.6974145607401927 accuracy 0.8119658119658121\n",
      "Val   loss 0.32950213365256786 accuracy 0.9230769230769231\n",
      "\n",
      "Epoch 2/10\n",
      "----------\n",
      "Train loss 0.7324514353182167 accuracy 0.8461538461538463\n",
      "Val   loss 0.3138763438910246 accuracy 0.9230769230769231\n",
      "\n",
      "Epoch 3/10\n",
      "----------\n",
      "Train loss 0.7529483499005437 accuracy 0.8461538461538463\n",
      "Val   loss 0.2549473945982754 accuracy 0.9230769230769231\n",
      "\n",
      "Epoch 4/10\n",
      "----------\n",
      "Train loss 0.5516829454960922 accuracy 0.8461538461538463\n",
      "Val   loss 0.1842976410407573 accuracy 0.9230769230769231\n",
      "\n",
      "Epoch 5/10\n",
      "----------\n",
      "Train loss 0.39444381175562737 accuracy 0.8717948717948719\n",
      "Val   loss 0.33728070789948106 accuracy 0.9230769230769231\n",
      "\n",
      "Epoch 6/10\n",
      "----------\n",
      "Train loss 0.1857807689967255 accuracy 0.9401709401709403\n",
      "Val   loss 0.0068564958637580276 accuracy 1.0\n",
      "\n",
      "Epoch 7/10\n",
      "----------\n",
      "Train loss 0.11227488704025745 accuracy 0.982905982905983\n",
      "Val   loss 0.6060182137880474 accuracy 0.8461538461538463\n",
      "\n",
      "Epoch 8/10\n",
      "----------\n",
      "Train loss 0.02134245141254117 accuracy 0.9914529914529916\n",
      "Val   loss 0.47524071170482785 accuracy 0.9230769230769231\n",
      "\n",
      "Epoch 9/10\n",
      "----------\n",
      "Train loss 0.005234838781567911 accuracy 1.0\n",
      "Val   loss 0.20394882760592736 accuracy 1.0\n",
      "\n",
      "Epoch 10/10\n",
      "----------\n",
      "Train loss 0.004034935659728944 accuracy 1.0\n",
      "Val   loss 0.1943081361532677 accuracy 1.0\n",
      "\n",
      "CPU times: user 3min 19s, sys: 46 s, total: 4min 5s\n",
      "Wall time: 4min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "history = defaultdict(list)\n",
    "best_accuracy = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "  print('-' * 10)\n",
    "\n",
    "  train_acc, train_loss = train_epoch(\n",
    "    model,\n",
    "    train_data_loader,    \n",
    "    loss_fn, \n",
    "    optimizer, \n",
    "    DEVICE, \n",
    "    scheduler, \n",
    "    len(df_train)\n",
    "  )\n",
    "\n",
    "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "\n",
    "  val_acc, val_loss = eval_model(\n",
    "    model,\n",
    "    val_data_loader,\n",
    "    loss_fn, \n",
    "    DEVICE, \n",
    "    len(df_val)\n",
    "  )\n",
    "\n",
    "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
    "  print()\n",
    "\n",
    "  history['train_acc'].append(train_acc)\n",
    "  history['train_loss'].append(train_loss)\n",
    "  history['val_acc'].append(val_acc)\n",
    "  history['val_loss'].append(val_loss)\n",
    "\n",
    "  if val_acc > best_accuracy:\n",
    "    torch.save(model.state_dict(), 'best_model_state.bin')\n",
    "    best_accuracy = val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8120, 0.8462, 0.8462, 0.8462, 0.8718, 0.9402, 0.9829, 0.9915, 1.0000,\n",
       "        1.0000], dtype=torch.float64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(history['train_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(torch.tensor(history['train_acc']), label='train accuracy')\n",
    "plt.plot(torch.tensor(history['val_acc']), label='validation accuracy')\n",
    "\n",
    "plt.title('Training history')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.ylim([0, 1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"So we can solve the dual comparison problem (18) using any eﬃcient SVM solver, such as libsvm (Chang & Lin 2011). We used the R interface in the kernlab package (Karatzoglou et al. 2004), and our code is available in the rankSVMcompare package on Github.\"\n",
    "\n",
    "print(text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = BertTokenizer.from_pretrained('/home/tvhahn/scibert_scivocab_uncased') # hpc\n",
    "tokenizer = BertTokenizer.from_pretrained('allenai/scibert_scivocab_uncased')  # local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text = tokenizer.tokenize(text)\n",
    "print(len(tokenized_text))\n",
    "print(tokenized_text)\n",
    "\n",
    "token_ids = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "print(token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tokenizer.encode_plus(\n",
    "  text,\n",
    "  max_length=512,\n",
    "  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
    "  return_token_type_ids=False,\n",
    "  padding='max_length',\n",
    "  return_attention_mask=True,\n",
    "  truncation=True,\n",
    "  return_tensors='pt',  # Return PyTorch tensors\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(encoding['input_ids'][0]))\n",
    "# encoding['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.convert_ids_to_tokens(encoding['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "# for hpc (need to manually download model)\n",
    "# model = AutoModel.from_pretrained('/home/tvhahn/scibert_scivocab_uncased')\n",
    "\n",
    "# for local computer\n",
    "# model = AutoModel.from_pretrained('/home/tvhahn/scibert_scivocab_uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text = tokenizer.tokenize(text)\n",
    "print(len(tokenized_text))\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stop words, etc\n",
    "stop = stopwords.words('english')\n",
    "text_tokens = word_tokenize(text)\n",
    "tokens_without_sw = [word for word in text_tokens if not word in stop]\n",
    "\n",
    "# text = text.lower()\n",
    "# text = text.apply(lambda x: x.split(' '))\n",
    "# text = text.apply(lambda x: [item for item in x if item not in stop])\n",
    "# text = text.apply(lambda x: ' '.join(x))\n",
    "# text = text.apply(lambda x: re.sub('[^A-Za-z\\s]+', ' ', x))\n",
    "# text = text.apply(lambda x: re.sub('\\n', ' ', x))\n",
    "# text = text.apply(lambda x: re.sub(r'\\s+', ' ', x))\n",
    "# text = text.apply(lambda x: re.sub(r'^\\s', '', x))\n",
    "# text = text.apply(lambda x: re.sub(r'\\s$', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_sentence = (\" \").join(tokens_without_sw)\n",
    "filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text = tokenizer.tokenize(text)\n",
    "print(len(tokenized_text))\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tokens = tokenizer.batch_encode_plus(text, pad_to_max_length=True, max_length=512, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tokens['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "17e082919eb97a8b1648db68459a0548143f50884a45122adabc4767e3d2dece"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
