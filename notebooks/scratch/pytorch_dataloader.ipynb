{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup, BertForSequenceClassification\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "device count: 1\n",
      "device name: NVIDIA GeForce GTX 980M\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"device count:\", torch.cuda.device_count())\n",
    "print(\"device name:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/code/colinlagator/pytorch-bert-multi-label/notebook\n",
    "\n",
    "https://discuss.huggingface.co/t/download-models-for-local-loading/1963"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pattern</th>\n",
       "      <th>token_count</th>\n",
       "      <th>update_date</th>\n",
       "      <th>label</th>\n",
       "      <th>para</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1710.02907</td>\n",
       "      <td>data, dataset</td>\n",
       "      <td>280</td>\n",
       "      <td>2022-04-21</td>\n",
       "      <td>0</td>\n",
       "      <td>Experiment 2: In this set of experiments, we e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1811.11012</td>\n",
       "      <td>data</td>\n",
       "      <td>195</td>\n",
       "      <td>2022-04-21</td>\n",
       "      <td>0</td>\n",
       "      <td>This section of the technical report is focuse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1811.11012</td>\n",
       "      <td>data, dataset</td>\n",
       "      <td>70</td>\n",
       "      <td>2022-04-21</td>\n",
       "      <td>0</td>\n",
       "      <td>volunteers’ vehicles were mounted with BSM-bro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1912.09582</td>\n",
       "      <td>dataset</td>\n",
       "      <td>13</td>\n",
       "      <td>2022-04-21</td>\n",
       "      <td>0</td>\n",
       "      <td>for small datasets–a case with Dutch book revi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1912.09582</td>\n",
       "      <td>dataset</td>\n",
       "      <td>15</td>\n",
       "      <td>2022-04-21</td>\n",
       "      <td>1</td>\n",
       "      <td>Table 4: Sentiment Analysis accuracy scores on...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id        pattern  token_count update_date  label  \\\n",
       "0  1710.02907  data, dataset          280  2022-04-21      0   \n",
       "1  1811.11012           data          195  2022-04-21      0   \n",
       "2  1811.11012  data, dataset           70  2022-04-21      0   \n",
       "3  1912.09582        dataset           13  2022-04-21      0   \n",
       "4  1912.09582        dataset           15  2022-04-21      1   \n",
       "\n",
       "                                                para  \n",
       "0  Experiment 2: In this set of experiments, we e...  \n",
       "1  This section of the technical report is focuse...  \n",
       "2  volunteers’ vehicles were mounted with BSM-bro...  \n",
       "3  for small datasets–a case with Dutch book revi...  \n",
       "4  Table 4: Sentiment Analysis accuracy scores on...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_data_folder = Path().cwd().parent.parent / \"data\"\n",
    "path_interim_folder = path_data_folder / \"interim\"\n",
    "path_label_folder = path_data_folder / \"processed\" / \"labels\" / \"labels_complete\"\n",
    "\n",
    "# load the labels.csv from the path_label_folder\n",
    "df = pd.read_csv(path_label_folder / \"labels.csv\", dtype={\"id\": str})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data loader -- inspired by https://curiousily.com/posts/sentiment-analysis-with-bert-and-hugging-face-using-pytorch-and-python/\n",
    "class ArxivDataset(Dataset):\n",
    "\n",
    "  def __init__(self, texts, labels, tokenizer, max_len):\n",
    "    self.texts = texts\n",
    "    self.labels = labels\n",
    "    self.tokenizer = tokenizer\n",
    "    self.max_len = max_len\n",
    "  \n",
    "  def __len__(self):\n",
    "    return len(self.texts)\n",
    "  \n",
    "  def __getitem__(self, item):\n",
    "    text = str(self.texts[item]).lower()\n",
    "    label = self.labels[item]\n",
    "\n",
    "    encoding = self.tokenizer.encode_plus(\n",
    "      text,\n",
    "      add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
    "      max_length=self.max_len,\n",
    "      return_token_type_ids=False,\n",
    "      padding='max_length',\n",
    "      return_attention_mask=True,\n",
    "      truncation=True,\n",
    "      return_tensors='pt', # Return PyTorch tensors\n",
    "    )\n",
    "\n",
    "    return {\n",
    "      'texts': text,\n",
    "      'input_ids': encoding['input_ids'].flatten(),\n",
    "      'attention_masks': encoding['attention_mask'].flatten(),\n",
    "      'labels': torch.tensor(label, dtype=torch.long)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pattern</th>\n",
       "      <th>token_count</th>\n",
       "      <th>update_date</th>\n",
       "      <th>label</th>\n",
       "      <th>para</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2011.05411</td>\n",
       "      <td>dataset</td>\n",
       "      <td>89</td>\n",
       "      <td>2022-04-21</td>\n",
       "      <td>0</td>\n",
       "      <td>2. Local Computation: Once receiving the globa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>2011.00242</td>\n",
       "      <td>python</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-04-21</td>\n",
       "      <td>0</td>\n",
       "      <td>PHP Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2108.02756</td>\n",
       "      <td>dataset</td>\n",
       "      <td>140</td>\n",
       "      <td>2022-04-21</td>\n",
       "      <td>0</td>\n",
       "      <td>Inspired by the defense mechanism presented in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2101.00522</td>\n",
       "      <td>dataset</td>\n",
       "      <td>104</td>\n",
       "      <td>2022-04-21</td>\n",
       "      <td>0</td>\n",
       "      <td>Table 3: The percentage of shift in pixel labe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2104.09994</td>\n",
       "      <td>publicly available, dataset</td>\n",
       "      <td>7</td>\n",
       "      <td>2022-04-21</td>\n",
       "      <td>0</td>\n",
       "      <td>Table 1 Public IoT network datasets.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                      pattern  token_count update_date  label  \\\n",
       "99  2011.05411                      dataset           89  2022-04-21      0   \n",
       "85  2011.00242                       python            2  2022-04-21      0   \n",
       "31  2108.02756                      dataset          140  2022-04-21      0   \n",
       "14  2101.00522                      dataset          104  2022-04-21      0   \n",
       "21  2104.09994  publicly available, dataset            7  2022-04-21      0   \n",
       "\n",
       "                                                 para  \n",
       "99  2. Local Computation: Once receiving the globa...  \n",
       "85                                         PHP Python  \n",
       "31  Inspired by the defense mechanism presented in...  \n",
       "14  Table 3: The percentage of shift in pixel labe...  \n",
       "21               Table 1 Public IoT network datasets.  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.1, random_state=12)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
    "  ds = ArxivDataset(\n",
    "    texts=df.para.to_numpy(),\n",
    "    labels=df.label.to_numpy(),\n",
    "    tokenizer=tokenizer,\n",
    "    max_len=max_len\n",
    "  )\n",
    "\n",
    "  return DataLoader(\n",
    "    ds,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=4\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('allenai/scibert_scivocab_uncased')  # local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 512\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['texts', 'input_ids', 'attention_masks', 'labels'])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = next(iter(train_data_loader))\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 512])\n",
      "torch.Size([2, 512])\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "print(data['input_ids'].shape)\n",
    "print(data['attention_masks'].shape)\n",
    "print(data['labels'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'texts': ['2. local computation: once receiving the global ml model from the server, the participants updates its current local ml model and then trains the updated model using the local dataset resided in the device. this step is operated at local nodes, and it requires end-users’ devices to install an fl client program to perform training algorithms such as federatedsgd and federated averaging, as well as to receive the global model updates and send the local ml model parameters from/to the server.',\n",
       "  'php python'],\n",
       " 'input_ids': tensor([[  102,   170,   205,  ...,     0,     0,     0],\n",
       "         [  102,   375, 30121,  ...,     0,     0,     0]]),\n",
       " 'attention_masks': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " 'labels': tensor([0, 0])}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_TRAINED_MODEL_NAME = 'allenai/scibert_scivocab_uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArxivClassifier(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(ArxivClassifier, self).__init__()\n",
    "        self.encoder = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "\n",
    "        self.dense_1 = torch.nn.Linear(768, 768)\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.dense_2 = torch.nn.Linear(768, n_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_masks):\n",
    "        output_1 = self.encoder(input_ids=input_ids, attention_mask=attention_masks)\n",
    "        hidden_state = output_1[0]\n",
    "        pooled_output = hidden_state[:, 0]\n",
    "        pooled_output = self.dense_1(pooled_output)\n",
    "        pooled_output = torch.nn.ReLU()(pooled_output)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        output = self.dense_2(pooled_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = ArxivClassifier(4)\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = data['input_ids'].to(DEVICE)\n",
    "attention_masks = data['attention_masks'].to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2160, 0.1752, 0.2717, 0.3371],\n",
       "        [0.1596, 0.1964, 0.2892, 0.3548]], device='cuda:0',\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(model(input_ids, attention_masks), dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"So we can solve the dual comparison problem (18) using any eﬃcient SVM solver, such as libsvm (Chang & Lin 2011). We used the R interface in the kernlab package (Karatzoglou et al. 2004), and our code is available in the rankSVMcompare package on Github.\"\n",
    "\n",
    "print(text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = BertTokenizer.from_pretrained('/home/tvhahn/scibert_scivocab_uncased') # hpc\n",
    "tokenizer = BertTokenizer.from_pretrained('allenai/scibert_scivocab_uncased')  # local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text = tokenizer.tokenize(text)\n",
    "print(len(tokenized_text))\n",
    "print(tokenized_text)\n",
    "\n",
    "token_ids = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "print(token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tokenizer.encode_plus(\n",
    "  text,\n",
    "  max_length=512,\n",
    "  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
    "  return_token_type_ids=False,\n",
    "  padding='max_length',\n",
    "  return_attention_mask=True,\n",
    "  truncation=True,\n",
    "  return_tensors='pt',  # Return PyTorch tensors\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(encoding['input_ids'][0]))\n",
    "# encoding['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.convert_ids_to_tokens(encoding['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "# for hpc (need to manually download model)\n",
    "# model = AutoModel.from_pretrained('/home/tvhahn/scibert_scivocab_uncased')\n",
    "\n",
    "# for local computer\n",
    "# model = AutoModel.from_pretrained('/home/tvhahn/scibert_scivocab_uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text = tokenizer.tokenize(text)\n",
    "print(len(tokenized_text))\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stop words, etc\n",
    "stop = stopwords.words('english')\n",
    "text_tokens = word_tokenize(text)\n",
    "tokens_without_sw = [word for word in text_tokens if not word in stop]\n",
    "\n",
    "# text = text.lower()\n",
    "# text = text.apply(lambda x: x.split(' '))\n",
    "# text = text.apply(lambda x: [item for item in x if item not in stop])\n",
    "# text = text.apply(lambda x: ' '.join(x))\n",
    "# text = text.apply(lambda x: re.sub('[^A-Za-z\\s]+', ' ', x))\n",
    "# text = text.apply(lambda x: re.sub('\\n', ' ', x))\n",
    "# text = text.apply(lambda x: re.sub(r'\\s+', ' ', x))\n",
    "# text = text.apply(lambda x: re.sub(r'^\\s', '', x))\n",
    "# text = text.apply(lambda x: re.sub(r'\\s$', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_sentence = (\" \").join(tokens_without_sw)\n",
    "filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text = tokenizer.tokenize(text)\n",
    "print(len(tokenized_text))\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tokens = tokenizer.batch_encode_plus(text, pad_to_max_length=True, max_length=512, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tokens['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "17e082919eb97a8b1648db68459a0548143f50884a45122adabc4767e3d2dece"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
