{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tim/Documents/arxiv-code-search/data/processed/labels/labels_complete\n"
     ]
    }
   ],
   "source": [
    "path_label_dir = Path.cwd().parent.parent / \"data/processed/labels/labels_complete\"\n",
    "print(path_label_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pattern</th>\n",
       "      <th>token_count</th>\n",
       "      <th>update_date</th>\n",
       "      <th>label</th>\n",
       "      <th>para</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1710.02907</td>\n",
       "      <td>data, dataset</td>\n",
       "      <td>280</td>\n",
       "      <td>2022-04-21</td>\n",
       "      <td>0</td>\n",
       "      <td>Experiment 2: In this set of experiments, we e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1811.11012</td>\n",
       "      <td>data</td>\n",
       "      <td>195</td>\n",
       "      <td>2022-04-21</td>\n",
       "      <td>0</td>\n",
       "      <td>This section of the technical report is focuse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1811.11012</td>\n",
       "      <td>data, dataset</td>\n",
       "      <td>70</td>\n",
       "      <td>2022-04-21</td>\n",
       "      <td>0</td>\n",
       "      <td>volunteers’ vehicles were mounted with BSM-bro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1912.09582</td>\n",
       "      <td>dataset</td>\n",
       "      <td>13</td>\n",
       "      <td>2022-04-21</td>\n",
       "      <td>0</td>\n",
       "      <td>for small datasets–a case with Dutch book revi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1912.09582</td>\n",
       "      <td>dataset</td>\n",
       "      <td>15</td>\n",
       "      <td>2022-04-21</td>\n",
       "      <td>1</td>\n",
       "      <td>Table 4: Sentiment Analysis accuracy scores on...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id        pattern  token_count update_date  label  \\\n",
       "0  1710.02907  data, dataset          280  2022-04-21      0   \n",
       "1  1811.11012           data          195  2022-04-21      0   \n",
       "2  1811.11012  data, dataset           70  2022-04-21      0   \n",
       "3  1912.09582        dataset           13  2022-04-21      0   \n",
       "4  1912.09582        dataset           15  2022-04-21      1   \n",
       "\n",
       "                                                para  \n",
       "0  Experiment 2: In this set of experiments, we e...  \n",
       "1  This section of the technical report is focuse...  \n",
       "2  volunteers’ vehicles were mounted with BSM-bro...  \n",
       "3  for small datasets–a case with Dutch book revi...  \n",
       "4  Table 4: Sentiment Analysis accuracy scores on...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path_label_dir / \"labels.csv\", dtype={\"id\": str})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make new column y, where value is 1 if label > 0, 0 otherwise\n",
    "df[\"y\"] = df[\"label\"].apply(lambda x: 1 if x > 0 else 0)\n",
    "df[\"y\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save df to csv\n",
    "df.to_csv(\"labels_complete_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700 50\n",
      "0    93.333333\n",
      "1     6.666667\n",
      "Name: y, dtype: float64\n",
      "700 50\n"
     ]
    }
   ],
   "source": [
    "df_train, df_val = train_test_split(df, test_size=0.4, random_state=12, stratify=df['y']) # TO-DO: add stratification, and select by date\n",
    "a, b =df_train[\"y\"].value_counts()\n",
    "print(a, b)\n",
    "\n",
    "# get percentages of each class in each split\n",
    "print(df_train[\"y\"].value_counts() / len(df_train) * 100)\n",
    "\n",
    "df_val[\"y\"].value_counts() / len(df_val) * 100\n",
    "\n",
    "a, b =df_train[\"y\"].value_counts()\n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    66.666667\n",
      "1    33.333333\n",
      "Name: y, dtype: float64\n",
      "0    700\n",
      "1    350\n",
      "Name: y, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "ros = RandomOverSampler(sampling_strategy=0.5, random_state=0)\n",
    "df_train, _ = ros.fit_resample(df_train, df_train['y'])\n",
    "print(df_train[\"y\"].value_counts() / len(df_train) * 100)\n",
    "print(df_train[\"y\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def under_over_sampler(x, y, method=None, ratio=0.5):\n",
    "    \"\"\"\n",
    "    Returns an undersampled or oversampled data set. Implemented using imbalanced-learn package.\n",
    "    ['random_over','random_under','random_under_bootstrap','smote', 'adasyn']\n",
    "    \"\"\"\n",
    "\n",
    "    if method == None:\n",
    "        return x, y\n",
    "\n",
    "    # oversample methods: https://imbalanced-learn.readthedocs.io/en/stable/over_sampling.html\n",
    "    elif method == \"random_over\":\n",
    "        # print('before:',sorted(Counter(y).items()))\n",
    "        ros = RandomOverSampler(sampling_strategy=ratio, random_state=0)\n",
    "        x_resampled, y_resampled = ros.fit_resample(x, y)\n",
    "        # print('after:',sorted(Counter(y_resampled).items()))\n",
    "        return x_resampled, y_resampled\n",
    "\n",
    "    elif method == \"random_under\":\n",
    "        rus = RandomUnderSampler(sampling_strategy=ratio, random_state=0)\n",
    "        x_resampled, y_resampled = rus.fit_resample(x, y)\n",
    "        return x_resampled, y_resampled\n",
    "\n",
    "    elif method == \"random_under_bootstrap\":\n",
    "        rus = RandomUnderSampler(\n",
    "            sampling_strategy=ratio, random_state=0, replacement=True\n",
    "        )\n",
    "        x_resampled, y_resampled = rus.fit_resample(x, y)\n",
    "        return x_resampled, y_resampled\n",
    "\n",
    "    elif method == \"smote\":\n",
    "        x_resampled, y_resampled = SMOTE(\n",
    "            sampling_strategy=ratio, random_state=0\n",
    "        ).fit_resample(x, y)\n",
    "        return x_resampled, y_resampled\n",
    "\n",
    "    elif method == \"adasyn\":\n",
    "        x_resampled, y_resampled = ADASYN(\n",
    "            sampling_strategy=ratio, random_state=0\n",
    "        ).fit_resample(x, y)\n",
    "        return x_resampled, y_resampled\n",
    "\n",
    "    else:\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train counts: 700, 50\n",
      "df_val counts: 467, 33\n",
      "0    700\n",
      "1    210\n",
      "Name: y, dtype: int64\n",
      "0    350\n",
      "1    210\n",
      "Name: y, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_train, df_val = train_test_split(df, test_size=0.4, random_state=12, stratify=df['y']) # TO-DO: add stratification, and select by date\n",
    "counts = df_train[\"y\"].value_counts()\n",
    "print(f\"df_train counts: {counts[0]}, {counts[1]}\")\n",
    "counts = df_val[\"y\"].value_counts()\n",
    "print(f\"df_val counts: {counts[0]}, {counts[1]}\")\n",
    "\n",
    "df_train, _ = under_over_sampler(df_train, df_train['y'], method=\"random_over\", ratio=0.3)\n",
    "print(df_train[\"y\"].value_counts())\n",
    "\n",
    "df_train, _ = under_over_sampler(df_train, df_train['y'], method=\"random_under\", ratio=0.6)\n",
    "print(df_train[\"y\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split by ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path_label_dir / \"labels.csv\", dtype={\"id\": str})\n",
    "df[\"y\"] = df[\"label\"].apply(lambda x: 1 if x > 0 else 0)\n",
    "ids = df[\"id\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train counts: 920, 60\n",
      "df_val counts: 247, 23\n"
     ]
    }
   ],
   "source": [
    "train_ids, val_ids = train_test_split(ids, test_size=0.4, random_state=13,)\n",
    "\n",
    "df_train = df[df['id'].isin(train_ids)]\n",
    "counts = df_train[\"y\"].value_counts()\n",
    "print(f\"df_train counts: {counts[0]}, {counts[1]}\")\n",
    "\n",
    "df_val = df[df['id'].isin(val_ids)]\n",
    "counts = df_val[\"y\"].value_counts()\n",
    "print(f\"df_val counts: {counts[0]}, {counts[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "17e082919eb97a8b1648db68459a0548143f50884a45122adabc4767e3d2dece"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('arxiv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
