{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "device count: 1\n",
      "device name: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"device count:\", torch.cuda.device_count())\n",
    "print(\"device name:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/code/colinlagator/pytorch-bert-multi-label/notebook\n",
    "\n",
    "https://discuss.huggingface.co/t/download-models-for-local-loading/1963"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"In the original study, the authors reported the results of a grid-independence study to justify the spatial and temporal grid resolutions used for the parametric study. They compared force coefficients, profiles of the velocity components, profiles of the fluctuating kinetic energy, and distances between vortical structures in the near wake, obtained with different grid resolutions. Here, we also report the results of our grid-independence study before moving on to the results of the parametric study. We use the same domain size as in the original study: 30c × 25c × 25c (where c is the chord length of the wing). The root of the wing (around which the plate undergoes the rolling/pitching motion) is located at the center of the computational domain. We keep the spatial grid uniform (with highest resolution) in the sub-area of the domain that covers the motion of the wing. Outside this area, we also add an extra uniform layer with grid-spacing size ∆x = 0.05c, in the sub-domain [−2c, 6c] × [−3c, 3c] × [−1c, 2c], which covers the near-wake region. (We opted for a smooth transition between the two uniform regions, in which the grid-cell widths are stretched with a constant ratio of 1.1 in all directions, except in the streamwise direction behind the wing where we used a ratio of 1.03.) Finally, the grid-cell width is stretched to the external boundaries with a constant ratio of 1.2. To the readers interested in further inspecting the geometric characteristics of the grids used in the present study: we used Python scripts to codify the grid parameters and saved them into PetIBM-readable yaml files (available on the GitHub repository). In the present study, we model the wing with a flat elliptical surface, discretized with Lagrangian markers uniformly distributed on its surface (with a similar resolution as the grid-spacing size of the background Eulerian grid). As in the original study, we consider the case of a circular wing (AR = 1.27) with Reynolds number Re = 200, Strouhal number St = 0.6, and phase-difference angle ψ = 90o, to assess independence in the numerical results. We investigated the effect of the grid-spacing size, the time-step size, and the convergence criterion of the iterative solvers, on the numerical solution. To assess the effect of the grid-spacing size ∆x in the vicinity of the wing on the solution, we computed five flapping cycles on three grids: coarse (∆x = 0.03c), nominal (∆x =\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /home/tvhahn/scibert_scivocab_uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "model = AutoModel.from_pretrained('/home/tvhahn/scibert_scivocab_uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('/home/tvhahn/scibert_scivocab_uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stop words, etc\n",
    "stop = stopwords.words('english')\n",
    "text_tokens = word_tokenize(text)\n",
    "tokens_without_sw = [word for word in text_tokens if not word in stop]\n",
    "\n",
    "# text = text.lower()\n",
    "# text = text.apply(lambda x: x.split(' '))\n",
    "# text = text.apply(lambda x: [item for item in x if item not in stop])\n",
    "# text = text.apply(lambda x: ' '.join(x))\n",
    "# text = text.apply(lambda x: re.sub('[^A-Za-z\\s]+', ' ', x))\n",
    "# text = text.apply(lambda x: re.sub('\\n', ' ', x))\n",
    "# text = text.apply(lambda x: re.sub(r'\\s+', ' ', x))\n",
    "# text = text.apply(lambda x: re.sub(r'^\\s', '', x))\n",
    "# text = text.apply(lambda x: re.sub(r'\\s$', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'original study , authors reported results grid-independence study justify spatial temporal grid resolutions used parametric study . compared force coefficients , profiles velocity components , profiles fluctuating kinetic energy , distances vortical structures near wake , obtained different grid resolutions . , also report results grid-independence study moving results parametric study . use domain size original study : 30c × 25c × 25c ( c chord length wing ) . root wing ( around plate undergoes rolling/pitching motion ) located center computational domain . keep spatial grid uniform ( highest resolution ) sub-area domain covers motion wing . outside area , also add extra uniform layer grid-spacing size ∆x = 0.05c , sub-domain [ −2c , 6c ] × [ −3c , 3c ] × [ −1c , 2c ] , covers near-wake region . ( opted smooth transition two uniform regions , grid-cell widths stretched constant ratio 1.1 directions , except streamwise direction behind wing used ratio 1.03 . ) finally , grid-cell width stretched external boundaries constant ratio 1.2. readers interested inspecting geometric characteristics grids used present study : used python scripts codify grid parameters saved petibm-readable yaml files ( available github repository ) . present study , model wing flat elliptical surface , discretized lagrangian markers uniformly distributed surface ( similar resolution grid-spacing size background eulerian grid ) . original study , consider case circular wing ( ar = 1.27 ) reynolds number = 200 , strouhal number st = 0.6 , phase-difference angle ψ = 90o , assess independence numerical results . investigated effect grid-spacing size , time-step size , convergence criterion iterative solvers , numerical solution . assess effect grid-spacing size ∆x vicinity wing solution , computed five flapping cycles three grids : coarse ( ∆x = 0.03c ) , nominal ( ∆x ='"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_sentence = (\" \").join(tokens_without_sw)\n",
    "filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "545\n",
      "['in', 'the', 'original', 'study', ',', 'the', 'authors', 'reported', 'the', 'results', 'of', 'a', 'grid', '-', 'independence', 'study', 'to', 'justify', 'the', 'spatial', 'and', 'temporal', 'grid', 'resolutions', 'used', 'for', 'the', 'parametric', 'study', '.', 'they', 'compared', 'force', 'coefficients', ',', 'profiles', 'of', 'the', 'velocity', 'components', ',', 'profiles', 'of', 'the', 'fluctuating', 'kinetic', 'energy', ',', 'and', 'distances', 'between', 'vor', '##tical', 'structures', 'in', 'the', 'near', 'wake', ',', 'obtained', 'with', 'different', 'grid', 'resolutions', '.', 'here', ',', 'we', 'also', 'report', 'the', 'results', 'of', 'our', 'grid', '-', 'independence', 'study', 'before', 'moving', 'on', 'to', 'the', 'results', 'of', 'the', 'parametric', 'study', '.', 'we', 'use', 'the', 'same', 'domain', 'size', 'as', 'in', 'the', 'original', 'study', ':', '30', '##c', '×', '25', '##c', '×', '25', '##c', '(', 'where', 'c', 'is', 'the', 'chord', 'length', 'of', 'the', 'wing', ')', '.', 'the', 'root', 'of', 'the', 'wing', '(', 'around', 'which', 'the', 'plate', 'undergoes', 'the', 'rolling', '/', 'pitch', '##ing', 'motion', ')', 'is', 'located', 'at', 'the', 'center', 'of', 'the', 'computational', 'domain', '.', 'we', 'keep', 'the', 'spatial', 'grid', 'uniform', '(', 'with', 'highest', 'resolution', ')', 'in', 'the', 'sub', '-', 'area', 'of', 'the', 'domain', 'that', 'covers', 'the', 'motion', 'of', 'the', 'wing', '.', 'outside', 'this', 'area', ',', 'we', 'also', 'add', 'an', 'extra', 'uniform', 'layer', 'with', 'grid', '-', 'spacing', 'size', '∆', '##x', '=', '0', '.', '05', '##c', ',', 'in', 'the', 'sub', '-', 'domain', '[', '−2', '##c', ',', '6', '##c', ']', '×', '[', '−3', '##c', ',', '3', '##c', ']', '×', '[', '−1', '##c', ',', '2', '##c', ']', ',', 'which', 'covers', 'the', 'near', '-', 'wake', 'region', '.', '(', 'we', 'opt', '##ed', 'for', 'a', 'smooth', 'transition', 'between', 'the', 'two', 'uniform', 'regions', ',', 'in', 'which', 'the', 'grid', '-', 'cell', 'widths', 'are', 'stretched', 'with', 'a', 'constant', 'ratio', 'of', '1', '.', '1', 'in', 'all', 'directions', ',', 'except', 'in', 'the', 'stream', '##wise', 'direction', 'behind', 'the', 'wing', 'where', 'we', 'used', 'a', 'ratio', 'of', '1', '.', '03', '.', ')', 'finally', ',', 'the', 'grid', '-', 'cell', 'width', 'is', 'stretched', 'to', 'the', 'external', 'boundaries', 'with', 'a', 'constant', 'ratio', 'of', '1', '.', '2', '.', 'to', 'the', 'readers', 'interested', 'in', 'further', 'insp', '##ecting', 'the', 'geometric', 'characteristics', 'of', 'the', 'grids', 'used', 'in', 'the', 'present', 'study', ':', 'we', 'used', 'python', 'scripts', 'to', 'cod', '##ify', 'the', 'grid', 'parameters', 'and', 'saved', 'them', 'into', 'pet', '##ib', '##m', '-', 'read', '##able', 'yam', '##l', 'files', '(', 'available', 'on', 'the', 'gi', '##th', '##ub', 'repository', ')', '.', 'in', 'the', 'present', 'study', ',', 'we', 'model', 'the', 'wing', 'with', 'a', 'flat', 'elliptical', 'surface', ',', 'discretized', 'with', 'lagrangian', 'markers', 'uniformly', 'distributed', 'on', 'its', 'surface', '(', 'with', 'a', 'similar', 'resolution', 'as', 'the', 'grid', '-', 'spacing', 'size', 'of', 'the', 'background', 'euler', '##ian', 'grid', ')', '.', 'as', 'in', 'the', 'original', 'study', ',', 'we', 'consider', 'the', 'case', 'of', 'a', 'circular', 'wing', '(', 'ar', '=', '1', '.', '27', ')', 'with', 'reynolds', 'number', 're', '=', '200', ',', 'stro', '##uh', '##al', 'number', 'st', '=', '0', '.', '6', ',', 'and', 'phase', '-', 'difference', 'angle', 'ψ', '=', '90', '##o', ',', 'to', 'assess', 'independence', 'in', 'the', 'numerical', 'results', '.', 'we', 'investigated', 'the', 'effect', 'of', 'the', 'grid', '-', 'spacing', 'size', ',', 'the', 'time', '-', 'step', 'size', ',', 'and', 'the', 'convergence', 'criterion', 'of', 'the', 'iterative', 'solvers', ',', 'on', 'the', 'numerical', 'solution', '.', 'to', 'assess', 'the', 'effect', 'of', 'the', 'grid', '-', 'spacing', 'size', '∆', '##x', 'in', 'the', 'vicinity', 'of', 'the', 'wing', 'on', 'the', 'solution', ',', 'we', 'computed', 'five', 'flap', '##ping', 'cycles', 'on', 'three', 'grids', ':', 'coarse', '(', '∆', '##x', '=', '0', '.', '03', '##c', ')', ',', 'nominal', '(', '∆', '##x', '=']\n"
     ]
    }
   ],
   "source": [
    "tokenized_text = tokenizer.tokenize(text)\n",
    "print(len(tokenized_text))\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/tvhahn/arxiv/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2271: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "text_tokens = tokenizer.batch_encode_plus(text, pad_to_max_length=True, max_length=512, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2441, 512])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_tokens['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[102, 259, 103,  ...,   0,   0,   0],\n",
       "        [102, 146, 103,  ...,   0,   0,   0],\n",
       "        [102, 103,   0,  ...,   0,   0,   0],\n",
       "        ...,\n",
       "        [102, 412, 103,  ...,   0,   0,   0],\n",
       "        [102, 103,   0,  ...,   0,   0,   0],\n",
       "        [102, 275, 103,  ...,   0,   0,   0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 0,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "17e082919eb97a8b1648db68459a0548143f50884a45122adabc4767e3d2dece"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
