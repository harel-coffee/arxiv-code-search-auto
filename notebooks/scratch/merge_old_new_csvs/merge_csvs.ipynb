{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_no = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3280, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pattern</th>\n",
       "      <th>update_date</th>\n",
       "      <th>label</th>\n",
       "      <th>para</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2203.05084</td>\n",
       "      <td>data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>composability can also be obtained in terms of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2109.1263</td>\n",
       "      <td>data repos</td>\n",
       "      <td>04/22/22</td>\n",
       "      <td>0</td>\n",
       "      <td>Imperial endorsements were employed as a celeb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2109.1263</td>\n",
       "      <td>data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Before we go towards social media mining, ﬁrst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2109.1263</td>\n",
       "      <td>data repos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coerce, sadness, and anger, and fear) [86][38]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2105.00775</td>\n",
       "      <td>open-source, data repos, code, code available,...</td>\n",
       "      <td>04/22/22</td>\n",
       "      <td>3</td>\n",
       "      <td>production, wake topology, and propulsive perf...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                            pattern update_date  \\\n",
       "0  2203.05084                                               data         NaN   \n",
       "1   2109.1263                                         data repos    04/22/22   \n",
       "2   2109.1263                                               data         NaN   \n",
       "3   2109.1263                                         data repos         NaN   \n",
       "4  2105.00775  open-source, data repos, code, code available,...    04/22/22   \n",
       "\n",
       "  label                                               para  \n",
       "0   NaN  composability can also be obtained in terms of...  \n",
       "1     0  Imperial endorsements were employed as a celeb...  \n",
       "2   NaN  Before we go towards social media mining, ﬁrst...  \n",
       "3   NaN  coerce, sadness, and anger, and fear) [86][38]...  \n",
       "4     3  production, wake topology, and propulsive perf...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_old = pd.read_csv(f\"labels_{index_no}_old.csv\", dtype=str)\n",
    "print(df_old.shape)\n",
    "df_old.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, '0', '3', '2'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_old['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3065, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pattern</th>\n",
       "      <th>token_count</th>\n",
       "      <th>para</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1401.8008</td>\n",
       "      <td>code package, github, code available, code, pa...</td>\n",
       "      <td>56</td>\n",
       "      <td>So we can solve the dual comparison problem (1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1401.8008</td>\n",
       "      <td>data</td>\n",
       "      <td>2</td>\n",
       "      <td>training data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1401.8008</td>\n",
       "      <td>data</td>\n",
       "      <td>7</td>\n",
       "      <td>3.2. Kernelized QP for non-separable data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1401.8008</td>\n",
       "      <td>data</td>\n",
       "      <td>11</td>\n",
       "      <td>4. Comparison to SVMrank in sushi and simulate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1401.8008</td>\n",
       "      <td>data</td>\n",
       "      <td>15</td>\n",
       "      <td>Overall from the sushi data, it is clear that ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                            pattern token_count  \\\n",
       "0  1401.8008  code package, github, code available, code, pa...          56   \n",
       "1  1401.8008                                               data           2   \n",
       "2  1401.8008                                               data           7   \n",
       "3  1401.8008                                               data          11   \n",
       "4  1401.8008                                               data          15   \n",
       "\n",
       "                                                para  \n",
       "0  So we can solve the dual comparison problem (1...  \n",
       "1                                      training data  \n",
       "2          3.2. Kernelized QP for non-separable data  \n",
       "3  4. Comparison to SVMrank in sushi and simulate...  \n",
       "4  Overall from the sushi data, it is clear that ...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = pd.read_csv(f\"labels_{index_no}_new.csv\", dtype=str).drop(columns=[\"update_date\", \"label\"])\n",
    "print(df_new.shape)\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_new.merge(df_old, on=[\"id\", \"para\"], how=\"left\").rename(columns={\"pattern_x\": \"pattern\"}).drop(columns=[\"pattern_y\"])\n",
    "# df_new = df_new[[\"id\", \"pattern\", \"token_count\", \"update_date\", \"label\", \"para\"]].sort_values(by=[\"id\", \"pattern\", \"token_count\"])\n",
    "# print(df_new.shape)\n",
    "# df_new.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pattern_x</th>\n",
       "      <th>token_count</th>\n",
       "      <th>para</th>\n",
       "      <th>pattern_y</th>\n",
       "      <th>update_date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1401.8008</td>\n",
       "      <td>code package, github, code available, code, pa...</td>\n",
       "      <td>56</td>\n",
       "      <td>So we can solve the dual comparison problem (1...</td>\n",
       "      <td>package, code available, code, code package, g...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1401.8008</td>\n",
       "      <td>data</td>\n",
       "      <td>2</td>\n",
       "      <td>training data</td>\n",
       "      <td>data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1401.8008</td>\n",
       "      <td>data</td>\n",
       "      <td>7</td>\n",
       "      <td>3.2. Kernelized QP for non-separable data</td>\n",
       "      <td>data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1401.8008</td>\n",
       "      <td>data</td>\n",
       "      <td>11</td>\n",
       "      <td>4. Comparison to SVMrank in sushi and simulate...</td>\n",
       "      <td>data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1401.8008</td>\n",
       "      <td>data</td>\n",
       "      <td>15</td>\n",
       "      <td>Overall from the sushi data, it is clear that ...</td>\n",
       "      <td>data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                          pattern_x token_count  \\\n",
       "0  1401.8008  code package, github, code available, code, pa...          56   \n",
       "1  1401.8008                                               data           2   \n",
       "2  1401.8008                                               data           7   \n",
       "3  1401.8008                                               data          11   \n",
       "4  1401.8008                                               data          15   \n",
       "\n",
       "                                                para  \\\n",
       "0  So we can solve the dual comparison problem (1...   \n",
       "1                                      training data   \n",
       "2          3.2. Kernelized QP for non-separable data   \n",
       "3  4. Comparison to SVMrank in sushi and simulate...   \n",
       "4  Overall from the sushi data, it is clear that ...   \n",
       "\n",
       "                                           pattern_y update_date label  \n",
       "0  package, code available, code, code package, g...         NaN   NaN  \n",
       "1                                               data         NaN   NaN  \n",
       "2                                               data         NaN   NaN  \n",
       "3                                               data         NaN   NaN  \n",
       "4                                               data         NaN   NaN  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.to_csv(f\"labels_{index_no}_new_merged.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_existing_new_labels(df_existing, df_new):\n",
    "    df_existing = df_existing.merge(\n",
    "        df_new[[\"para\", \"id\", \"pattern\", \"token_count\"]], on=[\"para\", \"id\", \"token_count\"], how=\"outer\"\n",
    "    )\n",
    "\n",
    "    # if pattern_y is NaN, then copy pattern_x to pattern_y\n",
    "    df_existing[\"pattern\"] = df_existing[\"pattern_y\"].fillna(df_existing[\"pattern_x\"])\n",
    "\n",
    "    # drop columns that are not needed, pattern_x and pattern_y\n",
    "    df_existing = df_existing.drop([\"pattern_x\", \"pattern_y\"], axis=1)\n",
    "    return df_existing[[\"id\", \"pattern\", \"token_count\", \"update_date\", \"label\", \"para\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "17e082919eb97a8b1648db68459a0548143f50884a45122adabc4767e3d2dece"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('arxiv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
