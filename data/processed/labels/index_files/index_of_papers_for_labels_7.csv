id,submitter,authors,title,comments,journal-ref,doi,report-no,categories,license,abstract,versions,update_date,authors_parsed
2007.01220,Zhiang Chen,"Zhiang Chen, Sarah Bearman, J Ramon Arrowsmith, Jnaneshwar Das","Localization and Mapping of Sparse Geologic Features with Unpiloted
  Aircraft Systems",,,,,cs.RO physics.geo-ph,http://creativecommons.org/licenses/by/4.0/,"  Robotic mapping is attractive in many scientific applications that involve
environmental surveys. This paper presents a system for localization and
mapping of sparsely distributed surface features such as precariously balanced
rocks (PBRs), whose geometric fragility parameters provide valuable information
on earthquake processes and landscape development. With this geomorphologic
problem as the test domain, we carry out a lawn-mower search pattern from a
high elevation using an Unpiloted Aerial Vehicle (UAV) equipped with a flight
controller, GPS module, stereo camera, and onboard computer. Once a potential
PBR target is detected by a deep neural network in real time, we track its
bounding box in the image coordinates by applying a Kalman filter that fuses
the deep learning detection with Kanade-Lucas-Tomasi (KLT) tracking. The target
is localized in world coordinates using depth filtering where a set of 3D
points are filtered by object bounding boxes from different camera
perspectives. The 3D points also provide a strong prior on target shape, which
is used for UAV path planning to closely map the target using RGBD SLAM. After
target mapping, the UAS resumes the lawn-mower search pattern to locate and map
the next target.
","[{'version': 'v1', 'created': 'Thu, 2 Jul 2020 16:05:07 GMT'}, {'version': 'v2', 'created': 'Sun, 1 Nov 2020 07:29:07 GMT'}]",2020-11-03,"[['Chen', 'Zhiang', ''], ['Bearman', 'Sarah', ''], ['Arrowsmith', 'J Ramon', ''], ['Das', 'Jnaneshwar', '']]"
2105.05167,Ray Garner,"Ray Garner III (1), J. Christopher Mihos (1), Paul Harding (1), Aaron
  E. Watkins (2,3) ((1) Case Western Reserve University, (2) Liverpool John
  Moores University, (3) University of Hertfordshire)",A Deep Census of Outlying Star Formation in the M101 Group,"24 pages, 14 figures, 6 tables, accepted for publication in ApJ",,10.3847/1538-4357/ac0055,,astro-ph.GA,http://creativecommons.org/licenses/by/4.0/,"  We present deep, narrowband imaging of the nearby spiral galaxy M101 and its
group environment to search for star-forming dwarf galaxies and outlying HII
regions. Using the Burrell Schmidt telescope, we target the brightest emission
lines of star-forming regions, H$\alpha$, H$\beta$, and [OIII], to detect
potential outlying star-forming regions. Our survey covers $\sim$6 square
degrees around M101, and we detect objects in emission down to an H$\alpha$
flux level of $5.7 \times 10^{-17}$ erg s$^{-1}$ cm$^{-2}$ (equivalent to a
limiting SFR of $1.7 \times 10^{-6}$ $M_\odot$ yr$^{-1}$ at the distance of
M101). After careful removal of background contaminants and foreground M stars,
we detect 19 objects in emission in all three bands, and 8 objects in emission
in H$\alpha$ and [OIII]. We compare the structural and photometric properties
of the detected sources to Local Group dwarf galaxies and star-forming galaxies
in the 11HUGS and SINGG surveys. We find no large population of outlying HII
regions or undiscovered star-forming dwarfs in the M101 Group, as most sources
(93%) are consistent with being M101 outer disk HII regions. Only two sources
were associated with other galaxies: a faint star-forming satellite of the
background galaxy NGC 5486, and a faint outlying HII region near the M101
companion NGC 5474. We also find no narrowband emission associated with
recently discovered ultradiffuse galaxies and starless HI clouds near M101. The
lack of any hidden population of low luminosity star-forming dwarfs around M101
suggests a rather shallow faint end slope (as flat as $\alpha \sim -1.0$) for
the star-forming luminosity function in the M101 Group. We discuss our results
in the context of tidally-triggered star formation models and the interaction
history of the M101 Group.
","[{'version': 'v1', 'created': 'Tue, 11 May 2021 16:24:04 GMT'}]",2021-07-14,"[['Garner', 'Ray', 'III'], ['Mihos', 'J. Christopher', ''], ['Harding', 'Paul', ''], ['Watkins', 'Aaron E.', '']]"
2201.11254,Haylee Archer,"Haylee N. Archer, Deidre A. Hunter, Bruce G. Elmegreen, Phil Cigan,
  Rolf A. Jansen, Rogier A. Windhorst, Leslie K. Hunt, Monica Rubio","The Environments of CO Cores and Star Formation in the Dwarf Irregular
  Galaxy WLM",In press in the Astronomical Journal,,10.3847/1538-3881/ac4e88,,astro-ph.GA,http://creativecommons.org/licenses/by/4.0/,"  The low metallicities of dwarf irregular galaxies (dIrr) greatly influence
the formation and structure of molecular clouds. These clouds, which consist
primarily of H$_2$, are typically traced by CO, but low metallicity galaxies
are found to have little CO despite ongoing star formation. In order to probe
the conditions necessary for CO core formation in dwarf galaxies, we have used
the catalog of Rubio et al. (2022, in preparation) for CO cores in WLM, a Local
Group dwarf with an oxygen abundance that is 13% of solar. Here we aim to
characterize the galactic environments in which these 57 CO cores formed. We
grouped the cores together based on proximity to each other and strong FUV
emission, examining properties of the star forming region enveloping the cores
and the surrounding environment where the cores formed. We find that high HI
surface density does not necessarily correspond to higher total CO mass, but
regions with higher CO mass have higher HI surface densities. We also find the
cores in star forming regions spanning a wide range of ages show no correlation
between age and CO core mass, suggesting that the small size of the cores is
not due to fragmentation of the clouds with age. The presence of CO cores in a
variety of different local environments, along with the similar properties
between star forming regions with and without CO cores, leads us to conclude
that there are no obvious environmental characteristics that drive the
formation of these CO cores.
","[{'version': 'v1', 'created': 'Thu, 27 Jan 2022 01:03:36 GMT'}]",2022-03-02,"[['Archer', 'Haylee N.', ''], ['Hunter', 'Deidre A.', ''], ['Elmegreen', 'Bruce G.', ''], ['Cigan', 'Phil', ''], ['Jansen', 'Rolf A.', ''], ['Windhorst', 'Rogier A.', ''], ['Hunt', 'Leslie K.', ''], ['Rubio', 'Monica', '']]"
2110.07931,Andrea Plati,Andrea Plati and Andrea Puglisi,"Collective drifts in vibrated granular packings: the interplay of
  friction and structure",10 pages and 7 figures (main text and supplemental material),,,,cond-mat.soft cond-mat.stat-mech,http://creativecommons.org/licenses/by/4.0/,"  We simulate vertically shaken dense granular packings with horizontal
periodic boundary conditions. A coordinated translating motion of the whole
medium emerges when the horizontal symmetry is broken by disorder or defects in
the packing and the shaking is weak enough to conserve the structure. We argue
that such a drift originates in the interplay between structural symmetry
breaking and frictional forces transmitted by the vibrating plate. A non-linear
ratchet model with stick-slips reproduces many faces of the phenomenon. The
collective motion discussed here underlies phenomena observed recently with
vibrofluidized granular materials, such as persistent rotations and anomalous
diffusion.
","[{'version': 'v1', 'created': 'Fri, 15 Oct 2021 08:22:40 GMT'}]",2021-10-18,"[['Plati', 'Andrea', ''], ['Puglisi', 'Andrea', '']]"
2203.09239,Sai Peng,"Sai Peng, Tingting Tang, Jianhui Li, Mengqi Zhang and Peng Yu",Numerical Study of Viscoelastic Upstream Instability,,,,,physics.flu-dyn,http://creativecommons.org/licenses/by/4.0/,"  In this work, we report numerical results on the flow instability and
bifurcation of a viscoelastic fluid in the upstream region of a confined
cylinder in a narrow channel. Two-dimensional direct numerical simulations
based on the FENE-P model (the finite-extensible nonlinear elastic model with
the Peterlin closure) are conducted with numerical stabilization techniques.
Our results show that the macroscopic viscoelastic constitutive relation can
capture the viscoelastic upstream instability reported in previous experiments
for low-Reynolds-number flows. The numerical simulations reveal that the
non-dimensional recirculation length ($L_D$) is affected by the cylinder
blocking rate ($BR$), the Weissenberg number ($Wi$), the viscosity ratio
($\beta$), and the maximum polymer extension ($L$). Close to the onset of
upstream recirculation, depending on the values of $L$ and $\beta$, the
bifurcation can be supercritical or subcritical. $\beta$ has a nonlinear
influence on the upstream recirculation length. This work contributes to our
theoretical understanding of this new instability mechanism in viscoelastic
wake flows.
","[{'version': 'v1', 'created': 'Thu, 17 Mar 2022 11:06:49 GMT'}]",2022-03-18,"[['Peng', 'Sai', ''], ['Tang', 'Tingting', ''], ['Li', 'Jianhui', ''], ['Zhang', 'Mengqi', ''], ['Yu', 'Peng', '']]"
2110.07754,Jeffrey D. Scargle,Jeffrey D. Scargle,"Detection of the Permanent Strain Offset Component of Gravitational-Wave
  Memory in Black Hole Mergers","16 pages, 6 figures, 1 table. Major additions and corrections
  (especially in the data table)",,,,gr-qc astro-ph.HE astro-ph.IM,http://creativecommons.org/licenses/by/4.0/,"  This paper reports direct measurements of the permanent space-time strain
offset component of the gravitational-wave memory predicted by general
relativity to accompany black hole mergers. Such a change in strain, persisting
after the wave itself is long past -- measurable in principle but with
considerable difficulty -- has heretofore eluded detection. Since it is
independent of the form of the time-development of the memory strain, this
approach circumvents the need for precise modeling of the memory and non-memory
signals. A model-independent analysis using a template-like algorithm, applied
to a selection of 67 observations of 41 black hole merger events in the
LIGO/Virgo Gravitational Wave Transient Catalog, yields a mixture of probable
detections and upper limits. The associated statistical significance is
assessed using parallel analysis of a large number of intervals shifted in time
away from the mergers. The resulting p-value for a reasonably formulated null
hypothesis (no real signals anywhere in the ensemble) is less than .003.
Appendices contain MatLab code for the operations in the analysis, including an
algorithm for the complex Fourier transform for arbitrarily spaced data.
","[{'version': 'v1', 'created': 'Thu, 14 Oct 2021 22:33:11 GMT'}, {'version': 'v2', 'created': 'Thu, 28 Oct 2021 04:58:12 GMT'}, {'version': 'v3', 'created': 'Tue, 22 Feb 2022 05:29:29 GMT'}]",2022-02-23,"[['Scargle', 'Jeffrey D.', '']]"
2010.01571,Nicola Orio,"Nicola Orio, Norbert Schnell, and Marcelo M. Wanderley",Input Devices for Musical Expression: Borrowing Tools from HCI,"Proceedings of the International Conference on New Interfaces for
  Musical Expression, 2001",,10.5281/zenodo.1176370,,cs.HC cs.SD eess.AS,http://creativecommons.org/licenses/by/4.0/,"  This paper reviews the existing literature on input device evaluation and
design in human-computer interaction (HCI) and discusses possible applications
of this knowledge to the design and evaluation of new interfaces for musical
expression. Specifically, a set of musical tasks is suggested to allow the
evaluation of different existing controllers.
","[{'version': 'v1', 'created': 'Sun, 4 Oct 2020 12:56:14 GMT'}]",2020-10-06,"[['Orio', 'Nicola', ''], ['Schnell', 'Norbert', ''], ['Wanderley', 'Marcelo M.', '']]"
2203.07853,Lan Truong,"Lan V. Truong, Giuseppe Cocco, Josep Font-Segura, Albert Guill\'en i
  F\`abregas",Concentration Properties of Random Codes,98 pages,,,,cs.IT math.IT math.PR math.ST stat.TH,http://creativecommons.org/licenses/by/4.0/,"  This paper studies the concentration properties of random codes.
Specifically, we show that, for discrete memoryless channels, the error
exponent of a randomly generated code with pairwise-independent codewords
converges in probability to its expectation -- the typical error exponent. For
high rates, the result is a consequence of the fact that the random-coding
error exponent and the sphere-packing error exponent coincide. For low rates,
instead, the convergence is based on the fact that the union bound accurately
characterizes the probability of error. The paper also zooms into the behavior
at asymptotically low rates and shows that the error exponent converges in
distribution to a Gaussian-like distribution. Finally, we present several
results on the convergence of the error probability and error exponent for
generic ensembles and channels.
","[{'version': 'v1', 'created': 'Tue, 15 Mar 2022 13:06:09 GMT'}]",2022-03-16,"[['Truong', 'Lan V.', ''], ['Cocco', 'Giuseppe', ''], ['Font-Segura', 'Josep', ''], ['Fàbregas', 'Albert Guillén i', '']]"
2203.07694,Ramana Sundararaman,"Ramana Sundararaman, Gautam Pai, Maks Ovsjanikov",Implicit field supervision for robust non-rigid shape matching,,,,,cs.CV,http://creativecommons.org/licenses/by/4.0/,"  Establishing a correspondence between two non-rigidly deforming shapes is one
of the most fundamental problems in visual computing. Existing methods often
show weak resilience when presented with challenges innate to real-world data
such as noise, outliers, self-occlusion etc. On the other hand, auto-decoders
have demonstrated strong expressive power in learning geometrically meaningful
latent embeddings. However, their use in shape analysis and especially in
non-rigid shape correspondence has been limited. In this paper, we introduce an
approach based on auto-decoder framework, that learns a continuous shape-wise
deformation field over a fixed template. By supervising the deformation field
for points on-surface and regularising for points off-surface through a novel
Signed Distance Regularisation (SDR), we learn an alignment between the
template and shape volumes. Unlike classical correspondence techniques, our
method is remarkably robust in the presence of strong artefacts and can be
generalised to arbitrary shape categories. Trained on clean water-tight meshes,
without any data-augmentation, we demonstrate compelling performance on
compromised data and real-world scans.
","[{'version': 'v1', 'created': 'Tue, 15 Mar 2022 07:22:52 GMT'}, {'version': 'v2', 'created': 'Wed, 16 Mar 2022 14:01:00 GMT'}]",2022-03-17,"[['Sundararaman', 'Ramana', ''], ['Pai', 'Gautam', ''], ['Ovsjanikov', 'Maks', '']]"
2102.06399,Shuxun Tian,S. X. Tian and Zong-Hong Zhu,Early dark energy in $k$-essence,"5 pages, 2 figures, published in Phys. Rev. D","Phys. Rev. D 103, 043518 (2021)",10.1103/PhysRevD.103.043518,,gr-qc astro-ph.CO,http://creativecommons.org/licenses/by/4.0/,"  Early dark energy (EDE) that becomes subdominant around the epoch of
matter-radiation equality can be used to ease the Hubble tension. However,
there is a theoretical problem that why the energy scale of EDE is in
coincidence with that of matter-radiation equality when their physics are
completely unrelated. Sakstein and Trodden [Phys. Rev. Lett. 124, 161301
(2020)] proposed a mechanism to solve this coincidence problem with
$\mathcal{O}({\rm eV})$-mass neutrino. In this paper, in order to solve the
coincidence problem, we propose a new scenario for EDE, in which the onset and
ending of EDE are triggered by the radiation-matter transition. The specific
example we study is a $k$-essence model. The cosmic evolution equations can be
recast into a two-dimensional dynamical system and its main properties are
analyzed. Our results suggest that $k$-essence seems unable to realize the new
scenario for EDE. However, an EDE model with different scenario is realized in
$k$-essence. In this model, the ending of EDE can be triggered by the
radiation-matter transition while the onset depends on the initial conditions
of the scalar field. Therefore, the obtained model can only be used to solve
half of the coincidence problem. The full resolution in the framework of our
initial proposed scenario is worthy of more research.
","[{'version': 'v1', 'created': 'Fri, 12 Feb 2021 08:57:19 GMT'}]",2021-02-15,"[['Tian', 'S. X.', ''], ['Zhu', 'Zong-Hong', '']]"
2108.12093,Wan-Lei Zhao,"Shi-Ying Lan, Run-Qing Chen, Wan-Lei Zhao",Anomaly Detection on IT Operation Series via Online Matrix Profile,"10 pages, 6 figures; Shi-Ying Lan and Run-Qing Chen contributed
  equally",,,,cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Anomaly detection on time series is a fundamental task in monitoring the Key
Performance Indicators (KPIs) of IT systems. Many of the existing approaches in
the literature show good performance while requiring a lot of training
resources. In this paper, the online matrix profile, which requires no
training, is proposed to address this issue. The anomalies are detected by
referring to the past subsequence that is the closest to the current one. The
distance significance is introduced based on the online matrix profile, which
demonstrates a prominent pattern when an anomaly occurs. Another training-free
approach spectral residual is integrated into our approach to further enhance
the detection accuracy. Moreover, the proposed approach is sped up by at least
four times for long time series by the introduced cache strategy. In comparison
to the existing approaches, the online matrix profile makes a good trade-off
between accuracy and efficiency. More importantly, it is generic to various
types of time series in the sense that it works without the constraint from any
trained model.
","[{'version': 'v1', 'created': 'Fri, 27 Aug 2021 02:40:37 GMT'}, {'version': 'v2', 'created': 'Mon, 6 Sep 2021 11:08:00 GMT'}]",2021-09-07,"[['Lan', 'Shi-Ying', ''], ['Chen', 'Run-Qing', ''], ['Zhao', 'Wan-Lei', '']]"
2010.11093,Stephen Warren,"Stephen Warren, Saad Ahmed, and Richard Laithwaite","The local vertical density distribution of ultracool dwarfs M7 to L2.5
  and their luminosity function",,,10.21105/astro.2010.11093,,astro-ph.GA astro-ph.SR,http://creativecommons.org/licenses/by/4.0/,"  We investigate the form of the local vertical density profile of the stars in
the Galactic disk, close to the Galactic plane. We use a homogeneous sample of
34000 ultracool dwarfs M7 to L2.5 that all lie within 350 pc of the plane. We
fit a profile of the form sech$^\alpha$, where $\alpha=2$ is the theoretically
preferred isothermal profile and $\alpha=0$ is the exponential function. Larger
values of $\alpha$ correspond to greater flattening of the profile towards the
plane. We employ a likelihood analysis that accounts in a direct way for
unresolved binaries in the sample, as well as for the spread in absolute
magnitude $M_J$ within each spectral sub-type (Malmquist bias). We measure
$\alpha=0.29^{+0.12}_{-0.13}$. The $\alpha=1$ (sech) and flatter profiles are
ruled out at high confidence for this sample, while $\alpha=0$ (exponential) is
included in the 95% credible interval. Any flattening relative to exponential
is modest, and is confined to within 50 pc of the plane. The measured value of
$\alpha$ is consistent with the results of the recent analysis by Xiang et al.
Our value for $\alpha$ is also similar to that determined for nearby spiral
galaxies by de Grijs et al., measured from photometry of galaxies viewed edge
on. The measured profile allows an accurate determination of the local space
density of ultracool dwarfs M7 to L2.5, and we use this to make a new
determination of the luminosity function at the bottom of the main sequence.
Our results for the luminosity function are a factor two to three lower than
the recent measurement by Bardalez Gagliuffi et al., that uses stars in the
local 25 pc radius bubble, but agree well with the older study by Cruz et al.
","[{'version': 'v1', 'created': 'Mon, 19 Oct 2020 05:47:28 GMT'}, {'version': 'v2', 'created': 'Thu, 3 Jun 2021 13:20:56 GMT'}]",2021-06-07,"[['Warren', 'Stephen', ''], ['Ahmed', 'Saad', ''], ['Laithwaite', 'Richard', '']]"
1905.12934,Muhammad Firmansyah Kasim,"M. F. Kasim, A. F. A. Bott, P. Tzeferacos, D. Q. Lamb, G. Gregori, and
  S. M. Vinko",Retrieving fields from proton radiography without source profiles,,"Phys. Rev. E 100, 033208 (2019)",10.1103/PhysRevE.100.033208,,physics.plasm-ph stat.CO,http://creativecommons.org/licenses/by/4.0/,"  Proton radiography is a technique in high energy density science to diagnose
magnetic and/or electric fields in a plasma by firing a proton beam and
detecting its modulated intensity profile on a screen. Current approaches to
retrieve the integrated field from the modulated intensity profile require the
unmodulated beam intensity profile before the interaction, which is rarely
available experimentally due to shot-to-shot variability. In this paper, we
present a statistical method to retrieve the integrated field without needing
to know the exact source profile. We apply our method to experimental data,
showing the robustness of our approach. Our proposed technique allows not only
for the retrieval of the path-integrated fields, but also of the statistical
properties of the fields.
","[{'version': 'v1', 'created': 'Thu, 30 May 2019 09:51:31 GMT'}, {'version': 'v2', 'created': 'Fri, 13 Sep 2019 12:12:25 GMT'}]",2019-10-02,"[['Kasim', 'M. F.', ''], ['Bott', 'A. F. A.', ''], ['Tzeferacos', 'P.', ''], ['Lamb', 'D. Q.', ''], ['Gregori', 'G.', ''], ['Vinko', 'S. M.', '']]"
1912.07742,Huy Phan,"Huy Phan, Yi Xie, Siyu Liao, Jie Chen, Bo Yuan","CAG: A Real-time Low-cost Enhanced-robustness High-transferability
  Content-aware Adversarial Attack Generator",,,,,cs.CV cs.CR,http://creativecommons.org/licenses/by/4.0/,"  Deep neural networks (DNNs) are vulnerable to adversarial attack despite
their tremendous success in many AI fields. Adversarial attack is a method that
causes the intended misclassfication by adding imperceptible perturbations to
legitimate inputs. Researchers have developed numerous types of adversarial
attack methods. However, from the perspective of practical deployment, these
methods suffer from several drawbacks such as long attack generating time, high
memory cost, insufficient robustness and low transferability. We propose a
Content-aware Adversarial Attack Generator (CAG) to achieve real-time,
low-cost, enhanced-robustness and high-transferability adversarial attack.
First, as a type of generative model-based attack, CAG shows significant
speedup (at least 500 times) in generating adversarial examples compared to the
state-of-the-art attacks such as PGD and C\&W. CAG only needs a single
generative model to perform targeted attack to any targeted class. Because CAG
encodes the label information into a trainable embedding layer, it differs from
prior generative model-based adversarial attacks that use $n$ different copies
of generative models for $n$ different targeted classes. As a result, CAG
significantly reduces the required memory cost for generating adversarial
examples. CAG can generate adversarial perturbations that focus on the critical
areas of input by integrating the class activation maps information in the
training process, and hence improve the robustness of CAG attack against the
state-of-art adversarial defenses. In addition, CAG exhibits high
transferability across different DNN classifier models in black-box attack
scenario by introducing random dropout in the process of generating
perturbations. Extensive experiments on different datasets and DNN models have
verified the real-time, low-cost, enhanced-robustness, and high-transferability
benefits of CAG.
","[{'version': 'v1', 'created': 'Mon, 16 Dec 2019 22:48:38 GMT'}]",2019-12-18,"[['Phan', 'Huy', ''], ['Xie', 'Yi', ''], ['Liao', 'Siyu', ''], ['Chen', 'Jie', ''], ['Yuan', 'Bo', '']]"
2109.14199,Seolhwa Lee,"Seolhwa Lee, Kisu Yang, Chanjun Park, Jo\~ao Sedoc, Heuiseok Lim","Who speaks like a style of Vitamin: Towards Syntax-Aware
  DialogueSummarization using Multi-task Learning","This work has been accepted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Abstractive dialogue summarization is a challenging task for several reasons.
First, most of the important pieces of information in a conversation are
scattered across utterances through multi-party interactions with different
textual styles. Second, dialogues are often informal structures, wherein
different individuals express personal perspectives, unlike text summarization,
tasks that usually target formal documents such as news articles. To address
these issues, we focused on the association between utterances from individual
speakers and unique syntactic structures. Speakers have unique textual styles
that can contain linguistic information, such as voiceprint. Therefore, we
constructed a syntax-aware model by leveraging linguistic information (i.e.,
POS tagging), which alleviates the above issues by inherently distinguishing
sentences uttered from individual speakers. We employed multi-task learning of
both syntax-aware information and dialogue summarization. To the best of our
knowledge, our approach is the first method to apply multi-task learning to the
dialogue summarization task. Experiments on a SAMSum corpus (a large-scale
dialogue summarization corpus) demonstrated that our method improved upon the
vanilla model. We further analyze the costs and benefits of our approach
relative to baseline models.
","[{'version': 'v1', 'created': 'Wed, 29 Sep 2021 05:30:39 GMT'}, {'version': 'v2', 'created': 'Thu, 4 Nov 2021 13:35:51 GMT'}]",2021-11-05,"[['Lee', 'Seolhwa', ''], ['Yang', 'Kisu', ''], ['Park', 'Chanjun', ''], ['Sedoc', 'João', ''], ['Lim', 'Heuiseok', '']]"
2112.08721,Ashot Chilingarian A,"A. Chilingarian, G. Hovsepyan, M. Zazyan",Atmospheric electricity and thunderstorm ground enhancements,,,,,physics.ao-ph,http://creativecommons.org/licenses/by/4.0/,"  The comparative analysis of three thunderstorms on Aragats in May 2021
demonstrates that relativistic runaway electron avalanches are developing in
large areas of the thunderous atmosphere.
","[{'version': 'v1', 'created': 'Thu, 16 Dec 2021 09:19:58 GMT'}]",2021-12-17,"[['Chilingarian', 'A.', ''], ['Hovsepyan', 'G.', ''], ['Zazyan', 'M.', '']]"
2110.01581,Yuchen Liang,Yuchen Liang and Venugopal V. Veeravalli,"Quickest Change Detection with Non-stationary and Composite Post-change
  Distribution",,,,,eess.SP math.ST stat.AP stat.TH,http://creativecommons.org/licenses/by/4.0/,"  The problem of quickest detection of a change in the distribution of a
sequence of independent observations is considered. The pre-change distribution
is assumed to be known and stationary, while the post-change distributions are
assumed to evolve in a pre-determined non-stationary manner with some possible
parametric uncertainty. In particular, it is assumed that the cumulative KL
divergence between the post-change and the pre-change distributions grows
super-linearly with time after the change-point. For the case where the
post-change distributions are known, a universal asymptotic lower bound on the
delay is derived, as the false alarm rate goes to zero. Furthermore, a
window-limited CuSum test is developed, and shown to achieve the lower bound
asymptotically. For the case where the post-change distributions have
parametric uncertainty, a window-limited generalized likelihood-ratio test is
developed and is shown to achieve the universal lower bound asymptotically.
Extensions to the case with dependent observations are discussed. The analysis
is validated through numerical results on synthetic data. The use of the
window-limited generalized likelihood-ratio test in monitoring pandemics is
also demonstrated.
","[{'version': 'v1', 'created': 'Mon, 4 Oct 2021 17:25:01 GMT'}]",2021-10-05,"[['Liang', 'Yuchen', ''], ['Veeravalli', 'Venugopal V.', '']]"
1709.08203,Supriya Pandhre,"Supriya Pandhre, Shagun Sodhani",Survey of Recent Advances in Visual Question Answering,"7 pages, 2 tables",,,,cs.CV,http://creativecommons.org/licenses/by/4.0/,"  Visual Question Answering (VQA) presents a unique challenge as it requires
the ability to understand and encode the multi-modal inputs - in terms of image
processing and natural language processing. The algorithm further needs to
learn how to perform reasoning over this multi-modal representation so it can
answer the questions correctly. This paper presents a survey of different
approaches proposed to solve the problem of Visual Question Answering. We also
describe the current state of the art model in later part of paper. In
particular, the paper describes the approaches taken by various algorithms to
extract image features, text features and the way these are employed to predict
answers. We also briefly discuss the experiments performed to evaluate the VQA
models and report their performances on diverse datasets including newly
released VQA2.0[8].
","[{'version': 'v1', 'created': 'Sun, 24 Sep 2017 14:42:17 GMT'}]",2017-09-26,"[['Pandhre', 'Supriya', ''], ['Sodhani', 'Shagun', '']]"
2011.05655,Wenqi Yan,"Wenqi Yan, Tao Hu, Li Zhou, Jun Cao, Xiao Cai, Jian Fang, Lijun Sun,
  Boxiang Yu, Xilei Sun, Zeyuan Yu, Yayun Ding, Mengchao Liu, Xiaoyan Ma,
  Xiaohui Qian, Wanjin Liu, Yuguang Xie","The replacement system of the JUNO liquid scintillator pilot experiment
  at Daya Bay","16 pages, 10 figures",,10.1016/j.nima.2021.165109,,physics.ins-det hep-ex,http://creativecommons.org/licenses/by/4.0/,"  The Jiangmen Underground Neutrino Observatory (JUNO), a multi-purpose
neutrino experiment, will use 20 kt liquid scintillator (LS). To achieve the
physics goal of determining the neutrino mass ordering, 3$\%$ energy resolution
at 1 MeV is required. This puts strict requirements on the LS light yield and
the transparency. Four LS purification steps have been designed and mid-scale
plants have been built at Daya Bay. To examine the performance of the purified
LS and find the optimized LS composition, the purified LS was injected to the
antineutrino detector 1 in the experimental hall 1 (EH1-AD1) of the Daya Bay
neutrino experiment. To pump out the original gadolinium loaded LS and fill the
new LS, a LS replacement system has been built in EH1 in 2017. By replacing the
Gd-LS with purified water, then replacing the water with purified LS, the
replacement system successfully achieved the designed goal. Subsequently, the
fluorescence and the wavelength shifter were added to higher concentrations via
the replacement system. The data taken at various LS compositions helped JUNO
determine the final LS cocktail. Details of the design, the construction, and
the operation of the replacement system are reported in this paper.
","[{'version': 'v1', 'created': 'Wed, 11 Nov 2020 09:31:00 GMT'}, {'version': 'v2', 'created': 'Thu, 12 Nov 2020 05:58:12 GMT'}, {'version': 'v3', 'created': 'Fri, 13 Nov 2020 02:06:49 GMT'}]",2021-03-17,"[['Yan', 'Wenqi', ''], ['Hu', 'Tao', ''], ['Zhou', 'Li', ''], ['Cao', 'Jun', ''], ['Cai', 'Xiao', ''], ['Fang', 'Jian', ''], ['Sun', 'Lijun', ''], ['Yu', 'Boxiang', ''], ['Sun', 'Xilei', ''], ['Yu', 'Zeyuan', ''], ['Ding', 'Yayun', ''], ['Liu', 'Mengchao', ''], ['Ma', 'Xiaoyan', ''], ['Qian', 'Xiaohui', ''], ['Liu', 'Wanjin', ''], ['Xie', 'Yuguang', '']]"
2110.04490,Ilia Kopchinskii,"Ilia Kopchinskii (1 and 2), Petr Satunin (2) ((1) Moscow State
  University, (2) Institute for Nuclear Research of the Russian Academy of
  Sciences)","On resonant generation of electromagnetic modes in nonlinear
  electrodynamics: Classical approach","10 pages, 5 tables",,10.1103/PhysRevA.105.013508,INR-TH-2021-018,physics.optics hep-th,http://creativecommons.org/licenses/by/4.0/,"  The paper explores a theoretical possibility of resonant amplification of
electromagnetic modes generated by a nonlinear effect in Euler-Heisenberg
electrodynamics. Precisely, we examine the possibility of the amplification for
the third harmonics induced by a single electromagnetic mode in radiofrequency
cavity, as well as the generation of signal mode of combined frequencies
induced by two pump modes ($\omega_1$ and $\omega_2$) in the cavity. Solving
inhomogeneous wave equations for the signal mode, we formulate two resonant
conditions for a cavity of arbitrary shape, and apply the obtained formalism to
linear and rectangular cavities. We explicitly show that the third harmonics as
well as the mode of combined frequency $2\omega_1 + \omega_2$ are not
resonantly amplified while the signal mode with frequency $2\omega_1 -
\omega_2$ is amplified for a certain cavity geometry.
","[{'version': 'v1', 'created': 'Sat, 9 Oct 2021 07:28:33 GMT'}, {'version': 'v2', 'created': 'Tue, 26 Oct 2021 10:00:16 GMT'}]",2022-01-19,"[['Kopchinskii', 'Ilia', '', '1 and 2'], ['Satunin', 'Petr', '']]"
2101.01131,Barbara Cohen,"Barbara A. Cohen, Kelsey E. Young, Nicolle E. B. Zellner, Kris Zacny,
  R. Aileen Yingst, Ryan N. Watkins, Richard Warwick, Sarah N. Valencia,
  Timothy D. Swindle, Stuart J. Robbins, Noah E. Petro, Anthony Nicoletti,
  Daniel P. Moriarty, III, Richard Lynch, Stephen J. Indyk, Juliane Gross,
  Jennifer A. Grier, John A. Grant, Amani Ginyard, Caleb I. Fassett, Kenneth A.
  Farley, Benjamin J. Farcy, Bethany L. Ehlmann, M. Darby Dyar, Gerard
  Daelemans, Natalie M. Curran, Carolyn H. van der Bogert, Ricardo D. Arevalo,
  Jr, F. Scott Anderson","In Situ Geochronology for the Next Decade: Mission Designs for the Moon,
  Mars, and Vesta","Submitted to the Planetary Science Journal, October 2020",,,,astro-ph.EP astro-ph.IM,http://creativecommons.org/licenses/by/4.0/,"  Geochronology, or determination of absolute ages for geologic events,
underpins many inquiries into the formation and evolution of planets and our
Solar System. Absolute ages of ancient and recent magmatic products provide
strong constraints on the dynamics of magma oceans and crustal formation, as
well as the longevity and evolution of interior heat engines and distinct
mantle/crustal source regions. Absolute dating also relates habitability
markers to the timescale of evolution of life on Earth. However, the number of
geochronologically-significant terrains across the inner Solar System far
exceeds our ability to conduct sample return from all of them. In preparation
for the upcoming Decadal Survey, our team formulated a set of medium-class (New
Frontiers) mission concepts to three different locations (the Moon, Mars, and
Vesta) where sites that record Solar System bombardment, magmatism, and/or
habitability are uniquely preserved and accessible. We developed a notional
payload to directly date planetary surfaces, consisting of two instruments
capable of measuring radiometric ages in situ, an imaging spectrometer, optical
cameras to provide site geologic context and sample characterization, a trace
element analyzer to augment sample contextualization, and a sample acquisition
and handling system. Landers carrying this payload to the Moon, Mars, and Vesta
would likely fit into the New Frontiers cost cap in our study (~$1B). A mission
of this type would provide crucial constraints on planetary history while also
enabling a broad suite of investigations such as basic geologic
characterization, geomorphologic analysis, ground truth for remote sensing
analyses, analyses of major, minor, trace, and volatile elements, atmospheric
and other long-lived monitoring, organic molecule analyses, and soil and
geotechnical properties.
","[{'version': 'v1', 'created': 'Mon, 4 Jan 2021 17:54:14 GMT'}]",2021-01-05,"[['Cohen', 'Barbara A.', ''], ['Young', 'Kelsey E.', ''], ['Zellner', 'Nicolle E. B.', ''], ['Zacny', 'Kris', ''], ['Yingst', 'R. Aileen', ''], ['Watkins', 'Ryan N.', ''], ['Warwick', 'Richard', ''], ['Valencia', 'Sarah N.', ''], ['Swindle', 'Timothy D.', ''], ['Robbins', 'Stuart J.', ''], ['Petro', 'Noah E.', ''], ['Nicoletti', 'Anthony', ''], ['Moriarty', 'Daniel P.', ''], ['III', '', ''], ['Lynch', 'Richard', ''], ['Indyk', 'Stephen J.', ''], ['Gross', 'Juliane', ''], ['Grier', 'Jennifer A.', ''], ['Grant', 'John A.', ''], ['Ginyard', 'Amani', ''], ['Fassett', 'Caleb I.', ''], ['Farley', 'Kenneth A.', ''], ['Farcy', 'Benjamin J.', ''], ['Ehlmann', 'Bethany L.', ''], ['Dyar', 'M. Darby', ''], ['Daelemans', 'Gerard', ''], ['Curran', 'Natalie M.', ''], ['van der Bogert', 'Carolyn H.', ''], ['Arevalo,', 'Ricardo D.', 'Jr'], ['Anderson', 'F. Scott', '']]"
1807.04269,Jolanda Kossakowski,"Jolanda J Kossakowski and Marijke C M Gordijn and Harriette Riese and
  Lourens J Waldorp","Applying a Dynamical Systems Model and Network Theory to Major
  Depressive Disorder",arXiv admin note: text overlap with arXiv:1610.05046,,,,physics.soc-ph stat.OT,http://creativecommons.org/licenses/by/4.0/,"  Mental disorders like major depressive disorder can be seen as complex
dynamical systems. In this study we investigate the dynamic behaviour of
individuals to see whether or not we can expect a transition to another mood
state. We introduce a mean field model to a binomial process, where we reduce a
dynamic multidimensional system (stochastic cellular automaton) to a
one-dimensional system to analyse the dynamics. Using maximum likelihood
estimation, we can estimate the parameter of interest which, in combination
with a bifurcation diagram, reflects the expectancy that someone has to
transition to another mood state. After validating the proposed method with
simulated data, we apply this method to two empirical examples, where we show
its use in a clinical sample consisting of patients diagnosed with major
depressive disorder, and a general population sample. Results showed that the
majority of the clinical sample was categorized as having an expectancy for a
transition, while the majority of the general population sample did not have
this expectancy. We conclude that the mean field model has great potential in
assessing the expectancy for a transition between mood states. With some
extensions it could, in the future, aid clinical therapists in the treatment of
depressed patients.
","[{'version': 'v1', 'created': 'Tue, 10 Jul 2018 12:36:15 GMT'}, {'version': 'v2', 'created': 'Thu, 22 Nov 2018 17:56:05 GMT'}, {'version': 'v3', 'created': 'Tue, 26 Mar 2019 14:35:25 GMT'}]",2019-03-27,"[['Kossakowski', 'Jolanda J', ''], ['Gordijn', 'Marijke C M', ''], ['Riese', 'Harriette', ''], ['Waldorp', 'Lourens J', '']]"
2112.14624,Jamie Duell,"Jamie Duell, Monika Seisenberger, Gert Aarts, Shangming Zhou and Xiuyi
  Fan",Towards a Shapley Value Graph Framework for Medical peer-influence,Preliminary work - to be expanded and amended,,,,cs.AI,http://creativecommons.org/licenses/by/4.0/,"  eXplainable Artificial Intelligence (XAI) is a sub-field of Artificial
Intelligence (AI) that is at the forefront of AI research. In XAI, feature
attribution methods produce explanations in the form of feature importance.
People often use feature importance as guidance for intervention. However, a
limitation of existing feature attribution methods is that there is a lack of
explanation towards the consequence of intervention. In other words, although
contribution towards a certain prediction is highlighted by feature attribution
methods, the relation between features and the consequence of intervention is
not studied. The aim of this paper is to introduce a new framework, called a
peer influence framework to look deeper into explanations using graph
representation for feature-to-feature interactions to improve the
interpretability of black-box Machine Learning models and inform intervention.
","[{'version': 'v1', 'created': 'Wed, 29 Dec 2021 16:24:50 GMT'}, {'version': 'v2', 'created': 'Tue, 8 Feb 2022 11:45:05 GMT'}]",2022-02-09,"[['Duell', 'Jamie', ''], ['Seisenberger', 'Monika', ''], ['Aarts', 'Gert', ''], ['Zhou', 'Shangming', ''], ['Fan', 'Xiuyi', '']]"
2112.00155,Philipp Kopp,"Philipp Kopp, Victor Calo, Ernst Rank and Stefan Kollmannsberger","Space-time hp finite elements for heat evolution in laser-based additive
  manufacturing",,,,,math.NA cs.NA,http://creativecommons.org/licenses/by/4.0/,"  The direct numerical simulation of metal additive manufacturing processes
such as laser powder bed fusion is challenging due to the vast differences in
spatial and temporal scales. Classical approaches based on locally refined
finite elements combined with time-stepping schemes can only address the
spatial multi-scale nature and provide only limited scaling potential for
massively parallel computations. We address these shortcomings in a space-time
Galerkin framework where the finite element interpolation also includes the
temporal direction. In this setting, we construct four-dimensional meshes that
are locally refined towards the laser spot and allow for varying temporal
accuracy depending on the position in space. By splitting the mesh into
conforming time slabs, we recover a stepwise solution to solve the space-time
problem locally in time at this slab; additionally, we can choose time-slab
sizes significantly larger than classical time-stepping schemes. As a result,
we believe this setting to be well suited for large-scale parallelization. In
our work, we use a continuous Galerkin-Petrov formulation of the nonlinear heat
equation with an apparent heat capacity model to account for the phase change.
We validate our approach by computing the AMB2018-02 benchmark, where we obtain
an excellent agreement with the measured melt pool shape. Using the same setup,
we demonstrate the performance potential of our approach by hatching a square
area with a laser path length of about one meter.
","[{'version': 'v1', 'created': 'Tue, 30 Nov 2021 22:52:44 GMT'}]",2021-12-02,"[['Kopp', 'Philipp', ''], ['Calo', 'Victor', ''], ['Rank', 'Ernst', ''], ['Kollmannsberger', 'Stefan', '']]"
2106.15716,C.B. Scott,"Cory Braker Scott, Eric Mjolsness, Diane Oyen, Chie Kodera, David
  Bouchez, and Magalie Uyttewaal","Diff2Dist: Learning Spectrally Distinct Edge Functions, with
  Applications to Cell Morphology Analysis",,,,,cs.LG cs.CV math.MG,http://creativecommons.org/licenses/by/4.0/,"  We present a method for learning ""spectrally descriptive"" edge weights for
graphs. We generalize a previously known distance measure on graphs (Graph
Diffusion Distance), thereby allowing it to be tuned to minimize an arbitrary
loss function. Because all steps involved in calculating this modified GDD are
differentiable, we demonstrate that it is possible for a small neural network
model to learn edge weights which minimize loss. GDD alone does not effectively
discriminate between graphs constructed from shoot apical meristem images of
wild-type vs. mutant \emph{Arabidopsis thaliana} specimens. However, training
edge weights and kernel parameters with contrastive loss produces a learned
distance metric with large margins between these graph categories. We
demonstrate this by showing improved performance of a simple
k-nearest-neighbors classifier on the learned distance matrix. We also
demonstrate a further application of this method to biological image analysis:
once trained, we use our model to compute the distance between the biological
graphs and a set of graphs output by a cell division simulator. This allows us
to identify simulation parameter regimes which are similar to each class of
graph in our original dataset.
","[{'version': 'v1', 'created': 'Tue, 29 Jun 2021 20:40:22 GMT'}]",2021-07-01,"[['Scott', 'Cory Braker', ''], ['Mjolsness', 'Eric', ''], ['Oyen', 'Diane', ''], ['Kodera', 'Chie', ''], ['Bouchez', 'David', ''], ['Uyttewaal', 'Magalie', '']]"
2101.10250,Gabriella Skitalinskaya,"Gabriella Skitalinskaya, Jonas Klaff and Henning Wachsmuth","Learning From Revisions: Quality Assessment of Claims in Argumentation
  at Scale",Accepted as a long paper at EACL 2021,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Assessing the quality of arguments and of the claims the arguments are
composed of has become a key task in computational argumentation. However, even
if different claims share the same stance on the same topic, their assessment
depends on the prior perception and weighting of the different aspects of the
topic being discussed. This renders it difficult to learn topic-independent
quality indicators. In this paper, we study claim quality assessment
irrespective of discussed aspects by comparing different revisions of the same
claim. We compile a large-scale corpus with over 377k claim revision pairs of
various types from kialo.com, covering diverse topics from politics, ethics,
entertainment, and others. We then propose two tasks: (a) assessing which claim
of a revision pair is better, and (b) ranking all versions of a claim by
quality. Our first experiments with embedding-based logistic regression and
transformer-based neural networks show promising results, suggesting that
learned indicators generalize well across topics. In a detailed error analysis,
we give insights into what quality dimensions of claims can be assessed
reliably. We provide the data and scripts needed to reproduce all results.
","[{'version': 'v1', 'created': 'Mon, 25 Jan 2021 17:32:04 GMT'}]",2021-01-26,"[['Skitalinskaya', 'Gabriella', ''], ['Klaff', 'Jonas', ''], ['Wachsmuth', 'Henning', '']]"
2202.03073,Diego Romero Abujetas,"Diego R. Abujetas, Jos\'e A. S\'anchez-Gil, Jorge Olmos-Trigo","Tailoring accidental double bound states in the continuum in
  all-dielectric metasurfaces","14 pages, 4 figures",,,,physics.optics cond-mat.mtrl-sci,http://creativecommons.org/licenses/by/4.0/,"  Bound states in the continuum (BICs) have been thoroughly investigated due to
their formally divergent Q-factor, especially those emerging in all-dielectric,
nanostructured metasurfaces from symmetry protection at the $\Gamma$ point
(in-plane wavevector $k_{||}=0$). Less attention has been paid to accidental
BICs that may appear at any other $k_{||}\not =0$ in the band structure of
supported modes, being in turn difficult to predict. Here we make use of a
coupled electric/magnetic dipole model to determine analytical conditions for
the emergence of accidental BICs, valid for any planar array of meta-atoms that
can be described by dipolar resonances, which is the case of many
nanostructures in the optical domain. This is explored for all-dielectric
nanospheres through explicit analytical conditions that allow us in turn to
predict accidental BIC positions in the parameter space $(\omega,\bf{k_{||}}$).
Finally, such conditions are exploited to determine not only single, but also
double (for both linear polarizations) accidental BICs occurring at the same
position in the dispersion relation $\omega-\bf{k_{||}}$ for realistic
semiconductor nanodisk meta-atoms, which might pave the way to a variety of
BIC-enhanced light-matter interaction phenomena at the nanoscale such as lasing
or non-linear conversion, that benefit from emerging at wavevectors away from
the $\Gamma$ point (off-normal incidence) overlapping for both linear
polarizations.
","[{'version': 'v1', 'created': 'Mon, 7 Feb 2022 11:10:55 GMT'}]",2022-02-08,"[['Abujetas', 'Diego R.', ''], ['Sánchez-Gil', 'José A.', ''], ['Olmos-Trigo', 'Jorge', '']]"
2105.02647,Na Liu,"Xiaoyang Duan, Simon Kamin, Na Liu",Dynamic plasmonic colour display,,"Nature Communications 8, Article number: 14606 (2017)",10.1038/ncomms14606,,physics.optics physics.app-ph,http://creativecommons.org/licenses/by/4.0/,"  Plasmonic colour printing based on engineered metasurfaces has revolutionized
colour display science due to its unprecedented subwavelength resolution and
high-density optical data storage. However, advanced plasmonic displays with
novel functionalities including dynamic multicolour printing, animations, and
highly secure encryption have remained in their infancy. Here we demonstrate a
dynamic plasmonic colour display technique that enables all the aforementioned
functionalities using catalytic magnesium metasurfaces. Controlled
hydrogenation and dehydrogenation of the constituent magnesium nanoparticles,
which serve as dynamic pixels, allow for plasmonic colour printing, tuning,
erasing and restoration of colour. Different dynamic pixels feature distinct
colour transformation kinetics, enabling plasmonic animations. Through smart
material processing, information encoded on selected pixels, which are
indiscernible to both optical and scanning electron microscopies, can only be
read out using hydrogen as a decoding key, suggesting a new generation of
information encryption and anti-counterfeiting applications.
","[{'version': 'v1', 'created': 'Tue, 4 May 2021 15:06:12 GMT'}]",2021-05-07,"[['Duan', 'Xiaoyang', ''], ['Kamin', 'Simon', ''], ['Liu', 'Na', '']]"
2111.09762,Vladislav Dorofeev,"Vladislav Dorofeev, Petro Trokhimchuk",Hybrid Super Intelligence and Polymetric Analysis,,,,,cs.AI cs.CC,http://creativecommons.org/licenses/by/4.0/,"  The problem of possible applications Polymetric Analysis for the resolution
problems of artificial Intelligence is discussed. As example the hybrid super
intelligence system by N. Moiseev type was selected. The bond between
polymetric analysis and hybrid super intelligence system was shown. In
operational sense polymetric analysis is more general system. Therefore main
principles of Moiseev concept may be unify with the help of polymetric
analysis. Main peculiarities of this unification are analyzed.
","[{'version': 'v1', 'created': 'Thu, 18 Nov 2021 15:44:08 GMT'}]",2021-11-19,"[['Dorofeev', 'Vladislav', ''], ['Trokhimchuk', 'Petro', '']]"
2107.07104,Benjamin Maier,Benjamin Maier,Scalable Biophysical Simulations of the Neuromuscular System,"PhD thesis, 530 pages, 208 figures",,,,cs.DC cs.CE cs.NA math.NA physics.bio-ph q-bio.QM,http://creativecommons.org/licenses/by/4.0/,"  The human neuromuscular system consisting of skeletal muscles and neural
circuits is a complex system that is not yet fully understood. Surface
electromyography (EMG) can be used to study muscle behavior from the outside.
Computer simulations with detailed biophysical models provide a non-invasive
tool to interpret EMG signals and gain new insights into the system. The
numerical solution of such multi-scale models imposes high computational work
loads, which restricts their application to short simulation time spans or
coarse resolutions. We tackled this challenge by providing scalable software
employing instruction-level and task-level parallelism, suitable numerical
methods and efficient data handling. We implemented a comprehensive,
state-of-the-art, multi-scale multi-physics model framework that can simulate
surface EMG signals and muscle contraction as a result of neuromuscular
stimulation.
  This work describes the model framework and its numerical discretization,
develops new algorithms for mesh generation and parallelization, covers the use
and implementation of our software OpenDiHu, and evaluates its computational
performance in numerous use cases. We obtain a speedup of several hundred
compared to a baseline solver from the literature and demonstrate, that our
distributed-memory parallelization and the use of High Performance Computing
resources enables us to simulate muscular surface EMG of the biceps brachii
muscle with realistic muscle fiber counts of several hundred thousands. We find
that certain model effects are only visible with such high resolution. In
conclusion, our software contributes to more realistic simulations of the
neuromuscular system and provides a tool for applied researchers to complement
in vivo experiments with in-silico studies. It can serve as a building block to
set up comprehensive models for more organs in the musculoskeletal system.
","[{'version': 'v1', 'created': 'Tue, 13 Jul 2021 19:12:46 GMT'}]",2021-07-16,"[['Maier', 'Benjamin', '']]"
2107.00868,Yuanbang Li,Yuanbang Li,"Construction and Adaptability Analysis of User's Preference Models Based
  on Check-in Data in LBSN",,,,,cs.HC,http://creativecommons.org/licenses/by/4.0/,"  With the widespread use of mobile phones, users can share their location
anytime, anywhere, as a form of check-in data. These data reflect user
preferences. Furthermore, the preference rules for different users vary. How to
discover a user's preference from their related information and how to validate
whether a preference model is suited to a user is important for providing a
suitable service to the user. This study provides four main contributions.
First, multiple preference models from different views for each user are
constructed. Second, an algorithm is proposed to validate whether a preference
model is applicable to the user by calculating the stability value of the
user's long-term check-in data for each model. Third, a unified model, i.e., a
multi-channel convolutional neural network is used to characterize this
applicability. Finally, three datasets from multiple sources are used to verify
the validity of the method, the results of which show the effectiveness of the
method.
","[{'version': 'v1', 'created': 'Fri, 2 Jul 2021 06:50:29 GMT'}, {'version': 'v2', 'created': 'Mon, 5 Jul 2021 03:36:48 GMT'}]",2021-07-06,"[['Li', 'Yuanbang', '']]"
2103.09272,Timothy Sipkens,"Timothy A. Sipkens (1 and 2), Max Frei (3 and 4), Alberto Baldelli (1
  and 5), P. Kirchen (1), Frank E. Kruis (3 and 4), Steven N. Rogak (1) ((1)
  Department of Mechanical Engineering, University of British Columbia, (2)
  Department of Mechanical Engineering, University of Alberta, (3) Institute of
  Technology for Nanostructures, University of Duisburg-Essen, (4) Center for
  Nanointegration Duisburg-Essen, University of Duisburg-Essen, (5) Faculty of
  Land and Food Systems, University of British Columbia)",Characterizing soot in TEM images using a convolutional neural network,"23 pages, 8 figures, 5 tables, for associated code see
  https://github.com/tsipkens/atems and
  https://github.com/maxfrei750/CarbonBlackSegmentation",PowderTechnol. 387 (2021) 313-324,10.1016/j.powtec.2021.04.026,,physics.app-ph,http://creativecommons.org/licenses/by/4.0/,"  Soot is an important material with impacts that depend on particle
morphology. Transmission electron microscopy (TEM) represents one of the most
direct routes to qualitatively assess particle characteristics. However,
producing quantitative information requires robust image processing tools,
which is complicated by the low image contrast and complex aggregated
morphologies characteristic of soot. The current work presents a new
convolutional neural network explicitly trained to characterize soot, using
pre-classified images of particles from a natural gas engine; a laboratory gas
flare; and a marine engine. The results are compared against other existing
classifiers before considering the effect that the classifiers have on
automated primary particle size methods. Estimates of the overall uncertainties
between fully automated approaches of aggregate characterization range from 25%
in d_{p,100} to 85% in D_{TEM}. A consistent correlation is observed between
projected-area equivalent diameter and primary particle size across all of the
techniques.
","[{'version': 'v1', 'created': 'Tue, 16 Mar 2021 18:33:15 GMT'}]",2022-02-01,"[['Sipkens', 'Timothy A.', '', '1 and 2'], ['Frei', 'Max', '', '3 and 4'], ['Baldelli', 'Alberto', '', '1\n  and 5'], ['Kirchen', 'P.', '', '3 and 4'], ['Kruis', 'Frank E.', '', '3 and 4'], ['Rogak', 'Steven N.', '']]"
2203.07258,Kirit Karkare,"Kirit S. Karkare, Azadeh Moradinezhad Dizgah, Garrett K. Keating,
  Patrick Breysse, Dongwoo T. Chung (for the Snowmass Cosmic Frontier 5 Topical
  Group)","Snowmass 2021 Cosmic Frontier White Paper: Cosmology with
  Millimeter-Wave Line Intensity Mapping","25 pages, 4 figures. Contribution to Snowmass 2021",,,,astro-ph.CO hep-ex,http://creativecommons.org/licenses/by/4.0/,"  Next-generation tests of fundamental physics and cosmology using large scale
structure require measurements over large volumes of the Universe, including
high redshifts inaccessible to present-day surveys. Line intensity mapping, an
emerging technique that detects the integrated emission of atomic and molecular
lines without resolving sources, can efficiently map cosmic structure over a
wide range of redshifts. Observations at millimeter wavelengths detect far-IR
emission lines such as CO/[CII], and take advantage of observational and
analysis techniques developed by CMB experiments. These measurements can
provide constraints with unprecedented precision on the physics of inflation,
neutrino masses, light relativistic species, dark energy and modified gravity,
and dark matter, among many other science goals. In this white paper we
forecast the sensitivity requirements for future ground-based mm-wave intensity
mapping experiments to enable transformational cosmological constraints. We
outline a staged experimental program to steadily improve sensitivity, and
describe the necessary investments in developing detector technology and
analysis techniques.
","[{'version': 'v1', 'created': 'Mon, 14 Mar 2022 16:40:17 GMT'}]",2022-03-15,"[['Karkare', 'Kirit S.', '', 'for the Snowmass Cosmic Frontier 5 Topical\n  Group'], ['Dizgah', 'Azadeh Moradinezhad', '', 'for the Snowmass Cosmic Frontier 5 Topical\n  Group'], ['Keating', 'Garrett K.', '', 'for the Snowmass Cosmic Frontier 5 Topical\n  Group'], ['Breysse', 'Patrick', '', 'for the Snowmass Cosmic Frontier 5 Topical\n  Group'], ['Chung', 'Dongwoo T.', '', 'for the Snowmass Cosmic Frontier 5 Topical\n  Group']]"
1509.03249,C\'edric B\'eny,C\'edric B\'eny,Coarse-grained distinguishability of field interactions,,"Quantum 2, 67 (2018)",10.22331/q-2018-05-24-67,,quant-ph cond-mat.stat-mech hep-th,http://creativecommons.org/licenses/by/4.0/,"  Information-theoretical quantities such as statistical distinguishability
typically result from optimisations over all conceivable observables. Physical
theories, however, are not generally considered valid for all mathematically
allowed measurements. For instance, quantum field theories are not meant to be
correct or even consistent at arbitrarily small lengthscales. A general way of
limiting such an optimisation to certain observables is to first coarse-grain
the states by a quantum channel. We show how to calculate contractive quantum
information metrics on coarse-grained equilibrium states of free bosonic
systems (Gaussian states), in directions generated by arbitrary perturbations
of the Hamiltonian. As an example, we study the Klein-Gordon field. If the
phase-space resolution is coarse compared to h-bar, the various metrics become
equal and the calculations simplify. In that context, we compute the scale
dependence of the distinguishability of the quartic interaction.
","[{'version': 'v1', 'created': 'Thu, 10 Sep 2015 17:57:22 GMT'}, {'version': 'v2', 'created': 'Mon, 5 Oct 2015 08:44:36 GMT'}, {'version': 'v3', 'created': 'Mon, 6 Jun 2016 09:09:50 GMT'}, {'version': 'v4', 'created': 'Tue, 17 Oct 2017 07:03:32 GMT'}, {'version': 'v5', 'created': 'Wed, 16 May 2018 13:54:22 GMT'}]",2018-05-28,"[['Bény', 'Cédric', '']]"
1912.09855,Maximilian Bachl,"Alexander Hartl, Maximilian Bachl, Joachim Fabini, Tanja Zseby",Explainability and Adversarial Robustness for RNNs,Accepted at IEEE BigDataService 2020,"2020 IEEE Sixth International Conference on Big Data Computing
  Service and Applications (BigDataService)",10.1109/BigDataService49289.2020.00030,,cs.LG cs.CR cs.NI stat.ML,http://creativecommons.org/licenses/by/4.0/,"  Recurrent Neural Networks (RNNs) yield attractive properties for constructing
Intrusion Detection Systems (IDSs) for network data. With the rise of
ubiquitous Machine Learning (ML) systems, malicious actors have been catching
up quickly to find new ways to exploit ML vulnerabilities for profit. Recently
developed adversarial ML techniques focus on computer vision and their
applicability to network traffic is not straightforward: Network packets expose
fewer features than an image, are sequential and impose several constraints on
their features.
  We show that despite these completely different characteristics, adversarial
samples can be generated reliably for RNNs. To understand a classifier's
potential for misclassification, we extend existing explainability techniques
and propose new ones, suitable particularly for sequential data. Applying them
shows that already the first packets of a communication flow are of crucial
importance and are likely to be targeted by attackers. Feature importance
methods show that even relatively unimportant features can be effectively
abused to generate adversarial samples. Since traditional evaluation metrics
such as accuracy are not sufficient for quantifying the adversarial threat, we
propose the Adversarial Robustness Score (ARS) for comparing IDSs, capturing a
common notion of adversarial robustness, and show that an adversarial training
procedure can significantly and successfully reduce the attack surface.
","[{'version': 'v1', 'created': 'Fri, 20 Dec 2019 14:47:09 GMT'}, {'version': 'v2', 'created': 'Wed, 19 Feb 2020 13:23:07 GMT'}]",2020-10-16,"[['Hartl', 'Alexander', ''], ['Bachl', 'Maximilian', ''], ['Fabini', 'Joachim', ''], ['Zseby', 'Tanja', '']]"
2109.06818,Florian Meyer,Florian Meyer and Kay L. Gemba,"Acoustic Source Localization in Shallow Water: A Probabilistic
  Focalization Approach","6 pages, 5 figures",,,,eess.SP,http://creativecommons.org/licenses/by/4.0/,"  This paper presents a Bayesian estimation method for the passive localization
of an acoustic source in shallow water. Our probabilistic focalization approach
estimates the time-varying source location by associating direction of arrival
(DOA) observations to DOAs predicted based on a statistical model. Embedded ray
tracing makes it possible to incorporate environmental parameters and
characterize the nonlinear acoustic waveguide. We demonstrate performance
advantages of our approach compared to matched field processing using data
collected during the SWellEx-96 experiment.
","[{'version': 'v1', 'created': 'Tue, 14 Sep 2021 16:57:59 GMT'}]",2021-09-15,"[['Meyer', 'Florian', ''], ['Gemba', 'Kay L.', '']]"
2112.09130,Nupur Kumari,"Nupur Kumari, Richard Zhang, Eli Shechtman, Jun-Yan Zhu",Ensembling Off-the-shelf Models for GAN Training,"GitHub: https://github.com/nupurkmr9/vision-aided-gan Project
  webpage: https://www.cs.cmu.edu/~vision-aided-gan/",,,,cs.CV cs.GR cs.LG,http://creativecommons.org/licenses/by/4.0/,"  The advent of large-scale training has produced a cornucopia of powerful
visual recognition models. However, generative models, such as GANs, have
traditionally been trained from scratch in an unsupervised manner. Can the
collective ""knowledge"" from a large bank of pretrained vision models be
leveraged to improve GAN training? If so, with so many models to choose from,
which one(s) should be selected, and in what manner are they most effective? We
find that pretrained computer vision models can significantly improve
performance when used in an ensemble of discriminators. Notably, the particular
subset of selected models greatly affects performance. We propose an effective
selection mechanism, by probing the linear separability between real and fake
samples in pretrained model embeddings, choosing the most accurate model, and
progressively adding it to the discriminator ensemble. Interestingly, our
method can improve GAN training in both limited data and large-scale settings.
Given only 10k training samples, our FID on LSUN Cat matches the StyleGAN2
trained on 1.6M images. On the full dataset, our method improves FID by 1.5x to
2x on cat, church, and horse categories of LSUN.
","[{'version': 'v1', 'created': 'Thu, 16 Dec 2021 18:59:50 GMT'}, {'version': 'v2', 'created': 'Tue, 18 Jan 2022 18:59:46 GMT'}]",2022-01-19,"[['Kumari', 'Nupur', ''], ['Zhang', 'Richard', ''], ['Shechtman', 'Eli', ''], ['Zhu', 'Jun-Yan', '']]"
2109.04634,EPTCS,"Brendan Hall (Honeywell Advanced Technology, Plymouth, USA), Sarat
  Chandra Varanasi (The University of Texas at Dallas, Richardson, USA), Jan
  Fiedor (Honeywell Internation s.r.o & Brno University of Technology, Brno,
  Czech Republic), Joaqu\'in Arias (Universidad Rey Juan Carlos, Madrid,
  Spain), Kinjal Basu (The University of Texas at Dallas, Richardson, USA),
  Fang Li (The University of Texas at Dallas, Richardson, USA), Devesh Bhatt
  (Honeywell Advanced Technology, Plymouth, USA), Kevin Driscoll (Honeywell
  Advanced Technology, Plymouth, USA), Elmer Salazar (The University of Texas
  at Dallas, Richardson, USA), Gopal Gupta (The University of Texas at Dallas,
  Richardson, USA)","Knowledge-Assisted Reasoning of Model-Augmented System Requirements with
  Event Calculus and Goal-Directed Answer Set Programming","In Proceedings HCVS 2021, arXiv:2109.03988","EPTCS 344, 2021, pp. 79-90",10.4204/EPTCS.344.6,,cs.LO cs.AI cs.SC,http://creativecommons.org/licenses/by/4.0/,"  We consider requirements for cyber-physical systems represented in
constrained natural language. We present novel automated techniques for aiding
in the development of these requirements so that they are consistent and can
withstand perceived failures. We show how cyber-physical systems' requirements
can be modeled using the event calculus (EC), a formalism used in AI for
representing actions and change. We also show how answer set programming (ASP)
and its query-driven implementation s(CASP) can be used to directly realize the
event calculus model of the requirements. This event calculus model can be used
to automatically validate the requirements. Since ASP is an expressive
knowledge representation language, it can also be used to represent contextual
knowledge about cyber-physical systems, which, in turn, can be used to find
gaps in their requirements specifications. We illustrate our approach through
an altitude alerting system from the avionics domain.
","[{'version': 'v1', 'created': 'Fri, 10 Sep 2021 02:43:08 GMT'}]",2021-09-13,"[['Hall', 'Brendan', '', 'Honeywell Advanced Technology, Plymouth, USA'], ['Varanasi', 'Sarat Chandra', '', 'The University of Texas at Dallas, Richardson, USA'], ['Fiedor', 'Jan', '', 'Honeywell Internation s.r.o & Brno University of Technology, Brno,\n  Czech Republic'], ['Arias', 'Joaquín', '', 'Universidad Rey Juan Carlos, Madrid,\n  Spain'], ['Basu', 'Kinjal', '', 'The University of Texas at Dallas, Richardson, USA'], ['Li', 'Fang', '', 'The University of Texas at Dallas, Richardson, USA'], ['Bhatt', 'Devesh', '', 'Honeywell Advanced Technology, Plymouth, USA'], ['Driscoll', 'Kevin', '', 'Honeywell\n  Advanced Technology, Plymouth, USA'], ['Salazar', 'Elmer', '', 'The University of Texas\n  at Dallas, Richardson, USA'], ['Gupta', 'Gopal', '', 'The University of Texas at Dallas,\n  Richardson, USA']]"
2107.00873,Heiko Paulheim,"Malte Brockmeier, Yawen Liu, Sunita Pateer, Sven Hertling and Heiko
  Paulheim","On-Demand and Lightweight Knowledge Graph Generation -- a Demonstration
  with DBpedia",Accepted at Semantics 2021,,,,cs.IR cs.AI cs.DB,http://creativecommons.org/licenses/by/4.0/,"  Modern large-scale knowledge graphs, such as DBpedia, are datasets which
require large computational resources to serve and process. Moreover, they
often have longer release cycles, which leads to outdated information in those
graphs. In this paper, we present DBpedia on Demand -- a system which serves
DBpedia resources on demand without the need to materialize and store the
entire graph, and which even provides limited querying functionality.
","[{'version': 'v1', 'created': 'Fri, 2 Jul 2021 07:15:27 GMT'}]",2021-07-05,"[['Brockmeier', 'Malte', ''], ['Liu', 'Yawen', ''], ['Pateer', 'Sunita', ''], ['Hertling', 'Sven', ''], ['Paulheim', 'Heiko', '']]"
2104.05980,Nina Hosseini-Kivanani,"Nina Hosseini-Kivanani, Roberto Gretter, Marco Matassoni, and Giuseppe
  Daniele Falavigna","Experiments of ASR-based mispronunciation detection for children and
  adult English learners",Submitted to INTERSPEECH2021,,,,cs.CL cs.SD eess.AS,http://creativecommons.org/licenses/by/4.0/,"  Pronunciation is one of the fundamentals of language learning, and it is
considered a primary factor of spoken language when it comes to an
understanding and being understood by others. The persistent presence of high
error rates in speech recognition domains resulting from mispronunciations
motivates us to find alternative techniques for handling mispronunciations. In
this study, we develop a mispronunciation assessment system that checks the
pronunciation of non-native English speakers, identifies the commonly
mispronounced phonemes of Italian learners of English, and presents an
evaluation of the non-native pronunciation observed in phonetically annotated
speech corpora. In this work, to detect mispronunciations, we used a
phone-based ASR implemented using Kaldi. We used two non-native English labeled
corpora; (i) a corpus of Italian adults contains 5,867 utterances from 46
speakers, and (ii) a corpus of Italian children consists of 5,268 utterances
from 78 children. Our results show that the selected error model can
discriminate correct sounds from incorrect sounds in both native and nonnative
speech, and therefore can be used to detect pronunciation errors in non-native
speech. The phone error rates show improvement in using the error language
model. The ASR system shows better accuracy after applying the error model on
our selected corpora.
","[{'version': 'v1', 'created': 'Tue, 13 Apr 2021 07:24:05 GMT'}]",2021-04-14,"[['Hosseini-Kivanani', 'Nina', ''], ['Gretter', 'Roberto', ''], ['Matassoni', 'Marco', ''], ['Falavigna', 'Giuseppe Daniele', '']]"
2202.02131,Konstantina Nikita S,"Panagiota Karatza, Kalliopi V. Dalakleidi, Maria Athanasiou,
  Konstantina S. Nikita","Interpretability methods of machine learning algorithms with
  applications in breast cancer diagnosis","2021 43rd Annual International Conference of the IEEE Engineering in
  Medicine & Biology Society (EMBC)",,10.1109/EMBC46164.2021.9630556,,cs.LG cs.AI physics.med-ph,http://creativecommons.org/licenses/by/4.0/,"  Early detection of breast cancer is a powerful tool towards decreasing its
socioeconomic burden. Although, artificial intelligence (AI) methods have shown
remarkable results towards this goal, their ""black box"" nature hinders their
wide adoption in clinical practice. To address the need for AI guided breast
cancer diagnosis, interpretability methods can be utilized. In this study, we
used AI methods, i.e., Random Forests (RF), Neural Networks (NN) and Ensembles
of Neural Networks (ENN), towards this goal and explained and optimized their
performance through interpretability techniques, such as the Global Surrogate
(GS) method, the Individual Conditional Expectation (ICE) plots and the Shapley
values (SV). The Wisconsin Diagnostic Breast Cancer (WDBC) dataset of the open
UCI repository was used for the training and evaluation of the AI algorithms.
The best performance for breast cancer diagnosis was achieved by the proposed
ENN (96.6% accuracy and 0.96 area under the ROC curve), and its predictions
were explained by ICE plots, proving that its decisions were compliant with
current medical knowledge and can be further utilized to gain new insights in
the pathophysiological mechanisms of breast cancer. Feature selection based on
features' importance according to the GS model improved the performance of the
RF (leading the accuracy from 96.49% to 97.18% and the area under the ROC curve
from 0.96 to 0.97) and feature selection based on features' importance
according to SV improved the performance of the NN (leading the accuracy from
94.6% to 95.53% and the area under the ROC curve from 0.94 to 0.95). Compared
to other approaches on the same dataset, our proposed models demonstrated state
of the art performance while being interpretable.
","[{'version': 'v1', 'created': 'Fri, 4 Feb 2022 13:41:30 GMT'}]",2022-02-07,"[['Karatza', 'Panagiota', ''], ['Dalakleidi', 'Kalliopi V.', ''], ['Athanasiou', 'Maria', ''], ['Nikita', 'Konstantina S.', '']]"
2203.03642,Antonio Ambrosone,"A. Ambrosone, M. Chianese, D.F.G. Fiorillo, A. Marinelli and G. Miele","Observable Signatures of Cosmic Rays Transport in Starburst Galaxies on
  Gamma-ray and Neutrino Observations","9 pages, 5 figures, 3 tables",,,,astro-ph.HE hep-ph,http://creativecommons.org/licenses/by/4.0/,"  The gamma-ray emission from Starburst and Starforming Galaxies (SBGs and
SFGs) strongly suggest a correlation between star-forming activity and
gamma-ray luminosity. However, the very nature of cosmic-ray (CR) transport and
the degree of their confinement within SBG cores are still open questions. We
aim at probing the imprints left by CR transport on gamma-ray and neutrino
observations of point-like SFGs and SBGs, looking into quantitative ways to
discriminate among different transport models. Moreover, following the reported
scenarios, we quantitatively assess the SBGs and SFGs contribution to the
Extra-galactic Gamma-Ray Background (EGB data) and the IceCube diffuse
observations (HESE data). We analyse the 10-year Fermi-LAT spectral energy
distributions of 13 nearby galaxies with two different CR transport models,
taking into account the corresponding IR and UV observations. We generate mock
gamma-ray data to simulate the CTA performance in detecting these sources. In
the way, we propose a test to discriminate between the two CR models,
quantifying the statistical confidence at which one model can be preferred over
the other. We point out that current data already give a slight preference to
CR models which are dominated by advection in their nucleus. Moreover, we show
that CTA will allow us to firmly disfavour models dominated by diffusion over
self-induced turbulence, compared to advection-dominated models, with Bayes
factors which can be as large as $10^7$ for some of the SBGs. Finally, we
estimate the diffuse gamma-ray and neutrino fluxes of SFGs and SBGs, showing
that they can explain $25\%$ of the diffuse HESE data, while remaining
consistent with gamma-ray limits on non-blazar sources.
","[{'version': 'v1', 'created': 'Mon, 7 Mar 2022 19:00:00 GMT'}]",2022-03-09,"[['Ambrosone', 'A.', ''], ['Chianese', 'M.', ''], ['Fiorillo', 'D. F. G.', ''], ['Marinelli', 'A.', ''], ['Miele', 'G.', '']]"
2010.13022,Mingming Nie,"Mingming Nie, Shu-Wei Huang","Deterministic generation of parametrically driven dissipative Kerr
  soliton",,,,,physics.optics,http://creativecommons.org/licenses/by/4.0/,"  We theoretically study the nature of parametrically driven dissipative Kerr
soliton (PD-DKS) in a doubly resonant degenerate micro-optical parametric
oscillator (DR-D{\mu}OPO) with the cooperation of \c{hi}(2) and \c{hi}(3)
nonlinearities. Lifting the assumption of close-to-zero group velocity mismatch
(GVM) that requires extensive dispersion engineering, we show that there is a
threshold GVM above which single PD-DKS in DR-D{\mu}OPO can be generated
deterministically. We find that the exact PD-DKS generation dynamics can be
divided into two distinctive regimes depending on the phase matching condition.
In both regimes, the perturbative effective third-order nonlinearity resulting
from the cascaded quadratic process is responsible for the soliton annihilation
and the deterministic single PD-DKS generation. We also develop the
experimental design guidelines for accessing such deterministic single PD-DKS
state. The working principle can be applied to different material platforms as
a competitive ultrashort pulse and broadband frequency comb source architecture
at the mid-infrared spectral range.
","[{'version': 'v1', 'created': 'Sun, 25 Oct 2020 03:02:26 GMT'}, {'version': 'v2', 'created': 'Wed, 24 Mar 2021 19:09:49 GMT'}]",2021-03-26,"[['Nie', 'Mingming', ''], ['Huang', 'Shu-Wei', '']]"
2012.06275,Yu Tsao,"Kun-Hsi Tsai, Wei-Chien Wang, Chui-Hsuan Cheng, Chan-Yen Tsai, Jou-Kou
  Wang, Tzu-Hao Lin, Shih-Hau Fang, Li-Chin Chen, Yu Tsao","Blind Monaural Source Separation on Heart and Lung Sounds Based on
  Periodic-Coded Deep Autoencoder","13 pages, 11 figures, Accepted by IEEE Journal of Biomedical and
  Health Informatics",,10.1109/JBHI.2020.3016831,,eess.AS,http://creativecommons.org/licenses/by/4.0/,"  Auscultation is the most efficient way to diagnose cardiovascular and
respiratory diseases. To reach accurate diagnoses, a device must be able to
recognize heart and lung sounds from various clinical situations. However, the
recorded chest sounds are mixed by heart and lung sounds. Thus, effectively
separating these two sounds is critical in the pre-processing stage. Recent
advances in machine learning have progressed on monaural source separations,
but most of the well-known techniques require paired mixed sounds and
individual pure sounds for model training. As the preparation of pure heart and
lung sounds is difficult, special designs must be considered to derive
effective heart and lung sound separation techniques. In this study, we
proposed a novel periodicity-coded deep auto-encoder (PC-DAE) approach to
separate mixed heart-lung sounds in an unsupervised manner via the assumption
of different periodicities between heart rate and respiration rate. The PC-DAE
benefits from deep-learning-based models by extracting representative features
and considers the periodicity of heart and lung sounds to carry out the
separation. We evaluated PC-DAE on two datasets. The first one includes sounds
from the Student Auscultation Manikin (SAM), and the second is prepared by
recording chest sounds in real-world conditions. Experimental results indicate
that PC-DAE outperforms several well-known separations works in terms of
standardized evaluation metrics. Moreover, waveforms and spectrograms
demonstrate the effectiveness of PC-DAE compared to existing approaches. It is
also confirmed that by using the proposed PC-DAE as a pre-processing stage, the
heart sound recognition accuracies can be notably boosted. The experimental
results confirmed the effectiveness of PC-DAE and its potential to be used in
clinical applications.
","[{'version': 'v1', 'created': 'Fri, 11 Dec 2020 12:13:46 GMT'}]",2020-12-14,"[['Tsai', 'Kun-Hsi', ''], ['Wang', 'Wei-Chien', ''], ['Cheng', 'Chui-Hsuan', ''], ['Tsai', 'Chan-Yen', ''], ['Wang', 'Jou-Kou', ''], ['Lin', 'Tzu-Hao', ''], ['Fang', 'Shih-Hau', ''], ['Chen', 'Li-Chin', ''], ['Tsao', 'Yu', '']]"
2004.07099,Peter Nooteboom,"Peter D. Nooteboom, Philippe Delandmeter, Erik van Sebille, Peter K.
  Bijl, Henk A. Dijkstra and Anna S. von der Heydt","Resolution dependency of sinking Lagrangian particles in ocean general
  circulation models",,,10.1371/journal.pone.0238650,,physics.ao-ph,http://creativecommons.org/licenses/by/4.0/,"  Any type of non-buoyant material in the ocean is transported horizontally by
currents during its sinking journey. This lateral transport can be far from
negligible for small sinking velocities. To estimate its magnitude and
direction, the material is often modelled as a set of Lagrangian particles
advected by current velocities that are obtained from Ocean General Circulation
Models (OGCMs). State-of-the-art OGCMs are strongly eddying, similar to the
real ocean, providing results with a spatial resolution on the order of 10 km
on a daily frequency. While the importance of eddies in OGCMs is
well-appreciated in the physical oceanographic community, other marine research
communities may not. To demonstrate how much the absence of mesoscale features
in low-resolution models influences the Lagrangian particle transport, we
simulate the transport of sinking Lagrangian particles using low- and
high-resolution global OGCMs, and assess the lateral transport differences
resulting from the difference in spatial and temporal model resolution. We find
major differences between the transport in the non-eddying OGCM and in the
eddying OGCM. Addition of stochastic noise to the particle trajectories in the
non-eddying OGCM parameterises the effect of eddies well in some cases. The
effect of a coarser temporal resolution (5-daily) is smaller compared to a
coarser spatial resolution (0.1$^{\circ}$ versus 1$^{\circ}$ horizontally). We
recommend to use sinking Lagrangian particles, representing e.g. marine snow,
microplankton or sinking plastic, only with velocity fields from eddying OGCMs,
requiring high-resolution models in e.g. paleoceanographic studies. To increase
the accessibility of our particle trace simulations, we launch
planktondrift.science.uu.nl, an online tool to reconstruct the surface origin
of sedimentary particles in a specific location.
","[{'version': 'v1', 'created': 'Wed, 15 Apr 2020 14:10:11 GMT'}, {'version': 'v2', 'created': 'Mon, 14 Sep 2020 13:28:40 GMT'}]",2020-09-15,"[['Nooteboom', 'Peter D.', ''], ['Delandmeter', 'Philippe', ''], ['van Sebille', 'Erik', ''], ['Bijl', 'Peter K.', ''], ['Dijkstra', 'Henk A.', ''], ['von der Heydt', 'Anna S.', '']]"
2107.01984,Jeffrey Carver,"Sarah Heckman and Jeffrey C. Carver and Mark Sherriff and Ahmed
  Al-Zubidy","A Systematic Literature Review of Empiricism and Norms of Reporting in
  Computing Education Research Literature",Paper to appear in ACM Transactions on Computing Education,ACM Transactions on Computing Education. 22(1):1-46. 2021,10.1145/3470652,,cs.CY,http://creativecommons.org/licenses/by/4.0/,"  Computing Education Research (CER) is critical for supporting the increasing
number of students who need to learn computing skills. To systematically
advance knowledge, publications must be clear enough to support replications,
meta-analyses, and theory-building. The goal of this study is to characterize
the reporting of empiricism in CER literature by identifying whether
publications include information to support replications, meta-analyses, and
theory building. The research questions are: RQ1) What percentage of papers in
CER venues have empirical evaluation? RQ2) What are the characteristics of the
empirical evaluation? RQ3) Do the papers with empirical evaluation follow
reporting norms (both for inclusion and for labeling of key information)? We
conducted an SLR of 427 papers published during 2014 and 2015 in five CER
venues: SIGCSE TS, ICER, ITiCSE, TOCE, and CSE. We developed and applied the
CER Empiricism Assessment Rubric. Over 80% of papers had some form of empirical
evaluation. Quantitative evaluation methods were the most frequent. Papers most
frequently reported results on interventions around pedagogical techniques,
curriculum, community, or tools. There was a split in papers that had some type
of comparison between an intervention and some other data set or baseline. Many
papers lacked properly reported research objectives, goals, research questions,
or hypotheses, description of participants, study design, data collection, and
threats to validity. CER authors are contributing empirical results to the
literature; however, not all norms for reporting are met. We encourage authors
to provide clear, labeled details about their work so readers can use the
methodologies and results for replications and meta-analyses. As our community
grows, our reporting of CER should mature to help establish computing education
theory to support the next generation of computing learners.
","[{'version': 'v1', 'created': 'Fri, 2 Jul 2021 16:37:29 GMT'}]",2021-10-20,"[['Heckman', 'Sarah', ''], ['Carver', 'Jeffrey C.', ''], ['Sherriff', 'Mark', ''], ['Al-Zubidy', 'Ahmed', '']]"
2106.02847,Aymen Al Marjani,"Aymen Al Marjani, Aur\'elien Garivier, Alexandre Proutiere",Navigating to the Best Policy in Markov Decision Processes,,,,,stat.ML cs.LG,http://creativecommons.org/licenses/by/4.0/,"  We investigate the classical active pure exploration problem in Markov
Decision Processes, where the agent sequentially selects actions and, from the
resulting system trajectory, aims at identifying the best policy as fast as
possible. We propose a problem-dependent lower bound on the average number of
steps required before a correct answer can be given with probability at least
$1-\delta$. We further provide the first algorithm with an instance-specific
sample complexity in this setting. This algorithm addresses the general case of
communicating MDPs; we also propose a variant with a reduced exploration rate
(and hence faster convergence) under an additional ergodicity assumption. This
work extends previous results relative to the \emph{generative
setting}~\cite{pmlr-v139-marjani21a}, where the agent could at each step query
the random outcome of any (state, action) pair. In contrast, we show here how
to deal with the \emph{navigation constraints}, induced by the \emph{online
setting}. Our analysis relies on an ergodic theorem for non-homogeneous Markov
chains which we consider of wide interest in the analysis of Markov Decision
Processes.
","[{'version': 'v1', 'created': 'Sat, 5 Jun 2021 09:16:28 GMT'}, {'version': 'v2', 'created': 'Mon, 25 Oct 2021 14:48:55 GMT'}]",2021-10-26,"[['Marjani', 'Aymen Al', ''], ['Garivier', 'Aurélien', ''], ['Proutiere', 'Alexandre', '']]"
2203.03673,Wenkai Xu,Wenkai Xu and Gesine Reinert,"AgraSSt: Approximate Graph Stein Statistics for Interpretable Assessment
  of Implicit Graph Generators",,,,,stat.ML cs.LG,http://creativecommons.org/licenses/by/4.0/,"  We propose and analyse a novel statistical procedure, coined AgraSSt, to
assess the quality of graph generators that may not be available in explicit
form. In particular, AgraSSt can be used to determine whether a learnt graph
generating process is capable of generating graphs that resemble a given input
graph. Inspired by Stein operators for random graphs, the key idea of AgraSSt
is the construction of a kernel discrepancy based on an operator obtained from
the graph generator. AgraSSt can provide interpretable criticisms for a graph
generator training procedure and help identify reliable sample batches for
downstream tasks. Using Stein`s method we give theoretical guarantees for a
broad class of random graph models. We provide empirical results on both
synthetic input graphs with known graph generation procedures, and real-world
input graphs that the state-of-the-art (deep) generative models for graphs are
trained on.
","[{'version': 'v1', 'created': 'Mon, 7 Mar 2022 19:12:40 GMT'}]",2022-03-09,"[['Xu', 'Wenkai', ''], ['Reinert', 'Gesine', '']]"
2107.00506,Michael Cushing,"Michael C. Cushing, Adam C. Schneider, J. Davy Kirkpatrick, Caroline
  V. Morley, Mark S. Marley, Christopher R. Gelino, Gregory N. Mace, Edward L.
  Wright, Peter R. Eisenhardt, Michael F. Skrutskie, Kenneth A. Marsh","An Improved Near-Infrared Spectrum of the Archetype Y Dwarf WISEP
  J182831.08+265037.8",Accepted for publication in the Astrophysical Journal,,10.3847/1538-4357/ac12cb,,astro-ph.SR,http://creativecommons.org/licenses/by/4.0/,"  We present a Hubble Space Telescope/Wide-Field Camera 3 near infrared
spectrum of the archetype Y dwarf WISEP 182831.08+265037.8. The spectrum covers
the 0.9-1.7 um wavelength range at a resolving power of lambda/Delta lambda
~180 and is a significant improvement over the previously published spectrum
because it covers a broader wavelength range and is uncontaminated by light
from a background star. The spectrum is unique for a cool brown dwarf in that
the flux peaks in the Y, J, and H band are of near equal intensity in units of
f_lambda. We fail to detect any absorption bands of NH_3 in the spectrum, in
contrast to the predictions of chemical equilibrium models, but tentatively
identify CH_4 as the carrier of an unknown absorption feature centered at 1.015
um. Using previously published ground- and spaced-based photometry, and using a
Rayleigh Jeans tail to account for flux emerging longward of 4.5 um, we compute
a bolometric luminosity of log (L_bol/L_sun)=-6.50+-0.02 which is significantly
lower than previously published results. Finally, we compare the spectrum and
photometry to two sets of atmospheric models and find that best overall match
to the observed properties of WISEP 182831.08+265037.8 is a ~1 Gyr old binary
composed of two T_eff~325 K, ~5 M_Jup brown dwarfs with subsolar [C/O] ratios.
","[{'version': 'v1', 'created': 'Thu, 1 Jul 2021 14:53:12 GMT'}]",2021-10-20,"[['Cushing', 'Michael C.', ''], ['Schneider', 'Adam C.', ''], ['Kirkpatrick', 'J. Davy', ''], ['Morley', 'Caroline V.', ''], ['Marley', 'Mark S.', ''], ['Gelino', 'Christopher R.', ''], ['Mace', 'Gregory N.', ''], ['Wright', 'Edward L.', ''], ['Eisenhardt', 'Peter R.', ''], ['Skrutskie', 'Michael F.', ''], ['Marsh', 'Kenneth A.', '']]"
2011.06825,Md Saif Hassan Onim,"Md. Saif Hassan Onim, Aiman Rafeed Ehtesham, Amreen Anbar, A. K. M.
  Nazrul Islam, A. K. M. Mahbubur Rahman","LULC classification by semantic segmentation of satellite images using
  FastFCN",,,10.1109/ICAICT51780.2020.9333522,,cs.CV cs.LG,http://creativecommons.org/licenses/by/4.0/,"  This paper analyses how well a Fast Fully Convolutional Network (FastFCN)
semantically segments satellite images and thus classifies Land Use/Land
Cover(LULC) classes. Fast-FCN was used on Gaofen-2 Image Dataset (GID-2) to
segment them in five different classes: BuiltUp, Meadow, Farmland, Water and
Forest. The results showed better accuracy (0.93), precision (0.99), recall
(0.98) and mean Intersection over Union (mIoU)(0.97) than other approaches like
using FCN-8 or eCognition, a readily available software. We presented a
comparison between the results. We propose FastFCN to be both faster and more
accurate automated method than other existing methods for LULC classification.
","[{'version': 'v1', 'created': 'Fri, 13 Nov 2020 09:33:03 GMT'}, {'version': 'v2', 'created': 'Thu, 3 Dec 2020 19:50:31 GMT'}]",2022-02-25,"[['Onim', 'Md. Saif Hassan', ''], ['Ehtesham', 'Aiman Rafeed', ''], ['Anbar', 'Amreen', ''], ['Islam', 'A. K. M. Nazrul', ''], ['Rahman', 'A. K. M. Mahbubur', '']]"
2108.06076,Cheng Zhang,"Cheng Zhang, Haocheng Wan, Xinyi Shen, Zizhao Wu",PVT: Point-Voxel Transformer for Point Cloud Learning,29 pages,,,,cs.CV cs.AI cs.GR,http://creativecommons.org/licenses/by/4.0/,"  The recently developed pure Transformer architectures have attained promising
accuracy on point cloud learning benchmarks compared to convolutional neural
networks. However, existing point cloud Transformers are computationally
expensive since they waste a significant amount of time on structuring the
irregular data. To solve this shortcoming, we present Sparse Window Attention
(SWA) module to gather coarse-grained local features from non-empty voxels,
which not only bypasses the expensive irregular data structuring and invalid
empty voxel computation, but also obtains linear computational complexity with
respect to voxel resolution. Meanwhile, to gather fine-grained features about
the global shape, we introduce relative attention (RA) module, a more robust
self-attention variant for rigid transformations of objects. Equipped with the
SWA and RA, we construct our neural architecture called PVT that integrates
both modules into a joint framework for point cloud learning. Compared with
previous Transformer-based and attention-based models, our method attains top
accuracy of 94.0% on classification benchmark and 10x inference speedup on
average. Extensive experiments also valid the effectiveness of PVT on part and
semantic segmentation benchmarks (86.6% and 69.2% mIoU, respectively).
","[{'version': 'v1', 'created': 'Fri, 13 Aug 2021 06:07:57 GMT'}, {'version': 'v2', 'created': 'Wed, 22 Sep 2021 05:17:40 GMT'}, {'version': 'v3', 'created': 'Mon, 10 Jan 2022 13:59:37 GMT'}]",2022-01-11,"[['Zhang', 'Cheng', ''], ['Wan', 'Haocheng', ''], ['Shen', 'Xinyi', ''], ['Wu', 'Zizhao', '']]"
2103.10186,Dinh Nguyen,"Dinh C. Nguyen, Pubudu N. Pathirana, Ming Ding, Aruna Seneviratne","A Cooperative Architecture of Data Offloading and Sharing for Smart
  Healthcare with Blockchain","Accepted in the IEEE International Conference on Blockchain and
  Cryptocurrency (IEEE ICBC 2021)",,,,cs.CR eess.SP,http://creativecommons.org/licenses/by/4.0/,"  The healthcare industry has witnessed significant transformations in e-health
services where Electronic Health Records (EHRs) are transferred to mobile edge
clouds to facilitate healthcare. Many edge cloud-based system designs have been
proposed, but some technical challenges still remain, such as low quality of
services (QoS), data privacy and system security due to centralized healthcare
architectures. In this paper, we propose a novel hybrid approach of data
offloading and data sharing for healthcare using edge cloud and blockchain.
First, an efficient data offloading scheme is proposed where IoT health data
can be offloaded to nearby edge servers for data processing with privacy
awareness. Then, a data sharing scheme is integrated to enable data exchange
among healthcare users via blockchain. Particularly, a trustworthy access
control mechanism is developed using smart contracts for access authentication
to achieve secure EHRs sharing. Implementation results from extensive
real-world experiments show the superior advantages of the proposal over the
existing schemes in terms of improved QoS, enhanced data privacy and security,
and low smart contract costs.
","[{'version': 'v1', 'created': 'Thu, 18 Mar 2021 11:50:36 GMT'}, {'version': 'v2', 'created': 'Tue, 30 Mar 2021 10:39:21 GMT'}]",2021-03-31,"[['Nguyen', 'Dinh C.', ''], ['Pathirana', 'Pubudu N.', ''], ['Ding', 'Ming', ''], ['Seneviratne', 'Aruna', '']]"
2101.12151,Takashi Odagaki,Takashi Odagaki,Self-organization of oscillation in an epidemic model for COVID-19,"11 pages, 6 figures",,10.1016/j.physa.2021.125925,,q-bio.PE physics.med-ph physics.soc-ph,http://creativecommons.org/licenses/by/4.0/,"  On the basis of a compartment model, the epidemic curve is investigated when
the net rate $\lambda$ of change of the number of infected individuals $I$ is
given by an ellipse in the $\lambda$-$I$ plane which is supported in
$[I_{\ell}, I_h]$. With $a \equiv (I_h - I_{\ell})/(I_h + I_{\ell})$, it is
shown that (1) when $a < 1$ or $I_{\ell} >0$, oscillation of the infection
curve is self-organized and the period of the oscillation is in proportion to
the ratio of the difference $ (I_h - I_{\ell})$ and the geometric mean
$\sqrt{I_h I_{\ell}}$ of $I_h$ and $I_{\ell}$, (2) when $a = 1$, the infection
curve shows a critical behavior where it decays obeying a power law function
with exponent $-2$ in the long time limit after a peak, and (3) when $a > 1$,
the infection curve decays exponentially in the long time limit after a peak.
The present result indicates that the pandemic can be controlled by a measure
which makes $I_{\ell} < 0$.
","[{'version': 'v1', 'created': 'Wed, 27 Jan 2021 02:09:10 GMT'}, {'version': 'v2', 'created': 'Tue, 16 Feb 2021 11:45:55 GMT'}]",2021-04-07,"[['Odagaki', 'Takashi', '']]"
2203.00001,Maxx Richard Rahman,"Maxx Richard Rahman, Jacob Bejder, Thomas Christian Bonne, Andreas
  Breenfeldt Andersen, Jes\'us Rodr\'iguez Huertas, Reid Aikin, Nikolai
  Baastrup Nordsborg and Wolfgang Maa{\ss}",AI-based approach for improving the detection of blood doping in sports,,,,,cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Sports officials around the world are facing incredible challenges due to the
unfair means of practices performed by the athletes to improve their
performance in the game. It includes the intake of hormonal based drugs or
transfusion of blood to increase their strength and the result of their
training. However, the current direct test of detection of these cases includes
the laboratory-based method, which is limited because of the cost factors,
availability of medical experts, etc. This leads us to seek for indirect tests.
With the growing interest of Artificial Intelligence in healthcare, it is
important to propose an algorithm based on blood parameters to improve decision
making. In this paper, we proposed a statistical and machine learning-based
approach to identify the presence of doping substance rhEPO in blood samples.
","[{'version': 'v1', 'created': 'Wed, 9 Feb 2022 16:23:44 GMT'}]",2022-03-02,"[['Rahman', 'Maxx Richard', ''], ['Bejder', 'Jacob', ''], ['Bonne', 'Thomas Christian', ''], ['Andersen', 'Andreas Breenfeldt', ''], ['Huertas', 'Jesús Rodríguez', ''], ['Aikin', 'Reid', ''], ['Nordsborg', 'Nikolai Baastrup', ''], ['Maaß', 'Wolfgang', '']]"
2006.16967,Alireza Ghasemi,Alireza Ghasemi and Amina Chebira,"Lest We Forget: A Dataset of Coronavirus-Related News Headlines in Swiss
  Media",,,,,cs.DL cs.CL,http://creativecommons.org/licenses/by/4.0/,"  We release our COVID-19 news dataset, containing more than 10,000 links to
news articles related to the Coronavirus pandemic published in the Swiss media
since early January 2020. This collection can prove beneficial in mining and
analysis of the reaction of the Swiss media and the COVID-19 pandemic and
extracting insightful information for further research. We hope this dataset
helps researchers and the public deliver results that will help analyse the
pandemic and potentially lead to a better understanding of the events.
","[{'version': 'v1', 'created': 'Thu, 25 Jun 2020 19:43:13 GMT'}]",2020-07-01,"[['Ghasemi', 'Alireza', ''], ['Chebira', 'Amina', '']]"
1809.03562,Estelle Ma\'eva Inack,"E. M. Inack, G. E. Santoro, L. Dell'Anna and S. Pilati","Projective quantum Monte Carlo simulations guided by unrestricted neural
  network states","10 pages, 6 figures","Phys. Rev. B 98, 235145 (2018)",10.1103/PhysRevB.98.235145,,cond-mat.stat-mech physics.comp-ph,http://creativecommons.org/licenses/by/4.0/,"  We investigate the use of variational wave-functions that mimic stochastic
recurrent neural networks, specifically, unrestricted Boltzmann machines, as
guiding functions in projective quantum Monte Carlo (PQMC) simulations of
quantum spin models. As a preliminary step, we investigate the accuracy of such
unrestricted neural network states as variational Ans\""atze for the ground
state of the ferromagnetic quantum Ising chain. We find that by optimizing just
three variational parameters, independently on the system size, accurate
ground-state energies are obtained, comparable to those previously obtained
using restricted Boltzmann machines with few variational parameters per spin.
Chiefly, we show that if one uses optimized unrestricted neural network states
as guiding functions for importance sampling the efficiency of the PQMC
algorithms is greatly enhanced, drastically reducing the most relevant
systematic bias, namely that due to the finite random-walker population. The
scaling of the computational cost with the system size changes from the
exponential scaling characteristic of PQMC simulations performed without
importance sampling, to a polynomial scaling, even at the ferromagnetic quantum
critical point. The important role of the protocol chosen to sample
hidden-spins configurations, in particular at the critical point, is analyzed.
We discuss the implications of these findings for what concerns the problem of
simulating adiabatic quantum optimization using stochastic algorithms on
classical computers.
","[{'version': 'v1', 'created': 'Mon, 10 Sep 2018 19:43:35 GMT'}]",2018-12-27,"[['Inack', 'E. M.', ''], ['Santoro', 'G. E.', ''], [""Dell'Anna"", 'L.', ''], ['Pilati', 'S.', '']]"
2112.13302,Akira Dohi,"Akira Dohi, Helei Liu, Tsuneo Noda, Masa-aki Hashimoto","Cooling of Isolated Neutron Stars with Pion Condensation: Possible Fast
  Cooling in a Low-Symmetry-Energy Model","21 pages, 8 figures, accepted by Int. J. Mod. Phys. E",,,RIKEN-iTHEMS-Report-21,astro-ph.HE hep-ph nucl-th,http://creativecommons.org/licenses/by/4.0/,"  We studied thermal evolution of isolated neutron stars (NSs) including the
pion condensation core, with an emphasis on the stiffness of equation of state
(EOS). Many temperature observations can be explained by the minimal cooling
scenario which excludes the fast neutrino cooling process. However, several NSs
are cold enough to require it. The most crucial problem for NS cooling theory
is whether the nucleon direct Urca (DU) process is open. The DU process is
forbidden if the nucleon symmetry energy is significantly low. Hence, another
fast cooling process is required in such an EOS. As the candidate to solve this
problem, we consider the pion condensation. We show that the
low-symmetry-energy model can account for most cooling observations including
cold NSs, with strong neutron superfluidity. Simultaneously, it holds the
$2~M_{\odot}$ observations even if the pion condensation core exists. Thus, we
propose the possibility of pion condensation, as an exotic state to solve the
problem in low-symmetry-energy EOSs. We examined the consistency of our EOSs
with other various observations as well.
","[{'version': 'v1', 'created': 'Sun, 26 Dec 2021 00:15:21 GMT'}]",2021-12-28,"[['Dohi', 'Akira', ''], ['Liu', 'Helei', ''], ['Noda', 'Tsuneo', ''], ['Hashimoto', 'Masa-aki', '']]"
2105.03354,Dominik Dellermann,"Dominik Dellermann, Adrian Calma, Nikolaus Lipusch, Thorsten Weber,
  Sascha Weigel, and Philipp Ebel","The future of human-AI collaboration: a taxonomy of design knowledge for
  hybrid intelligence systems",,,,,cs.AI cs.HC,http://creativecommons.org/licenses/by/4.0/,"  Recent technological advances, especially in the field of machine learning,
provide astonishing progress on the road towards artificial general
intelligence. However, tasks in current real-world business applications cannot
yet be solved by machines alone. We, therefore, identify the need for
developing socio-technological ensembles of humans and machines. Such systems
possess the ability to accomplish complex goals by combining human and
artificial intelligence to collectively achieve superior results and
continuously improve by learning from each other. Thus, the need for structured
design knowledge for those systems arises. Following a taxonomy development
method, this article provides three main contributions: First, we present a
structured overview of interdisciplinary research on the role of humans in the
machine learning pipeline. Second, we envision hybrid intelligence systems and
conceptualize the relevant dimensions for system design for the first time.
Finally, we offer useful guidance for system developers during the
implementation of such applications.
","[{'version': 'v1', 'created': 'Fri, 7 May 2021 16:10:44 GMT'}]",2021-05-10,"[['Dellermann', 'Dominik', ''], ['Calma', 'Adrian', ''], ['Lipusch', 'Nikolaus', ''], ['Weber', 'Thorsten', ''], ['Weigel', 'Sascha', ''], ['Ebel', 'Philipp', '']]"
2107.10456,Hyukseong Kwon,"Hyukseong Kwon, Amir Rahimi, Kevin G. Lee, Amit Agarwal, Rajan
  Bhattacharyya",CogSense: A Cognitively Inspired Framework for Perception Adaptation,,,,,cs.CV,http://creativecommons.org/licenses/by/4.0/,"  This paper proposes the CogSense system, which is inspired by sense-making
cognition and perception in the mammalian brain to perform perception error
detection and perception parameter adaptation using probabilistic signal
temporal logic. As a specific application, a contrast-based perception adaption
method is presented and validated. The proposed method evaluates perception
errors using heterogeneous probe functions computed from the detected objects
and subsequently solves a contrast optimization problem to correct perception
errors. The CogSense probe functions utilize the characteristics of geometry,
dynamics, and detected blob image quality of the objects to develop axioms in a
probabilistic signal temporal logic framework. By evaluating these axioms, we
can formally verify whether the detections are valid or erroneous. Further,
using the CogSense axioms, we generate the probabilistic signal temporal
logic-based constraints to finally solve the contrast-based optimization
problem to reduce false positives and false negatives.
","[{'version': 'v1', 'created': 'Thu, 22 Jul 2021 05:01:05 GMT'}]",2021-07-23,"[['Kwon', 'Hyukseong', ''], ['Rahimi', 'Amir', ''], ['Lee', 'Kevin G.', ''], ['Agarwal', 'Amit', ''], ['Bhattacharyya', 'Rajan', '']]"
2105.06299,Kohei Ishizaki,"K. Ishizaki, H. Hotta, I. Ide, M. Iinuma, T. Iwata, M. Kitaguchi, H.
  Kohri, D. Miura, Y. Miyachi, T. Ohta, H. M. Shimizu, H. Yoshikawa, M. Yosoi","Measurement of nuclear spin relaxation time in lanthanum aluminate for
  development of polarized lanthanum target","10 pages, 8 figures",,10.1016/j.nima.2021.165845,,physics.ins-det nucl-ex,http://creativecommons.org/licenses/by/4.0/,"  The nuclear spin-lattice relaxation time ($T_1$) of lanthanum and aluminum
nuclei in a single crystal of lanthanum aluminate doped with neodymium ions is
studied to estimate the feasibility of the dynamically polarized lanthanum
target applicable to beam experiments. The application of our interest is the
study of fundamental discrete symmetries in the spin optics of epithermal
neutrons. This study requires a highly flexible choice of the applied magnetic
field for neutron spin control and favors longer $T_1$ under lower magnetic
field and at higher temperature. The $T_1$ of $^{139}{\rm La}$ and ${}^{27}{\rm
Al}$ was measured under magnetic fields of $0.5$-$2.5$ T and at temperatures of
$0.1$-$1.5$ K and found widely distributed up to 100 h. The result suggests
that the $T_1$ can be as long as $T_1 \sim$ 1 h at $0.1$ K with a magnetic
field of $0.1$ T, which partially fulfills the requirement of the neutron beam
experiment. Possible improvements to achieve a longer $T_1$ are discussed.
","[{'version': 'v1', 'created': 'Tue, 11 May 2021 04:21:26 GMT'}, {'version': 'v2', 'created': 'Thu, 16 Sep 2021 15:14:58 GMT'}]",2021-10-27,"[['Ishizaki', 'K.', ''], ['Hotta', 'H.', ''], ['Ide', 'I.', ''], ['Iinuma', 'M.', ''], ['Iwata', 'T.', ''], ['Kitaguchi', 'M.', ''], ['Kohri', 'H.', ''], ['Miura', 'D.', ''], ['Miyachi', 'Y.', ''], ['Ohta', 'T.', ''], ['Shimizu', 'H. M.', ''], ['Yoshikawa', 'H.', ''], ['Yosoi', 'M.', '']]"
2012.02117,Dimitrios Psaltis,"Dimitrios Psaltis, Colm Talbot, Ethan Payne, Ilya Mandel","Probing the Black Hole Metric. I. Black Hole Shadows and Binary
  Black-Hole Inspirals","Physical Review D, submitted","Phys. Rev. D 103, 104036 (2021)",10.1103/PhysRevD.103.104036,,gr-qc astro-ph.HE,http://creativecommons.org/licenses/by/4.0/,"  In General Relativity, the spacetimes of black holes have three fundamental
properties: (i) they are the same, to lowest order in spin, as the metrics of
stellar objects; (ii) they are independent of mass, when expressed in geometric
units; and (iii) they are described by the Kerr metric. In this paper, we
quantify the upper bounds on potential black-hole metric deviations imposed by
observations of black-hole shadows and of binary black-hole inspirals in order
to explore the current experimental limits on possible violations of the last
two predictions. We find that both types of experiments provide correlated
constraints on deviation parameters that are primarily in the tt-components of
the spacetimes, when expressed in areal coordinates. We conclude that,
currently, there is no evidence for a deviations from the Kerr metric across
the 8 orders of magnitudes in masses and 16 orders in curvatures spanned by the
two types of black holes. Moreover, because of the particular masses of black
holes in the current sample of gravitational-wave sources, the correlations
imposed by the two experiments are aligned and of similar magnitudes when
expressed in terms of the far field, post-Newtonian predictions of the metrics.
If a future coalescing black-hole binary with two low-mass (e.g., ~3 Msun)
components is discovered, the degeneracy between the deviation parameters can
be broken by combining the inspiral constraints with those from the black-hole
shadow measurements.
","[{'version': 'v1', 'created': 'Thu, 3 Dec 2020 17:51:05 GMT'}]",2021-05-26,"[['Psaltis', 'Dimitrios', ''], ['Talbot', 'Colm', ''], ['Payne', 'Ethan', ''], ['Mandel', 'Ilya', '']]"
2101.10345,Nickolas Pingel,"N. M. Pingel, D. J. Pisano, M. Ruzindana, M. Burnett, K. M. Rajwade,
  R. Black, B. Jeffs, D. R. Lorimer, D. Anish Roshi, R. Prestage, M. A.
  McLaughlin, D. Agarwal, T. Chamberlin, L. Hawkins, L. Jensen, P. Marganian,
  J. D. Nelson, W. Shillue, E. Smith, B. Simon, V. Van Tonder and S. White","Commissioning the HI Observing Mode of the Beamformer for the
  Cryogenically Cooled Focal L-band Array for the GBT (FLAG)","28 ages, 18 figures. Accepted for publication in the Astronomical
  Journal",,10.3847/1538-3881/abdec2,,astro-ph.IM,http://creativecommons.org/licenses/by/4.0/,"  We present the results of commissioning observations for a new digital
beamforming back end for the Focal plane L-band Array for the Robert C. Byrd
Green Bank Telescope (FLAG), a cryogenically cooled Phased Array Feed (PAF)
with the lowest measured T_sys/eta of any PAF outfitted on a radio telescope to
date. We describe the custom software used to apply beamforming weights to the
raw element covariances to create research quality spectral line images for the
new fine-channel mode, study the stability of the beam weights over time,
characterize FLAG's sensitivity over a frequency range of 150 MHz, and compare
the measured noise properties and observed distribution of neutral hydrogen
emission from several extragalactic and Galactic sources with data obtained
with the current single-pixel L-band receiver. These commissioning runs
establish FLAG as the preeminent PAF receiver currently available for spectral
line observations on the world's major radio telescopes.
","[{'version': 'v1', 'created': 'Mon, 25 Jan 2021 19:00:09 GMT'}]",2021-03-10,"[['Pingel', 'N. M.', ''], ['Pisano', 'D. J.', ''], ['Ruzindana', 'M.', ''], ['Burnett', 'M.', ''], ['Rajwade', 'K. M.', ''], ['Black', 'R.', ''], ['Jeffs', 'B.', ''], ['Lorimer', 'D. R.', ''], ['Roshi', 'D. Anish', ''], ['Prestage', 'R.', ''], ['McLaughlin', 'M. A.', ''], ['Agarwal', 'D.', ''], ['Chamberlin', 'T.', ''], ['Hawkins', 'L.', ''], ['Jensen', 'L.', ''], ['Marganian', 'P.', ''], ['Nelson', 'J. D.', ''], ['Shillue', 'W.', ''], ['Smith', 'E.', ''], ['Simon', 'B.', ''], ['Van Tonder', 'V.', ''], ['White', 'S.', '']]"
2202.09561,Markus Gaug,"Christian Fruck, Markus Gaug, Alexander Hahn, Victor Acciari, J\""urgen
  Besenrieder, Dijana Dominis Prester, Daniela Dorner, David Fink, Llu\'is
  Font, Sa\v{s}a Mi\'canovi\'c, Razmik Mirzoyan, Dominik M\""uller, Lovro
  Pavleti\'c, Felix Schmuckermaier, Martin Will","Characterizing the aerosol atmosphere above the Observatorio del Roque
  de los Muchachos by analyzing seven years of data taken with an GaAsP
  HPD-readout, absolutely calibrated elastic LIDAR","40 pages, submitted to MNRAS",,,,astro-ph.IM,http://creativecommons.org/licenses/by/4.0/,"  We present a new elastic LIDAR concept, based on a bi-axially mounted Nd:YAG
laser and a telescope with HPD readout, combined with fast FADC signal
digitization and offline pulse analysis. The LIDAR return signals have been
extensively quality checked and absolutely calibrated. We analyze seven years
of quasi-continuous LIDAR data taken during those nights when the MAGIC
telescopes were operating. Characterization of the nocturnal ground layer
yields zenith and azimuth angle dependent aerosol extinction scale heights for
clear nights. We derive aerosol transmission statistics for light emitted from
various altitudes throughout the year and separated by seasons. We find further
seasonal dependencies of cloud base and top altitudes, but none for the LIDAR
ratios of clouds. Finally, the night sky background light is characterized
using the LIDAR photon backgrounds. abstract.txt
","[{'version': 'v1', 'created': 'Sat, 19 Feb 2022 09:51:43 GMT'}]",2022-02-22,"[['Fruck', 'Christian', ''], ['Gaug', 'Markus', ''], ['Hahn', 'Alexander', ''], ['Acciari', 'Victor', ''], ['Besenrieder', 'Jürgen', ''], ['Prester', 'Dijana Dominis', ''], ['Dorner', 'Daniela', ''], ['Fink', 'David', ''], ['Font', 'Lluís', ''], ['Mićanović', 'Saša', ''], ['Mirzoyan', 'Razmik', ''], ['Müller', 'Dominik', ''], ['Pavletić', 'Lovro', ''], ['Schmuckermaier', 'Felix', ''], ['Will', 'Martin', '']]"
2106.01529,Alden Green,"Alden Green, Sivaraman Balakrishnan, Ryan J. Tibshirani","Minimax Optimal Regression over Sobolev Spaces via Laplacian
  Regularization on Neighborhood Graphs",,,,,math.ST stat.ML stat.TH,http://creativecommons.org/licenses/by/4.0/,"  In this paper we study the statistical properties of Laplacian smoothing, a
graph-based approach to nonparametric regression. Under standard regularity
conditions, we establish upper bounds on the error of the Laplacian smoothing
estimator $\widehat{f}$, and a goodness-of-fit test also based on
$\widehat{f}$. These upper bounds match the minimax optimal estimation and
testing rates of convergence over the first-order Sobolev class
$H^1(\mathcal{X})$, for $\mathcal{X}\subseteq \mathbb{R}^d$ and $1 \leq d < 4$;
in the estimation problem, for $d = 4$, they are optimal modulo a $\log n$
factor. Additionally, we prove that Laplacian smoothing is manifold-adaptive:
if $\mathcal{X} \subseteq \mathbb{R}^d$ is an $m$-dimensional manifold with $m
< d$, then the error rate of Laplacian smoothing (in either estimation or
testing) depends only on $m$, in the same way it would if $\mathcal{X}$ were a
full-dimensional set in $\mathbb{R}^d$.
","[{'version': 'v1', 'created': 'Thu, 3 Jun 2021 01:20:41 GMT'}]",2021-06-04,"[['Green', 'Alden', ''], ['Balakrishnan', 'Sivaraman', ''], ['Tibshirani', 'Ryan J.', '']]"
2011.11320,Cyril Pitrou,"Cyril Pitrou, Alain Coc, Jean-Philippe Uzan, Elisabeth Vangioni",A new tension in the cosmological model from primordial deuterium?,"10 pages, 4 figures. Accepted in MNRAS",,10.1093/mnras/stab135,,astro-ph.CO nucl-th,http://creativecommons.org/licenses/by/4.0/,"  Recent measurements of the D(p,$\gamma)^3$He, nuclear reaction cross-section
and of the neutron lifetime, along with the reevaluation of the cosmological
baryon abundance from cosmic microwave background (CMB) analysis, call for an
update of abundance predictions for light elements produced during the big-bang
nucleosynthesis (BBN). While considered as a pillar of the hot big-bang model
in its early days, BBN constraining power mostly rests on deuterium abundance.
We point out a new $\simeq1.8\sigma$-tension on the baryonic density, or
equivalently on the D/H abundance, between the value inferred on one hand from
the analysis of the primordial abundances of light elements and, on the other
hand, from the combination of CMB and baryonic oscillation data. This draws the
attention on this sector of the theory and gives us the opportunity to
reevaluate the status of BBN in the context of precision cosmology. Finally,
this paper presents an upgrade of the BBN code PRIMAT.
","[{'version': 'v1', 'created': 'Mon, 23 Nov 2020 10:48:02 GMT'}, {'version': 'v2', 'created': 'Fri, 4 Dec 2020 13:21:36 GMT'}, {'version': 'v3', 'created': 'Mon, 25 Jan 2021 10:05:47 GMT'}]",2021-02-17,"[['Pitrou', 'Cyril', ''], ['Coc', 'Alain', ''], ['Uzan', 'Jean-Philippe', ''], ['Vangioni', 'Elisabeth', '']]"
2201.07924,Luisa Rebull,"Elena Scire, Luisa Rebull, Seppo Laine",Spitzer Publication Statistics,Accepted by PASP,,,,astro-ph.IM,http://creativecommons.org/licenses/by/4.0/,"  We present statistics on the number of refereed astronomy journal articles
that used data from NASA's Spitzer Space Telescope through the end of the
calendar year 2020. We discuss the various types of science programs and
science categories that were used to collect data during the mission and
discuss how operational changes brought on by the depletion of cryogen in May
2009, including the resulting budget cuts, impacted the publication rate. The
post-cryogenic (warm) mission produced fewer papers than the cryogenic mission,
but the percentage of the exposure time published did not appreciably change
between the warm and cryogenic missions. This was mostly because in the warm
mission the length of observations increased, so that each warm paper on
average uses more data than the cryogenic papers. We also discuss the speed of
publication, archival usage, and the tremendous efficacy of the Legacy and
Exploration Science programs (large, coherent investigations), including the
value of having well-advertised enhanced data products hosted in centralized
archives. We also identify the observations that have been published the
largest number of times, and sort them by a variety of metrics (including
program type, instrument used, and observation length). Data that have the
highest reuse rates in publications were taken early in the Spitzer mission, or
belong to one of the large surveys (large either in number of objects, in
number of hours observed, or in area covered on the sky). We also assess how
often authors have cited the Spitzer fundamental papers or have correctly
referenced the Spitzer data they used, finding that as many as 40% of papers
have failed to cite the papers, and 15% have made it impossible to identify the
data they used.
","[{'version': 'v1', 'created': 'Thu, 20 Jan 2022 00:13:45 GMT'}]",2022-01-21,"[['Scire', 'Elena', ''], ['Rebull', 'Luisa', ''], ['Laine', 'Seppo', '']]"
2105.14188,Liyi Guo,"Liyi Guo, Junqi Jin, Haoqi Zhang, Zhenzhe Zheng, Zhiye Yang, Zhizhuang
  Xing, Fei Pan, Lvyin Niu, Fan Wu, Haiyang Xu, Chuan Yu, Yuning Jiang,
  Xiaoqiang Zhu","We Know What You Want: An Advertising Strategy Recommender System for
  Online Advertising",,"Proceedings of the 27th ACM SIGKDD Conference on Knowledge
  Discovery and Data Mining (KDD '21), August 14--18, 2021, Virtual Event,
  Singapore",10.1145/3447548.3467175,,cs.IR cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Advertising expenditures have become the major source of revenue for
e-commerce platforms. Providing good advertising experiences for advertisers by
reducing their costs of trial and error in discovering the optimal advertising
strategies is crucial for the long-term prosperity of online advertising. To
achieve this goal, the advertising platform needs to identify the advertiser's
optimization objectives, and then recommend the corresponding strategies to
fulfill the objectives. In this work, we first deploy a prototype of strategy
recommender system on Taobao display advertising platform, which indeed
increases the advertisers' performance and the platform's revenue, indicating
the effectiveness of strategy recommendation for online advertising. We further
augment this prototype system by explicitly learning the advertisers'
preferences over various advertising performance indicators and then
optimization objectives through their adoptions of different recommending
advertising strategies. We use contextual bandit algorithms to efficiently
learn the advertisers' preferences and maximize the recommendation adoption,
simultaneously. Simulation experiments based on Taobao online bidding data show
that the designed algorithms can effectively optimize the strategy adoption
rate of advertisers.
","[{'version': 'v1', 'created': 'Tue, 25 May 2021 17:06:59 GMT'}, {'version': 'v2', 'created': 'Tue, 8 Jun 2021 12:28:10 GMT'}, {'version': 'v3', 'created': 'Sun, 13 Jun 2021 07:34:43 GMT'}]",2021-06-15,"[['Guo', 'Liyi', ''], ['Jin', 'Junqi', ''], ['Zhang', 'Haoqi', ''], ['Zheng', 'Zhenzhe', ''], ['Yang', 'Zhiye', ''], ['Xing', 'Zhizhuang', ''], ['Pan', 'Fei', ''], ['Niu', 'Lvyin', ''], ['Wu', 'Fan', ''], ['Xu', 'Haiyang', ''], ['Yu', 'Chuan', ''], ['Jiang', 'Yuning', ''], ['Zhu', 'Xiaoqiang', '']]"
2112.10805,Yun-Hsin Hsu,"Yun-Hsin Hsu, Yen-Ting Lin, Song Huang, Dylan Nelson, Vicente
  Rodriguez-Gomez, Hsuan-Ting Lai, Jenny Greene, Alexie Leauthaud, Alfonso
  Arag\'on-Salamanca, Kevin Bundy, Eric Emsellem, Michael Merrifield, Surhud
  More, Nobuhiro Okabe, Yu Rong, Joel R. Brownstein, Richard R. Lane, Kaike
  Pan, Donald P. Schneider","SDSS-IV MaNGA: Cannibalism Caught in the Act -- on the Frequency of
  Occurrence of Multiple Cores in Brightest Cluster Galaxies","33 pages, 27 figures, 5 tables; Submitted to ApJ",,,,astro-ph.GA,http://creativecommons.org/licenses/by/4.0/,"  Although it is generally accepted that massive galaxies form in a two-phased
fashion, beginning with a rapid mass buildup through intense starburst
activities, followed by primarily dry mergers that mainly deposit stellar mass
at outskirts, the late time stellar mass growth of brightest cluster galaxies
(BCGs), the most massive galaxies in the universe, is still not well
understood. Several independent measurements have indicated a slower mass
growth rate than predictions from theoretical models. We attempt to resolve the
discrepancy by measuring the frequency of BCGs with multiple-cores, which serve
as a proxy of the merger rates in the central region and facilitate a more
direct comparison with theoretical predictions. Using 79 BCGs at $z=0.06-0.15$
with integral field spectroscopic (IFS) data from the Mapping Nearby Galaxies
at APO (MaNGA) project, we obtain a multiple-core fraction of $0.11 \pm 0.04$
at $z\approx 0.1$ within a 18 kpc radius from the center, which is comparable
to the value of $0.08 \pm 0.04$ derived from mock observations of 218 simulated
BCGs from the cosmological hydrodynamical simulation IllustrisTNG. We find that
most of cores that appear close to the BCGs from imaging data turn out to be
physically associated systems. Anchoring on the similarity in the multiple-core
frequency between the MaNGA and IllustrisTNG, we discuss the mass growth rate
of BCGs over the past 4.5 Gyr.
","[{'version': 'v1', 'created': 'Mon, 20 Dec 2021 19:07:33 GMT'}]",2021-12-22,"[['Hsu', 'Yun-Hsin', ''], ['Lin', 'Yen-Ting', ''], ['Huang', 'Song', ''], ['Nelson', 'Dylan', ''], ['Rodriguez-Gomez', 'Vicente', ''], ['Lai', 'Hsuan-Ting', ''], ['Greene', 'Jenny', ''], ['Leauthaud', 'Alexie', ''], ['Aragón-Salamanca', 'Alfonso', ''], ['Bundy', 'Kevin', ''], ['Emsellem', 'Eric', ''], ['Merrifield', 'Michael', ''], ['More', 'Surhud', ''], ['Okabe', 'Nobuhiro', ''], ['Rong', 'Yu', ''], ['Brownstein', 'Joel R.', ''], ['Lane', 'Richard R.', ''], ['Pan', 'Kaike', ''], ['Schneider', 'Donald P.', '']]"
2104.08540,Dominik Schlechtweg,"Dominik Schlechtweg, Nina Tahmasebi, Simon Hengchen, Haim Dubossarsky,
  Barbara McGillivray",DWUG: A large Resource of Diachronic Word Usage Graphs in Four Languages,"EMNLP, 9 pages",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Word meaning is notoriously difficult to capture, both synchronically and
diachronically. In this paper, we describe the creation of the largest resource
of graded contextualized, diachronic word meaning annotation in four different
languages, based on 100,000 human semantic proximity judgments. We thoroughly
describe the multi-round incremental annotation process, the choice for a
clustering algorithm to group usages into senses, and possible - diachronic and
synchronic - uses for this dataset.
","[{'version': 'v1', 'created': 'Sat, 17 Apr 2021 13:34:45 GMT'}, {'version': 'v2', 'created': 'Thu, 14 Oct 2021 20:47:13 GMT'}]",2021-10-18,"[['Schlechtweg', 'Dominik', ''], ['Tahmasebi', 'Nina', ''], ['Hengchen', 'Simon', ''], ['Dubossarsky', 'Haim', ''], ['McGillivray', 'Barbara', '']]"
2108.07868,Elias Aydi Dr.,"E. Aydi, K. V. Sokolovsky, J. S. Bright, E. Tremou, M. M. Nyamai, A.
  Evans, J. Strader, L. Chomiuk, G. Myers, F-J. Hambsch, K. L. Page, D. A. H.
  Buckley, C. E. Woodward, F. M. Walter, P. Mr\'oz, P. J. Vallely, T. R.
  Geballe, D. P. K. Banerjee, R. D. Gehrz, R. P. Fender, M. Gromadzki, A.
  Kawash, C. Knigge, K. Mukai, U. Munari, M. Orio, V. A. R. M. Ribeiro, J. L.
  Sokoloski, S. Starrfield, A. Udalski, and P. A. Woudt","The 2019 outburst of the 2005 classical nova V1047 Cen: a record
  breaking dwarf nova outburst or a new phenomenon?","36 pages, 27 figures, 8 tables. Submitted to ApJ",,,,astro-ph.SR astro-ph.HE,http://creativecommons.org/licenses/by/4.0/,"  We present a detailed study of the 2019 outburst of the cataclysmic variable
V1047 Cen, which hosted a classical nova eruption in 2005. The peculiar
outburst occurred 14 years after the classical nova event, lasted for more than
400 days, and reached an amplitude of around 6 magnitudes in the optical. Early
spectral follow-up revealed what could be a dwarf nova (accretion disk
instability) outburst in a classical nova system. However, the outburst
duration, high velocity ($>$2000 km s$^{-1}$) features in the optical line
profiles, luminous optical emission, and the presence of prominent long-lasting
radio emission, together suggest a phenomenon more exotic and energetic than a
dwarf nova outburst. There are striking similarities between this V1047 Cen
outburst and those of ""combination novae"" in classical symbiotic stars. We
suggest that the outburst may have started as a dwarf nova that led to the
accretion of a massive disk, which in turn triggered enhanced nuclear shell
burning on the white dwarf and eventually led to generation of a wind/outflow.
From optical photometry we find a \bf{possible} orbital period of 8.36 days,
which supports the combination nova scenario and makes the system an
intermediate case between typical cataclysmic variables and classical symbiotic
binaries. If true, such a phenomenon would be the first of its kind to occur in
a system that has undergone a classical nova eruption and is intermediate
between cataclysmic variables and symbiotic binaries.
","[{'version': 'v1', 'created': 'Tue, 17 Aug 2021 20:36:12 GMT'}]",2021-08-19,"[['Aydi', 'E.', ''], ['Sokolovsky', 'K. V.', ''], ['Bright', 'J. S.', ''], ['Tremou', 'E.', ''], ['Nyamai', 'M. M.', ''], ['Evans', 'A.', ''], ['Strader', 'J.', ''], ['Chomiuk', 'L.', ''], ['Myers', 'G.', ''], ['Hambsch', 'F-J.', ''], ['Page', 'K. L.', ''], ['Buckley', 'D. A. H.', ''], ['Woodward', 'C. E.', ''], ['Walter', 'F. M.', ''], ['Mróz', 'P.', ''], ['Vallely', 'P. J.', ''], ['Geballe', 'T. R.', ''], ['Banerjee', 'D. P. K.', ''], ['Gehrz', 'R. D.', ''], ['Fender', 'R. P.', ''], ['Gromadzki', 'M.', ''], ['Kawash', 'A.', ''], ['Knigge', 'C.', ''], ['Mukai', 'K.', ''], ['Munari', 'U.', ''], ['Orio', 'M.', ''], ['Ribeiro', 'V. A. R. M.', ''], ['Sokoloski', 'J. L.', ''], ['Starrfield', 'S.', ''], ['Udalski', 'A.', ''], ['Woudt', 'P. A.', '']]"
2109.12621,Eduardo Ramos,"Eduardo Ramos-P\'erez, Pablo J. Alonso-Gonz\'alez, Jos\'e Javier
  N\'u\~nez-Vel\'azquez","Multi-Transformer: A New Neural Network-Based Architecture for
  Forecasting S&P Volatility",,"Mathematics 2021, 9, 1794",10.3390/math9151794,,q-fin.CP cs.LG stat.CO,http://creativecommons.org/licenses/by/4.0/,"  Events such as the Financial Crisis of 2007-2008 or the COVID-19 pandemic
caused significant losses to banks and insurance entities. They also
demonstrated the importance of using accurate equity risk models and having a
risk management function able to implement effective hedging strategies. Stock
volatility forecasts play a key role in the estimation of equity risk and,
thus, in the management actions carried out by financial institutions.
Therefore, this paper has the aim of proposing more accurate stock volatility
models based on novel machine and deep learning techniques. This paper
introduces a neural network-based architecture, called Multi-Transformer.
Multi-Transformer is a variant of Transformer models, which have already been
successfully applied in the field of natural language processing. Indeed, this
paper also adapts traditional Transformer layers in order to be used in
volatility forecasting models. The empirical results obtained in this paper
suggest that the hybrid models based on Multi-Transformer and Transformer
layers are more accurate and, hence, they lead to more appropriate risk
measures than other autoregressive algorithms or hybrid models based on feed
forward layers or long short term memory cells.
","[{'version': 'v1', 'created': 'Sun, 26 Sep 2021 14:47:04 GMT'}]",2021-09-28,"[['Ramos-Pérez', 'Eduardo', ''], ['Alonso-González', 'Pablo J.', ''], ['Núñez-Velázquez', 'José Javier', '']]"
2006.08363,Genevieve Gorrell,"Genevieve Gorrell, Tracie Farrell and Kalina Bontcheva",MP Twitter Abuse in the Age of COVID-19: White Paper,,,,,cs.CY cs.SI,http://creativecommons.org/licenses/by/4.0/,"  As COVID-19 sweeps the globe, outcomes depend on effective relationships
between the public and decision-makers. In the UK there were uncivil tweets to
MPs about perceived UK tardiness to go into lockdown. The pandemic has led to
increased attention on ministers with a role in the crisis. However, generally
this surge has been civil. Prime minister Boris Johnson's severe illness with
COVID-19 resulted in an unusual peak of supportive responses on Twitter. Those
who receive more COVID-19 mentions in their replies tend to receive less abuse
(significant negative correlation). Following Mr Johnson's recovery, with
rising economic concerns and anger about lockdown violations by influential
figures, abuse levels began to rise in May. 1,902 replies to MPs within the
study period were found containing hashtags or terms that refute the existence
of the virus (e.g. #coronahoax, #coronabollocks, 0.04% of a total 4.7 million
replies, or 9% of the number of mentions of ""stay home save lives"" and
variants). These have tended to be more abusive. Evidence of some members of
the public believing in COVID-19 conspiracy theories was also found. Higher
abuse levels were associated with hashtags blaming China for the pandemic.
","[{'version': 'v1', 'created': 'Wed, 10 Jun 2020 16:21:42 GMT'}]",2020-06-16,"[['Gorrell', 'Genevieve', ''], ['Farrell', 'Tracie', ''], ['Bontcheva', 'Kalina', '']]"
1902.01851,Vibhav Bharadwaj,"L. Kotsedi, V. Furlan, V. Bharadwaj, K. Kaviyarasu, B. Sotillo, C.B.
  Mtshali, N. Matinise, A. G. Demir, B. Previtali, R. Ramponi, S.M. Eaton, M.
  Maaza","Chromium Oxide Formation on Nanosecond and Femtosecond Laser Irradiated
  Thin Chromium Films",,,,,physics.app-ph,http://creativecommons.org/licenses/by/4.0/,"  Thin coatings of Chromium oxide have been used for applications as absorbing
material in solar cells, as protections for magnetic data recording devices and
as shields in flexible solar cells. Thin coatings of pure chromium were vacuum
deposited on a glass substrate using hot electrons from tungsten filament.
These coatings were then treated with a nanosecond and femtosecond laser in
ambient conditions. The microstructure, morphology and the color of the
coatings treated with laser sources were modified and there was a formation of
an oxide layer due to the heat dissipation on the chromium coating from the
energetic photons. High-resolution scanning electron microscope studies showed
the morphological evolution that are directly correlated with the laser fluence
of both the nanosecond and femtosecond lasers. This morphological evolution was
accompanied by the microstructural change as observed from the x-ray
diffraction patterns, the chromaticity response of the coating was studied by
UV-Vis spectrometer and the response of the coating in the visible region
evolved with the laser fluences. The Rutherford backscattering depth profiling
of the laser treated coatings revealed the diffusion of oxygen atoms in the
coating as a result of laser treatment fluence.
","[{'version': 'v1', 'created': 'Tue, 5 Feb 2019 18:55:45 GMT'}, {'version': 'v2', 'created': 'Wed, 6 Feb 2019 10:59:26 GMT'}, {'version': 'v3', 'created': 'Tue, 2 Apr 2019 09:49:29 GMT'}, {'version': 'v4', 'created': 'Mon, 17 Jun 2019 13:45:56 GMT'}]",2019-06-18,"[['Kotsedi', 'L.', ''], ['Furlan', 'V.', ''], ['Bharadwaj', 'V.', ''], ['Kaviyarasu', 'K.', ''], ['Sotillo', 'B.', ''], ['Mtshali', 'C. B.', ''], ['Matinise', 'N.', ''], ['Demir', 'A. G.', ''], ['Previtali', 'B.', ''], ['Ramponi', 'R.', ''], ['Eaton', 'S. M.', ''], ['Maaza', 'M.', '']]"
2104.08402,Emil Alfred Edgar Mendoza,"Fabian Dunker, Emil Mendoza, Marco Reale","Regularized Maximum Likelihood Estimation for the Random Coefficients
  Model","23 Pages, 13 figures",,,,stat.ME stat.AP,http://creativecommons.org/licenses/by/4.0/,"  The random coefficients model $Y_i={\beta_0}_i+{\beta_1}_i
{X_1}_i+{\beta_2}_i {X_2}_i+\ldots+{\beta_d}_i {X_d}_i$, with $\mathbf{X}_i$,
$Y_i$, $\mathbf{\beta}_i$ i.i.d, and $\mathbf{\beta}_i$ independent of $X_i$ is
often used to capture unobserved heterogeneity in a population. We propose a
quasi-maximum likelihood method to estimate the joint density distribution of
the random coefficient model. This method implicitly involves the inversion of
the Radon transformation in order to reconstruct the joint distribution, and
hence is an inverse problem. Nonparametric estimation for the joint density of
$\mathbf{\beta}_i=({\beta_0}_i,\ldots, {\beta_d}_i)$ based on kernel methods or
Fourier inversion have been proposed in recent years. Most of these methods
assume a heavy tailed design density $f_\mathbf{X}$. To add stability to the
solution, we apply regularization methods. We analyze the convergence of the
method without assuming heavy tails for $f_\mathbf{X}$ and illustrate
performance by applying the method on simulated and real data. To add stability
to the solution, we apply a Tikhonov-type regularization method.
","[{'version': 'v1', 'created': 'Fri, 16 Apr 2021 23:09:55 GMT'}, {'version': 'v2', 'created': 'Sun, 15 Aug 2021 00:47:33 GMT'}]",2021-08-17,"[['Dunker', 'Fabian', ''], ['Mendoza', 'Emil', ''], ['Reale', 'Marco', '']]"
2105.08445,Kyra Ahrens,"Kyra Ahrens, Fares Abawi, Stefan Wermter",DRILL: Dynamic Representations for Imbalanced Lifelong Learning,,"Proceedings of the 30th International Conference on Artificial
  Neural Networks (ICANN 2021)",10.1007/978-3-030-86340-1_33,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Continual or lifelong learning has been a long-standing challenge in machine
learning to date, especially in natural language processing (NLP). Although
state-of-the-art language models such as BERT have ushered in a new era in this
field due to their outstanding performance in multitask learning scenarios,
they suffer from forgetting when being exposed to a continuous stream of data
with shifting data distributions. In this paper, we introduce DRILL, a novel
continual learning architecture for open-domain text classification. DRILL
leverages a biologically inspired self-organizing neural architecture to
selectively gate latent language representations from BERT in a
task-incremental manner. We demonstrate in our experiments that DRILL
outperforms current methods in a realistic scenario of imbalanced,
non-stationary data without prior knowledge about task boundaries. To the best
of our knowledge, DRILL is the first of its kind to use a self-organizing
neural architecture for open-domain lifelong learning in NLP.
","[{'version': 'v1', 'created': 'Tue, 18 May 2021 11:36:37 GMT'}, {'version': 'v2', 'created': 'Mon, 20 Sep 2021 07:53:38 GMT'}]",2021-09-21,"[['Ahrens', 'Kyra', ''], ['Abawi', 'Fares', ''], ['Wermter', 'Stefan', '']]"
2203.03119,Ryosuke Abe,"Ryosuke Abe, Shigeya Suzuki, Kenji Saito, Hiroya Tanaka, Osamu
  Nakamura, Jun Murai",Fabchain: Managing Audit-able 3D Print Job over Blockchain,,,,,cs.DC cs.CR cs.CY,http://creativecommons.org/licenses/by/4.0/,"  Improvements in fabrication devices such as 3D printers are becoming possible
for personal fabrication to freely fabricate any products. To clarify who is
liable for the product, the fabricator should keep the fabrication history in
an immutable and sustainably accessible manner. In this paper, we propose a new
scheme, ""Fabchain,"" that can record the fabrication history in such a manner.
By utilizing a scheme that employs a blockchain as an audit-able communication
channel, Fabchain manages print jobs for the fabricator's 3D printer over the
blockchain, while maintaining a history of a print job. We implemented Fabchain
on Ethereum and evaluated the performance for recording a print job. Our
results demonstrate that Fabchain can complete communication of a print job
sequence in less than 1 minute on the Ethereum test network. We conclude that
Fabchain can manage a print job in a reasonable duration for 3D printing, while
satisfying the requirements for immutability and sustainability.
","[{'version': 'v1', 'created': 'Mon, 7 Mar 2022 03:41:17 GMT'}]",2022-03-08,"[['Abe', 'Ryosuke', ''], ['Suzuki', 'Shigeya', ''], ['Saito', 'Kenji', ''], ['Tanaka', 'Hiroya', ''], ['Nakamura', 'Osamu', ''], ['Murai', 'Jun', '']]"
2012.10865,"Asim \""Onder","Asim \""Onder, Philip L.-F. Liu, Wu-ting Tsai",Generation and Breakdown of Surface Streaks in Wind-Driven Aqueous Flow,,,,,physics.flu-dyn,http://creativecommons.org/licenses/by/4.0/,"  A bypass transition scenario in a wind-stress driven aqueous flow is analysed
using a temporally developing boundary layer model with accelerating surface
drift velocity. The parameters of the model are selected to mimic a wave-tank
experiment with a reference wind speed of 5 m/s. To study the boundary layer
processes in isolation, a flat free surface is adapted, which inhibits the
initiation of waves. First, preferred initial perturbations to which the
boundary layer is the most sensitive are identified using linear non-normal
growth theory. These perturbations are arranged as streamwise-constant vortex
pairs located adjacent to the free surface. Subsequently, direct numerical
simulations are initialized with these optimal perturbations and streamwise
streaks are generated. High-speed streaks penetrate into deeper water layers
and undergo sinuous instabilities reminiscent of the instabilities developing
on low-speed streaks in wall-bounded flows. Streak instabilities induce lateral
undulations at the free surface, which closely resemble the dye patterns before
the onset of waves in wind-wave-tank experiments. The present analysis provides
a theoretical background for these experimental observations.
","[{'version': 'v1', 'created': 'Sun, 20 Dec 2020 08:35:51 GMT'}]",2020-12-22,"[['Önder', 'Asim', ''], ['Liu', 'Philip L. -F.', ''], ['Tsai', 'Wu-ting', '']]"
2105.12307,Venkata Vaishnav Tadiparthi,Vaishnav Tadiparthi and Raktim Bhattacharya,Optimal Transport Based Refinement of Physics-Informed Neural Networks,,,,,cs.CE cs.LG cs.NE cs.SY eess.SY,http://creativecommons.org/licenses/by/4.0/,"  In this paper, we propose a refinement strategy to the well-known
Physics-Informed Neural Networks (PINNs) for solving partial differential
equations (PDEs) based on the concept of Optimal Transport (OT).
  Conventional black-box PINNs solvers have been found to suffer from a host of
issues: spectral bias in fully-connected architectures, unstable gradient
pathologies, as well as difficulties with convergence and accuracy.
  Current network training strategies are agnostic to dimension sizes and rely
on the availability of powerful computing resources to optimize through a large
number of collocation points.
  This is particularly challenging when studying stochastic dynamical systems
with the Fokker-Planck-Kolmogorov Equation (FPKE), a second-order PDE which is
typically solved in high-dimensional state space.
  While we focus exclusively on the stationary form of the FPKE, positivity and
normalization constraints on its solution make it all the more unfavorable to
solve directly using standard PINNs approaches.
  To mitigate the above challenges, we present a novel training strategy for
solving the FPKE using OT-based sampling to supplement the existing PINNs
framework.
  It is an iterative approach that induces a network trained on a small dataset
to add samples to its training dataset from regions where it nominally makes
the most error.
  The new samples are found by solving a linear programming problem at every
iteration.
  The paper is complemented by an experimental evaluation of the proposed
method showing its applicability on a variety of stochastic systems with
nonlinear dynamics.
","[{'version': 'v1', 'created': 'Wed, 26 May 2021 02:51:20 GMT'}, {'version': 'v2', 'created': 'Thu, 27 May 2021 16:26:01 GMT'}]",2021-05-31,"[['Tadiparthi', 'Vaishnav', ''], ['Bhattacharya', 'Raktim', '']]"
2011.13361,Samadhi Poornima Kumarasinghe Wickrama Arachchilage,"S. W. Arachchilage, E. Izquierdo",SSDL: Self-Supervised Domain Learning for Improved Face Recognition,,,,,cs.CV cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Face recognition in unconstrained environments is challenging due to
variations in illumination, quality of sensing, motion blur and etc. An
individual's face appearance can vary drastically under different conditions
creating a gap between train (source) and varying test (target) data. The
domain gap could cause decreased performance levels in direct knowledge
transfer from source to target. Despite fine-tuning with domain specific data
could be an effective solution, collecting and annotating data for all domains
is extremely expensive. To this end, we propose a self-supervised domain
learning (SSDL) scheme that trains on triplets mined from unlabelled data. A
key factor in effective discriminative learning, is selecting informative
triplets. Building on most confident predictions, we follow an ""easy-to-hard""
scheme of alternate triplet mining and self-learning. Comprehensive experiments
on four different benchmarks show that SSDL generalizes well on different
domains.
","[{'version': 'v1', 'created': 'Thu, 26 Nov 2020 15:55:59 GMT'}]",2020-11-30,"[['Arachchilage', 'S. W.', ''], ['Izquierdo', 'E.', '']]"
2111.15118,Daeseong Park,"Daeseong Park, Aaron J. Barth, Luis C. Ho, Ari Laor","A New Iron Emission Template for Active Galactic Nuclei. I. Optical
  Template for the H$\beta$ region","Accepted for publication in ApJS. download the new template file at
  https://github.com/DaeseongPark/Iron_Template",,10.3847/1538-4365/ac3f3e,,astro-ph.GA,http://creativecommons.org/licenses/by/4.0/,"  We present a new empirical template for iron emission in active galactic
nuclei (AGN) covering the $4000-5600$ A range. The new template is based on a
spectrum of the narrow-line Seyfert 1 galaxy Mrk 493 obtained with the Hubble
Space Telescope. In comparison with the canonical iron template object I Zw 1,
Mrk 493 has narrower broad-line widths, lower reddening, and a less extreme
Eddington ratio, making it a superior choice for template construction. We
carried out a multicomponent spectral decomposition to produce a template
incorporating all permitted and forbidden lines of Fe II identified in the Mrk
493 spectrum over this wavelength range, as well as lines from Ti II, Ni II,
and Cr II. We tested the template by fitting it to AGN spectra spanning a broad
range of iron emission properties, and we present a detailed comparison with
fits using other widely used monolithic and multi-component iron emission
templates. The new template generally provides the best fit (lowest $\chi^2$)
compared to other widely used monolithic empirical templates. In addition, the
new template yields more accurate spectral measurements including a
significantly better match of the derived Balmer line profiles (H$\beta$,
H$\gamma$, H$\delta$), in contrast with results obtained using the other
templates. Our comparison tests show that the choice of iron template can
introduce a systematic bias in measurements of the H$\beta$ line width, which
consequently impacts single-epoch black hole mass estimates by $\sim0.1$ dex on
average and possibly up to $\sim0.3-0.5$ dex individually.
","[{'version': 'v1', 'created': 'Tue, 30 Nov 2021 04:23:49 GMT'}, {'version': 'v2', 'created': 'Thu, 2 Dec 2021 03:38:36 GMT'}]",2022-02-09,"[['Park', 'Daeseong', ''], ['Barth', 'Aaron J.', ''], ['Ho', 'Luis C.', ''], ['Laor', 'Ari', '']]"
2112.09579,Thinh Doan,Thinh T. Doan,"Convergence Rates of Two-Time-Scale Gradient Descent-Ascent Dynamics for
  Solving Nonconvex Min-Max Problems",,,,,math.OC cs.GT cs.LG,http://creativecommons.org/licenses/by/4.0/,"  There are much recent interests in solving noncovnex min-max optimization
problems due to its broad applications in many areas including machine
learning, networked resource allocations, and distributed optimization.
Perhaps, the most popular first-order method in solving min-max optimization is
the so-called simultaneous (or single-loop) gradient descent-ascent algorithm
due to its simplicity in implementation. However, theoretical guarantees on the
convergence of this algorithm is very sparse since it can diverge even in a
simple bilinear problem.
  In this paper, our focus is to characterize the finite-time performance (or
convergence rates) of the continuous-time variant of simultaneous gradient
descent-ascent algorithm. In particular, we derive the rates of convergence of
this method under a number of different conditions on the underlying objective
function, namely, two-sided Polyak-L ojasiewicz (PL), one-sided PL,
nonconvex-strongly concave, and strongly convex-nonconcave conditions. Our
convergence results improve the ones in prior works under the same conditions
of objective functions. The key idea in our analysis is to use the classic
singular perturbation theory and coupling Lyapunov functions to address the
time-scale difference and interactions between the gradient descent and ascent
dynamics. Our results on the behavior of continuous-time algorithm may be used
to enhance the convergence properties of its discrete-time counterpart.
","[{'version': 'v1', 'created': 'Fri, 17 Dec 2021 15:51:04 GMT'}]",2021-12-20,"[['Doan', 'Thinh T.', '']]"
2011.09779,Peter Jeglic,"Katja Gosar, Tina Arh, Tadej Me\v{z}nar\v{s}i\v{c}, Ivan Kvasi\v{c},
  Du\v{s}an Ponikvar, Toma\v{z} Apih, Rainer Kaltenbaek, Rok \v{Z}itko, Erik
  Zupani\v{c}, Samo Begu\v{s}, and Peter Jegli\v{c}","Single-shot Stern-Gerlach magnetic gradiometer with an expanding cloud
  of cold cesium atoms","7 pages, 5 figures","Phys. Rev. A 103, 022611 (2021)",10.1103/PhysRevA.103.022611,,physics.atom-ph quant-ph,http://creativecommons.org/licenses/by/4.0/,"  We combine the Ramsey interferometry protocol, the Stern-Gerlach detection
scheme, and the use of elongated geometry of a cloud of fully polarized cold
cesium atoms to measure the selected component of the magnetic field gradient
along the atomic cloud in a single shot. In contrast to the standard method
where the precession of two spatially separated atomic clouds is simultaneously
measured to extract their phase difference, which is proportional to the
magnetic field gradient, we here demonstrate a gradiometer using a single image
of an expanding atomic cloud with the phase difference imprinted along the
cloud. Using resonant radio-frequency pulses and Stern-Gerlach imaging, we
first demonstrate nutation and Larmor precession of atomic magnetization in an
applied magnetic field. Next, we let the cold atom cloud expand in one
dimension and apply the protocol for measuring the magnetic field gradient. The
resolution of our single-shot gradiometer is not limited by thermal motion of
atoms and has an estimated absolute accuracy below $\pm0.2$~mG/cm
($\pm20$~nT/cm).
","[{'version': 'v1', 'created': 'Thu, 19 Nov 2020 11:35:27 GMT'}, {'version': 'v2', 'created': 'Fri, 19 Feb 2021 21:03:10 GMT'}]",2021-02-23,"[['Gosar', 'Katja', ''], ['Arh', 'Tina', ''], ['Mežnaršič', 'Tadej', ''], ['Kvasič', 'Ivan', ''], ['Ponikvar', 'Dušan', ''], ['Apih', 'Tomaž', ''], ['Kaltenbaek', 'Rainer', ''], ['Žitko', 'Rok', ''], ['Zupanič', 'Erik', ''], ['Beguš', 'Samo', ''], ['Jeglič', 'Peter', '']]"
2102.07067,Shan An,"Shan An, Xiajie Zhang, Dong Wei, Haogang Zhu, Jianyu Yang, and
  Konstantinos A. Tsintotas",Fast Monocular Hand Pose Estimation on Embedded Systems,,,,,cs.RO cs.CV,http://creativecommons.org/licenses/by/4.0/,"  Hand pose estimation is a fundamental task in many human-robot
interaction-related applications. However, previous approaches suffer from
unsatisfying hand landmark predictions in real-world scenes and high
computation burden. This paper proposes a fast and accurate framework for hand
pose estimation, dubbed as ""FastHand"". Using a lightweight encoder-decoder
network architecture, FastHand fulfills the requirements of practical
applications running on embedded devices. The encoder consists of deep layers
with a small number of parameters, while the decoder makes use of spatial
location information to obtain more accurate results. The evaluation took place
on two publicly available datasets demonstrating the improved performance of
the proposed pipeline compared to other state-of-the-art approaches. FastHand
offers high accuracy scores while reaching a speed of 25 frames per second on
an NVIDIA Jetson TX2 graphics processing unit.
","[{'version': 'v1', 'created': 'Sun, 14 Feb 2021 04:12:41 GMT'}, {'version': 'v2', 'created': 'Sat, 7 Aug 2021 03:16:49 GMT'}, {'version': 'v3', 'created': 'Tue, 12 Oct 2021 03:40:05 GMT'}]",2021-10-13,"[['An', 'Shan', ''], ['Zhang', 'Xiajie', ''], ['Wei', 'Dong', ''], ['Zhu', 'Haogang', ''], ['Yang', 'Jianyu', ''], ['Tsintotas', 'Konstantinos A.', '']]"
2012.10382,Pedro Amaro,"P. Amaro, J. P. Santos, S. Bhattacharyya, T. K. Mukherjee, J. K. Saha","Stabilization method with Relativistic Configuration-interaction applied
  to two-electron resonances","v0: Accepted to publication in Physical Review A,
  https://journals.aps.org/pra/accepted/8c076N97Jbf10614983021c0e80a175051a9473a2","Phys. Rev. A 103, 012811 (2021)",10.1103/PhysRevA.103.012811,,physics.atom-ph,http://creativecommons.org/licenses/by/4.0/,"  We applied a relativistic configuration-interaction (CI) framework to the
stabilization method as an approach for obtaining the autoionization resonance
structure of heliumlike ions. In this method, the ion is confined within an
impenetrable spherical cavity, the size of which determines the radial space
available for electron wavefunctions and electron-electron interactions. By
varying the size of the cavity, one can obtain the autoionization resonance
position and width. The applicability of this method is tested on the
resonances of He atom while comparing with benchmark data available in the
literature. The present method is further applied to the determination of the
resonance structure of heliumlike uranium ion, where a relativistic framework
is mandatory. In the strong-confinement region, the present method can be
useful to simulate the properties of an atom or ion under extreme pressure. An
exemplary application of the present method to determine the structure of ions
embedded in a dense plasma environment is briefly discussed.
","[{'version': 'v1', 'created': 'Fri, 18 Dec 2020 17:53:08 GMT'}]",2021-01-27,"[['Amaro', 'P.', ''], ['Santos', 'J. P.', ''], ['Bhattacharyya', 'S.', ''], ['Mukherjee', 'T. K.', ''], ['Saha', 'J. K.', '']]"
2106.07700,David E. Jaffe,David E. Jaffe,A Decade of Discoveries by the Daya Bay Reactor Neutrino Experiment,Submitted to MPLA,,10.1142/S0217732321300214,,hep-ex physics.ins-det,http://creativecommons.org/licenses/by/4.0/,"  With the end of Daya Bay experimental operations in December 2020, I review
the history, discoveries, measurements and impact of the Daya Bay reactor
neutrino experiment in China.
","[{'version': 'v1', 'created': 'Mon, 14 Jun 2021 18:41:50 GMT'}]",2021-07-28,"[['Jaffe', 'David E.', '']]"
1812.10648,Lixin Ge,"Lixin Ge, Ke Gong, Yuping Cang, Yongsong Luo, Xi Shi, and Ying Wu","Magnetically tunable multi-band near-field radiative heat transfer
  between two graphene sheets","8 pages, 7 figures","Phys. Rev. B 100, 035414 (2019)",10.1103/PhysRevB.100.035414,,cond-mat.mes-hall physics.optics,http://creativecommons.org/licenses/by/4.0/,"  Near-field radiative heat transfer (NFRHT) is strongly related with many
applications such as near-field imaging, thermos-photovoltaics and thermal
circuit devices. The active control of NFRHT is of great interest since it
provides a degree of tunability by external means. In this work, a magnetically
tunable multi-band NFRHT is revealed in a system of two suspended graphene
sheets at room temperature. It is found that the single-band spectra for B=0
split into multi-band spectra under an external magnetic field. Dual-band
spectra can be realized for a modest magnetic field (e.g., B=4 T). One band is
determined by intra-band transitions in the classical regime, which undergoes a
blue shift as the chemical potential increases. Meanwhile, the other band is
contributed by inter-Landau-level transitions in the quantum regime, which is
robust against the change of chemical potentials. For a strong magnetic field
(e.g., B=15 T), there is an additional band with the resonant peak appearing at
near-zero frequency (microwave regime), stemming from the magneto-plasmon zero
modes. The great enhancement of NFRHT at such low frequency has not been found
in any previous systems yet. This work may pave a way for multi-band thermal
information transfer based on atomically thin graphene sheets.
","[{'version': 'v1', 'created': 'Thu, 27 Dec 2018 07:29:42 GMT'}]",2019-07-17,"[['Ge', 'Lixin', ''], ['Gong', 'Ke', ''], ['Cang', 'Yuping', ''], ['Luo', 'Yongsong', ''], ['Shi', 'Xi', ''], ['Wu', 'Ying', '']]"
2101.05493,Zhihao Zhou,"Zhihao Zhou, Wei Liu, Jiajing He, Lei Chen, Xin Luo, Dongyi Shen,
  Jianjun Cao, Yaping Dan, Xianfeng Chen and Wenjie Wan",Far-Field Super-Resolution Imaging By Nonlinear Excited Evanescent Waves,,,,,physics.optics,http://creativecommons.org/licenses/by/4.0/,"  Abbe's resolution limit, one of the best-known physical limitations, poses a
great challenge for any wave systems in imaging, wave transport, and dynamics.
Originally formulated in linear optics, this Abbe's limit can be broken using
nonlinear optical interactions. Here we extend the Abbe theory into a nonlinear
regime and experimentally demonstrate a far-field, label-free, and scan-free
super-resolution imaging technique based on nonlinear four-wave mixing to
retrieve near-field scattered evanescent waves, achieving sub-wavelength
resolution of $\lambda/15.6$. This method paves the way for application in
biomedical imaging, semiconductor metrology, and photolithography.
","[{'version': 'v1', 'created': 'Thu, 14 Jan 2021 08:03:21 GMT'}]",2021-01-15,"[['Zhou', 'Zhihao', ''], ['Liu', 'Wei', ''], ['He', 'Jiajing', ''], ['Chen', 'Lei', ''], ['Luo', 'Xin', ''], ['Shen', 'Dongyi', ''], ['Cao', 'Jianjun', ''], ['Dan', 'Yaping', ''], ['Chen', 'Xianfeng', ''], ['Wan', 'Wenjie', '']]"
2102.01563,Zhuang Li,"Shuo Huang, Zhuang Li, Lizhen Qu, Lei Pan",On Robustness of Neural Semantic Parsers,"Long Paper, Accepted to EACL2021",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Semantic parsing maps natural language (NL) utterances into logical forms
(LFs), which underpins many advanced NLP problems. Semantic parsers gain
performance boosts with deep neural networks, but inherit vulnerabilities
against adversarial examples. In this paper, we provide the empirical study on
the robustness of semantic parsers in the presence of adversarial attacks.
Formally, adversaries of semantic parsing are considered to be the perturbed
utterance-LF pairs, whose utterances have exactly the same meanings as the
original ones. A scalable methodology is proposed to construct robustness test
sets based on existing benchmark corpora. Our results answered five research
questions in measuring the sate-of-the-art parsers' performance on robustness
test sets, and evaluating the effect of data augmentation.
","[{'version': 'v1', 'created': 'Tue, 2 Feb 2021 15:41:28 GMT'}, {'version': 'v2', 'created': 'Wed, 3 Feb 2021 12:19:10 GMT'}]",2021-02-04,"[['Huang', 'Shuo', ''], ['Li', 'Zhuang', ''], ['Qu', 'Lizhen', ''], ['Pan', 'Lei', '']]"
2103.06602,Alexandros Nikou PhD,"Alexandros Nikou, Anusha Mujumdar, Marin Orlic, Aneta Vulgarakis
  Feljan",Symbolic Reinforcement Learning for Safe RAN Control,"The paper has been accepted to be presented in 20th International
  Conference on Autonomous Agents and Multiagent Systems (AAMAS 2021), May 3-7,
  London, UK (demo track)",,,,cs.AI,http://creativecommons.org/licenses/by/4.0/,"  In this paper, we demonstrate a Symbolic Reinforcement Learning (SRL)
architecture for safe control in Radio Access Network (RAN) applications. In
our automated tool, a user can select a high-level safety specifications
expressed in Linear Temporal Logic (LTL) to shield an RL agent running in a
given cellular network with aim of optimizing network performance, as measured
through certain Key Performance Indicators (KPIs). In the proposed
architecture, network safety shielding is ensured through model-checking
techniques over combined discrete system models (automata) that are abstracted
through reinforcement learning. We demonstrate the user interface (UI) helping
the user set intent specifications to the architecture and inspect the
difference in allowed and blocked actions.
","[{'version': 'v1', 'created': 'Thu, 11 Mar 2021 10:56:49 GMT'}]",2021-03-12,"[['Nikou', 'Alexandros', ''], ['Mujumdar', 'Anusha', ''], ['Orlic', 'Marin', ''], ['Feljan', 'Aneta Vulgarakis', '']]"
2105.03724,Kartik Venkatraman Prof.,Pradeepa T. Karnick and Kartik Venkatraman,"Viscosity, shock-induced separation, and shock reversal -- Oscillating
  wing section in transonic flow","25 pages, 13 figures",,,,physics.flu-dyn,http://creativecommons.org/licenses/by/4.0/,"  We numerically examine the mechanisms that describe the shock-boundary layer
interactions in transonic flow past an oscillating wing section. At moderate
and high angles of incidence but low amplitudes of oscillation, shock induced
flow separation or shock-stall is observed accompanied by shock reversal. Even
though the power input to the airfoil by the viscous forces is three orders of
magnitude lower than that due to the pressure forces on the airfoil, the
boundary layer manipulates the shock location and shock motion and
redistributes the power input to the airfoil by the pressure forces. The shock
motion is reversed relative to that in an inviscid flow as the boundary layer
cannot sustain an adverse pressure gradient posed by the shock, causing the
shock to move upstream leading to an early separation. The shock motion shows a
phase difference with reference to the airfoil motion and is a function of the
frequency of the oscillation. At low angles of incidence, and low amplitudes of
oscillation, the boundary layer changes the profile presented to the external
flow, leads to a slower expansion of the flow resulting in an early shock, and
a diffused shock-foot caused by the boundary layer.
","[{'version': 'v1', 'created': 'Sat, 8 May 2021 15:59:20 GMT'}]",2021-05-11,"[['Karnick', 'Pradeepa T.', ''], ['Venkatraman', 'Kartik', '']]"
2005.04651,Muhammad Usama Mr,Muhammad Usama and Jaehong Kim,"Vector Control Algorithm Based on Different Current Control Switching
  Techniques for Ac Motor Drives",,,10.1051/e3sconf/202015203009,,eess.SY cs.SY,http://creativecommons.org/licenses/by/4.0/,"  A comparative analysis of vector control scheme based on different current
control switching pulses (HC, SPWM, DPWM and SVPWM) for the speed response of
motor drive is analysed in this paper. The control system using different
switching techniques, are comparatively simulated and analysed. Ac motor drives
are progressively used in high-performance application industries due to small
size, efficient performance, robust to torque response and high power to size
ratio. A mathematical model of ac motor drives is presented in order to explain
the numerical theory of motor drives. The vector control technique is utilized
for efficient speed control of ac motor drive based on independent torque and
air gap flux control. The study compares the total harmonic distortion contents
of phase currents of ac motor drive and speed response in each case. The
simulation result shows that total harmonic distortion across the phase current
in SVPWM is less as compared to other switching techniques while the rise time
in speed response across SVPWM technique is faster as compared to other
switching methods. The simulation result of ac motor drives speed control is
demonstrated in Matlab/Simulink 2018b.
","[{'version': 'v1', 'created': 'Sun, 10 May 2020 13:00:41 GMT'}]",2020-05-12,"[['Usama', 'Muhammad', ''], ['Kim', 'Jaehong', '']]"
1911.04404,Gerco van Heerdt,"Gerco van Heerdt, Clemens Kupke, Jurriaan Rot, Alexandra Silva",Learning Weighted Automata over Principal Ideal Domains,,,,,cs.FL,http://creativecommons.org/licenses/by/4.0/,"  In this paper, we study active learning algorithms for weighted automata over
a semiring. We show that a variant of Angluin's seminal \LStar\ algorithm works
when the semiring is a principal ideal domain, but not for general semirings
such as the natural numbers.
","[{'version': 'v1', 'created': 'Mon, 11 Nov 2019 17:24:36 GMT'}, {'version': 'v2', 'created': 'Thu, 14 Oct 2021 08:42:36 GMT'}]",2021-10-15,"[['van Heerdt', 'Gerco', ''], ['Kupke', 'Clemens', ''], ['Rot', 'Jurriaan', ''], ['Silva', 'Alexandra', '']]"
2111.06205,Aaron Labdon,Aaron Labdon,The Inner Astronomical Unit of Protoplanetary Disks,PhD Thesis submitted at University of Exeter,,,,astro-ph.SR astro-ph.EP astro-ph.IM,http://creativecommons.org/licenses/by/4.0/,"  A golden age of interferometry is upon us, allowing observations at smaller
scales in greater detail than ever before. In few fields has this had the huge
impact as that of planet formation and the study of young stars. State of the
art high angular resolution observations provide invaluable insights into a
host of physical processed from accretion and sublimation, to disk winds and
other outflows. In this thesis, I present the wide-ranging works of my PhD,
encompassing both instrumentation and observational science. Instrumentational
activities stem from the development of new generation baseline solutions at
CHARA to the commissioning of a new observing mode on MIRC-X, allowing for the
first ever J band interferometric observations of a young stellar object ever
published. The science results find direct evidence of a dusty wind emanating
from the innermost regions of the young object SU Aurigae in addition to
exquisite image reconstruction revealing inclination induced asymmetries.
Additionally, I find evidence of viscous heating of the inner disk of
outbursting star FU Orionis as I derive the temperature gradient to
unparalleled precision. While it is difficult to draw one overall conclusion
from the varied works of this thesis, the results described here are a
testament to the uniqueness of young stellar systems and provide vital
information on some the most ubiquitous processes in astrophysics. The
instrumentational developments also open up exciting opportunities for future
science in the ever-growing field of optical interferometry.
","[{'version': 'v1', 'created': 'Thu, 11 Nov 2021 13:46:10 GMT'}]",2021-11-12,"[['Labdon', 'Aaron', '']]"
1812.05230,Mansoo Choi,"Wooik Jung, Yoon-ho Jung, Peter V. Pikhitsa, Jooyeon Shin, Kijoon
  Bang, Jicheng Feng and Mansoo Choi",Three-dimensional nanoprinting via charged aerosol focusing,,,,,physics.app-ph,http://creativecommons.org/licenses/by/4.0/,"  A powerful and flexible method of 3D nano-printing, based on focusing charged
aerosol, has been developed. The self-consistent electric field configuration,
created with a holey floating mask and used as the scaffold for printing
structures, has no restriction as to sizes down to nano-scale. The electric
field line is used as a writing tool. Broad material independence opens the way
for producing hybrid structures that are essential for electronic devices. The
method contains three modes which are complementary: controlled tip-directed
3D-growth printing, the writing mode (that can also produce 3D structures in
repeating passages), and the stencil mode that produces wall-like structures of
various shapes. Manipulating them gives freedom to manufacture complex 3D
designs that we report. The desired morphology of the grown structures is
controlled according to a simple phenomenological theory that helps organize
the 2D stage motion and the 3D printing process to compete with the 3D printing
provided by laser techniques in polymer based material.
","[{'version': 'v1', 'created': 'Thu, 13 Dec 2018 02:14:41 GMT'}]",2018-12-14,"[['Jung', 'Wooik', ''], ['Jung', 'Yoon-ho', ''], ['Pikhitsa', 'Peter V.', ''], ['Shin', 'Jooyeon', ''], ['Bang', 'Kijoon', ''], ['Feng', 'Jicheng', ''], ['Choi', 'Mansoo', '']]"
2104.06368,David Yevick,David Yevick,"Variational Autoencoder Analysis of Ising Model Statistical
  Distributions and Phase Transitions",,,,,cond-mat.stat-mech cond-mat.dis-nn cs.NE,http://creativecommons.org/licenses/by/4.0/,"  Variational autoencoders employ an encoding neural network to generate a
probabilistic representation of a data set within a low-dimensional space of
latent variables followed by a decoding stage that maps the latent variables
back to the original variable space. Once trained, a statistical ensemble of
simulated data realizations can be obtained by randomly assigning values to the
latent variables that are subsequently processed by the decoding section of the
network. To determine the accuracy of such a procedure when applied to lattice
models, an autoencoder is here trained on a thermal equilibrium distribution of
Ising spin realizations. When the output of the decoder for synthetic data is
interpreted probabilistically, spin realizations can be generated by randomly
assigning spin values according to the computed likelihood. The resulting state
distribution in energy-magnetization space then qualitatively resembles that of
the training samples. However, because correlations between spins are
suppressed, the computed energies are unphysically large for low-dimensional
latent variable spaces. The features of the learned distributions as a function
of temperature, however, provide a qualitative indication of the presence of a
phase transition and the distribution of realizations with characteristic
cluster sizes.
","[{'version': 'v1', 'created': 'Tue, 13 Apr 2021 17:24:19 GMT'}]",2021-04-14,"[['Yevick', 'David', '']]"
2103.05961,Jian Zhang,"Chong Mou, Jian Zhang, Xiaopeng Fan, Hangfan Liu, Ronggang Wang",COLA-Net: Collaborative Attention Network for Image Restoration,"11 pages, 6 tables, 9 figures, to be published in IEEE Transactions
  on Multimedia",,10.1109/TMM.2021.3063916,,cs.CV,http://creativecommons.org/licenses/by/4.0/,"  Local and non-local attention-based methods have been well studied in various
image restoration tasks while leading to promising performance. However, most
of the existing methods solely focus on one type of attention mechanism (local
or non-local). Furthermore, by exploiting the self-similarity of natural
images, existing pixel-wise non-local attention operations tend to give rise to
deviations in the process of characterizing long-range dependence due to image
degeneration. To overcome these problems, in this paper we propose a novel
collaborative attention network (COLA-Net) for image restoration, as the first
attempt to combine local and non-local attention mechanisms to restore image
content in the areas with complex textures and with highly repetitive details
respectively. In addition, an effective and robust patch-wise non-local
attention model is developed to capture long-range feature correspondences
through 3D patches. Extensive experiments on synthetic image denoising, real
image denoising and compression artifact reduction tasks demonstrate that our
proposed COLA-Net is able to achieve state-of-the-art performance in both peak
signal-to-noise ratio and visual perception, while maintaining an attractive
computational complexity. The source code is available on
https://github.com/MC-E/COLA-Net.
","[{'version': 'v1', 'created': 'Wed, 10 Mar 2021 09:33:17 GMT'}]",2021-03-11,"[['Mou', 'Chong', ''], ['Zhang', 'Jian', ''], ['Fan', 'Xiaopeng', ''], ['Liu', 'Hangfan', ''], ['Wang', 'Ronggang', '']]"
2104.00378,Seamus Brady,Seamus Brady,"The Comprehensive Blub Archive Network: Towards Design Principals for
  Open Source Programming Language Repositories",,,,,cs.PL,http://creativecommons.org/licenses/by/4.0/,"  Many popular open source programming languages (Perl, Ruby or Python for
example) have systems for distributing packaged source code that software
developers can use when working in that particular programming language. This
paper will consider the design principals that should be followed if designing
such an open source code repository.
","[{'version': 'v1', 'created': 'Thu, 1 Apr 2021 10:13:42 GMT'}]",2021-04-02,"[['Brady', 'Seamus', '']]"
2011.08970,Ben Marinberg,"Ben Marinberg, Ariel Cohen, Eilam Ben-Dror and Haim Permuter","A Study on MIMO Channel Estimation by 2D and 3D Convolutional Neural
  Networks",,,,,eess.SP cs.LG cs.SY eess.SY,http://creativecommons.org/licenses/by/4.0/,"  In this paper, we study the usage of Convolutional Neural Network (CNN)
estimators for the task of Multiple-Input-Multiple-Output Orthogonal Frequency
Division Multiplexing (MIMO-OFDM) Channel Estimation (CE). Specifically, the
CNN estimators interpolate the channel values of reference signals for
estimating the channel of the full OFDM resource element (RE) matrix. We have
designed a 2D CNN architecture based on U-net, and a 3D CNN architecture for
handling spatial correlation. We investigate the performance of various CNN
architectures fora diverse data set generated according to the 5G NR standard
and in particular, we investigate the influence of spatial correlation,
Doppler, and reference signal resource allocation. The CE CNN estimators are
then integrated with MIMO detection algorithms for testing their influence on
the system level Bit Error Rate(BER) performance.
","[{'version': 'v1', 'created': 'Thu, 12 Nov 2020 12:24:14 GMT'}]",2020-11-19,"[['Marinberg', 'Ben', ''], ['Cohen', 'Ariel', ''], ['Ben-Dror', 'Eilam', ''], ['Permuter', 'Haim', '']]"
2105.14023,Wei Xue,"Csaba Cs\'aki, Sungwoo Hong, Gowri Kurup, Seung J. Lee, Maxim
  Perelstein and Wei Xue",Z-portal Continuum Dark Matter,"9 pages, 5 figures; Version published in PRL",,10.1103/PhysRevLett.128.081807,,hep-ph astro-ph.CO,http://creativecommons.org/licenses/by/4.0/,"  We examine the possibility that dark matter (DM) consists of a gapped
continuum, rather than ordinary particles. A Weakly-Interacting Continuum (WIC)
model, coupled to the Standard Model via a Z-portal, provides an explicit
realization of this idea. The thermal DM relic density in this model is
naturally consistent with observations, providing a continuum counterpart of
the ""WIMP miracle"". Direct detection cross sections are strongly suppressed
compared to ordinary Z-portal WIMP, thanks to a unique effect of the continuum
kinematics. Continuum DM states decay throughout the history of the universe,
and observations of cosmic microwave background place constraints on potential
late decays. Production of WICs at colliders can provide a striking
cascade-decay signature. We show that a simple Z-portal WIC model provides a
fully viable DM candidate consistent with all current experimental constraints.
","[{'version': 'v1', 'created': 'Fri, 28 May 2021 18:00:00 GMT'}, {'version': 'v2', 'created': 'Sat, 17 Jul 2021 12:53:24 GMT'}, {'version': 'v3', 'created': 'Sat, 15 Jan 2022 02:42:34 GMT'}]",2022-03-14,"[['Csáki', 'Csaba', ''], ['Hong', 'Sungwoo', ''], ['Kurup', 'Gowri', ''], ['Lee', 'Seung J.', ''], ['Perelstein', 'Maxim', ''], ['Xue', 'Wei', '']]"
2203.09312,Yingjian Wang,"Yingjian Wang, Xiangyong Wen, Longji Yin, Chao Xu, Yanjun Cao, Fei Gao","Certifiably Optimal Mutual Localization with Anonymous Bearing
  Measurements",,,,,cs.RO,http://creativecommons.org/licenses/by/4.0/,"  Mutual localization is essential for coordination and cooperation in
multi-robot systems. Previous works have tackled this problem by assuming
available correspondences between measurements and received odometry
estimations, which are difficult to acquire, especially for unified robot
teams. Furthermore, most local optimization methods ask for initial guesses and
are sensitive to their quality. In this paper, we present a certifiably optimal
algorithm that uses only anonymous bearing measurements to formulate a novel
mixed-integer quadratically constrained quadratic problem (MIQCQP). Then, we
relax the original nonconvex problem into a semidefinite programming (SDP)
problem and obtain a certifiably global optimum using with off-the-shelf
solvers. As a result, our method can determine bearing-pose correspondences and
furthermore recover the initial relative poses between robots under a certain
condition. We compare the performance with local optimization methods on
extensive simulations under different noise levels to show our advantage in
global optimality and robustness. Real-world experiments are conducted to show
the practicality and robustness.
","[{'version': 'v1', 'created': 'Thu, 17 Mar 2022 13:30:17 GMT'}]",2022-03-18,"[['Wang', 'Yingjian', ''], ['Wen', 'Xiangyong', ''], ['Yin', 'Longji', ''], ['Xu', 'Chao', ''], ['Cao', 'Yanjun', ''], ['Gao', 'Fei', '']]"
2103.07242,Lesandro Ponciano,Maria Augusta Nelson and Lesandro Ponciano,"Experiences and insights from using Github Classroom to support
  Project-Based Courses","5 pages, 6 figures, position paper accepted to the Third
  International Workshop on Software Engineering Education for the Next
  Generation (SEENG workshop)","2021 Third International Workshop on Software Engineering
  Education for the Next Generation",10.1109/SEENG53126.2021.00013,,cs.SE,http://creativecommons.org/licenses/by/4.0/,"  This work presents an approach for using GitHub classroom as a shared,
structured, and persistent repository to support project-based courses at the
Software Engineering Undergraduate program at PUC Minas, in Brazil. We discuss
the needs of the different stakeholders that guided the development of the
approach. Results on the perceptions of professors and students show that the
approach brings benefits. Besides the lessons learned, we present insights on
improving the education of the next generation of software engineers by
employing metrics to monitor skill development, verifying student work
portfolios, and employing tooling support in project-based courses.
","[{'version': 'v1', 'created': 'Fri, 12 Mar 2021 12:46:18 GMT'}]",2021-07-13,"[['Nelson', 'Maria Augusta', ''], ['Ponciano', 'Lesandro', '']]"
1508.06017,Zhizheng Pan,"Zhizheng Pan, Xianzhong Zheng, Weipeng Lin, Jinrong Li, Jing Wang,
  Lulu Fan, Xu Kong","What drives the M*-SFR relation turning over at high masses? The role of
  bulges",this paper has been refused by ApJL,,,,astro-ph.GA,http://creativecommons.org/licenses/by/4.0/,"  It is unclear whether bulge growth is responsible for the flattening of the
star formation main sequence (MS) at the high mass end. To investigate the role
of bulges in shaping the MS, we compare the NUV$-r$ color between the central
($r<R_{50}$) and outer regions for a sample of 6401 local star-forming
galaxies. The NUV$-r$ color is a good specific star formation rate indicator.
We find that at $M_{\ast}<10^{10.2}M_{\sun}$, the central NUV$-r$ is on average
only $\sim$ 0.25 mag redder than the outer NUV$-r$. Above
$M_{\ast}=10^{10.2}M_{\sun}$, the central NUV$-r$ becomes systematically much
redder than the outer NUV$-r$ for more massive galaxies, indicating that the
central bulge is more evolved at the massive end. When dividing the galaxies
according to their S\'ersic index $n$, we find that galaxies with $n$>2.0 tend
to be redder in the central NUV$-r$ color than those with $n$<2.0, even at
fixed B/T and $M_{\ast}$. This suggests that star formation in bulges is more
strongly dependent on $n$ (or central mass density) than on B/T. Finally, we
find that the fraction of galaxies with $n$>2.0 rapidly increases with
$M_{\ast}$ at $M_{\ast}>10^{10.2}M_{\sun}$, which is consistent with the
turning over of the MS at the same transition mass. We conclude that the
increasing fraction of low-sSFR dense bulges in $M_{\ast}>10^{10.2}M_{\sun}$
galaxies, rather than increasing B/T, is responsible for the flattened slope of
the $M_{\ast}$$-$SFR relation at high masses.
","[{'version': 'v1', 'created': 'Tue, 25 Aug 2015 03:08:58 GMT'}, {'version': 'v2', 'created': 'Wed, 30 Aug 2017 01:48:36 GMT'}]",2017-08-31,"[['Pan', 'Zhizheng', ''], ['Zheng', 'Xianzhong', ''], ['Lin', 'Weipeng', ''], ['Li', 'Jinrong', ''], ['Wang', 'Jing', ''], ['Fan', 'Lulu', ''], ['Kong', 'Xu', '']]"
2106.05355,Andrey Kupavskii,"Peter Frankl, Sergei Kiselev, Andrey Kupavskii","Best possible bounds on the number of distinct differences in
  intersecting families",,,,,math.CO cs.DM,http://creativecommons.org/licenses/by/4.0/,"  For a family $\mathcal F$, let $\mathcal D(\mathcal F)$ stand for the family
of all sets that can be expressed as $F\setminus G$, where $F,G\in \mathcal F$.
A family $\mathcal F$ is intersecting if any two sets from the family have
non-empty intersection. In this paper, we study the following question: what is
the maximum of $|\mathcal D(\mathcal F)|$ for an intersecting family of
$k$-element sets? Frankl conjectured that the maximum is attained when
$\mathcal F$ is the family of all sets containing a fixed element. We show that
this holds if $n>50k\log k$ and $k>50$. At the same time, we provide a
counterexample for $n< 4k.$
","[{'version': 'v1', 'created': 'Wed, 9 Jun 2021 19:42:11 GMT'}]",2021-06-11,"[['Frankl', 'Peter', ''], ['Kiselev', 'Sergei', ''], ['Kupavskii', 'Andrey', '']]"
2006.01536,Gabriela Lewenfus,"Gabriela Lewenfus, Wallace Alves Martins, Symeon Chatzinotas, and
  Bj\""orn Ottersten",Joint Forecasting and Interpolation of Graph Signals Using Deep Learning,,,,,eess.SP,http://creativecommons.org/licenses/by/4.0/,"  We tackle the problem of forecasting network-signal snapshots using past
signal measurements acquired by a subset of network nodes. This task can be
seen as a combination of multivariate time-series prediction and graph-signal
interpolation. This is a fundamental problem for many applications wherein
deploying a high granularity network is impractical. Our solution combines
recurrent neural networks with frequency-analysis tools from graph signal
processing, and assumes that data is sufficiently smooth with respect to the
underlying graph. The proposed approach outperforms state-of-the-art deep
learning techniques, especially when only a small fraction of the graph signals
is accessible, considering two distinct real world datasets: temperatures in
the US and speed flow in Seattle. The results also indicate that our method can
handle noisy signals and missing data, making it suitable to many practical
applications.
","[{'version': 'v1', 'created': 'Tue, 2 Jun 2020 11:55:31 GMT'}]",2020-06-03,"[['Lewenfus', 'Gabriela', ''], ['Martins', 'Wallace Alves', ''], ['Chatzinotas', 'Symeon', ''], ['Ottersten', 'Björn', '']]"
2101.08530,Alessia Allevi,"S. Cassina, A. Allevi, V. Mascagna, M. Prest, E. Vallazza and M.
  Bondani","Exploiting the wide dynamic range of Silicon photomultipliers for
  Quantum Optics applications","13 pages, 13 figures",,,,quant-ph physics.ins-det physics.optics,http://creativecommons.org/licenses/by/4.0/,"  Silicon photomultipliers are photon-number-resolving detectors endowed with
hundreds of cells enabling them to reveal high-populated quantum optical
states. In this paper, we address such a goal by showing the possible
acquisition strategies that can be adopted and discussing their advantages and
limitations. In particular, we determine the best acquisition solution in order
to properly reveal the nature, either classical or nonclassical, of mesoscopic
quantum optical states.
","[{'version': 'v1', 'created': 'Thu, 21 Jan 2021 10:31:00 GMT'}]",2021-01-22,"[['Cassina', 'S.', ''], ['Allevi', 'A.', ''], ['Mascagna', 'V.', ''], ['Prest', 'M.', ''], ['Vallazza', 'E.', ''], ['Bondani', 'M.', '']]"
1803.09502,Luca Bertinetto,"Jack Valmadre, Luca Bertinetto, Jo\~ao F. Henriques, Ran Tao, Andrea
  Vedaldi, Arnold Smeulders, Philip Torr, Efstratios Gavves",Long-term Tracking in the Wild: A Benchmark,To appear at ECCV 2018,,,,cs.CV,http://creativecommons.org/licenses/by/4.0/,"  We introduce the OxUvA dataset and benchmark for evaluating single-object
tracking algorithms. Benchmarks have enabled great strides in the field of
object tracking by defining standardized evaluations on large sets of diverse
videos. However, these works have focused exclusively on sequences that are
just tens of seconds in length and in which the target is always visible.
Consequently, most researchers have designed methods tailored to this
""short-term"" scenario, which is poorly representative of practitioners' needs.
Aiming to address this disparity, we compile a long-term, large-scale tracking
dataset of sequences with average length greater than two minutes and with
frequent target object disappearance. The OxUvA dataset is much larger than the
object tracking datasets of recent years: it comprises 366 sequences spanning
14 hours of video. We assess the performance of several algorithms, considering
both the ability to locate the target and to determine whether it is present or
absent. Our goal is to offer the community a large and diverse benchmark to
enable the design and evaluation of tracking methods ready to be used ""in the
wild"". The project website is http://oxuva.net
","[{'version': 'v1', 'created': 'Mon, 26 Mar 2018 10:43:45 GMT'}, {'version': 'v2', 'created': 'Fri, 20 Apr 2018 14:08:21 GMT'}, {'version': 'v3', 'created': 'Fri, 10 Aug 2018 16:03:38 GMT'}]",2018-08-13,"[['Valmadre', 'Jack', ''], ['Bertinetto', 'Luca', ''], ['Henriques', 'João F.', ''], ['Tao', 'Ran', ''], ['Vedaldi', 'Andrea', ''], ['Smeulders', 'Arnold', ''], ['Torr', 'Philip', ''], ['Gavves', 'Efstratios', '']]"
1607.00440,Eric J. Korpela,"Stuart Bowyer, Michael Lampton, Eric Korpela, Jeff Cobb, Matt
  Lebofsky, and Dan Werthimer (Space Sciences Laboratory, University of
  California Berkeley, Berkeley, CA, USA)",The SERENDIP III 70 cm Search for Extraterrestrial Intelligence,9 pages. 5 figures. 2 tables. emulateapj 5/12/14 or later required,,,,astro-ph.IM astro-ph.EP,http://creativecommons.org/licenses/by/4.0/,"  We employed the SERENDIP III system with the Arecibo radio telescope to
search for possible artificial extraterrestrial signals. Over the four years of
this search we covered 93% of the sky observable at Arecibo at least once and
44% of the sky five times or more with a sensitivity of ~3E-25 W/m2. The data
were sent to a 4 million channel spectrum analyzer. Information was obtained
from over 1E+14 independent data points and the results were then analyzed via
a suite of pattern detection algorithms to identify narrow band spectral power
peaks that were not readily identifiable as the product of human activity. We
separately selected data coincident with interesting nearby G dwarf stars that
were encountered by chance in our sky survey for suggestions of excess power
peaks. The peak power distributions in both these data sets were consistent
with random noise. We report upper limits on possible signals from the stars
investigated and provide examples of the most interesting candidates identified
in the sky survey. This paper was intended for publication in 2000 and is
presented here without change from the version submitted to ApJS in 2000.
","[{'version': 'v1', 'created': 'Sat, 2 Jul 2016 00:32:39 GMT'}]",2016-07-05,"[['Bowyer', 'Stuart', '', 'Space Sciences Laboratory, University of\n  California Berkeley, Berkeley, CA, USA'], ['Lampton', 'Michael', '', 'Space Sciences Laboratory, University of\n  California Berkeley, Berkeley, CA, USA'], ['Korpela', 'Eric', '', 'Space Sciences Laboratory, University of\n  California Berkeley, Berkeley, CA, USA'], ['Cobb', 'Jeff', '', 'Space Sciences Laboratory, University of\n  California Berkeley, Berkeley, CA, USA'], ['Lebofsky', 'Matt', '', 'Space Sciences Laboratory, University of\n  California Berkeley, Berkeley, CA, USA'], ['Werthimer', 'Dan', '', 'Space Sciences Laboratory, University of\n  California Berkeley, Berkeley, CA, USA']]"
2110.02758,Benjamin Eysenbach,"Benjamin Eysenbach, Alexander Khazatsky, Sergey Levine, and Ruslan
  Salakhutdinov",Mismatched No More: Joint Model-Policy Optimization for Model-Based RL,,,,,cs.LG cs.AI cs.RO,http://creativecommons.org/licenses/by/4.0/,"  Many model-based reinforcement learning (RL) methods follow a similar
template: fit a model to previously observed data, and then use data from that
model for RL or planning. However, models that achieve better training
performance (e.g., lower MSE) are not necessarily better for control: an RL
agent may seek out the small fraction of states where an accurate model makes
mistakes, or it might act in ways that do not expose the errors of an
inaccurate model. As noted in prior work, there is an objective mismatch:
models are useful if they yield good policies, but they are trained to maximize
their accuracy, rather than the performance of the policies that result from
them. In this work, we propose a single objective for jointly training the
model and the policy, such that updates to either component increases a lower
bound on expected return. This joint optimization mends the objective mismatch
in prior work. Our objective is a global lower bound on expected return, and
this bound becomes tight under certain assumptions. The resulting algorithm
(MnM) is conceptually similar to a GAN: a classifier distinguishes between real
and fake transitions, the model is updated to produce transitions that look
realistic, and the policy is updated to avoid states where the model
predictions are unrealistic.
","[{'version': 'v1', 'created': 'Wed, 6 Oct 2021 13:43:27 GMT'}]",2021-10-07,"[['Eysenbach', 'Benjamin', ''], ['Khazatsky', 'Alexander', ''], ['Levine', 'Sergey', ''], ['Salakhutdinov', 'Ruslan', '']]"
1704.02272,Xavier Bellekens,"Xavier Bellekens and Christos Tachtatzis and Robert Atkinson and Craig
  Renfrew and Tony Kirkham","A Highly-Efficient Memory-Compression Scheme for GPU-Accelerated
  Intrusion Detection Systems","Published in The 7th International Conference of Security of
  Information and Networks, SIN 2014, Glasgow, UK, September, 2014",,10.1145/2659651.2659723,,cs.DC cs.CR,http://creativecommons.org/licenses/by/4.0/,"  Pattern Matching is a computationally intensive task used in many research
fields and real world applications. Due to the ever-growing volume of data to
be processed, and increasing link speeds, the number of patterns to be matched
has risen significantly. In this paper we explore the parallel capabilities of
modern General Purpose Graphics Processing Units (GPGPU) applications for high
speed pattern matching. A highly compressed failure-less Aho-Corasick algorithm
is presented for Intrusion Detection Systems on off-the-shelf hardware. This
approach maximises the bandwidth for data transfers between the host and the
Graphics Processing Unit (GPU). Experiments are performed on multiple alphabet
sizes, demonstrating the capabilities of the library to be used in different
research fields, while sustaining an adequate throughput for intrusion
detection systems or DNA sequencing. The work also explores the performance
impact of adequate prefix matching for alphabet sizes and varying pattern
numbers achieving speeds up to 8Gbps and low memory consumption for intrusion
detection systems.
","[{'version': 'v1', 'created': 'Fri, 7 Apr 2017 15:57:37 GMT'}]",2017-04-10,"[['Bellekens', 'Xavier', ''], ['Tachtatzis', 'Christos', ''], ['Atkinson', 'Robert', ''], ['Renfrew', 'Craig', ''], ['Kirkham', 'Tony', '']]"
2107.06314,Andr\'es Salcedo,"Andr\'es N. Salcedo, David H. Weinberg, Hao-Yi Wu, Benjamin D. Wibking","Exploiting Non-linear Scales in Galaxy-Galaxy Lensing and Galaxy
  Clustering: A Forecast for the Dark Energy Survey","17 pages, 7 figures, to be submitted to MNRAS",,10.1093/mnras/stab3793,,astro-ph.CO,http://creativecommons.org/licenses/by/4.0/,"  The combination of galaxy-galaxy lensing (GGL) and galaxy clustering is a
powerful probe of low redshift matter clustering, especially if it is extended
to the non-linear regime. To this end, we extend the N-body and halo occupation
distribution (HOD) emulator method of arxiv:1907.06293 to model the redMaGiC
sample of colour-selected passive galaxies in the Dark Energy Survey (DES),
adding parameters that describe central galaxy incompleteness, galaxy assembly
bias, and a scale-independent multiplicative lensing bias $A_{lens}$. We use
this emulator to forecast cosmological constraints attainable from the GGL
surface density profile $\Delta\Sigma(r_p)$ and the projected galaxy
correlation function $w_{p,gg}(r_p)$ in the final (Year 6) DES data set over
scales $r_p=0.3-30h^{-1}$ Mpc. For a $3\%$ prior on $A_{lens}$ we forecast
precisions of $1.9\%$, $2.0\%$, and $1.9\%$ on $\Omega_m$, $\sigma_8$, and $S_8
\equiv \sigma_8\Omega_m^{0.5}$, marginalized over all halo occupation
distribution (HOD) parameters as well as $A_{lens}$ and a point-mass
contribution to $\Delta\Sigma$. Adding scales $r_p=0.3-3h^{-1}$ Mpc improves
the $S_8$ precision by a factor of $\sim1.6$ relative to a large scale
($3.0-30.0h^{-1}$ Mpc) analysis, equivalent to increasing the survey area by a
factor of ${\sim}2.6$. Sharpening the $A_{lens}$ prior to $1\%$ further
improves the $S_8$ precision by a factor of $1.7$ (to $1.1\%$), and it
amplifies the gain from including non-linear scales. Our emulator achieves
percent-level accuracy similar to the projected DES statistical uncertainties,
demonstrating the feasibility of a fully non-linear analysis. Obtaining precise
parameter constraints from multiple galaxy types and from measurements that
span linear and non-linear clustering offers many opportunities for internal
cross-checks, which can diagnose systematics and demonstrate the robustness of
cosmological results.
","[{'version': 'v1', 'created': 'Tue, 13 Jul 2021 18:21:09 GMT'}]",2022-01-12,"[['Salcedo', 'Andrés N.', ''], ['Weinberg', 'David H.', ''], ['Wu', 'Hao-Yi', ''], ['Wibking', 'Benjamin D.', '']]"
1909.12299,Subba Reddy Oota,Subba Reddy Oota and Naresh Manwani and Raju S. Bapi,"Expert2Coder: Capturing Divergent Brain Regions Using Mixture of
  Regression Experts",15 pages,,,,cs.LG cs.CL q-bio.NC stat.ML,http://creativecommons.org/licenses/by/4.0/,"  fMRI semantic category understanding using linguistic encoding models
attempts to learn a forward mapping that relates stimuli to the corresponding
brain activation. State-of-the-art encoding models use a single global model
(linear or non-linear) to predict brain activation given the stimulus. However,
the critical assumption in these methods is that a priori different brain
regions respond the same way to all the stimuli, that is, there is no
modularity or specialization assumed for any region. This goes against the
modularity theory, supported by many cognitive neuroscience investigations
suggesting that there are functionally specialized regions in the brain. In
this paper, we achieve this by clustering similar regions together and for
every cluster we learn a different linear regression model using a mixture of
linear experts model. The key idea here is that each linear expert captures the
behaviour of similar brain regions. Given a new stimulus, the utility of the
proposed model is twofold (i) predicts the brain activation as a weighted
linear combination of the activations of multiple linear experts and (ii) to
learn multiple experts corresponding to different brain regions. We argue that
each expert captures activity patterns related to a particular region of
interest (ROI) in the human brain. This study helps in understanding the brain
regions that are activated together given different kinds of stimuli.
Importantly, we suggest that the mixture of regression experts (MoRE) framework
successfully combines the two principles of organization of function in the
brain, namely that of specialization and integration. Experiments on fMRI data
from paradigm 1 [1]where participants view linguistic stimuli show that the
proposed MoRE model has better prediction accuracy compared to that of
conventional models.
","[{'version': 'v1', 'created': 'Thu, 26 Sep 2019 17:59:33 GMT'}, {'version': 'v2', 'created': 'Fri, 29 May 2020 19:45:25 GMT'}]",2020-06-02,"[['Oota', 'Subba Reddy', ''], ['Manwani', 'Naresh', ''], ['Bapi', 'Raju S.', '']]"
2106.04014,Olivia Curtis,Olivia Curtis and Tereasa Brainerd and Anthony Hernandez,Cosmic Voids in GAN-Generated Maps of Large-Scale Structure,"accepted for publication in Astronomy & Computing, 16 pages, 8
  figures",,,,astro-ph.CO,http://creativecommons.org/licenses/by/4.0/,"  A Generative Adversarial Network (GAN) was used to investigate the statistics
and properties of voids in a $\Lambda$CDMuniverse. The total number of voids
and the distribution of void sizes is similar in both sets of images and,
within the formal error bars, the mean void properties are consistent with each
other. However, the generated images yield somewhat fewer small voids than do
the simulated images. In addition, the generated images yield far fewer voids
with central density contrast $\sim$ $-$1. Because the generated images yield
fewer of the emptiest voids, the distribution of the mean interior density
contrast is systematically higher for the generated voids than it is for the
simulated voids. The mean radial underdensity profiles of the largest voids are
similar in both sets of images, but systematic differences are apparent. On
small scales (r $< 0.5r_{v}$), the underdensity profiles of the voids in the
generated images exceed those of the voids in the simulated images. On large
scales (r $> 0.5r_{v}$), the underdensity profiles of the voids in the
simulated images exceed those of the voids in the generated images. The
discrepancies between the void properties in the two sets of images are
attributable to the GAN struggling to capture absolute patterns in the data. In
particular, the GAN produces too few pixels with density contrasts $\sim$ $-$1
and too many pixels with density contrasts in the range $\sim$ $-$0.88 to
$\sim$ $-$0.63.
","[{'version': 'v1', 'created': 'Mon, 7 Jun 2021 23:55:47 GMT'}, {'version': 'v2', 'created': 'Fri, 19 Nov 2021 17:38:23 GMT'}]",2021-11-22,"[['Curtis', 'Olivia', ''], ['Brainerd', 'Tereasa', ''], ['Hernandez', 'Anthony', '']]"
2108.09951,James Blake,"James S.D. Blake, Leigh N. Fletcher, Thomas K. Greathouse, Glenn S.
  Orton, Henrik Melin, Mike T. Roman, Arrate Antu\~nano, Padraig T. Donnelly,
  Naomi Rowe-Gurney, Oliver King",Refining Saturn's deuterium-hydrogen ratio via IRTF/TEXES spectroscopy,"9 pages, 6 figures, 1 table",,10.1051/0004-6361/202038229,,astro-ph.EP physics.space-ph,http://creativecommons.org/licenses/by/4.0/,"  The abundance of deuterium in giant planet atmospheres provides constraints
on the reservoirs of ices incorporated into these worlds during their formation
and evolution. Motivated by discrepancies in the measured deuterium-hydrogen
ratio (D/H) on Jupiter and Saturn, we present a new measurement of the D/H
ratio in methane for Saturn from ground-based measurements. We analysed a
spectral cube (covering 1151-1160 cm$^{-1}$ from 6 February 2013) from the
Texas Echelon Cross Echelle Spectrograph (TEXES) on NASA's Infrared Telescope
Facility (IRTF) where emission lines from both methane and deuterated methane
are well resolved. Our estimate of the D/H ratio in stratospheric methane,
$1.65_{-0.21}^{+0.27} \times 10^{-5}$ is in agreement with results derived from
Cassini CIRS and ISO/SWS observations, confirming the unexpectedly low
CH$_{3}$D abundance. Assuming a fractionation factor of $1.34 \pm 0.19$ we
derive a hydrogen D/H of $1.23_{-0.23}^{+0.27} \times 10^{-5}$. This value
remains lower than previous tropospheric hydrogen D/H measurements of (i)
Saturn $2.10 (\pm 0.13) \times 10^{-5}$, (ii) Jupiter $2.6 (\pm 0.7) \times
10^{-5}$ and (iii) the proto-solar hydrogen D/H of $2.1 (\pm 0.5) \times
10^{-5}$, suggesting that the fractionation factor may not be appropriate for
stratospheric methane, or that the D/H ratio in Saturn's stratosphere is not
representative of the bulk of the planet.
","[{'version': 'v1', 'created': 'Mon, 23 Aug 2021 05:48:29 GMT'}]",2021-09-15,"[['Blake', 'James S. D.', ''], ['Fletcher', 'Leigh N.', ''], ['Greathouse', 'Thomas K.', ''], ['Orton', 'Glenn S.', ''], ['Melin', 'Henrik', ''], ['Roman', 'Mike T.', ''], ['Antuñano', 'Arrate', ''], ['Donnelly', 'Padraig T.', ''], ['Rowe-Gurney', 'Naomi', ''], ['King', 'Oliver', '']]"
2112.08360,Badr AlKhamissi,"Badr AlKhamissi, Akshay Srinivasan, Zeb-Kurth Nelson, Sam Ritter","How to Learn and Represent Abstractions: An Investigation using Symbolic
  Alchemy",Preprint,,,,cs.LG cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Alchemy is a new meta-learning environment rich enough to contain interesting
abstractions, yet simple enough to make fine-grained analysis tractable.
Further, Alchemy provides an optional symbolic interface that enables meta-RL
research without a large compute budget. In this work, we take the first steps
toward using Symbolic Alchemy to identify design choices that enable deep-RL
agents to learn various types of abstraction. Then, using a variety of
behavioral and introspective analyses we investigate how our trained agents use
and represent abstract task variables, and find intriguing connections to the
neuroscience of abstraction. We conclude by discussing the next steps for using
meta-RL and Alchemy to better understand the representation of abstract
variables in the brain.
","[{'version': 'v1', 'created': 'Tue, 14 Dec 2021 19:35:20 GMT'}]",2021-12-17,"[['AlKhamissi', 'Badr', ''], ['Srinivasan', 'Akshay', ''], ['Nelson', 'Zeb-Kurth', ''], ['Ritter', 'Sam', '']]"
2007.14511,Bin Cheng,"Bin Cheng, Inderjot Singh Saggu, Raunak Shah, Gaurav Bansal, Dinesh
  Bharadia","$S^3$Net: Semantic-Aware Self-supervised Depth Estimation with Monocular
  Videos and Synthetic Data",,,,,cs.CV,http://creativecommons.org/licenses/by/4.0/,"  Solving depth estimation with monocular cameras enables the possibility of
widespread use of cameras as low-cost depth estimation sensors in applications
such as autonomous driving and robotics. However, learning such a scalable
depth estimation model would require a lot of labeled data which is expensive
to collect. There are two popular existing approaches which do not require
annotated depth maps: (i) using labeled synthetic and unlabeled real data in an
adversarial framework to predict more accurate depth, and (ii) unsupervised
models which exploit geometric structure across space and time in monocular
video frames. Ideally, we would like to leverage features provided by both
approaches as they complement each other; however, existing methods do not
adequately exploit these additive benefits. We present $S^3$Net, a
self-supervised framework which combines these complementary features: we use
synthetic and real-world images for training while exploiting geometric,
temporal, as well as semantic constraints. Our novel consolidated architecture
provides a new state-of-the-art in self-supervised depth estimation using
monocular videos. We present a unique way to train this self-supervised
framework, and achieve (i) more than $15\%$ improvement over previous synthetic
supervised approaches that use domain adaptation and (ii) more than $10\%$
improvement over previous self-supervised approaches which exploit geometric
constraints from the real data.
","[{'version': 'v1', 'created': 'Tue, 28 Jul 2020 22:40:54 GMT'}]",2020-07-30,"[['Cheng', 'Bin', ''], ['Saggu', 'Inderjot Singh', ''], ['Shah', 'Raunak', ''], ['Bansal', 'Gaurav', ''], ['Bharadia', 'Dinesh', '']]"
2201.10808,Anthony Strittmatter,"Uwe Sunde, Dainis Zegners, Anthony Strittmatter","Speed, Quality, and the Optimal Timing of Complex Decisions: Field
  Evidence",,,,,econ.GN cs.AI q-fin.EC stat.AP,http://creativecommons.org/licenses/by/4.0/,"  This paper presents an empirical investigation of the relation between
decision speed and decision quality for a real-world setting of
cognitively-demanding decisions in which the timing of decisions is endogenous:
professional chess. Move-by-move data provide exceptionally detailed and
precise information about decision times and decision quality, based on a
comparison of actual decisions to a computational benchmark of best moves
constructed using the artificial intelligence of a chess engine. The results
reveal that faster decisions are associated with better performance. The
findings are consistent with the predictions of procedural decision models like
drift-diffusion-models in which decision makers sequentially acquire
information about decision alternatives with uncertain valuations.
","[{'version': 'v1', 'created': 'Wed, 26 Jan 2022 08:29:05 GMT'}]",2022-01-27,"[['Sunde', 'Uwe', ''], ['Zegners', 'Dainis', ''], ['Strittmatter', 'Anthony', '']]"
1906.10996,Stefan Balke,"Stefan Balke, Matthias Dorfer, Luis Carvalho, Andreas Arzt, Gerhard
  Widmer","Learning Soft-Attention Models for Tempo-invariant Audio-Sheet Music
  Retrieval",Accepted for publication at ISMIR 2019,,,,cs.IR cs.CV cs.LG cs.SD eess.AS,http://creativecommons.org/licenses/by/4.0/,"  Connecting large libraries of digitized audio recordings to their
corresponding sheet music images has long been a motivation for researchers to
develop new cross-modal retrieval systems. In recent years, retrieval systems
based on embedding space learning with deep neural networks got a step closer
to fulfilling this vision. However, global and local tempo deviations in the
music recordings still require careful tuning of the amount of temporal context
given to the system. In this paper, we address this problem by introducing an
additional soft-attention mechanism on the audio input. Quantitative and
qualitative results on synthesized piano data indicate that this attention
increases the robustness of the retrieval system by focusing on different parts
of the input representation based on the tempo of the audio. Encouraged by
these results, we argue for the potential of attention models as a very general
tool for many MIR tasks.
","[{'version': 'v1', 'created': 'Wed, 26 Jun 2019 11:52:49 GMT'}]",2019-06-27,"[['Balke', 'Stefan', ''], ['Dorfer', 'Matthias', ''], ['Carvalho', 'Luis', ''], ['Arzt', 'Andreas', ''], ['Widmer', 'Gerhard', '']]"
2202.10502,Giuseppe Montanaro,Giuseppe Montanaro,"Flexible Skylines: Customizing Skyline Queries Catching Desired
  Preferences",,,,,cs.DB,http://creativecommons.org/licenses/by/4.0/,"  The techniques most extensively used to retrieve interesting data from
data-sets are the Skyline and the Top-k queries. Sadly, they are not enough for
facing modern problems, so the needing of something more usable and reliable
has come. In this survey we are going to explore Flexible Skylines which are
proposed to overcame the old fashion techniques' problems by extending the
concept of dominance. After, we are going to compare this approach with the old
and new ones evaluating pros and cons. Finally, we will see some interesting
applications.
","[{'version': 'v1', 'created': 'Mon, 21 Feb 2022 19:26:52 GMT'}]",2022-02-23,"[['Montanaro', 'Giuseppe', '']]"
2109.07488,Adrian Benton,"Sameer Bansal, Adrian Benton","Comparing Euclidean and Hyperbolic Embeddings on the WordNet Nouns
  Hypernymy Graph",,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Nickel and Kiela (2017) present a new method for embedding tree nodes in the
Poincare ball, and suggest that these hyperbolic embeddings are far more
effective than Euclidean embeddings at embedding nodes in large, hierarchically
structured graphs like the WordNet nouns hypernymy tree. This is especially
true in low dimensions (Nickel and Kiela, 2017, Table 1). In this work, we seek
to reproduce their experiments on embedding and reconstructing the WordNet
nouns hypernymy graph. Counter to what they report, we find that Euclidean
embeddings are able to represent this tree at least as well as Poincare
embeddings, when allowed at least 50 dimensions. We note that this does not
diminish the significance of their work given the impressive performance of
hyperbolic embeddings in very low-dimensional settings. However, given the wide
influence of their work, our aim here is to present an updated and more
accurate comparison between the Euclidean and hyperbolic embeddings.
","[{'version': 'v1', 'created': 'Wed, 15 Sep 2021 18:00:05 GMT'}]",2021-09-17,"[['Bansal', 'Sameer', ''], ['Benton', 'Adrian', '']]"
2106.00780,Ran Zmigrod,"Ran Zmigrod, Tim Vieira, Ryan Cotterell",On Finding the $K$-best Non-projective Dependency Trees,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  The connection between the maximum spanning tree in a directed graph and the
best dependency tree of a sentence has been exploited by the NLP community.
However, for many dependency parsing schemes, an important detail of this
approach is that the spanning tree must have exactly one edge emanating from
the root. While work has been done to efficiently solve this problem for
finding the one-best dependency tree, no research has attempted to extend this
solution to finding the $K$-best dependency trees. This is arguably a more
important extension as a larger proportion of decoded trees will not be subject
to the root constraint of dependency trees. Indeed, we show that the rate of
root constraint violations increases by an average of $13$ times when decoding
with $K\!=\!50$ as opposed to $K\!=\!1$. In this paper, we provide a
simplification of the $K$-best spanning tree algorithm of Camerini et al.
(1980). Our simplification allows us to obtain a constant time speed-up over
the original algorithm. Furthermore, we present a novel extension of the
algorithm for decoding the $K$-best dependency trees of a graph which are
subject to a root constraint.
","[{'version': 'v1', 'created': 'Tue, 1 Jun 2021 20:23:41 GMT'}]",2021-06-03,"[['Zmigrod', 'Ran', ''], ['Vieira', 'Tim', ''], ['Cotterell', 'Ryan', '']]"
2012.07460,Xurong Xie,"Xurong Xie, Xunying Liu, Tan Lee, Lan Wang",Bayesian Learning for Deep Neural Network Adaptation,"published in TASLP, and with extra appendices of released codes and
  updated results","IEEE/ACM Transactions on Audio, Speech, and Language Processing,
  Volume: 29, 2021",10.1109/TASLP.2021.3084072,,cs.SD eess.AS stat.ML,http://creativecommons.org/licenses/by/4.0/,"  A key task for speech recognition systems is to reduce the mismatch between
training and evaluation data that is often attributable to speaker differences.
Speaker adaptation techniques play a vital role to reduce the mismatch.
Model-based speaker adaptation approaches often require sufficient amounts of
target speaker data to ensure robustness. When the amount of speaker level data
is limited, speaker adaptation is prone to overfitting and poor generalization.
To address the issue, this paper proposes a full Bayesian learning based DNN
speaker adaptation framework to model speaker-dependent (SD) parameter
uncertainty given limited speaker specific adaptation data. This framework is
investigated in three forms of model based DNN adaptation techniques: Bayesian
learning of hidden unit contributions (BLHUC), Bayesian parameterized
activation functions (BPAct), and Bayesian hidden unit bias vectors (BHUB). In
the three methods, deterministic SD parameters are replaced by latent variable
posterior distributions for each speaker, whose parameters are efficiently
estimated using a variational inference based approach. Experiments conducted
on 300-hour speed perturbed Switchboard corpus trained LF-MMI TDNN/CNN-TDNN
systems suggest the proposed Bayesian adaptation approaches consistently
outperform the deterministic adaptation on the NIST Hub5'00 and RT03 evaluation
sets. When using only the first five utterances from each speaker as adaptation
data, significant word error rate reductions up to 1.4% absolute (7.2%
relative) were obtained on the CallHome subset. The efficacy of the proposed
Bayesian adaptation techniques is further demonstrated in a comparison against
the state-of-the-art performance obtained on the same task using the most
recent systems reported in the literature.
","[{'version': 'v1', 'created': 'Mon, 14 Dec 2020 12:30:41 GMT'}, {'version': 'v2', 'created': 'Wed, 4 Aug 2021 10:44:11 GMT'}, {'version': 'v3', 'created': 'Sun, 15 Aug 2021 08:45:22 GMT'}]",2021-08-17,"[['Xie', 'Xurong', ''], ['Liu', 'Xunying', ''], ['Lee', 'Tan', ''], ['Wang', 'Lan', '']]"
2203.07083,Candace Savonen,"Candace Savonen, Carrie Wright, Ava M. Hoffman, John Muschelli,
  Katherine Cox, Frederick J. Tan, Jeffrey T. Leek",Open-source Tools for Training Resources -- OTTR,"19 pages, 5 figures, submitted to Journal of Statistics and Data
  Science Education",,,,cs.CY,http://creativecommons.org/licenses/by/4.0/,"  Data science and informatics tools are developing at a blistering rate, but
their users often lack the educational background or resources to efficiently
apply the methods to their research. Training resources often deprecate because
their maintenance is not prioritized by funding, giving teams little time to
devote to such endeavors. Our group has developed Open-source Tools for
Training Resources (OTTR) to offer greater efficiency and flexibility for
creating and maintaining online course content. OTTR empowers creators to
customize their work and allows for a simple workflow to publish using multiple
platforms. OTTR allows content creators to publish material to multiple massive
online learner communities using familiar rendering mechanics. OTTR allows the
incorporation of pedagogical practices like formative and summative assessments
in the form of multiple choice questions and fill in the blank problems that
are automatically graded. No local installation of any software is required to
begin creating content with OTTR. Thus far, 15 courses have been created with
OTTR repository template. By using the OTTR system, the maintenance workload
for updating these courses across platforms has been drastically reduced.
","[{'version': 'v1', 'created': 'Thu, 10 Mar 2022 13:44:50 GMT'}]",2022-03-15,"[['Savonen', 'Candace', ''], ['Wright', 'Carrie', ''], ['Hoffman', 'Ava M.', ''], ['Muschelli', 'John', ''], ['Cox', 'Katherine', ''], ['Tan', 'Frederick J.', ''], ['Leek', 'Jeffrey T.', '']]"
2003.05919,Hadrien Kurkjian,Hadrien Kurkjian and Zoran Ristivojevic,Damping of elementary excitations in one-dimensional dipolar Bose gases,"6 pages, 3 figures","Phys. Rev. Research 2, 033337 (2020)",10.1103/PhysRevResearch.2.033337,,cond-mat.quant-gas physics.atom-ph,http://creativecommons.org/licenses/by/4.0/,"  In the presence of dipolar interactions the excitation spectrum of a Bose gas
can acquire a local minimum. The corresponding quasiparticles are known as
rotons. They are gaped and do not decay at zero temperature. Here we study the
decay of rotons in one-dimensional Bose gases at low temperatures. It
predominantly occurs due to the backscattering of thermal phonons on rotons.
The resulting rate scales with the third power of temperature and is inversely
proportional to the sixth power of the roton gap near the solidification phase
transition. The hydrodynamic approach used here enables us to find the decay
rate for quasiparticles at practically any momenta, with minimal assumptions on
the exact form of the interparticle interactions. Our results are an essential
prerequisite for the description of all the dissipative phenomena in dipolar
gases and have direct experimental relevance.
","[{'version': 'v1', 'created': 'Thu, 12 Mar 2020 17:34:00 GMT'}]",2020-09-09,"[['Kurkjian', 'Hadrien', ''], ['Ristivojevic', 'Zoran', '']]"
2112.05728,Michele Mancarella,"Michele Mancarella, Edwin Genoud-Prachex, Michele Maggiore","Cosmology and modified gravitational wave propagation from binary black
  hole population models","15+6 pages, 7 figures, code $\tt{MGCosmoPop}$ available at
  \url{https://github.com/CosmoStatGW/MGCosmoPop}. v2: minor changes, matches
  version to appear on PRD",,,,gr-qc astro-ph.CO astro-ph.HE,http://creativecommons.org/licenses/by/4.0/,"  A joint hierarchical Bayesian analysis of the binary black hole (BBH) mass
function, merger rate evolution and cosmological parameters can be used to
extract information on both the cosmological and population parameters. We
extend this technique to include the effect of modified gravitational wave (GW)
propagation. We discuss the constraints on the parameter $\Xi_0$ that describes
this phenomenon (with $\Xi_0=1$ in General Relativity, GR) using the data from
the GWTC-3 catalog. We find the constraints $\Xi_0 = 1.2^{+0.7}_{-0.7}$ with a
flat prior on $\Xi_0$, and $\Xi_0 = 1.0^{+0.4}_{-0.8}$ with a prior uniform in
$\log\Xi_0$ ($68\%$ C.L., maximum posterior and HDI), which only rely on the
presence of a feature in the BBH mass distribution around $\sim 30-45
M_{\odot}$, and are robust to whether or not the event GW190521 is considered
an outlier of the population. We then study in more detail the effects of
modified GW propagation on population and cosmological analyses for LIGO/Virgo
at design sensitivity. For a given data-taking period, the relative error
$\Delta\Xi_0/\Xi_0$ has a significant dependence on the fiducial value of
$\Xi_0$, since the latter has a strong influence on the detection rate. For
five years of data, the accuracy ranges from $\sim 10\%$ on $\Xi_0$ when
$\Xi_0=1$ to $\Delta\Xi_0/\Xi_0\sim 20\%$ for $\Xi_0=1.8$ - a large deviation
from GR, still consistent with current limits and predicted by viable
cosmological models. For the Hubble parameter, we forecast an accuracy of
$\Delta H_0/H_0 \sim 20\%$, and an accuracy on $H(z)$ of $\sim7\%$ at a pivot
redshift $z_*\sim 0.8$. We finally show that, if Nature is described by a
modified gravity theory with a large deviation from the GR value $\Xi_0=1$,
such as $\Xi_0=1.8$, analysing the data assuming GR produces a significant bias
in the inferred values of the mass scales, Hubble constant, and BBH merger
rate.
","[{'version': 'v1', 'created': 'Fri, 10 Dec 2021 18:32:22 GMT'}, {'version': 'v2', 'created': 'Fri, 11 Mar 2022 22:50:02 GMT'}]",2022-03-15,"[['Mancarella', 'Michele', ''], ['Genoud-Prachex', 'Edwin', ''], ['Maggiore', 'Michele', '']]"
2101.07726,Vishesh Jain,"Vishesh Jain, Ashwin Sah, Mehtaab Sawhney",Anticoncentration versus the number of subset sums,10 pages; revised version,,,,math.CO cs.DS math.PR,http://creativecommons.org/licenses/by/4.0/,"  Let $\vec{w} = (w_1,\dots, w_n) \in \mathbb{R}^{n}$. We show that for any
$n^{-2}\le\epsilon\le 1$, if \[\#\{\vec{\xi} \in \{0,1\}^{n}: \langle
\vec{\xi}, \vec{w} \rangle = \tau\} \ge 2^{-\epsilon n}\cdot 2^{n}\] for some
$\tau \in \mathbb{R}$, then \[\#\{\langle \vec{\xi}, \vec{w} \rangle :
\vec{\xi} \in \{0,1\}^{n}\} \le 2^{O(\sqrt{\epsilon}n)}.\] This exponentially
improves the $\epsilon$ dependence in a recent result of Nederlof, Pawlewicz,
Swennenhuis, and W\k{e}grzycki and leads to a similar improvement in the
parameterized (by the number of bins) runtime of bin packing.
","[{'version': 'v1', 'created': 'Tue, 19 Jan 2021 16:59:03 GMT'}, {'version': 'v2', 'created': 'Mon, 14 Jun 2021 21:48:47 GMT'}]",2021-06-16,"[['Jain', 'Vishesh', ''], ['Sah', 'Ashwin', ''], ['Sawhney', 'Mehtaab', '']]"
2106.11420,Aounon Kumar,"Aounon Kumar, Alexander Levine and Soheil Feizi",Policy Smoothing for Provably Robust Reinforcement Learning,,,,,cs.LG,http://creativecommons.org/licenses/by/4.0/,"  The study of provable adversarial robustness for deep neural networks (DNNs)
has mainly focused on static supervised learning tasks such as image
classification. However, DNNs have been used extensively in real-world adaptive
tasks such as reinforcement learning (RL), making such systems vulnerable to
adversarial attacks as well. Prior works in provable robustness in RL seek to
certify the behaviour of the victim policy at every time-step against a
non-adaptive adversary using methods developed for the static setting. But in
the real world, an RL adversary can infer the defense strategy used by the
victim agent by observing the states, actions, etc. from previous time-steps
and adapt itself to produce stronger attacks in future steps. We present an
efficient procedure, designed specifically to defend against an adaptive RL
adversary, that can directly certify the total reward without requiring the
policy to be robust at each time-step. Our main theoretical contribution is to
prove an adaptive version of the Neyman-Pearson Lemma -- a key lemma for
smoothing-based certificates -- where the adversarial perturbation at a
particular time can be a stochastic function of current and previous
observations and states as well as previous actions. Building on this result,
we propose policy smoothing where the agent adds a Gaussian noise to its
observation at each time-step before passing it through the policy function.
Our robustness certificates guarantee that the final total reward obtained by
policy smoothing remains above a certain threshold, even though the actions at
intermediate time-steps may change under the attack. Our experiments on various
environments like Cartpole, Pong, Freeway and Mountain Car show that our method
can yield meaningful robustness guarantees in practice.
","[{'version': 'v1', 'created': 'Mon, 21 Jun 2021 21:42:08 GMT'}, {'version': 'v2', 'created': 'Mon, 11 Oct 2021 20:28:59 GMT'}]",2021-10-13,"[['Kumar', 'Aounon', ''], ['Levine', 'Alexander', ''], ['Feizi', 'Soheil', '']]"
2108.11205,Nataliia Stulova,"Arianna Blasi, Nataliia Stulova, Alessandra Gorla, Oscar Nierstrasz",RepliComment: Identifying Clones in Code Comments,"31 pages, 1 figure, 9 tables. To appear in the Journal of Systems and
  Software",,,,cs.SE,http://creativecommons.org/licenses/by/4.0/,"  Code comments are the primary means to document implementation and facilitate
program comprehension. Thus, their quality should be a primary concern to
improve program maintenance. While much effort has been dedicated to detecting
bad smells, such as clones in code, little work has focused on comments. In
this paper we present our solution to detect clones in comments that developers
should fix. RepliComment can automatically analyze Java projects and report
instances of copy-and-paste errors in comments, and can point developers to
which comments should be fixed. Moreover, it can report when clones are signs
of poorly written comments. Developers should fix these instances too in order
to improve the quality of the code documentation. Our evaluation of 10
well-known open source Java projects identified over 11K instances of comment
clones, and over 1,300 of them are potentially critical. We improve on our own
previous work, which could only find 36 issues in the same dataset. Our manual
inspection of 412 issues reported by RepliComment reveals that it achieves a
precision of 79% in reporting critical comment clones. The manual inspection of
200 additional comment clones that RepliComment filters out as being
legitimate, could not evince any false negative.
","[{'version': 'v1', 'created': 'Wed, 25 Aug 2021 12:41:23 GMT'}]",2021-08-26,"[['Blasi', 'Arianna', ''], ['Stulova', 'Nataliia', ''], ['Gorla', 'Alessandra', ''], ['Nierstrasz', 'Oscar', '']]"
1712.06982,Graeme Stewart,"Johannes Albrecht, Antonio Augusto Alves Jr, Guilherme Amadio,
  Giuseppe Andronico, Nguyen Anh-Ky, Laurent Aphecetche, John Apostolakis,
  Makoto Asai, Luca Atzori, Marian Babik, Giuseppe Bagliesi, Marilena
  Bandieramonte, Sunanda Banerjee, Martin Barisits, Lothar A.T. Bauerdick,
  Stefano Belforte, Douglas Benjamin, Catrin Bernius, Wahid Bhimji, Riccardo
  Maria Bianchi, Ian Bird, Catherine Biscarat, Jakob Blomer, Kenneth Bloom,
  Tommaso Boccali, Brian Bockelman, Tomasz Bold, Daniele Bonacorsi, Antonio
  Boveia, Concezio Bozzi, Marko Bracko, David Britton, Andy Buckley, Predrag
  Buncic, Paolo Calafiura, Simone Campana, Philippe Canal, Luca Canali,
  Gianpaolo Carlino, Nuno Castro, Marco Cattaneo, Gianluca Cerminara, Javier
  Cervantes Villanueva, Philip Chang, John Chapman, Gang Chen, Taylor Childers,
  Peter Clarke, Marco Clemencic, Eric Cogneras, Jeremy Coles, Ian Collier,
  David Colling, Gloria Corti, Gabriele Cosmo, Davide Costanzo, Ben Couturier,
  Kyle Cranmer, Jack Cranshaw, Leonardo Cristella, David Crooks, Sabine
  Cr\'ep\'e-Renaudin, Robert Currie, S\""unje Dallmeier-Tiessen, Kaushik De,
  Michel De Cian, Albert De Roeck, Antonio Delgado Peris, Fr\'ed\'eric Derue,
  Alessandro Di Girolamo, Salvatore Di Guida, Gancho Dimitrov, Caterina
  Doglioni, Andrea Dotti, Dirk Duellmann, Laurent Duflot, Dave Dykstra,
  Katarzyna Dziedziniewicz-Wojcik, Agnieszka Dziurda, Ulrik Egede, Peter Elmer,
  Johannes Elmsheuser, V. Daniel Elvira, Giulio Eulisse, Steven Farrell, Torben
  Ferber, Andrej Filipcic, Ian Fisk, Conor Fitzpatrick, Jos\'e Flix, Andrea
  Formica, Alessandra Forti, Giovanni Franzoni, James Frost, Stu Fuess, Frank
  Gaede, Gerardo Ganis, Robert Gardner, Vincent Garonne, Andreas Gellrich,
  Krzysztof Genser, Simon George, Frank Geurts, Andrei Gheata, Mihaela Gheata,
  Francesco Giacomini, Stefano Giagu, Manuel Giffels, Douglas Gingrich, Maria
  Girone, Vladimir V. Gligorov, Ivan Glushkov, Wesley Gohn, Jose Benito
  Gonzalez Lopez, Isidro Gonz\'alez Caballero, Juan R. Gonz\'alez Fern\'andez,
  Giacomo Govi, Claudio Grandi, Hadrien Grasland, Heather Gray, Lucia Grillo,
  Wen Guan, Oliver Gutsche, Vardan Gyurjyan, Andrew Hanushevsky, Farah Hariri,
  Thomas Hartmann, John Harvey, Thomas Hauth, Benedikt Hegner, Beate Heinemann,
  Lukas Heinrich, Andreas Heiss, Jos\'e M. Hern\'andez, Michael Hildreth, Mark
  Hodgkinson, Stefan Hoeche, Burt Holzman, Peter Hristov, Xingtao Huang,
  Vladimir N. Ivanchenko, Todor Ivanov, Jan Iven, Brij Jashal, Bodhitha
  Jayatilaka, Roger Jones, Michel Jouvin, Soon Yung Jun, Michael Kagan, Charles
  William Kalderon, Meghan Kane, Edward Karavakis, Daniel S. Katz, Dorian
  Kcira, Oliver Keeble, Borut Paul Kersevan, Michael Kirby, Alexei Klimentov,
  Markus Klute, Ilya Komarov, Dmitri Konstantinov, Patrick Koppenburg, Jim
  Kowalkowski, Luke Kreczko, Thomas Kuhr, Robert Kutschke, Valentin Kuznetsov,
  Walter Lampl, Eric Lancon, David Lange, Mario Lassnig, Paul Laycock, Charles
  Leggett, James Letts, Birgit Lewendel, Teng Li, Guilherme Lima, Jacob
  Linacre, Tomas Linden, Miron Livny, Giuseppe Lo Presti, Sebastian Lopienski,
  Peter Love, Adam Lyon, Nicol\`o Magini, Zachary L. Marshall, Edoardo
  Martelli, Stewart Martin-Haugh, Pere Mato, Kajari Mazumdar, Thomas McCauley,
  Josh McFayden, Shawn McKee, Andrew McNab, Rashid Mehdiyev, Helge Meinhard,
  Dario Menasce, Patricia Mendez Lorenzo, Alaettin Serhan Mete, Michele
  Michelotto, Jovan Mitrevski, Lorenzo Moneta, Ben Morgan, Richard Mount,
  Edward Moyse, Sean Murray, Armin Nairz, Mark S. Neubauer, Andrew Norman,
  S\'ergio Novaes, Mihaly Novak, Arantza Oyanguren, Nurcan Ozturk, Andres
  Pacheco Pages, Michela Paganini, Jerome Pansanel, Vincent R. Pascuzzi, Glenn
  Patrick, Alex Pearce, Ben Pearson, Kevin Pedro, Gabriel Perdue, Antonio
  Perez-Calero Yzquierdo, Luca Perrozzi, Troels Petersen, Marko Petric, Andreas
  Petzold, J\'onatan Piedra, Leo Piilonen, Danilo Piparo, Jim Pivarski, Witold
  Pokorski, Francesco Polci, Karolos Potamianos, Fernanda Psihas, Albert Puig
  Navarro, G\""unter Quast, Gerhard Raven, J\""urgen Reuter, Alberto Ribon,
  Lorenzo Rinaldi, Martin Ritter, James Robinson, Eduardo Rodrigues, Stefan
  Roiser, David Rousseau, Gareth Roy, Grigori Rybkine, Andre Sailer, Tai
  Sakuma, Renato Santana, Andrea Sartirana, Heidi Schellman, Jaroslava
  Schovancov\'a, Steven Schramm, Markus Schulz, Andrea Sciab\`a, Sally Seidel,
  Sezen Sekmen, Cedric Serfon, Horst Severini, Elizabeth Sexton-Kennedy,
  Michael Seymour, Davide Sgalaberna, Illya Shapoval, Jamie Shiers, Jing-Ge
  Shiu, Hannah Short, Gian Piero Siroli, Sam Skipsey, Tim Smith, Scott Snyder,
  Michael D. Sokoloff, Panagiotis Spentzouris, Hartmut Stadie, Giordon Stark,
  Gordon Stewart, Graeme A. Stewart, Arturo S\'anchez, Alberto
  S\'anchez-Hern\'andez, Anyes Taffard, Umberto Tamponi, Jeff Templon, Giacomo
  Tenaglia, Vakhtang Tsulaia, Christopher Tunnell, Eric Vaandering, Andrea
  Valassi, Sofia Vallecorsa, Liviu Valsan, Peter Van Gemmeren, Renaud Vernet,
  Brett Viren, Jean-Roch Vlimant, Christian Voss, Margaret Votava, Carl
  Vuosalo, Carlos V\'azquez Sierra, Romain Wartel, Gordon T. Watts, Torre
  Wenaus, Sandro Wenzel, Mike Williams, Frank Winklmeier, Christoph Wissing,
  Frank Wuerthwein, Benjamin Wynne, Zhang Xiaomei, Wei Yang, Efe Yazgan (HEP
  Software Foundation)",A Roadmap for HEP Software and Computing R&D for the 2020s,,"Comput Softw Big Sci (2019) 3, 7",10.1007/s41781-018-0018-8,HSF-CWP-2017-01,physics.comp-ph hep-ex,http://creativecommons.org/licenses/by/4.0/,"  Particle physics has an ambitious and broad experimental programme for the
coming decades. This programme requires large investments in detector hardware,
either to build new facilities and experiments, or to upgrade existing ones.
Similarly, it requires commensurate investment in the R&D of software to
acquire, manage, process, and analyse the shear amounts of data to be recorded.
In planning for the HL-LHC in particular, it is critical that all of the
collaborating stakeholders agree on the software goals and priorities, and that
the efforts complement each other. In this spirit, this white paper describes
the R&D activities required to prepare for this software upgrade.
","[{'version': 'v1', 'created': 'Mon, 18 Dec 2017 17:55:32 GMT'}, {'version': 'v2', 'created': 'Wed, 20 Dec 2017 08:33:04 GMT'}, {'version': 'v3', 'created': 'Sun, 11 Feb 2018 19:38:37 GMT'}, {'version': 'v4', 'created': 'Sun, 8 Jul 2018 19:57:04 GMT'}, {'version': 'v5', 'created': 'Wed, 19 Dec 2018 11:07:00 GMT'}]",2020-02-07,"[['Albrecht', 'Johannes', '', 'HEP\n  Software Foundation'], ['Alves', 'Antonio Augusto', 'Jr', 'HEP\n  Software Foundation'], ['Amadio', 'Guilherme', '', 'HEP\n  Software Foundation'], ['Andronico', 'Giuseppe', '', 'HEP\n  Software Foundation'], ['Anh-Ky', 'Nguyen', '', 'HEP\n  Software Foundation'], ['Aphecetche', 'Laurent', '', 'HEP\n  Software Foundation'], ['Apostolakis', 'John', '', 'HEP\n  Software Foundation'], ['Asai', 'Makoto', '', 'HEP\n  Software Foundation'], ['Atzori', 'Luca', '', 'HEP\n  Software Foundation'], ['Babik', 'Marian', '', 'HEP\n  Software Foundation'], ['Bagliesi', 'Giuseppe', '', 'HEP\n  Software Foundation'], ['Bandieramonte', 'Marilena', '', 'HEP\n  Software Foundation'], ['Banerjee', 'Sunanda', '', 'HEP\n  Software Foundation'], ['Barisits', 'Martin', '', 'HEP\n  Software Foundation'], ['Bauerdick', 'Lothar A. T.', '', 'HEP\n  Software Foundation'], ['Belforte', 'Stefano', '', 'HEP\n  Software Foundation'], ['Benjamin', 'Douglas', '', 'HEP\n  Software Foundation'], ['Bernius', 'Catrin', '', 'HEP\n  Software Foundation'], ['Bhimji', 'Wahid', '', 'HEP\n  Software Foundation'], ['Bianchi', 'Riccardo Maria', '', 'HEP\n  Software Foundation'], ['Bird', 'Ian', '', 'HEP\n  Software Foundation'], ['Biscarat', 'Catherine', '', 'HEP\n  Software Foundation'], ['Blomer', 'Jakob', '', 'HEP\n  Software Foundation'], ['Bloom', 'Kenneth', '', 'HEP\n  Software Foundation'], ['Boccali', 'Tommaso', '', 'HEP\n  Software Foundation'], ['Bockelman', 'Brian', '', 'HEP\n  Software Foundation'], ['Bold', 'Tomasz', '', 'HEP\n  Software Foundation'], ['Bonacorsi', 'Daniele', '', 'HEP\n  Software Foundation'], ['Boveia', 'Antonio', '', 'HEP\n  Software Foundation'], ['Bozzi', 'Concezio', '', 'HEP\n  Software Foundation'], ['Bracko', 'Marko', '', 'HEP\n  Software Foundation'], ['Britton', 'David', '', 'HEP\n  Software Foundation'], ['Buckley', 'Andy', '', 'HEP\n  Software Foundation'], ['Buncic', 'Predrag', '', 'HEP\n  Software Foundation'], ['Calafiura', 'Paolo', '', 'HEP\n  Software Foundation'], ['Campana', 'Simone', '', 'HEP\n  Software Foundation'], ['Canal', 'Philippe', '', 'HEP\n  Software Foundation'], ['Canali', 'Luca', '', 'HEP\n  Software Foundation'], ['Carlino', 'Gianpaolo', '', 'HEP\n  Software Foundation'], ['Castro', 'Nuno', '', 'HEP\n  Software Foundation'], ['Cattaneo', 'Marco', '', 'HEP\n  Software Foundation'], ['Cerminara', 'Gianluca', '', 'HEP\n  Software Foundation'], ['Villanueva', 'Javier Cervantes', '', 'HEP\n  Software Foundation'], ['Chang', 'Philip', '', 'HEP\n  Software Foundation'], ['Chapman', 'John', '', 'HEP\n  Software Foundation'], ['Chen', 'Gang', '', 'HEP\n  Software Foundation'], ['Childers', 'Taylor', '', 'HEP\n  Software Foundation'], ['Clarke', 'Peter', '', 'HEP\n  Software Foundation'], ['Clemencic', 'Marco', '', 'HEP\n  Software Foundation'], ['Cogneras', 'Eric', '', 'HEP\n  Software Foundation'], ['Coles', 'Jeremy', '', 'HEP\n  Software Foundation'], ['Collier', 'Ian', '', 'HEP\n  Software Foundation'], ['Colling', 'David', '', 'HEP\n  Software Foundation'], ['Corti', 'Gloria', '', 'HEP\n  Software Foundation'], ['Cosmo', 'Gabriele', '', 'HEP\n  Software Foundation'], ['Costanzo', 'Davide', '', 'HEP\n  Software Foundation'], ['Couturier', 'Ben', '', 'HEP\n  Software Foundation'], ['Cranmer', 'Kyle', '', 'HEP\n  Software Foundation'], ['Cranshaw', 'Jack', '', 'HEP\n  Software Foundation'], ['Cristella', 'Leonardo', '', 'HEP\n  Software Foundation'], ['Crooks', 'David', '', 'HEP\n  Software Foundation'], ['Crépé-Renaudin', 'Sabine', '', 'HEP\n  Software Foundation'], ['Currie', 'Robert', '', 'HEP\n  Software Foundation'], ['Dallmeier-Tiessen', 'Sünje', '', 'HEP\n  Software Foundation'], ['De', 'Kaushik', '', 'HEP\n  Software Foundation'], ['De Cian', 'Michel', '', 'HEP\n  Software Foundation'], ['De Roeck', 'Albert', '', 'HEP\n  Software Foundation'], ['Peris', 'Antonio Delgado', '', 'HEP\n  Software Foundation'], ['Derue', 'Frédéric', '', 'HEP\n  Software Foundation'], ['Di Girolamo', 'Alessandro', '', 'HEP\n  Software Foundation'], ['Di Guida', 'Salvatore', '', 'HEP\n  Software Foundation'], ['Dimitrov', 'Gancho', '', 'HEP\n  Software Foundation'], ['Doglioni', 'Caterina', '', 'HEP\n  Software Foundation'], ['Dotti', 'Andrea', '', 'HEP\n  Software Foundation'], ['Duellmann', 'Dirk', '', 'HEP\n  Software Foundation'], ['Duflot', 'Laurent', '', 'HEP\n  Software Foundation'], ['Dykstra', 'Dave', '', 'HEP\n  Software Foundation'], ['Dziedziniewicz-Wojcik', 'Katarzyna', '', 'HEP\n  Software Foundation'], ['Dziurda', 'Agnieszka', '', 'HEP\n  Software Foundation'], ['Egede', 'Ulrik', '', 'HEP\n  Software Foundation'], ['Elmer', 'Peter', '', 'HEP\n  Software Foundation'], ['Elmsheuser', 'Johannes', '', 'HEP\n  Software Foundation'], ['Elvira', 'V. Daniel', '', 'HEP\n  Software Foundation'], ['Eulisse', 'Giulio', '', 'HEP\n  Software Foundation'], ['Farrell', 'Steven', '', 'HEP\n  Software Foundation'], ['Ferber', 'Torben', '', 'HEP\n  Software Foundation'], ['Filipcic', 'Andrej', '', 'HEP\n  Software Foundation'], ['Fisk', 'Ian', '', 'HEP\n  Software Foundation'], ['Fitzpatrick', 'Conor', '', 'HEP\n  Software Foundation'], ['Flix', 'José', '', 'HEP\n  Software Foundation'], ['Formica', 'Andrea', '', 'HEP\n  Software Foundation'], ['Forti', 'Alessandra', '', 'HEP\n  Software Foundation'], ['Franzoni', 'Giovanni', '', 'HEP\n  Software Foundation'], ['Frost', 'James', '', 'HEP\n  Software Foundation'], ['Fuess', 'Stu', '', 'HEP\n  Software Foundation'], ['Gaede', 'Frank', '', 'HEP\n  Software Foundation'], ['Ganis', 'Gerardo', '', 'HEP\n  Software Foundation'], ['Gardner', 'Robert', '', 'HEP\n  Software Foundation'], ['Garonne', 'Vincent', '', 'HEP\n  Software Foundation'], ['Gellrich', 'Andreas', '', 'HEP\n  Software Foundation'], ['Genser', 'Krzysztof', '', 'HEP\n  Software Foundation'], ['George', 'Simon', '', 'HEP\n  Software Foundation'], ['Geurts', 'Frank', '', 'HEP\n  Software Foundation'], ['Gheata', 'Andrei', '', 'HEP\n  Software Foundation'], ['Gheata', 'Mihaela', '', 'HEP\n  Software Foundation'], ['Giacomini', 'Francesco', '', 'HEP\n  Software Foundation'], ['Giagu', 'Stefano', '', 'HEP\n  Software Foundation'], ['Giffels', 'Manuel', '', 'HEP\n  Software Foundation'], ['Gingrich', 'Douglas', '', 'HEP\n  Software Foundation'], ['Girone', 'Maria', '', 'HEP\n  Software Foundation'], ['Gligorov', 'Vladimir V.', '', 'HEP\n  Software Foundation'], ['Glushkov', 'Ivan', '', 'HEP\n  Software Foundation'], ['Gohn', 'Wesley', '', 'HEP\n  Software Foundation'], ['Lopez', 'Jose Benito Gonzalez', '', 'HEP\n  Software Foundation'], ['Caballero', 'Isidro González', '', 'HEP\n  Software Foundation'], ['Fernández', 'Juan R. González', '', 'HEP\n  Software Foundation'], ['Govi', 'Giacomo', '', 'HEP\n  Software Foundation'], ['Grandi', 'Claudio', '', 'HEP\n  Software Foundation'], ['Grasland', 'Hadrien', '', 'HEP\n  Software Foundation'], ['Gray', 'Heather', '', 'HEP\n  Software Foundation'], ['Grillo', 'Lucia', '', 'HEP\n  Software Foundation'], ['Guan', 'Wen', '', 'HEP\n  Software Foundation'], ['Gutsche', 'Oliver', '', 'HEP\n  Software Foundation'], ['Gyurjyan', 'Vardan', '', 'HEP\n  Software Foundation'], ['Hanushevsky', 'Andrew', '', 'HEP\n  Software Foundation'], ['Hariri', 'Farah', '', 'HEP\n  Software Foundation'], ['Hartmann', 'Thomas', '', 'HEP\n  Software Foundation'], ['Harvey', 'John', '', 'HEP\n  Software Foundation'], ['Hauth', 'Thomas', '', 'HEP\n  Software Foundation'], ['Hegner', 'Benedikt', '', 'HEP\n  Software Foundation'], ['Heinemann', 'Beate', '', 'HEP\n  Software Foundation'], ['Heinrich', 'Lukas', '', 'HEP\n  Software Foundation'], ['Heiss', 'Andreas', '', 'HEP\n  Software Foundation'], ['Hernández', 'José M.', '', 'HEP\n  Software Foundation'], ['Hildreth', 'Michael', '', 'HEP\n  Software Foundation'], ['Hodgkinson', 'Mark', '', 'HEP\n  Software Foundation'], ['Hoeche', 'Stefan', '', 'HEP\n  Software Foundation'], ['Holzman', 'Burt', '', 'HEP\n  Software Foundation'], ['Hristov', 'Peter', '', 'HEP\n  Software Foundation'], ['Huang', 'Xingtao', '', 'HEP\n  Software Foundation'], ['Ivanchenko', 'Vladimir N.', '', 'HEP\n  Software Foundation'], ['Ivanov', 'Todor', '', 'HEP\n  Software Foundation'], ['Iven', 'Jan', '', 'HEP\n  Software Foundation'], ['Jashal', 'Brij', '', 'HEP\n  Software Foundation'], ['Jayatilaka', 'Bodhitha', '', 'HEP\n  Software Foundation'], ['Jones', 'Roger', '', 'HEP\n  Software Foundation'], ['Jouvin', 'Michel', '', 'HEP\n  Software Foundation'], ['Jun', 'Soon Yung', '', 'HEP\n  Software Foundation'], ['Kagan', 'Michael', '', 'HEP\n  Software Foundation'], ['Kalderon', 'Charles William', '', 'HEP\n  Software Foundation'], ['Kane', 'Meghan', '', 'HEP\n  Software Foundation'], ['Karavakis', 'Edward', '', 'HEP\n  Software Foundation'], ['Katz', 'Daniel S.', '', 'HEP\n  Software Foundation'], ['Kcira', 'Dorian', '', 'HEP\n  Software Foundation'], ['Keeble', 'Oliver', '', 'HEP\n  Software Foundation'], ['Kersevan', 'Borut Paul', '', 'HEP\n  Software Foundation'], ['Kirby', 'Michael', '', 'HEP\n  Software Foundation'], ['Klimentov', 'Alexei', '', 'HEP\n  Software Foundation'], ['Klute', 'Markus', '', 'HEP\n  Software Foundation'], ['Komarov', 'Ilya', '', 'HEP\n  Software Foundation'], ['Konstantinov', 'Dmitri', '', 'HEP\n  Software Foundation'], ['Koppenburg', 'Patrick', '', 'HEP\n  Software Foundation'], ['Kowalkowski', 'Jim', '', 'HEP\n  Software Foundation'], ['Kreczko', 'Luke', '', 'HEP\n  Software Foundation'], ['Kuhr', 'Thomas', '', 'HEP\n  Software Foundation'], ['Kutschke', 'Robert', '', 'HEP\n  Software Foundation'], ['Kuznetsov', 'Valentin', '', 'HEP\n  Software Foundation'], ['Lampl', 'Walter', '', 'HEP\n  Software Foundation'], ['Lancon', 'Eric', '', 'HEP\n  Software Foundation'], ['Lange', 'David', '', 'HEP\n  Software Foundation'], ['Lassnig', 'Mario', '', 'HEP\n  Software Foundation'], ['Laycock', 'Paul', '', 'HEP\n  Software Foundation'], ['Leggett', 'Charles', '', 'HEP\n  Software Foundation'], ['Letts', 'James', '', 'HEP\n  Software Foundation'], ['Lewendel', 'Birgit', '', 'HEP\n  Software Foundation'], ['Li', 'Teng', '', 'HEP\n  Software Foundation'], ['Lima', 'Guilherme', '', 'HEP\n  Software Foundation'], ['Linacre', 'Jacob', '', 'HEP\n  Software Foundation'], ['Linden', 'Tomas', '', 'HEP\n  Software Foundation'], ['Livny', 'Miron', '', 'HEP\n  Software Foundation'], ['Presti', 'Giuseppe Lo', '', 'HEP\n  Software Foundation'], ['Lopienski', 'Sebastian', '', 'HEP\n  Software Foundation'], ['Love', 'Peter', '', 'HEP\n  Software Foundation'], ['Lyon', 'Adam', '', 'HEP\n  Software Foundation'], ['Magini', 'Nicolò', '', 'HEP\n  Software Foundation'], ['Marshall', 'Zachary L.', '', 'HEP\n  Software Foundation'], ['Martelli', 'Edoardo', '', 'HEP\n  Software Foundation'], ['Martin-Haugh', 'Stewart', '', 'HEP\n  Software Foundation'], ['Mato', 'Pere', '', 'HEP\n  Software Foundation'], ['Mazumdar', 'Kajari', '', 'HEP\n  Software Foundation'], ['McCauley', 'Thomas', '', 'HEP\n  Software Foundation'], ['McFayden', 'Josh', '', 'HEP\n  Software Foundation'], ['McKee', 'Shawn', '', 'HEP\n  Software Foundation'], ['McNab', 'Andrew', '', 'HEP\n  Software Foundation'], ['Mehdiyev', 'Rashid', '', 'HEP\n  Software Foundation'], ['Meinhard', 'Helge', '', 'HEP\n  Software Foundation'], ['Menasce', 'Dario', '', 'HEP\n  Software Foundation'], ['Lorenzo', 'Patricia Mendez', '', 'HEP\n  Software Foundation'], ['Mete', 'Alaettin Serhan', '', 'HEP\n  Software Foundation'], ['Michelotto', 'Michele', '', 'HEP\n  Software Foundation'], ['Mitrevski', 'Jovan', '', 'HEP\n  Software Foundation'], ['Moneta', 'Lorenzo', '', 'HEP\n  Software Foundation'], ['Morgan', 'Ben', '', 'HEP\n  Software Foundation'], ['Mount', 'Richard', '', 'HEP\n  Software Foundation'], ['Moyse', 'Edward', '', 'HEP\n  Software Foundation'], ['Murray', 'Sean', '', 'HEP\n  Software Foundation'], ['Nairz', 'Armin', '', 'HEP\n  Software Foundation'], ['Neubauer', 'Mark S.', '', 'HEP\n  Software Foundation'], ['Norman', 'Andrew', '', 'HEP\n  Software Foundation'], ['Novaes', 'Sérgio', '', 'HEP\n  Software Foundation'], ['Novak', 'Mihaly', '', 'HEP\n  Software Foundation'], ['Oyanguren', 'Arantza', '', 'HEP\n  Software Foundation'], ['Ozturk', 'Nurcan', '', 'HEP\n  Software Foundation'], ['Pages', 'Andres Pacheco', '', 'HEP\n  Software Foundation'], ['Paganini', 'Michela', '', 'HEP\n  Software Foundation'], ['Pansanel', 'Jerome', '', 'HEP\n  Software Foundation'], ['Pascuzzi', 'Vincent R.', '', 'HEP\n  Software Foundation'], ['Patrick', 'Glenn', '', 'HEP\n  Software Foundation'], ['Pearce', 'Alex', '', 'HEP\n  Software Foundation'], ['Pearson', 'Ben', '', 'HEP\n  Software Foundation'], ['Pedro', 'Kevin', '', 'HEP\n  Software Foundation'], ['Perdue', 'Gabriel', '', 'HEP\n  Software Foundation'], ['Yzquierdo', 'Antonio Perez-Calero', '', 'HEP\n  Software Foundation'], ['Perrozzi', 'Luca', '', 'HEP\n  Software Foundation'], ['Petersen', 'Troels', '', 'HEP\n  Software Foundation'], ['Petric', 'Marko', '', 'HEP\n  Software Foundation'], ['Petzold', 'Andreas', '', 'HEP\n  Software Foundation'], ['Piedra', 'Jónatan', '', 'HEP\n  Software Foundation'], ['Piilonen', 'Leo', '', 'HEP\n  Software Foundation'], ['Piparo', 'Danilo', '', 'HEP\n  Software Foundation'], ['Pivarski', 'Jim', '', 'HEP\n  Software Foundation'], ['Pokorski', 'Witold', '', 'HEP\n  Software Foundation'], ['Polci', 'Francesco', '', 'HEP\n  Software Foundation'], ['Potamianos', 'Karolos', '', 'HEP\n  Software Foundation'], ['Psihas', 'Fernanda', '', 'HEP\n  Software Foundation'], ['Navarro', 'Albert Puig', '', 'HEP\n  Software Foundation'], ['Quast', 'Günter', '', 'HEP\n  Software Foundation'], ['Raven', 'Gerhard', '', 'HEP\n  Software Foundation'], ['Reuter', 'Jürgen', '', 'HEP\n  Software Foundation'], ['Ribon', 'Alberto', '', 'HEP\n  Software Foundation'], ['Rinaldi', 'Lorenzo', '', 'HEP\n  Software Foundation'], ['Ritter', 'Martin', '', 'HEP\n  Software Foundation'], ['Robinson', 'James', '', 'HEP\n  Software Foundation'], ['Rodrigues', 'Eduardo', '', 'HEP\n  Software Foundation'], ['Roiser', 'Stefan', '', 'HEP\n  Software Foundation'], ['Rousseau', 'David', '', 'HEP\n  Software Foundation'], ['Roy', 'Gareth', '', 'HEP\n  Software Foundation'], ['Rybkine', 'Grigori', '', 'HEP\n  Software Foundation'], ['Sailer', 'Andre', '', 'HEP\n  Software Foundation'], ['Sakuma', 'Tai', '', 'HEP\n  Software Foundation'], ['Santana', 'Renato', '', 'HEP\n  Software Foundation'], ['Sartirana', 'Andrea', '', 'HEP\n  Software Foundation'], ['Schellman', 'Heidi', '', 'HEP\n  Software Foundation'], ['Schovancová', 'Jaroslava', '', 'HEP\n  Software Foundation'], ['Schramm', 'Steven', '', 'HEP\n  Software Foundation'], ['Schulz', 'Markus', '', 'HEP\n  Software Foundation'], ['Sciabà', 'Andrea', '', 'HEP\n  Software Foundation'], ['Seidel', 'Sally', '', 'HEP\n  Software Foundation'], ['Sekmen', 'Sezen', '', 'HEP\n  Software Foundation'], ['Serfon', 'Cedric', '', 'HEP\n  Software Foundation'], ['Severini', 'Horst', '', 'HEP\n  Software Foundation'], ['Sexton-Kennedy', 'Elizabeth', '', 'HEP\n  Software Foundation'], ['Seymour', 'Michael', '', 'HEP\n  Software Foundation'], ['Sgalaberna', 'Davide', '', 'HEP\n  Software Foundation'], ['Shapoval', 'Illya', '', 'HEP\n  Software Foundation'], ['Shiers', 'Jamie', '', 'HEP\n  Software Foundation'], ['Shiu', 'Jing-Ge', '', 'HEP\n  Software Foundation'], ['Short', 'Hannah', '', 'HEP\n  Software Foundation'], ['Siroli', 'Gian Piero', '', 'HEP\n  Software Foundation'], ['Skipsey', 'Sam', '', 'HEP\n  Software Foundation'], ['Smith', 'Tim', '', 'HEP\n  Software Foundation'], ['Snyder', 'Scott', '', 'HEP\n  Software Foundation'], ['Sokoloff', 'Michael D.', '', 'HEP\n  Software Foundation'], ['Spentzouris', 'Panagiotis', '', 'HEP\n  Software Foundation'], ['Stadie', 'Hartmut', '', 'HEP\n  Software Foundation'], ['Stark', 'Giordon', '', 'HEP\n  Software Foundation'], ['Stewart', 'Gordon', '', 'HEP\n  Software Foundation'], ['Stewart', 'Graeme A.', '', 'HEP\n  Software Foundation'], ['Sánchez', 'Arturo', '', 'HEP\n  Software Foundation'], ['Sánchez-Hernández', 'Alberto', '', 'HEP\n  Software Foundation'], ['Taffard', 'Anyes', '', 'HEP\n  Software Foundation'], ['Tamponi', 'Umberto', '', 'HEP\n  Software Foundation'], ['Templon', 'Jeff', '', 'HEP\n  Software Foundation'], ['Tenaglia', 'Giacomo', '', 'HEP\n  Software Foundation'], ['Tsulaia', 'Vakhtang', '', 'HEP\n  Software Foundation'], ['Tunnell', 'Christopher', '', 'HEP\n  Software Foundation'], ['Vaandering', 'Eric', '', 'HEP\n  Software Foundation'], ['Valassi', 'Andrea', '', 'HEP\n  Software Foundation'], ['Vallecorsa', 'Sofia', '', 'HEP\n  Software Foundation'], ['Valsan', 'Liviu', '', 'HEP\n  Software Foundation'], ['Van Gemmeren', 'Peter', '', 'HEP\n  Software Foundation'], ['Vernet', 'Renaud', '', 'HEP\n  Software Foundation'], ['Viren', 'Brett', '', 'HEP\n  Software Foundation'], ['Vlimant', 'Jean-Roch', '', 'HEP\n  Software Foundation'], ['Voss', 'Christian', '', 'HEP\n  Software Foundation'], ['Votava', 'Margaret', '', 'HEP\n  Software Foundation'], ['Vuosalo', 'Carl', '', 'HEP\n  Software Foundation'], ['Sierra', 'Carlos Vázquez', '', 'HEP\n  Software Foundation'], ['Wartel', 'Romain', '', 'HEP\n  Software Foundation'], ['Watts', 'Gordon T.', '', 'HEP\n  Software Foundation'], ['Wenaus', 'Torre', '', 'HEP\n  Software Foundation'], ['Wenzel', 'Sandro', '', 'HEP\n  Software Foundation'], ['Williams', 'Mike', '', 'HEP\n  Software Foundation'], ['Winklmeier', 'Frank', '', 'HEP\n  Software Foundation'], ['Wissing', 'Christoph', '', 'HEP\n  Software Foundation'], ['Wuerthwein', 'Frank', '', 'HEP\n  Software Foundation'], ['Wynne', 'Benjamin', '', 'HEP\n  Software Foundation'], ['Xiaomei', 'Zhang', '', 'HEP\n  Software Foundation'], ['Yang', 'Wei', '', 'HEP\n  Software Foundation'], ['Yazgan', 'Efe', '', 'HEP\n  Software Foundation']]"
2108.11262,Mehdi Khoshboresh-Masouleh,"Mehdi Khoshboresh-Masouleh, Reza Shah-Hosseini",Deep few-shot learning for bi-temporal building change detection,"5 pages, 3 figures","ISPRS-International Archives of the Photogrammetry, Remote Sensing
  and Spatial Information Sciences - 2021",,,cs.CV cs.LG eess.IV,http://creativecommons.org/licenses/by/4.0/,"  In real-world applications (e.g., change detection), annotating images is
very expensive. To build effective deep learning models in these applications,
deep few-shot learning methods have been developed and prove to be a robust
approach in small training data. The analysis of building change detection from
high spatial resolution remote sensing observations is important research in
photogrammetry, computer vision, and remote sensing nowadays, which can be
widely used in a variety of real-world applications, such as map updating. As
manual high resolution image interpretation is expensive and time-consuming,
building change detection methods are of high interest. The interest in
developing building change detection approaches from optical remote sensing
images is rapidly increasing due to larger coverages, and lower costs of
optical images. In this study, we focus on building change detection analysis
on a small set of building change from different regions that sit in several
cities. In this paper, a new deep few-shot learning method is proposed for
building change detection using Monte Carlo dropout and remote sensing
observations. The setup is based on a small dataset, including bitemporal
optical images labeled for building change detection.
","[{'version': 'v1', 'created': 'Wed, 25 Aug 2021 14:38:21 GMT'}, {'version': 'v2', 'created': 'Tue, 5 Oct 2021 10:48:15 GMT'}]",2021-10-06,"[['Khoshboresh-Masouleh', 'Mehdi', ''], ['Shah-Hosseini', 'Reza', '']]"
1903.00114,Clement Lee,Clement Lee and Darren J Wilkinson,A Review of Stochastic Block Models and Extensions for Graph Clustering,"93 pages, 3 figures, 4 tables",,10.1007/s41109-019-0232-2,,stat.ML cs.LG,http://creativecommons.org/licenses/by/4.0/,"  There have been rapid developments in model-based clustering of graphs, also
known as block modelling, over the last ten years or so. We review different
approaches and extensions proposed for different aspects in this area, such as
the type of the graph, the clustering approach, the inference approach, and
whether the number of groups is selected or estimated. We also review models
that combine block modelling with topic modelling and/or longitudinal
modelling, regarding how these models deal with multiple types of data. How
different approaches cope with various issues will be summarised and compared,
to facilitate the demand of practitioners for a concise overview of the current
status of these areas of literature.
","[{'version': 'v1', 'created': 'Fri, 1 Mar 2019 00:30:09 GMT'}, {'version': 'v2', 'created': 'Wed, 30 Oct 2019 20:46:20 GMT'}]",2020-01-01,"[['Lee', 'Clement', ''], ['Wilkinson', 'Darren J', '']]"
2109.10232,Haoyan Liu,"Haoyan Liu, Yanming Liu, and Min Yang",A Low Complexity MAP Detector for OTFS Modulation in Logarithmic Domain,,,,,cs.IT math.IT,http://creativecommons.org/licenses/by/4.0/,"  Orthogonal time-frequency space (OTFS) has been confirmed to take advantage
of full time-frequency diversity to significantly improve error performance in
high-mobility scenarios. We found that the proposed message passing (MP) and
variational Bayes (VB) detectors can achieve approximate maximum a posteriori
(MAP) detection, the interferences cannot be completely eliminated in the
absence of noise. To achieve near-optimal MAP detection, this letter proposes a
novel detection method based on sum-product algorithm (SPA) with low
complexity. Leveraging subtly factorized posteriori probabilities, the obtained
pairwise interactions can effectively avoid enumeration of high-dimensional
variables, thereby making it applicable to fractional Doppler cases. We further
simplify the proposed algorithm in the logarithmic domain so that the message
propagation processing only involves addition. Finally, simulations results
demonstrate the superior error performance gains of our proposed algorithm at
high signal-to-noise ratios (SNRs).
","[{'version': 'v1', 'created': 'Tue, 21 Sep 2021 14:58:23 GMT'}]",2021-09-22,"[['Liu', 'Haoyan', ''], ['Liu', 'Yanming', ''], ['Yang', 'Min', '']]"
2105.02958,Andrew Soroka,"Andrey Soroka (1), Alex Meshcheryakov (2), Sergey Gerasimov (1) ((1)
  Faculty of Computational Mathematics and Cybernetics Lomonosov Moscow State
  University, (2) Space Research Institute of RAS)","Morphological classification of astronomical images with limited
  labelling",,,,,cs.CV astro-ph.GA cs.LG,http://creativecommons.org/licenses/by/4.0/,"  The task of morphological classification is complex for simple
parameterization, but important for research in the galaxy evolution field.
Future galaxy surveys (e.g. EUCLID) will collect data about more than a $10^9$
galaxies. To obtain morphological information one needs to involve people to
mark up galaxy images, which requires either a considerable amount of money or
a huge number of volunteers. We propose an effective semi-supervised approach
for galaxy morphology classification task, based on active learning of
adversarial autoencoder (AAE) model. For a binary classification problem (top
level question of Galaxy Zoo 2 decision tree) we achieved accuracy 93.1% on the
test part with only 0.86 millions markup actions, this model can easily scale
up on any number of images. Our best model with additional markup achieves
accuracy of 95.5%. To the best of our knowledge it is a first time AAE
semi-supervised learning model used in astronomy.
","[{'version': 'v1', 'created': 'Tue, 27 Apr 2021 19:26:27 GMT'}]",2021-05-10,"[['Soroka', 'Andrey', ''], ['Meshcheryakov', 'Alex', ''], ['Gerasimov', 'Sergey', '']]"
2110.06155,Yuan Du,"Zhuang Shao, Xiaoliang Chen, Li Du, Lei Chen, Yuan Du, Wei Zhuang,
  Huadong Wei, Chenjia Xie, and Zhongfeng Wang","Memory-Efficient CNN Accelerator Based on Interlayer Feature Map
  Compression",,,,,cs.AR cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Existing deep convolutional neural networks (CNNs) generate massive
interlayer feature data during network inference. To maintain real-time
processing in embedded systems, large on-chip memory is required to buffer the
interlayer feature maps. In this paper, we propose an efficient hardware
accelerator with an interlayer feature compression technique to significantly
reduce the required on-chip memory size and off-chip memory access bandwidth.
The accelerator compresses interlayer feature maps through transforming the
stored data into frequency domain using hardware-implemented 8x8 discrete
cosine transform (DCT). The high-frequency components are removed after the DCT
through quantization. Sparse matrix compression is utilized to further compress
the interlayer feature maps. The on-chip memory allocation scheme is designed
to support dynamic configuration of the feature map buffer size and scratch pad
size according to different network-layer requirements. The hardware
accelerator combines compression, decompression, and CNN acceleration into one
computing stream, achieving minimal compressing and processing delay. A
prototype accelerator is implemented on an FPGA platform and also synthesized
in TSMC 28-nm COMS technology. It achieves 403GOPS peak throughput and
1.4x~3.3x interlayer feature map reduction by adding light hardware area
overhead, making it a promising hardware accelerator for intelligent IoT
devices.
","[{'version': 'v1', 'created': 'Tue, 12 Oct 2021 16:50:35 GMT'}]",2021-10-13,"[['Shao', 'Zhuang', ''], ['Chen', 'Xiaoliang', ''], ['Du', 'Li', ''], ['Chen', 'Lei', ''], ['Du', 'Yuan', ''], ['Zhuang', 'Wei', ''], ['Wei', 'Huadong', ''], ['Xie', 'Chenjia', ''], ['Wang', 'Zhongfeng', '']]"
2112.12054,Chennakesava Kadapa,Chennakesava Kadapa,"Machine Learning for Computational Science and Engineering -- a brief
  introduction and some critical questions",16 papges,,,,cs.LG cs.CE physics.comp-ph,http://creativecommons.org/licenses/by/4.0/,"  Artificial Intelligence (AI) is now entering every sub-field of science,
technology, engineering, arts, and management. Thanks to the hype and
availability of research funds, it is being adapted in many fields without much
thought. Computational Science and Engineering (CS&E) is one such sub-field. By
highlighting some critical questions around the issues and challenges in
adapting Machine Learning (ML) for CS&E, most of which are often overlooked in
journal papers, this contribution hopes to offer some insights into the
adaptation of ML for applications in CS\&E and related fields. This is a
general-purpose article written for a general audience and researchers new to
the fields of ML and/or CS\&E. This work focuses only on the forward problems
in computational science and engineering. Some basic equations and MATLAB code
are also provided to help the reader understand the basics.
","[{'version': 'v1', 'created': 'Wed, 22 Dec 2021 17:25:32 GMT'}]",2021-12-23,"[['Kadapa', 'Chennakesava', '']]"
1912.07380,Soheil Habibian,Soheil Habibian,Analysis and Control of Fiber-Reinforced Elastomeric Enclosures (FREEs),"Master's Thesis, Department of Mechanical Engineering, Bucknell
  University, 2019. Version of Record can be found at
  https://digitalcommons.bucknell.edu/masters_theses/229/",,,,cs.RO,http://creativecommons.org/licenses/by/4.0/,"  While rigid robots are extensively used in various applications, they are
limited in the tasks they can perform and can be unsafe in close human-robot
interactions. Soft robots on the other hand surpass the capabilities of rigid
robots in several ways, such as compatibility with the work environments,
degrees of freedom, manufacturing costs, and safe interactions with the
environment. This thesis studies the behavior of Fiber Reinforced Elastomeric
Enclosures (FREEs) as a particular type of soft pneumatic actuator that can be
used in soft manipulators. A dynamic lumped-parameter model is created to
simulate the motion of a single FREE under various operating conditions and to
inform the design of a controller. The proposed PID controller determines the
response of the FREE to a defined step input or a trajectory following
polynomial function, using rotation angle to control the orientation of the
end-effector. Additionally, Finite Element Analysis method is employed,
incorporating the inherently nonlinear material properties of FREEs, to
precisely evaluate various parameters and configurations of FREEs. This tool is
also used to determine the workspace of multiple FREEs in a module, which is
essentially a building block of a soft robotic arm.
","[{'version': 'v1', 'created': 'Fri, 13 Dec 2019 17:06:05 GMT'}, {'version': 'v2', 'created': 'Fri, 24 Dec 2021 17:11:47 GMT'}]",2021-12-28,"[['Habibian', 'Soheil', '']]"
2001.05569,Peter B. Lerner,P. B. Lerner,Foundations of Quantum Mechanics according to my teachers,,,,,physics.hist-ph quant-ph,http://creativecommons.org/licenses/by/4.0/,"  These are author's recollections of informal discussions on foundations of
quantum mechanics, which happened in his presence in 1970-80s
","[{'version': 'v1', 'created': 'Wed, 15 Jan 2020 21:43:43 GMT'}]",2020-01-21,"[['Lerner', 'P. B.', '']]"
2107.03857,Christof Schmidhuber,Christof Schmidhuber,Financial Markets and the Phase Transition between Water and Steam,"34 pages, 7 figures, significantly revised section 4, added
  predictions for Hurst exponents",,10.1016/j.physa.2022.126873,,q-fin.ST hep-th nlin.CG physics.soc-ph q-fin.GN,http://creativecommons.org/licenses/by/4.0/,"  Motivated by empirical observations on the interplay of trends and reversion,
a lattice gas model of financial markets is presented. The shares of an asset
are modeled by gas molecules that are distributed across a hidden social
network of investors. The model is equivalent to the Ising model on this
network, whose magnetization represents the deviation of the asset price from
its value. Moreover, the system should drive itself to its critical temperature
in efficient markets. There, it is characterized by universal critical
exponents, in analogy with the second-order phase transition between water and
steam. These critical exponents imply predictions for the auto-correlations of
financial market returns and for Hurst exponents. For a simple network
topology, consistency with empirical observations implies a fractal network
dimension near 3, and a correlation time at least as long as the economic cyle.
To also explain the observed market auto-correlations at intermediate scales,
the model should be extended beyond the critical domain, to other network
topologies, and to other models of critical dynamics.
","[{'version': 'v1', 'created': 'Thu, 8 Jul 2021 14:16:32 GMT'}, {'version': 'v2', 'created': 'Fri, 23 Jul 2021 15:55:45 GMT'}, {'version': 'v3', 'created': 'Wed, 15 Dec 2021 15:24:27 GMT'}]",2022-03-02,"[['Schmidhuber', 'Christof', '']]"
1805.07493,Md. Golam Kibria,"Md. Golam Kibria, Hassan Rivaz",Global Ultrasound Elastography Using Convolutional Neural Network,"4 pages, 4 figures; added acknowledgment section, submission type
  latex",,10.1007/978-3-030-01045-4_3,,eess.IV,http://creativecommons.org/licenses/by/4.0/,"  Displacement estimation is very important in ultrasound elastography and
failing to estimate displacement correctly results in failure in generating
strain images. As conventional ultrasound elastography techniques suffer from
decorrelation noise, they are prone to fail in estimating displacement between
echo signals obtained during tissue distortions. This study proposes a novel
elastography technique which addresses the decorrelation in estimating
displacement field. We call our method GLUENet (GLobal Ultrasound Elastography
Network) which uses deep Convolutional Neural Network (CNN) to get a coarse
time-delay estimation between two ultrasound images. This displacement is later
used for formulating a nonlinear cost function which incorporates similarity of
RF data intensity and prior information of estimated displacement. By
optimizing this cost function, we calculate the finer displacement by
exploiting all the information of all the samples of RF data simultaneously.
The Contrast to Noise Ratio (CNR) and Signal to Noise Ratio (SNR) of the strain
images from our technique is very much close to that of strain images from
GLUE. While most elastography algorithms are sensitive to parameter tuning, our
robust algorithm is substantially less sensitive to parameter tuning.
","[{'version': 'v1', 'created': 'Sat, 19 May 2018 02:35:32 GMT'}, {'version': 'v2', 'created': 'Tue, 12 Jun 2018 17:29:50 GMT'}]",2019-04-25,"[['Kibria', 'Md. Golam', ''], ['Rivaz', 'Hassan', '']]"
2108.03498,Xianghao Zhan,"Xianghao Zhan, Yiheng Li, Yuzhe Liu, Nicholas J. Cecchi, Olivier
  Gevaert, Michael M. Zeineh, Gerald A. Grant, David B. Camarillo","Kinematics clustering enables head impact subtyping for better traumatic
  brain injury prediction",4 figures,,,,stat.AP cs.LG q-bio.QM q-bio.TO,http://creativecommons.org/licenses/by/4.0/,"  Traumatic brain injury can be caused by various types of head impacts.
However, due to different kinematic characteristics, many brain injury risk
estimation models are not generalizable across the variety of impacts that
humans may sustain. The current definitions of head impact subtypes are based
on impact sources (e.g., football, traffic accident), which may not reflect the
intrinsic kinematic similarities of impacts across the impact sources. To
investigate the potential new definitions of impact subtypes based on
kinematics, 3,161 head impacts from various sources including simulation,
college football, mixed martial arts, and car racing were collected. We applied
the K-means clustering to cluster the impacts on 16 standardized temporal
features from head rotation kinematics. Then, we developed subtype-specific
ridge regression models for cumulative strain damage (using the threshold of
15%), which significantly improved the estimation accuracy compared with the
baseline method which mixed impacts from different sources and developed one
model (R^2 from 0.7 to 0.9). To investigate the effect of kinematic features,
we presented the top three critical features (maximum resultant angular
acceleration, maximum angular acceleration along the z-axis, maximum linear
acceleration along the y-axis) based on regression accuracy and used logistic
regression to find the critical points for each feature that partitioned the
subtypes. This study enables researchers to define head impact subtypes in a
data-driven manner, which leads to more generalizable brain injury risk
estimation.
","[{'version': 'v1', 'created': 'Sat, 7 Aug 2021 18:31:05 GMT'}]",2021-08-10,"[['Zhan', 'Xianghao', ''], ['Li', 'Yiheng', ''], ['Liu', 'Yuzhe', ''], ['Cecchi', 'Nicholas J.', ''], ['Gevaert', 'Olivier', ''], ['Zeineh', 'Michael M.', ''], ['Grant', 'Gerald A.', ''], ['Camarillo', 'David B.', '']]"
2103.09959,Yifan Du,"Yifan Du, Tamer A. Zaki",Evolutional Deep Neural Network,,"Phys. Rev. E 104, 045303 (2021)",10.1103/PhysRevE.104.045303,,physics.comp-ph cs.LG physics.flu-dyn,http://creativecommons.org/licenses/by/4.0/,"  The notion of an Evolutional Deep Neural Network (EDNN) is introduced for the
solution of partial differential equations (PDE). The parameters of the network
are trained to represent the initial state of the system only, and are
subsequently updated dynamically, without any further training, to provide an
accurate prediction of the evolution of the PDE system. In this framework, the
network parameters are treated as functions with respect to the appropriate
coordinate and are numerically updated using the governing equations. By
marching the neural network weights in the parameter space, EDNN can predict
state-space trajectories that are indefinitely long, which is difficult for
other neural network approaches. Boundary conditions of the PDEs are treated as
hard constraints, are embedded into the neural network, and are therefore
exactly satisfied throughout the entire solution trajectory. Several
applications including the heat equation, the advection equation, the Burgers
equation, the Kuramoto Sivashinsky equation and the Navier-Stokes equations are
solved to demonstrate the versatility and accuracy of EDNN. The application of
EDNN to the incompressible Navier-Stokes equation embeds the divergence-free
constraint into the network design so that the projection of the momentum
equation to solenoidal space is implicitly achieved. The numerical results
verify the accuracy of EDNN solutions relative to analytical and benchmark
numerical solutions, both for the transient dynamics and statistics of the
system.
","[{'version': 'v1', 'created': 'Thu, 18 Mar 2021 00:33:11 GMT'}]",2021-10-13,"[['Du', 'Yifan', ''], ['Zaki', 'Tamer A.', '']]"
2012.00859,Morteza Ghahremani,Morteza Ghahremani and Yonghuai Liu and Bernard Tiddeman,FFD: Fast Feature Detector,,"IEEE Transactions on Image Processing, 2021",10.1109/TIP.2020.3042057,,cs.CV,http://creativecommons.org/licenses/by/4.0/,"  Scale-invariance, good localization and robustness to noise and distortions
are the main properties that a local feature detector should possess. Most
existing local feature detectors find excessive unstable feature points that
increase the number of keypoints to be matched and the computational time of
the matching step. In this paper, we show that robust and accurate keypoints
exist in the specific scale-space domain. To this end, we first formulate the
superimposition problem into a mathematical model and then derive a closed-form
solution for multiscale analysis. The model is formulated via
difference-of-Gaussian (DoG) kernels in the continuous scale-space domain, and
it is proved that setting the scale-space pyramid's blurring ratio and
smoothness to 2 and 0.627, respectively, facilitates the detection of reliable
keypoints. For the applicability of the proposed model to discrete images, we
discretize it using the undecimated wavelet transform and the cubic spline
function. Theoretically, the complexity of our method is less than 5\% of that
of the popular baseline Scale Invariant Feature Transform (SIFT). Extensive
experimental results show the superiority of the proposed feature detector over
the existing representative hand-crafted and learning-based techniques in
accuracy and computational time. The code and supplementary materials can be
found at~{\url{https://github.com/mogvision/FFD}}.
","[{'version': 'v1', 'created': 'Tue, 1 Dec 2020 21:56:35 GMT'}]",2021-02-03,"[['Ghahremani', 'Morteza', ''], ['Liu', 'Yonghuai', ''], ['Tiddeman', 'Bernard', '']]"
2107.13788,Tom Wehrbein,"Tom Wehrbein, Marco Rudolph, Bodo Rosenhahn, Bastian Wandt",Probabilistic Monocular 3D Human Pose Estimation with Normalizing Flows,Accepted to ICCV 2021,,,,cs.CV,http://creativecommons.org/licenses/by/4.0/,"  3D human pose estimation from monocular images is a highly ill-posed problem
due to depth ambiguities and occlusions. Nonetheless, most existing works
ignore these ambiguities and only estimate a single solution. In contrast, we
generate a diverse set of hypotheses that represents the full posterior
distribution of feasible 3D poses. To this end, we propose a normalizing flow
based method that exploits the deterministic 3D-to-2D mapping to solve the
ambiguous inverse 2D-to-3D problem. Additionally, uncertain detections and
occlusions are effectively modeled by incorporating uncertainty information of
the 2D detector as condition. Further keys to success are a learned 3D pose
prior and a generalization of the best-of-M loss. We evaluate our approach on
the two benchmark datasets Human3.6M and MPI-INF-3DHP, outperforming all
comparable methods in most metrics. The implementation is available on GitHub.
","[{'version': 'v1', 'created': 'Thu, 29 Jul 2021 07:33:14 GMT'}, {'version': 'v2', 'created': 'Mon, 2 Aug 2021 07:19:48 GMT'}]",2021-08-03,"[['Wehrbein', 'Tom', ''], ['Rudolph', 'Marco', ''], ['Rosenhahn', 'Bodo', ''], ['Wandt', 'Bastian', '']]"
2105.10842,Stuart Eiffert,"Stuart Eiffert, Alexander Wendel, Peter Colborne-Veel, Nicholas Leong,
  John Gardenier, and Nathan Kirchner","Toolbox Spotter: A Computer Vision System for Real World Situational
  Awareness in Heavy Industries","Published in the 37th International Symposium on Automation and
  Robotics in Construction (ISARC 2020)",,10.22260/ISARC2020/0112,,cs.RO,http://creativecommons.org/licenses/by/4.0/,"  The majority of fatalities and traumatic injuries in heavy industries involve
mobile plant and vehicles, often resulting from a lapse of attention or
communication. Existing approaches to hazard identification include the use of
human spotters, passive reversing cameras, non-differentiating proximity
sensors and tag based systems. These approaches either suffer from problems of
worker attention or require the use of additional devices on all workers and
obstacles. Whilst computer vision detection systems have previously been
deployed in structured applications such as manufacturing and on-road vehicles,
there does not yet exist a robust and portable solution for use in unstructured
environments like construction that effectively communicates risks to relevant
workers. To address these limitations, our solution, the Toolbox Spotter (TBS),
acts to improve worker safety and reduce preventable incidents by employing an
embedded robotic perception and distributed HMI alert system to augment both
detection and communication of hazards in safety critical environments. In this
paper we outline the TBS safety system and evaluate its performance based on
data from real world implementations, demonstrating the suitability of the
Toolbox Spotter for applications in heavy industries.
","[{'version': 'v1', 'created': 'Sun, 23 May 2021 01:47:12 GMT'}]",2021-05-25,"[['Eiffert', 'Stuart', ''], ['Wendel', 'Alexander', ''], ['Colborne-Veel', 'Peter', ''], ['Leong', 'Nicholas', ''], ['Gardenier', 'John', ''], ['Kirchner', 'Nathan', '']]"
2105.11013,Emna Baccour,"Mohammed Jouhari, Abdulla Al-Ali, Emna Baccour, Amr Mohamed, Aiman
  Erbad, Mohsen Guizani, Mounir Hamdi","Distributed CNN Inference on Resource-Constrained UAVs for Surveillance
  Systems: Design and Optimization",Accepted in IEEE Internet of Things Journal,,10.1109/JIOT.2021.3079164,,cs.DC cs.LG cs.SY eess.SY,http://creativecommons.org/licenses/by/4.0/,"  Unmanned Aerial Vehicles (UAVs) have attracted great interest in the last few
years owing to their ability to cover large areas and access difficult and
hazardous target zones, which is not the case of traditional systems relying on
direct observations obtained from fixed cameras and sensors. Furthermore,
thanks to the advancements in computer vision and machine learning, UAVs are
being adopted for a broad range of solutions and applications. However, Deep
Neural Networks (DNNs) are progressing toward deeper and complex models that
prevent them from being executed on-board. In this paper, we propose a DNN
distribution methodology within UAVs to enable data classification in
resource-constrained devices and avoid extra delays introduced by the
server-based solutions due to data communication over air-to-ground links. The
proposed method is formulated as an optimization problem that aims to minimize
the latency between data collection and decision-making while considering the
mobility model and the resource constraints of the UAVs as part of the
air-to-air communication. We also introduce the mobility prediction to adapt
our system to the dynamics of UAVs and the network variation. The simulation
conducted to evaluate the performance and benchmark the proposed methods,
namely Optimal UAV-based Layer Distribution (OULD) and OULD with Mobility
Prediction (OULD-MP), were run in an HPC cluster. The obtained results show
that our optimization solution outperforms the existing and heuristic-based
approaches.
","[{'version': 'v1', 'created': 'Sun, 23 May 2021 20:19:43 GMT'}]",2021-05-25,"[['Jouhari', 'Mohammed', ''], ['Al-Ali', 'Abdulla', ''], ['Baccour', 'Emna', ''], ['Mohamed', 'Amr', ''], ['Erbad', 'Aiman', ''], ['Guizani', 'Mohsen', ''], ['Hamdi', 'Mounir', '']]"
2103.04716,Nikolai Chugai,N. N. Chugai and A. D. Kudryashov,Annihilation of positrons from $^{22}$Na in novae,Accepted by Astronomy Letters,,,,astro-ph.HE,http://creativecommons.org/licenses/by/4.0/,"  We explore for the first time effects of the magnetic field on the escape of
$^{22}$Na positrons and on the flux evolution of annihilation 511 keV line in
novae. It is shown that for the white dwarf magnetic field of $\sim 10^6$ G the
field of the expanding nova shell is able to significantly impede positrons
escape and increase the time of the nova emission in 511keV up to hundreds
days.
","[{'version': 'v1', 'created': 'Mon, 8 Mar 2021 12:50:32 GMT'}]",2021-03-09,"[['Chugai', 'N. N.', ''], ['Kudryashov', 'A. D.', '']]"
2011.09596,Utkarsh Sarawgi,"Rishab Khincha, Utkarsh Sarawgi, Wazeer Zulfikar, Pattie Maes","Robustness to Missing Features using Hierarchical Clustering with Split
  Neural Networks",To appear at AAAI 2021 Student Abstract,,,,cs.LG,http://creativecommons.org/licenses/by/4.0/,"  The problem of missing data has been persistent for a long time and poses a
major obstacle in machine learning and statistical data analysis. Past works in
this field have tried using various data imputation techniques to fill in the
missing data, or training neural networks (NNs) with the missing data. In this
work, we propose a simple yet effective approach that clusters similar input
features together using hierarchical clustering and then trains proportionately
split neural networks with a joint loss. We evaluate this approach on a series
of benchmark datasets and show promising improvements even with simple
imputation techniques. We attribute this to learning through clusters of
similar features in our model architecture. The source code is available at
https://github.com/usarawgi911/Robustness-to-Missing-Features
","[{'version': 'v1', 'created': 'Thu, 19 Nov 2020 00:35:08 GMT'}]",2020-11-20,"[['Khincha', 'Rishab', ''], ['Sarawgi', 'Utkarsh', ''], ['Zulfikar', 'Wazeer', ''], ['Maes', 'Pattie', '']]"
1912.01974,Jingang Zhong,"Zibang Zhang, Xiang Li, Manhong Yao, Shujun Zheng, Guoan Zheng,
  Jingang Zhong","Image-free real-time classification of fast moving objects using
  'learned' spatial light modulation and a single-pixel detector",,,10.1364/OE.392370,,eess.IV,http://creativecommons.org/licenses/by/4.0/,"  Objects classification generally relies on image acquisition and analysis.
Real-time classification of high-speed moving objects is challenging, as both
high temporal resolution in image acquisition and low computational complexity
in objects classification algorithms are required. Here we propose and
experimentally demonstrate an approach for real-time moving objects
classification without image acquisition. As objects classification algorithms
rely on the feature information of objects, we propose to use spatial light
modulation to acquire the feature information directly rather than performing
image acquisition followed by features extraction. A convolutional neural
network is designed and trained to learn the spatial features of the target
objects. The trained network can generate structured patterns for spatial light
modulation. Using the resulting structured patterns for spatial light
modulation, the feature information of target objects can be compressively
encoded into a short light intensity sequence. The resulting one-dimensional
signal is collected by a single-pixel detector and fed to the convolutional
neural network for objects classification. As experimentally demonstrated, the
proposed approach can achieve accurate and real-time classification of fast
moving objects. The proposed method has potential applications in the fields
where fast moving objects classification in real time and for long duration is
required.
","[{'version': 'v1', 'created': 'Tue, 3 Dec 2019 02:40:13 GMT'}, {'version': 'v2', 'created': 'Thu, 5 Dec 2019 03:45:57 GMT'}]",2020-05-20,"[['Zhang', 'Zibang', ''], ['Li', 'Xiang', ''], ['Yao', 'Manhong', ''], ['Zheng', 'Shujun', ''], ['Zheng', 'Guoan', ''], ['Zhong', 'Jingang', '']]"
2202.07881,Pietro Sala,"L. Bozzelli, A. Montanari, A. Peron, P. Sala","The addition of temporal neighborhood makes the logic of prefixes and
  sub-intervals EXPSPACE-complete",arXiv admin note: substantial text overlap with arXiv:2109.08320,,,,cs.LO,http://creativecommons.org/licenses/by/4.0/,"  A classic result by Stockmeyer gives a non-elementary lower bound to the
emptiness problem for star-free generalized regular expressions. This result is
intimately connected to the satisfiability problem for interval temporal logic,
notably for formulas that make use of the so-called chop operator. Such an
operator can indeed be interpreted as the inverse of the concatenation
operation on regular languages, and this correspondence enables reductions
between non-emptiness of star-free generalized regular expressions and
satisfiability of formulas of the interval temporal logic of chop under the
homogeneity assumption. In this paper, we study the complexity of the
satisfiability problem for suitable weakenings of the chop interval temporal
logic, that can be equivalently viewed as fragments of Halpern and Shoham
interval logic. We first consider the logic $\mathsf{BD}_{hom}$ featuring
modalities $B$, for \emph{begins}, corresponding to the prefix relation on
pairs of intervals, and $D$, for \emph{during}, corresponding to the infix
relation. The homogeneous models of $\mathsf{BD}_{hom}$ naturally correspond to
languages defined by restricted forms of regular expressions, that use union,
complementation, and the inverses of the prefix and infix relations. Such a
fragment has been recently shown to be PSPACE-complete . In this paper, we
study the extension $\mathsf{BD}_{hom}$ with the temporal neighborhood modality
$A$ (corresponding to the Allen relation \emph{Meets}), and prove that it
increases both its expressiveness and complexity. In particular, we show that
the resulting logic $\mathsf{BDA}_{hom}$ is EXPSPACE-complete.
","[{'version': 'v1', 'created': 'Wed, 16 Feb 2022 06:16:50 GMT'}]",2022-02-17,"[['Bozzelli', 'L.', ''], ['Montanari', 'A.', ''], ['Peron', 'A.', ''], ['Sala', 'P.', '']]"
2201.03005,Bo Tan,"Bo Tan, Bo Sun","Using Wi-Fi Signal as Sensing Medium: Passive Radar, Channel State
  Information and Followups","4 pages, 3 figures",,,,eess.SP,http://creativecommons.org/licenses/by/4.0/,"  The idea of exploiting the Wi-Fi bursts as the medium for sensing purposes,
particularly for the human targets in the indoor environment, was cultivated in
both radar and computer science communities and it has became a noticeable
research genre with cross-disciplinary impact in security, healthcare,
human-machine interaction etc.This article comparatively introduces passive
radar based and channel state information (CSI) based approaches. For each
means, the primary design principles, signal processing and representative
applications scenarios are shown. At last, some opportunities and challenges of
Wi-Fi sensing are pointed out for the sake of stepping closer to the
practitioners and end-users.
","[{'version': 'v1', 'created': 'Sun, 9 Jan 2022 13:18:21 GMT'}]",2022-01-11,"[['Tan', 'Bo', ''], ['Sun', 'Bo', '']]"
2110.15442,Gurpreet Singh,"Soumyajit Gupta, Gurpreet Singh, Matthew Lease","Scalable Uni-directional Pareto Optimality for Multi-Task Learning with
  Constraints",,,,,cs.LG,http://creativecommons.org/licenses/by/4.0/,"  We propose a scalable Pareto solver for Multi-Objective Optimization (MOO)
problems, including support for optimization under constraints. An important
application of this solver is to estimate high-dimensional neural models for
MOO classification tasks. We demonstrate significant runtime and space
improvement using our solver \vs prior methods, verify that solutions found are
truly Pareto optimal on a benchmark set of known non-convex MOO problems from
{\em operations research}, and provide a practical evaluation against prior
methods for Multi-Task Learning (MTL).
","[{'version': 'v1', 'created': 'Thu, 28 Oct 2021 21:35:59 GMT'}]",2021-11-01,"[['Gupta', 'Soumyajit', ''], ['Singh', 'Gurpreet', ''], ['Lease', 'Matthew', '']]"
2111.11913,Rafael Celestre,"Rafael Celestre, Sergey Antipov, Edgar Gomez, Thomas Zinn, Raymond
  Barrett, Thomas Roth",Polished diamond x-ray lenses,"12 pages, 19 figures, 2 tables",,10.1107/S1600577522001795,,physics.optics physics.app-ph,http://creativecommons.org/licenses/by/4.0/,"  We present high quality bi-concave 2D focusing diamond x-ray lenses of
apex-radius $R=100~\mu$m produced via laser-ablation and improved via a
mechanical polishing process. Both for polished and unpolished individual
lenses and for stacks of 10 lenses, we show the remaining figure errors
determined using x-ray speckle tracking and compare these results to those of
commercial $R=50~\mu$m beryllium lenses that have similar focusing strength and
physical aperture. For two stacks of 10 diamond lenses (polished and
unpolished) and a stack of 11 beryllium lenses, we present measured 2D beam
profiles out of focus and wire scans to obtain the beam size in the focal
plane. These results are complemented with small angle x-ray scattering (SAXS)
measurements of a polished and an unpolished diamond lens. Again, we compare
this to the SAXS of a beryllium lens. The polished x-ray lenses show similar
figure errors to commercially available Be lenses. While the beam size in the
focal plane is comparable with that of the Be lenses, the SAXS signal of the
polished diamond lenses is considerably lower.
","[{'version': 'v1', 'created': 'Tue, 23 Nov 2021 14:52:15 GMT'}]",2022-03-17,"[['Celestre', 'Rafael', ''], ['Antipov', 'Sergey', ''], ['Gomez', 'Edgar', ''], ['Zinn', 'Thomas', ''], ['Barrett', 'Raymond', ''], ['Roth', 'Thomas', '']]"
2108.06298,Quentin G. Bailey,"Kellie O'Neal-Ault, Quentin G. Bailey, Tyann Dumerchat, Leila Haegel,
  Jay Tasson","Analysis of birefringence and dispersion effects from spacetime-symmetry
  breaking in gravitational waves","18 pages, 2 figures, accepted to Universe, matches version published","Universe 2021, 7(10), 380",10.3390/universe7100380,,gr-qc astro-ph.CO,http://creativecommons.org/licenses/by/4.0/,"  In this work, we review the effective field theory framework to search for
Lorentz and CPT symmetry breaking during the propagation of gravitational
waves. The article is written so as to bridge the gap between the theory of
spacetime-symmetry breaking and the analysis of gravitational-waves signals
detected by ground-based interferometers. The primary physical effects beyond
General Relativity that we explore here are dispersion and birefringence of
gravitational waves. We discuss their implementation in the open-source
LIGO-Virgo algorithm library suite, as well as the statistical method used to
perform a Bayesian inference of the posterior probability of the coefficients
for symmetry-breaking. We present preliminary results of this work in the form
of simulations of modified gravitational waveforms, together with sensitivity
studies of the measurements of the coefficients for Lorentz and CPT violation.
The findings show the high potential of gravitational wave sources across the
sky to probe sensitively for these signals of new physics.
","[{'version': 'v1', 'created': 'Fri, 13 Aug 2021 16:04:15 GMT'}, {'version': 'v2', 'created': 'Sat, 9 Oct 2021 17:36:32 GMT'}]",2021-10-26,"[[""O'Neal-Ault"", 'Kellie', ''], ['Bailey', 'Quentin G.', ''], ['Dumerchat', 'Tyann', ''], ['Haegel', 'Leila', ''], ['Tasson', 'Jay', '']]"
2101.10634,Akira Okawa,Nobuhito Maru and Akira Okawa,"Non-Gaussianity from $X, Y$ gauge bosons in Cosmological Collider
  Physics","30 pages, 4 figures",,,"OCU-PHYS 528, NITEP 86",hep-ph astro-ph.CO gr-qc hep-th,http://creativecommons.org/licenses/by/4.0/,"  Heavy fields of Hubble scale order present during inflation contribute to the
non-Gaussian signature for the three-point function of the inflaton. Taking
into account that Hubble scale is around the scale of grand unified theory
(GUT), this opens a possibility that the GUT scale signatures, which are very
hard to be discovered at collider, might be detectable by using information
from the precise observations of cosmic microwave background. We discuss a
detactability of the $X, Y$ gauge boson present in any GUT in a framework of
cosmological collider physics. Calculating one-loop contributions of $X, Y$
gauge bosons to the inflaton three-point functions, we find a remarkable result
that one-loop diagram with interactions originated from the mass terms of $X,
Y$ gauge bosons provides an enhancement factor expressed by the ratio between
the $X, Y$ gauge boson mass and Hubble scale as $(m_X/H)^4$. In an estimation
of the non-Gaussianity, this factor is crucial and its impact on the
detactability of $X, Y$ gauge bosons is discussed.
","[{'version': 'v1', 'created': 'Tue, 26 Jan 2021 08:49:25 GMT'}]",2021-01-27,"[['Maru', 'Nobuhito', ''], ['Okawa', 'Akira', '']]"
2011.08428,Jin-Ping Zhu,"Jin-Ping Zhu, Bing Zhang, Yun-Wei Yu, and He Gao","Neutron Star Mergers in AGN Accretion Disks: Cocoon and Ejecta Shock
  Breakouts","9 pages, 3 figures, accepted for publication in ApJL",,10.3847/2041-8213/abd412,,astro-ph.HE astro-ph.GA astro-ph.SR,http://creativecommons.org/licenses/by/4.0/,"  Neutron star mergers are believed to occur in accretion disks around
supermassive black holes. Here we show that a putative jet launched from the
merger of a binary neutron star (BNS) or a neutron star--black hole (NSBH)
merger occurring at the migration trap in an active galactic nucleus (AGN) disk
would be choked. The jet energy is deposited within the disk materials to power
a hot cocoon. The cocoon is energetic enough to break out from the AGN disk and
produce a bright X-ray shock breakout transient peaking at $\sim0.15\,{\rm d}$
after the merger. The peak luminosity is estimated as $\sim 10^{46}\,{\rm
erg}\,{\rm s}^{-1}$, which can be discovered by Einstein Probe from $z\lesssim
0.5$. Later on, the non-relativistic ejecta launched from the merger would
break out the disk, powering an X-ray/UV flare peaking at $\sim 0.5\,{\rm d}$
after the merger. This second shock breakout signal may be detected by UV
transient searches. The cocoon cooling emission and kilonova emission are
outshone by the disk emission and difficult to be detected. Future joint
observations of gravitational waves from BNS/NSBH mergers and associated two
shock breakout signatures can provide a strong support for the compact binary
coalescence formation channel in AGN disks.
","[{'version': 'v1', 'created': 'Tue, 17 Nov 2020 05:38:31 GMT'}, {'version': 'v2', 'created': 'Thu, 19 Nov 2020 02:32:47 GMT'}, {'version': 'v3', 'created': 'Wed, 16 Dec 2020 09:09:27 GMT'}]",2021-01-15,"[['Zhu', 'Jin-Ping', ''], ['Zhang', 'Bing', ''], ['Yu', 'Yun-Wei', ''], ['Gao', 'He', '']]"
2104.14783,Ruibing Hou,"Ruibing Hou, Hong Chang, Bingpeng Ma, Rui Huang and Shiguang Shan","BiCnet-TKS: Learning Efficient Spatial-Temporal Representation for Video
  Person Re-Identification","Accepted by IEEE Conference on Computer Vision and Pattern
  Recognition (CVPR 2021) 2021",,,,cs.CV,http://creativecommons.org/licenses/by/4.0/,"  In this paper, we present an efficient spatial-temporal representation for
video person re-identification (reID). Firstly, we propose a Bilateral
Complementary Network (BiCnet) for spatial complementarity modeling.
Specifically, BiCnet contains two branches. Detail Branch processes frames at
original resolution to preserve the detailed visual clues, and Context Branch
with a down-sampling strategy is employed to capture long-range contexts. On
each branch, BiCnet appends multiple parallel and diverse attention modules to
discover divergent body parts for consecutive frames, so as to obtain an
integral characteristic of target identity. Furthermore, a Temporal Kernel
Selection (TKS) block is designed to capture short-term as well as long-term
temporal relations by an adaptive mode. TKS can be inserted into BiCnet at any
depth to construct BiCnetTKS for spatial-temporal modeling. Experimental
results on multiple benchmarks show that BiCnet-TKS outperforms
state-of-the-arts with about 50% less computations. The source code is
available at https://github.com/ blue-blue272/BiCnet-TKS.
","[{'version': 'v1', 'created': 'Fri, 30 Apr 2021 06:44:34 GMT'}]",2021-05-03,"[['Hou', 'Ruibing', ''], ['Chang', 'Hong', ''], ['Ma', 'Bingpeng', ''], ['Huang', 'Rui', ''], ['Shan', 'Shiguang', '']]"
2004.14845,Vaiva Vasiliauskaite,Vaiva Vasiliauskaite and Fernando E. Rosas,Understanding complexity via network theory: a gentle introduction,,,,,physics.soc-ph,http://creativecommons.org/licenses/by/4.0/,"  Network theory provides tools which are particularly appropriate for
assessing the complex interdependencies that characterise our modern connected
world. This article presents an introduction to network theory, in a way that
doesn't require a strong mathematical background. We explore how network theory
unveils commonalities in the interdependency profiles of various systems,
ranging from biological, to social, and artistic domains. Our aim is to enable
an intuitive understanding while conveying the fundamental principles and aims
of complexity science. Additionally, various network-theoretic tools are
discussed, and numerous references for more advanced materials are provided.
","[{'version': 'v1', 'created': 'Thu, 30 Apr 2020 14:56:05 GMT'}]",2020-05-01,"[['Vasiliauskaite', 'Vaiva', ''], ['Rosas', 'Fernando E.', '']]"
2201.12347,Varun Ojha,"Chandresh Pravin, Ivan Martino, Giuseppe Nicosia, Varun Ojha",Adversarial Robustness in Deep Learning: Attacks on Fragile Neurons,,Artificial Neural Networks and Machine Learning ICANN 2021,10.1007/978-3-030-86362-3_2,,cs.LG cs.CR,http://creativecommons.org/licenses/by/4.0/,"  We identify fragile and robust neurons of deep learning architectures using
nodal dropouts of the first convolutional layer. Using an adversarial targeting
algorithm, we correlate these neurons with the distribution of adversarial
attacks on the network. Adversarial robustness of neural networks has gained
significant attention in recent times and highlights intrinsic weaknesses of
deep learning networks against carefully constructed distortion applied to
input images. In this paper, we evaluate the robustness of state-of-the-art
image classification models trained on the MNIST and CIFAR10 datasets against
the fast gradient sign method attack, a simple yet effective method of
deceiving neural networks. Our method identifies the specific neurons of a
network that are most affected by the adversarial attack being applied. We,
therefore, propose to make fragile neurons more robust against these attacks by
compressing features within robust neurons and amplifying the fragile neurons
proportionally.
","[{'version': 'v1', 'created': 'Mon, 31 Jan 2022 14:34:07 GMT'}]",2022-02-01,"[['Pravin', 'Chandresh', ''], ['Martino', 'Ivan', ''], ['Nicosia', 'Giuseppe', ''], ['Ojha', 'Varun', '']]"
2012.04808,Yichong Xu,"Yichong Xu, Chenguang Zhu, Ruochen Xu, Yang Liu, Michael Zeng, Xuedong
  Huang",Fusing Context Into Knowledge Graph for Commonsense Question Answering,"To appear at ACL 2021. Code available at
  https://github.com/microsoft/DEKCOR-CommonsenseQA",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Commonsense question answering (QA) requires a model to grasp commonsense and
factual knowledge to answer questions about world events. Many prior methods
couple language modeling with knowledge graphs (KG). However, although a KG
contains rich structural information, it lacks the context to provide a more
precise understanding of the concepts. This creates a gap when fusing knowledge
graphs into language modeling, especially when there is insufficient labeled
data. Thus, we propose to employ external entity descriptions to provide
contextual information for knowledge understanding. We retrieve descriptions of
related concepts from Wiktionary and feed them as additional input to
pre-trained language models. The resulting model achieves state-of-the-art
result in the CommonsenseQA dataset and the best result among non-generative
models in OpenBookQA.
","[{'version': 'v1', 'created': 'Wed, 9 Dec 2020 00:57:49 GMT'}, {'version': 'v2', 'created': 'Tue, 1 Jun 2021 19:11:10 GMT'}, {'version': 'v3', 'created': 'Mon, 2 Aug 2021 19:39:59 GMT'}]",2021-08-04,"[['Xu', 'Yichong', ''], ['Zhu', 'Chenguang', ''], ['Xu', 'Ruochen', ''], ['Liu', 'Yang', ''], ['Zeng', 'Michael', ''], ['Huang', 'Xuedong', '']]"
2104.10690,Elizabeth Gonzalez Dr.,"Elizabeth J. Gonzalez, Facundo Rodriguez, Manuel Merch\'an, Diego
  Garc\'ia Lambas, Mart\'in Makler, Mart\'in Chalela, Maria E. S. Pereira,
  Bruno Moraes and HuanYuan Shan",On the weak lensing masses of a new sample of galaxy groups,"13 pages, 8 figures, plus appendices. Accepted in MNRAS",,10.1093/mnras/stab1168,,astro-ph.CO,http://creativecommons.org/licenses/by/4.0/,"  Galaxy group masses are important to relate these systems with the dark
matter halo hosts. However, deriving accurate mass estimates is particularly
challenging for low-mass galaxy groups. Moreover, calibration of bservational
mass-proxies using weak-lensing estimates have been mainly focused on massive
clusters. We present here a study of halo masses for a sample of galaxy groups
identified according to a spectroscopic catalogue, spanning a wide mass range.
The main motivation of our analysis is to assess mass estimates provided by the
galaxy group catalogue derived through an abundance matching luminosity
technique. We derive total halo mass estimates according to a stacking
weak-lensing analysis. Our study allows to test the accuracy of mass estimates
based on this technique as a proxy for the halo masses of large group samples.
Lensing profiles are computed combining the groups in different bins of
abundance matching mass, richness and redshift. Fitted lensing masses correlate
with the masses obtained from abundance matching. However, when considering
groups in the low- and intermediate-mass ranges, masses computed according to
the characteristic group luminosity tend to predict higher values than the
determined by the weak-lensing analysis. The agreement improves for the
low-mass range if the groups selected have a central early-type galaxy.
Presented results validate the use of mass estimates based on abundance
matching techniques which provide good proxies to the halo host mass in a wide
mass range.
","[{'version': 'v1', 'created': 'Wed, 21 Apr 2021 18:00:01 GMT'}]",2021-05-12,"[['Gonzalez', 'Elizabeth J.', ''], ['Rodriguez', 'Facundo', ''], ['Merchán', 'Manuel', ''], ['Lambas', 'Diego García', ''], ['Makler', 'Martín', ''], ['Chalela', 'Martín', ''], ['Pereira', 'Maria E. S.', ''], ['Moraes', 'Bruno', ''], ['Shan', 'HuanYuan', '']]"
2110.14797,Sarah Wagner,"Sarah M. Wagner, Paul R. Burd, Daniela Dorner, Karl Mannheim and Sara
  Buson, Andrea Gokus, Greg Madejski, Jeffrey D. Scargle (for the Fermi-LAT
  Collaboration) and Axel Arbet-Engels, Dominik Baack, Matteo Balbo, Adrian
  Biland, Thomas Bretz, Jens Buss, Laura Eisenberger, Dominik Elsaesser,
  Dorothee Hildebrand, Roman Iotov, Adelina Kalenski, Dominik Neise, Maximilian
  Noethe, Aleksander Paravac, Wolfgang Rhode, Bernd Schleicher, Vitalii
  Sliusar, Roland Walter (for the FACT Collaboration)","Statistical properties of flux variations in blazar light curves at GeV
  and TeV energies","for associated HOP algorithm, see
  https://github.com/swagner-astro/lightcurves and for associated OU algorithm,
  see https://github.com/PRBurd/astro-wue",,10.22323/1.395.0868,,astro-ph.HE,http://creativecommons.org/licenses/by/4.0/,"  Despite numerous detections of individual flares, the physical origin of the
rapid variability observed from blazars remains uncertain. Using Bayesian
blocks and the Eisenstein-Hut HOP algorithm, we characterize flux variations of
high significance in the $\gamma$-ray light curves of two samples of blazars.
Daily binned long-term light curves of TeV-bright blazars observed with the
First G-APD Cherenkov Telescope (FACT) are compared to those of GeV-bright
blazars observed with the Large Area Telescope on board the $Fermi$ Gamma-ray
Space Telescope ($Fermi$-LAT). We find no evidence for systematic asymmetry of
the flux variations based on the derived rise and decay time scales.
Additionally, we show that the daily-binned blazar light curves can be
described by an exponential stochastic Ornstein-Uhlenbeck (OU) process with
parameters depending on energy. Our analysis suggests that the flux variability
in both samples is a superposition of faster fluctuations. This is, for
instance, challenging to explain by shock-acceleration but expected for
magnetic reconnection.
","[{'version': 'v1', 'created': 'Wed, 27 Oct 2021 22:06:25 GMT'}, {'version': 'v2', 'created': 'Tue, 9 Nov 2021 04:21:15 GMT'}]",2021-11-10,"[['Wagner', 'Sarah M.', '', 'for the Fermi-LAT\n  Collaboration'], ['Burd', 'Paul R.', '', 'for the Fermi-LAT\n  Collaboration'], ['Dorner', 'Daniela', '', 'for the Fermi-LAT\n  Collaboration'], ['Mannheim', 'Karl', '', 'for the Fermi-LAT\n  Collaboration'], ['Buson', 'Sara', '', 'for the Fermi-LAT\n  Collaboration'], ['Gokus', 'Andrea', '', 'for the Fermi-LAT\n  Collaboration'], ['Madejski', 'Greg', '', 'for the Fermi-LAT\n  Collaboration'], ['Scargle', 'Jeffrey D.', '', 'for the Fermi-LAT\n  Collaboration'], ['Arbet-Engels', 'Axel', '', 'for the FACT Collaboration'], ['Baack', 'Dominik', '', 'for the FACT Collaboration'], ['Balbo', 'Matteo', '', 'for the FACT Collaboration'], ['Biland', 'Adrian', '', 'for the FACT Collaboration'], ['Bretz', 'Thomas', '', 'for the FACT Collaboration'], ['Buss', 'Jens', '', 'for the FACT Collaboration'], ['Eisenberger', 'Laura', '', 'for the FACT Collaboration'], ['Elsaesser', 'Dominik', '', 'for the FACT Collaboration'], ['Hildebrand', 'Dorothee', '', 'for the FACT Collaboration'], ['Iotov', 'Roman', '', 'for the FACT Collaboration'], ['Kalenski', 'Adelina', '', 'for the FACT Collaboration'], ['Neise', 'Dominik', '', 'for the FACT Collaboration'], ['Noethe', 'Maximilian', '', 'for the FACT Collaboration'], ['Paravac', 'Aleksander', '', 'for the FACT Collaboration'], ['Rhode', 'Wolfgang', '', 'for the FACT Collaboration'], ['Schleicher', 'Bernd', '', 'for the FACT Collaboration'], ['Sliusar', 'Vitalii', '', 'for the FACT Collaboration'], ['Walter', 'Roland', '', 'for the FACT Collaboration']]"
2105.11783,Xieyuanli Chen,"Andrzej Reinke, Xieyuanli Chen, Cyrill Stachniss",Simple But Effective Redundant Odometry for Autonomous Vehicles,"Accepted by ICRA 2021. Code:
  https://github.com/PRBonn/MutiverseOdometry",,,,cs.RO,http://creativecommons.org/licenses/by/4.0/,"  Robust and reliable ego-motion is a key component of most autonomous mobile
systems. Many odometry estimation methods have been developed using different
sensors such as cameras or LiDARs. In this work, we present a resilient
approach that exploits the redundancy of multiple odometry algorithms using a
3D LiDAR scanner and a monocular camera to provide reliable state estimation
for autonomous vehicles. Our system utilizes a stack of odometry algorithms
that run in parallel. It chooses from them the most promising pose estimation
considering sanity checks using dynamic and kinematic constraints of the
vehicle as well as a score computed between the current LiDAR scan and a
locally built point cloud map. In this way, our method can exploit the
advantages of different existing ego-motion estimating approaches. We evaluate
our method on the KITTI Odometry dataset. The experimental results suggest that
our approach is resilient to failure cases and achieves an overall better
performance than individual odometry methods employed by our system.
","[{'version': 'v1', 'created': 'Tue, 25 May 2021 09:25:38 GMT'}]",2021-05-26,"[['Reinke', 'Andrzej', ''], ['Chen', 'Xieyuanli', ''], ['Stachniss', 'Cyrill', '']]"
2106.03124,Jirong Mao,"J. Mao, R. J. Britto, D. A. H. Buckley, S. Covino, P. D'Avanzo, N. P.
  M. Kuin",On the Polarized Absorption Lines in Gamma-ray Burst Optical Afterglows,ApJ accepted,,10.3847/1538-4357/abfdc6,,astro-ph.HE,http://creativecommons.org/licenses/by/4.0/,"  Spectropolarimetric measurements of gamma-ray burst (GRB) optical afterglows
contain polarization information for both continuum and absorption lines. Based
on the Zeeman effect, an absorption line in a strong magnetic field is
polarized and split into a triplet. In this paper, we solve the polarization
radiative transfer equations of the absorption lines, and obtain the degree of
linear polarization of the absorption lines as a function of the optical depth.
In order to effectively measure the degree of linear polarization for the
absorption lines, a magnetic field strength of at least $10^3$ G is required.
The metal elements that produce the polarized absorption lines should be
sufficiently abundant and have large oscillation strengths or Einstein
absorption coefficients. We encourage both polarization measurements and
high-dispersion observations of the absorption lines in order to detect the
triplet structure in early GRB optical afterglows.
","[{'version': 'v1', 'created': 'Sun, 6 Jun 2021 13:37:37 GMT'}]",2021-06-30,"[['Mao', 'J.', ''], ['Britto', 'R. J.', ''], ['Buckley', 'D. A. H.', ''], ['Covino', 'S.', ''], [""D'Avanzo"", 'P.', ''], ['Kuin', 'N. P. M.', '']]"
2109.06132,Lucas Salvador,"Tyler Sorensen, Lucas F. Salvador, Harmit Raval, Hugues Evrard, John
  Wickerson, Margaret Martonosi, and Alastair F. Donaldson",Specifying and Testing GPU Workgroup Progress Models,OOPSLA 2021,,10.1145/3485508,,cs.PL,http://creativecommons.org/licenses/by/4.0/,"  As GPU availability has increased and programming support has matured, a
wider variety of applications are being ported to these platforms. Many
parallel applications contain fine-grained synchronization idioms; as such,
their correct execution depends on a degree of relative forward progress
between threads (or thread groups). Unfortunately, many GPU programming
specifications say almost nothing about relative forward progress guarantees
between workgroups. Although prior work has proposed a spectrum of plausible
progress models for GPUs, cross-vendor specifications have yet to commit to any
model.
  This work is a collection of tools experimental data to aid specification
designers when considering forward progress guarantees in programming
frameworks. As a foundation, we formalize a small parallel programming language
that captures the essence of fine-grained synchronization. We then provide a
means of formally specifying a progress model, and develop a termination oracle
that decides whether a given program is guaranteed to eventually terminate with
respect to a given progress model. Next, we formalize a constraint for
concurrent programs that require relative forward progress to terminate. Using
this constraint, we synthesize a large set of 483 progress litmus tests.
Combined with the termination oracle, this allows us to determine the expected
status of each litmus test -- i.e. whether it is guaranteed eventual
termination -- under various progress models. We present a large experimental
campaign running the litmus tests across 8 GPUs from 5 different vendors. Our
results highlight that GPUs have significantly different termination behaviors
under our test suite. Most notably, we find that Apple and ARM GPUs do not
support the linear occupancy-bound model, an intuitive progress model defined
by prior work and hypothesized to describe the workgroup schedulers of existing
GPUs.
","[{'version': 'v1', 'created': 'Mon, 13 Sep 2021 17:16:17 GMT'}]",2021-09-14,"[['Sorensen', 'Tyler', ''], ['Salvador', 'Lucas F.', ''], ['Raval', 'Harmit', ''], ['Evrard', 'Hugues', ''], ['Wickerson', 'John', ''], ['Martonosi', 'Margaret', ''], ['Donaldson', 'Alastair F.', '']]"
2202.08922,Hyunsung Cho,"Hyunsung Cho, Akhil Mathur, Fahim Kawsar",FLAME: Federated Learning Across Multi-device Environments,,,,,cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Federated Learning (FL) enables distributed training of machine learning
models while keeping personal data on user devices private. While we witness
increasing applications of FL in the area of mobile sensing, such as
human-activity recognition, FL has not been studied in the context of a
multi-device environment (MDE), wherein each user owns multiple data-producing
devices. With the proliferation of mobile and wearable devices, MDEs are
increasingly becoming popular in ubicomp settings, therefore necessitating the
study of FL in them. FL in MDEs is characterized by high non-IID-ness across
clients, complicated by the presence of both user and device heterogeneities.
Further, ensuring efficient utilization of system resources on FL clients in a
MDE remains an important challenge. In this paper, we propose FLAME, a
user-centered FL training approach to counter statistical and system
heterogeneity in MDEs, and bring consistency in inference performance across
devices. FLAME features (i) user-centered FL training utilizing the time
alignment across devices from the same user; (ii) accuracy- and
efficiency-aware device selection; and (iii) model personalization to devices.
We also present an FL evaluation testbed with realistic energy drain and
network bandwidth profiles, and a novel class-based data partitioning scheme to
extend existing HAR datasets to a federated setup. Our experiment results on
three multi-device HAR datasets show that FLAME outperforms various baselines
by 4.8-33.8% higher F-1 score, 1.02-2.86x greater energy efficiency, and up to
2.02x speedup in convergence to target accuracy through fair distribution of
the FL workload.
","[{'version': 'v1', 'created': 'Thu, 17 Feb 2022 22:23:56 GMT'}]",2022-02-21,"[['Cho', 'Hyunsung', ''], ['Mathur', 'Akhil', ''], ['Kawsar', 'Fahim', '']]"
2104.13979,Beniamino Accattoli,"Beniamino Accattoli, Giulio Guerrieri, Maico Leberle",Semantic Bounds and Strong Call-by-Value Normalization,,,,,cs.LO cs.PL,http://creativecommons.org/licenses/by/4.0/,"  This paper explores two topics at once: the use of denotational semantics to
bound the evaluation length of functional programs, and the semantics of strong
(that is, possibly under abstractions) call-by-value evaluation.
  About the first, we analyze de Carvalho's seminal use of relational semantics
for bounding the evaluation length of lambda-terms, starting from the
presentation of the semantics as an intersection types system. We focus on the
part of his work which is usually neglected in its many recent adaptations,
despite being probably the conceptually deeper one: how to transfer the
bounding power from the type system to the relational semantics itself. We
dissect this result and re-understand it via the isolation of a simpler size
representation property.
  About the second, we use relational semantics to develop a semantical study
of strong call-by-value evaluation, which is both a delicate and neglected
topic. We give a semantic characterization of terms normalizable with respect
to strong evaluation, providing in particular the first result of adequacy with
respect to strong call-by-value. Moreover, we extract bounds about strong
evaluation from both the type systems and the relational semantics.
  Essentially, we use strong call-by-value to revisit de Carvalho's semantic
bounds, and de Carvalho's technique to provide semantical foundations for
strong call-by-value.
","[{'version': 'v1', 'created': 'Wed, 28 Apr 2021 19:09:30 GMT'}]",2021-04-30,"[['Accattoli', 'Beniamino', ''], ['Guerrieri', 'Giulio', ''], ['Leberle', 'Maico', '']]"
2201.05506,Bernd Sturmfels,Irem Portakal and Bernd Sturmfels,Geometry of Dependency Equilibria,20 pages,,,,math.AG cs.GT,http://creativecommons.org/licenses/by/4.0/,"  An $n$-person game is specified by $n$ tensors of the same format. We view
its equilibria as points in that tensor space. Dependency equilibria are
defined by linear constraints on conditional probabilities, and thus by
determinantal quadrics in the tensor entries. These equations cut out the Spohn
variety, named after the philosopher who introduced dependency equilibria. The
Nash equilibria among these are the tensors of rank one. We study the real
algebraic geometry of the Spohn variety. This variety is rational, except for
$2 \times 2$ games, when it is an elliptic curve. For $3 \times 2$ games, it is
a del Pezzo surface of degree two. We characterize the payoff regions and their
boundaries using oriented matroids, and we develop the connection to Bayesian
networks in statistics.
","[{'version': 'v1', 'created': 'Fri, 14 Jan 2022 15:19:28 GMT'}]",2022-01-17,"[['Portakal', 'Irem', ''], ['Sturmfels', 'Bernd', '']]"
2012.00459,Cheng Zhang,Cheng Zhang,"Improved Variational Bayesian Phylogenetic Inference with Normalizing
  Flows",NeurIPS 2020,,,,q-bio.PE stat.ML,http://creativecommons.org/licenses/by/4.0/,"  Variational Bayesian phylogenetic inference (VBPI) provides a promising
general variational framework for efficient estimation of phylogenetic
posteriors. However, the current diagonal Lognormal branch length approximation
would significantly restrict the quality of the approximating distributions. In
this paper, we propose a new type of VBPI, VBPI-NF, as a first step to empower
phylogenetic posterior estimation with deep learning techniques. By handling
the non-Euclidean branch length space of phylogenetic models with carefully
designed permutation equivariant transformations, VBPI-NF uses normalizing
flows to provide a rich family of flexible branch length distributions that
generalize across different tree topologies. We show that VBPI-NF significantly
improves upon the vanilla VBPI on a benchmark of challenging real data Bayesian
phylogenetic inference problems. Further investigation also reveals that the
structured parameterization in those permutation equivariant transformations
can provide additional amortization benefit.
","[{'version': 'v1', 'created': 'Tue, 1 Dec 2020 13:10:00 GMT'}]",2020-12-02,"[['Zhang', 'Cheng', '']]"
2012.06942,Filander Sequeira,Fil\'ander A. Sequeira and Helen Guill\'en-Oviedo,"Some aspects on the computational implementation of diverse terms
  arising in mixed virtual element formulations",,,,,math.NA cs.NA,http://creativecommons.org/licenses/by/4.0/,"  In the present paper we describe the computational implementation of some
integral terms that arise from mixed virtual element methods (mixed-VEM) in
two-dimensional pseudostress-velocity formulations. The implementation
presented here consider any polynomial degree $k \geq 0$ in a natural way by
building several local matrices of small size through the matrix multiplication
and the Kronecker product. In particular, we apply the foregoing mentioned
matrices to the Navier-Stokes equations with Dirichlet boundary conditions,
whose mixed-VEM formulation was originally proposed and analyzed in a recent
work using virtual element subspaces for $H(\text{div})$ and $H^1$,
simultaneously. In addition, an algorithm is proposed for the assembly of the
associated global linear system for the Newton's iteration. Finally, we present
a numerical example in order to illustrate the performance of the mixed-VEM
scheme and confirming the expected theoretical convergence rates.
","[{'version': 'v1', 'created': 'Sun, 13 Dec 2020 02:24:54 GMT'}]",2020-12-15,"[['Sequeira', 'Filánder A.', ''], ['Guillén-Oviedo', 'Helen', '']]"
2109.14714,Alex Deibel,"Alex Deibel, M. E. Caplan, and C. J. Horowitz",Nuclear fission reaction simulations in compact stars,"8 pages, 5 figures",,,,astro-ph.SR astro-ph.HE nucl-th,http://creativecommons.org/licenses/by/4.0/,"  Type-Ia supernovae (SN Ia) are powerful stellar explosions that provide
important distance indicators in cosmology. Recently, we proposed a new SN Ia
mechanism that involves a nuclear fission chain-reaction in an isolated white
dwarf [PRL 126, 1311010]. Here we perform novel reaction network simulations of
the actinide-rich first solids in a cooling white dwarf. The network includes
neutron-capture and fission reactions on a range of U and Th isotopes with
various possible values for U-235 enrichment. We find, for modest U-235
enrichments, neutron-capture on U-238 and Th-232 can breed additional fissile
nuclei so that a significant fraction of all U and Th nuclei may fission during
the chain-reaction. The resulting large energy release could ignite
thermonuclear carbon burning and possibly trigger a SN Ia.
","[{'version': 'v1', 'created': 'Wed, 29 Sep 2021 20:48:38 GMT'}]",2021-10-01,"[['Deibel', 'Alex', ''], ['Caplan', 'M. E.', ''], ['Horowitz', 'C. J.', '']]"
2109.04494,Vo Hong Minh Phan,"Vo Hong Minh Phan, Thiem Hoang, and Abraham Loeb","Erosion of Icy Interstellar Objects by Cosmic Rays and Implications for
  `Oumuamua",7 pages and 3 figures,,,TTK-21-35,astro-ph.GA astro-ph.EP astro-ph.HE,http://creativecommons.org/licenses/by/4.0/,"  We study the destruction and modification of icy interstellar objects by
cosmic rays and gas collisions. Using the cosmic-ray flux measured in the local
interstellar medium as well as inferred from gamma-ray observations at the
different galactocentric radii, we find that cosmic-ray erosion is significant
for interstellar objects made of common types of ices. Interestingly,
cosmic-ray heating might destroy icy interstellar objects very efficiently such
that the initial size of an N$_2$ fragment as suggested by \citet{jackson2021}
to explain the composition of `Oumuamua should be at least 0.5 km in size in
order to survive the journey of about 0.5 Gyr in the ISM and might be even
larger if it originated from a region with an enhanced cosmic-ray flux. This
implies an initial N$_2$ mass that is at least an order of magnitude larger
than the final value, exacerbating the N$_2$ mass budget deficiency for
explaining `Oumuamua. The erosion time due to cosmic-ray heating and gas
collisions also allows us to set approximate limits on the initial size for
other types of icy interstellar objects, e.g. composed of CO, CO$_2$, or
CH$_4$. For a given initial size, we constrain the maximum distance to the
birth site for interstellar objects with different speeds. We also find that
cosmic-ray and gas heating could entirely modify the ice structure before
destroying interstellar objects.
","[{'version': 'v1', 'created': 'Thu, 9 Sep 2021 18:04:08 GMT'}, {'version': 'v2', 'created': 'Thu, 28 Oct 2021 22:01:23 GMT'}]",2021-11-01,"[['Phan', 'Vo Hong Minh', ''], ['Hoang', 'Thiem', ''], ['Loeb', 'Abraham', '']]"
1902.06689,Cass Dykeman,Mandy M. Greaves and Cass Dykeman,"Non-Suicidal Self-Injury Online Posts: Implications for Mental Health
  Professionals","12 pages, 1 Table",,,,cs.CY cs.CL,http://creativecommons.org/licenses/by/4.0/,"  While non-suicidal self-injury (NSSI) is not a new phenomenon, there is still
a limited yet little is still known about understanding of the behavior, the
intent behind the behavior and what the individuals themselves say about their
behavior. This study collected pro-NSSI public blog posts from Reddit on
pro-NSSI and analyzed the content linguistically using LIWC software, in order
to examine the use of NSSI specific words, linguistic properties and the
psychological linguistic properties. were examined. The results inform current
counseling practices by dispelling myths and providing insight into the inner
world of people who engage in use NSSII to cope. The most frequently appearing
category of For NSSI specific words categories, in the Reddit blogs was the
reasons in which one engagesfor engaging in NSSI was the most frequently used
in the Reddit blogs. The linguistic properties found in the analysis reflected
the predicted results; authors of pro-NSSI posts used demonstrated expected
results of first-person singular pronouns extensively, which indicatesing high
levels of mental health distress and isolation. The psychological linguistic
properties that could be observed of in these public Reddit posts were
dominantly in a negative emotional tone which demonstrates youth and
impulsivity. The linguistic properties found when these posts were analyzed
supports the work of earlier studies that dispelled common myths about NSSI
that were circulating in the mental health community. These findings suggest
that the language of people who engage in NSSI supports research findings in
dispelling common myths about NSSI.
","[{'version': 'v1', 'created': 'Sat, 2 Feb 2019 23:42:42 GMT'}, {'version': 'v2', 'created': 'Thu, 16 Dec 2021 20:31:33 GMT'}]",2021-12-20,"[['Greaves', 'Mandy M.', ''], ['Dykeman', 'Cass', '']]"
2103.15782,Michael Bowler Ph D,M. G. Bowler,"SS 433: flares in H alpha, GRAVITY observations & L2 ejection","9 pages, 4 Figures. arXiv admin note: text overlap with
  arXiv:0912.2428, arXiv:0708.2930",Galaxies 2021 9 46,,,astro-ph.GA astro-ph.HE astro-ph.SR,http://creativecommons.org/licenses/by/4.0/,"  Abstract The microquasar SS 433 exhibits in H alpha intermittent flares,
Doppler shifted to both the red and the blue. The mean remembers the orbital
phase of the compact object. I show that the flares are not intermittent
sightings of an accretion disk; rather, plasma must be expelled through the L2
point, thus remembering the phase of the orbit as it invades the space beyond
the system. That space has been mapped with GRAVITY observations of a similar
flare, revealing a strong rotation component.
","[{'version': 'v1', 'created': 'Mon, 29 Mar 2021 17:19:03 GMT'}]",2021-07-13,"[['Bowler', 'M. G.', '']]"
2111.13337,Luke Barnard,"Luke Barnard, Mathew Owens, Christopher J. Scott, Mike Lockwood, Curt
  A. de Koning, Tanja Amerstorfer, J\""urgen Hinterreiter, Christian M\""ostl,
  Jackie Davies, Pete Riley","Quantifying the uncertainty in CME kinematics derived from geometric
  modelling of Heliospheric Imager data","37 pages, 12 figures. Accepted for publication in Space Weather",,10.1029/2021SW002841,,astro-ph.SR physics.space-ph,http://creativecommons.org/licenses/by/4.0/,"  Geometric modelling of Coronal Mass Ejections (CMEs) is a widely used tool
for assessing their kinematic evolution. Furthermore, techniques based on
geometric modelling, such as ELEvoHI, are being developed into forecast tools
for space weather prediction. These models assume that solar wind structure
does not affect the evolution of the CME, which is an unquantified source of
uncertainty. We use a large number of Cone CME simulations with the HUXt solar
wind model to quantify the scale of uncertainty introduced into geometric
modelling and the ELEvoHI CME arrival times by solar wind structure. We produce
a database of simulations, representing an average, a fast, and an extreme CME
scenario, each independently propagating through 100 different ambient solar
wind environments. Synthetic heliospheric imager observations of these
simulations are then used with a range of geometric models to estimate the CME
kinematics. The errors of geometric modelling depend on the location of the
observer, but do not seem to depend on the CME scenario. In general, geometric
models are biased towards predicting CME apex distances that are larger than
the true value. For these CME scenarios, geometric modelling errors are
minimised for an observer in the L5 region. Furthermore, geometric modelling
errors increase with the level of solar wind structure in the path of the CME.
The ELEvoHI arrival time errors are minimised for an observer in the L5 region,
with mean absolute arrival time errors of $8.2\pm1.2$~h, $8.3\pm1.0$~h, and
$5.8\pm0.9$~h for the average, fast, and extreme CME scenarios.
","[{'version': 'v1', 'created': 'Fri, 26 Nov 2021 07:18:58 GMT'}]",2022-02-09,"[['Barnard', 'Luke', ''], ['Owens', 'Mathew', ''], ['Scott', 'Christopher J.', ''], ['Lockwood', 'Mike', ''], ['de Koning', 'Curt A.', ''], ['Amerstorfer', 'Tanja', ''], ['Hinterreiter', 'Jürgen', ''], ['Möstl', 'Christian', ''], ['Davies', 'Jackie', ''], ['Riley', 'Pete', '']]"
2110.11769,Ehsan Barkhordar,"Ehsan Barkhordar, Mohammad Hassan Shirali-Shahreza, Hamid Reza Sadeghi","Clustering of Bank Customers using LSTM-based encoder-decoder and
  Dynamic Time Warping",,,,,cs.LG cs.AI stat.ML,http://creativecommons.org/licenses/by/4.0/,"  Clustering is an unsupervised data mining technique that can be employed to
segment customers. The efficient clustering of customers enables banks to
design and make offers based on the features of the target customers. The
present study uses a real-world financial dataset (Berka, 2000) to cluster bank
customers by an encoder-decoder network and the dynamic time warping (DTW)
method. The customer features required for clustering are obtained in four
ways: Dynamic Time Warping (DTW), Recency Frequency and Monetary (RFM), LSTM
encoder-decoder network, and our proposed hybrid method. Once the LSTM model
was trained by customer transaction data, a feature vector of each customer was
automatically extracted by the encoder.Moreover, the distance between pairs of
sequences of transaction amounts was obtained using DTW. Another vector feature
was calculated for customers by RFM scoring. In the hybrid method, the feature
vectors are combined from the encoder-decoder output, the DTW distance, and the
demographic data (e.g., age and gender). Finally, feature vectors were
introduced as input to the k-means clustering algorithm, and we compared
clustering results with Silhouette and Davies-Bouldin index. As a result, the
clusters obtained from the hybrid approach are more accurate and meaningful
than those derived from individual clustering techniques. In addition, the type
of neural network layers had a substantial effect on the clusters, and high
network error does not necessarily worsen clustering performance.
","[{'version': 'v1', 'created': 'Fri, 22 Oct 2021 13:16:49 GMT'}]",2021-10-25,"[['Barkhordar', 'Ehsan', ''], ['Shirali-Shahreza', 'Mohammad Hassan', ''], ['Sadeghi', 'Hamid Reza', '']]"
2104.00941,Dongha Lee,"Dongha Lee, Sehun Yu, Hwanjo Yu",Multi-Class Data Description for Out-of-distribution Detection,"9 pages, 7 figures, published in SIGKDD 20","In Proceedings of the 26th ACM SIGKDD International Conference on
  Knowledge Discovery & Data Mining (pp. 1362-1370) 2020",10.1145/3394486.3403189,,cs.LG,http://creativecommons.org/licenses/by/4.0/,"  The capability of reliably detecting out-of-distribution samples is one of
the key factors in deploying a good classifier, as the test distribution always
does not match with the training distribution in most real-world applications.
In this work, we present a deep multi-class data description, termed as
Deep-MCDD, which is effective to detect out-of-distribution (OOD) samples as
well as classify in-distribution (ID) samples. Unlike the softmax classifier
that only focuses on the linear decision boundary partitioning its latent space
into multiple regions, our Deep-MCDD aims to find a spherical decision boundary
for each class which determines whether a test sample belongs to the class or
not. By integrating the concept of Gaussian discriminant analysis into deep
neural networks, we propose a deep learning objective to learn
class-conditional distributions that are explicitly modeled as separable
Gaussian distributions. Thereby, we can define the confidence score by the
distance of a test sample from each class-conditional distribution, and utilize
it for identifying OOD samples. Our empirical evaluation on multi-class tabular
and image datasets demonstrates that Deep-MCDD achieves the best performances
in distinguishing OOD samples while showing the classification accuracy as high
as the other competitors.
","[{'version': 'v1', 'created': 'Fri, 2 Apr 2021 08:41:51 GMT'}]",2021-04-05,"[['Lee', 'Dongha', ''], ['Yu', 'Sehun', ''], ['Yu', 'Hwanjo', '']]"
2103.03633,N M Anoop Krishnan,"Mohd Zaki, Vineeth Venugopal, R. Ravinder, Suresh Bishnoi, Sourabh
  Kumar Singh, Amarnath R. Allu, Jayadeva, N. M. Anoop Krishnan","Unveiling the Glass Veil: Elucidating the Optical Properties in Glasses
  with Interpretable Machine Learning","13 pages, 5 figures",,,,physics.optics cond-mat.mtrl-sci physics.data-an,http://creativecommons.org/licenses/by/4.0/,"  Due to their excellent optical properties, glasses are used for various
applications ranging from smartphone screens to telescopes. Developing
compositions with tailored Abbe number (Vd) and refractive index (nd), two
crucial optical properties, is a major challenge. To this extent, machine
learning (ML) approaches have been successfully used to develop
composition-property models. However, these models are essentially black-box in
nature and suffer from the lack of interpretability. In this paper, we
demonstrate the use of ML models to predict the composition-dependent
variations of Vd and n at 587.6 nm (nd). Further, using Shapely Additive
exPlanations (SHAP), we interpret the ML models to identify the contribution of
each of the input components toward a target prediction. We observe that the
glass formers such as SiO2, B2O3, and P2O5, and intermediates like TiO2, PbO,
and Bi2O3 play a significant role in controlling the optical properties.
Interestingly, components that contribute toward increasing the nd are found to
decrease the Vd and vice-versa. Finally, we develop the Abbe diagram, also
known as the ""glass veil"", using the ML models, allowing accelerated discovery
of new glasses for optical properties beyond the experimental pareto front.
Overall, employing explainable ML, we discover the hidden compositional control
on the optical properties of oxide glasses.
","[{'version': 'v1', 'created': 'Fri, 5 Mar 2021 12:30:00 GMT'}]",2021-03-08,"[['Zaki', 'Mohd', ''], ['Venugopal', 'Vineeth', ''], ['Ravinder', 'R.', ''], ['Bishnoi', 'Suresh', ''], ['Singh', 'Sourabh Kumar', ''], ['Allu', 'Amarnath R.', ''], ['Jayadeva', '', ''], ['Krishnan', 'N. M. Anoop', '']]"
2110.01550,Adam Faulkner,"John Xi Qiu, Adam Faulkner, Aysu Ezen Can",Towards Theme Detection in Personal Finance Questions,"Accepted to KDD-MLF 2021: ACM SIGKDD Workshop on Machine Learning in
  Finance",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Banking call centers receive millions of calls annually, with much of the
information in these calls unavailable to analysts interested in tracking new
and emerging call center trends. In this study we present an approach to call
center theme detection that captures the occurrence of multiple themes in a
question, using a publicly available corpus of StackExchange personal finance
questions, labeled by users with topic tags, as a testbed. To capture the
occurrence of multiple themes in a single question, the approach encodes and
clusters at the sentence- rather than question-level. We also present a
comparison of state-of-the-art sentence encoding models, including the SBERT
family of sentence encoders. We frame our evaluation as a multiclass
classification task and show that a simple combination of the original sentence
text, Universal Sentence Encoder, and KMeans outperforms more sophisticated
techniques that involve semantic parsing, SBERT-family models, and HDBSCAN. Our
highest performing approach achieves a Micro-F1 of 0.46 for this task and we
show that the resulting clusters, even when slightly noisy, contain sentences
that are topically consistent with the label associated with the cluster.
","[{'version': 'v1', 'created': 'Mon, 4 Oct 2021 16:44:16 GMT'}]",2021-10-05,"[['Qiu', 'John Xi', ''], ['Faulkner', 'Adam', ''], ['Can', 'Aysu Ezen', '']]"
2002.00319,Jingdong Li,"Jingdong Li, Hui Zhang, Xueliang Zhang, and Changliang Li","Single Channel Speech Enhancement Using Temporal Convolutional Recurrent
  Neural Networks",,,,,cs.SD cs.LG eess.AS,http://creativecommons.org/licenses/by/4.0/,"  In recent decades, neural network based methods have significantly improved
the performace of speech enhancement. Most of them estimate time-frequency
(T-F) representation of target speech directly or indirectly, then resynthesize
waveform using the estimated T-F representation. In this work, we proposed the
temporal convolutional recurrent network (TCRN), an end-to-end model that
directly map noisy waveform to clean waveform. The TCRN, which is combined
convolution and recurrent neural network, is able to efficiently and
effectively leverage short-term ang long-term information. Futuremore, we
present the architecture that repeatedly downsample and upsample speech during
forward propagation. We show that our model is able to improve the performance
of model, compared with existing convolutional recurrent networks. Futuremore,
We present several key techniques to stabilize the training process. The
experimental results show that our model consistently outperforms existing
speech enhancement approaches, in terms of speech intelligibility and quality.
","[{'version': 'v1', 'created': 'Sun, 2 Feb 2020 04:26:50 GMT'}]",2020-02-06,"[['Li', 'Jingdong', ''], ['Zhang', 'Hui', ''], ['Zhang', 'Xueliang', ''], ['Li', 'Changliang', '']]"
2109.06746,Chichun Zhou,"Jia-Yao Yang, Hao Zhu, Yue-Jie Hou, Ping Zhang, and Chi-Chun Zhou","Why Existing Machine Learning Methods Fails At Extracting the
  Information of Future Returns Out of Historical Sctock Prices : the
  Curve-Shape-Feature and Non-Curve-Shape-Feature Modes",,,,,cs.CE,http://creativecommons.org/licenses/by/4.0/,"  The financial time series analysis is important access to touch the complex
laws of financial markets. Among many goals of the financial time series
analysis, one is to construct a model that can extract the information of the
future return out of the known historical stock data, such as stock price,
financial news, and e.t.c. To design such a model, prior knowledge on how the
future return is correlated with the historical stock prices is needed. In this
work, we focus on the issue: in what mode the future return is correlated with
the historical stock prices. We manually design several financial time series
where the future return is correlated with the historical stock prices in
pre-designed modes, namely the curve-shape-feature (CSF) and the
non-curve-shape-feature (NCSF) modes. In the CSF mode, the future return can be
extracted from the curve shapes of the historical stock prices. By applying
various kinds of existing algorithms on those pre-designed time series and real
financial time series, we show that: (1) the major information of the future
return is not contained in the curve-shape features of historical stock prices.
That is, the future return is not mainly correlated with the historical stock
prices in the CSF mode. (2) Various kinds of existing machine learning
algorithms are good at extracting the curveshape features in the historical
stock prices and thus are inappropriate for financial time series analysis
although they are successful in the image recognition and natural language
processing. That is, new models handling the NCSF series are needed in the
financial time series analysis.
","[{'version': 'v1', 'created': 'Tue, 14 Sep 2021 15:04:21 GMT'}]",2021-09-15,"[['Yang', 'Jia-Yao', ''], ['Zhu', 'Hao', ''], ['Hou', 'Yue-Jie', ''], ['Zhang', 'Ping', ''], ['Zhou', 'Chi-Chun', '']]"
2103.01140,Axel Brandenburg,"Axel Brandenburg, Grigol Gogoberidze, Tina Kahniashvili, Sayan Mandal,
  Alberto Roper Pol, Nakul Shenoy","The scalar, vector, and tensor modes in gravitational wave turbulence
  simulations","25 pages, 8 figures","Class. Quantum Grav. 38, 145002 (2021)",10.1088/1361-6382/ac011c,NORDITA-2021-019,gr-qc astro-ph.CO physics.flu-dyn,http://creativecommons.org/licenses/by/4.0/,"  We study the gravitational wave (GW) signal sourced by primordial turbulence
that is assumed to be present at cosmological phase transitions like the
electroweak and quantum chromodynamics phase transitions. We consider various
models of primordial turbulence, such as those with and without helicity,
purely hydrodynamical turbulence induced by fluid motions, and
magnetohydrodynamic turbulence whose energy can be dominated either by kinetic
or magnetic energy, depending on the nature of the turbulence. We also study
circularly polarized GWs generated by parity violating sources such as helical
turbulence. Our ultimate goal is to determine the efficiency of GW production
through different classes of turbulence. We find that the GW energy and strain
tend to be large for acoustic or irrotational turbulence, even though its
tensor mode amplitude is relatively small at most wave numbers. Only at very
small wave numbers is the spectral tensor mode significant, which might explain
the efficient GW production in that case.
","[{'version': 'v1', 'created': 'Mon, 1 Mar 2021 17:21:33 GMT'}, {'version': 'v2', 'created': 'Fri, 25 Jun 2021 03:34:32 GMT'}]",2021-06-28,"[['Brandenburg', 'Axel', ''], ['Gogoberidze', 'Grigol', ''], ['Kahniashvili', 'Tina', ''], ['Mandal', 'Sayan', ''], ['Pol', 'Alberto Roper', ''], ['Shenoy', 'Nakul', '']]"
2112.03653,Nicolas Wu,"Matthew Pickering, Andres L\""oh, Nicolas Wu",A Specification for Typed Template Haskell,,,,,cs.PL,http://creativecommons.org/licenses/by/4.0/,"  Multi-stage programming is a proven technique that provides predictable
performance characteristics by controlling code generation. We propose a core
semantics for Typed Template Haskell, an extension of Haskell that supports
multi staged programming that interacts well with polymorphism and qualified
types. Our semantics relates a declarative source language with qualified types
to a core language based on the the polymorphic lambda calculus augmented with
multi-stage constructs.
","[{'version': 'v1', 'created': 'Tue, 7 Dec 2021 12:05:00 GMT'}]",2021-12-08,"[['Pickering', 'Matthew', ''], ['Löh', 'Andres', ''], ['Wu', 'Nicolas', '']]"
2105.08219,Fei Ma,"Fei Ma, Thushara D. Abhayapala, and Prasanga N. Samarasinghe",A time-domain nearfield frequency-invariant beamforming method,,,,,eess.AS eess.SP,http://creativecommons.org/licenses/by/4.0/,"  Most existing beamforming methods are frequency-domain methods, and are
designed for enhancing a farfield target source over a narrow frequency band.
They have found diverse applications and are still under active development.
However, they struggle to achieve desired performance if the target source is
in the nearfield with a broadband output. This paper proposes a time-domain
nearfield frequency-invariant beamforming method. The time-domain
implementation makes the beamformer output suitable for further use by
real-time applications, the nearfield focusing enables the beamforming method
to suppress an interference even if it is in the same direction as the target
source, and the frequency-invariant beampattern makes the beamforming method
suitable for enhancing the target source over a broad frequency band. These
three features together make the beamforming method suitable for real-time
broadband nearfield source enhancement, such as speech enhancement in room
environments. The beamformer design process is separated from the sound field
measurement process, and such that a designed beamformer applies to sensor
arrays with various structures. The beamformer design process is further
simplified by decomposing it into several independent parts. Simulation results
confirm the performance of the proposed beamforming method.
","[{'version': 'v1', 'created': 'Tue, 18 May 2021 01:22:11 GMT'}]",2021-05-19,"[['Ma', 'Fei', ''], ['Abhayapala', 'Thushara D.', ''], ['Samarasinghe', 'Prasanga N.', '']]"
2012.05947,Rik Claes,"R. Claes, J. Kluska, H. Van Winckel, M. Min",Neural network based image reconstruction with astrophysical priors,"SPIE Astronomical Telescopes + Instrumentation 2020 conference Paper
  No. 11446-110","Proc. SPIE 11446, Optical and Infrared Interferometry and Imaging
  VII, 114461U (13 December 2020)",10.1117/12.2576321,,astro-ph.IM,http://creativecommons.org/licenses/by/4.0/,"  With the advent of interferometric instruments with 4 telescopes at the VLTI
and 6 telescopes at CHARA, the scientific possibility arose to routinely obtain
milli-arcsecond scale images of the observed targets. Such an image
reconstruction process is typically performed in a Bayesian framework where the
function to minimize is made of two terms: the datalikelihood and the Bayesian
prior. This prior should be based on our prior knowledge of the observed
source. Up to now,this prior was chosen from a set of generic and arbitrary
functions, such as total variation for example. Here, we present an image
reconstruction framework using generative adversarial networks where the
Bayesian prior is defined using state-of-the-art radiative transfer models of
the targeted objects. We validate this new image reconstruction algorithm on
synthetic data with added noise. The generated images display a drastic
reduction of artefacts and allow a more straight forward astrophysical
interpretation. The results can be seen as a first illustration of how neural
networks can provide significant improvements to the image reconstruction of a
variety of astrophysical sources.
","[{'version': 'v1', 'created': 'Thu, 10 Dec 2020 20:05:14 GMT'}, {'version': 'v2', 'created': 'Mon, 14 Dec 2020 16:24:48 GMT'}, {'version': 'v3', 'created': 'Fri, 18 Dec 2020 23:03:28 GMT'}]",2020-12-22,"[['Claes', 'R.', ''], ['Kluska', 'J.', ''], ['Van Winckel', 'H.', ''], ['Min', 'M.', '']]"
2110.14426,Tejas Kulkarni,"Tejas Kulkarni, Joonas J\""alk\""o, Samuel Kaski, Antti Honkela",Locally Differentially Private Bayesian Inference,,,,,stat.ML cs.CR cs.LG,http://creativecommons.org/licenses/by/4.0/,"  In recent years, local differential privacy (LDP) has emerged as a technique
of choice for privacy-preserving data collection in several scenarios when the
aggregator is not trustworthy. LDP provides client-side privacy by adding noise
at the user's end. Thus, clients need not rely on the trustworthiness of the
aggregator.
  In this work, we provide a noise-aware probabilistic modeling framework,
which allows Bayesian inference to take into account the noise added for
privacy under LDP, conditioned on locally perturbed observations. Stronger
privacy protection (compared to the central model) provided by LDP protocols
comes at a much harsher privacy-utility trade-off. Our framework tackles
several computational and statistical challenges posed by LDP for accurate
uncertainty quantification under Bayesian settings. We demonstrate the efficacy
of our framework in parameter estimation for univariate and multi-variate
distributions as well as logistic and linear regression.
","[{'version': 'v1', 'created': 'Wed, 27 Oct 2021 13:36:43 GMT'}]",2021-10-28,"[['Kulkarni', 'Tejas', ''], ['Jälkö', 'Joonas', ''], ['Kaski', 'Samuel', ''], ['Honkela', 'Antti', '']]"
1610.10084,Emanuele Angelo Bagnaschi,"E. Bagnaschi, J.C. Costa, K. Sakurai, M. Borsato, O. Buchmueller, R.
  Cavanaugh, V. Chobanova, M. Citron, A. De Roeck, M.J. Dolan, J.R. Ellis, H.
  Fl\""acher, S. Heinemeyer, G. Isidori, M. Lucio, D. Mart\'inez Santos, K.A.
  Olive, A. Richards, K.J. de Vries and G. Weiglein",Likelihood Analysis of Supersymmetric SU(5) GUTs,"38 pages, 22 figures, version published on EPJC","Eur.Phys.J. C77 (2017) no.2, 104",10.1140/epjc/s10052-017-4639-6,"KCL-PH-TH/2016-57, CERN-PH-TH/2016-217, DESY 16-156,
  IFT-UAM/CSIC-16-105, FTPI-MINN-16/29, UMN-TH-3609/16,
  FERMILAB-PUB-16-453-CMS, IPPP/16/97",hep-ph astro-ph.HE hep-ex,http://creativecommons.org/licenses/by/4.0/,"  We perform a likelihood analysis of the constraints from accelerator
experiments and astrophysical observations on supersymmetric (SUSY) models with
SU(5) boundary conditions on soft SUSY-breaking parameters at the GUT scale.
The parameter space of the models studied has 7 parameters: a universal gaugino
mass $m_{1/2}$, distinct masses for the scalar partners of matter fermions in
five- and ten-dimensional representations of SU(5), $m_5$ and $m_{10}$, and for
the $\mathbf{5}$ and $\mathbf{\bar 5}$ Higgs representations $m_{H_u}$ and
$m_{H_d}$, a universal trilinear soft SUSY-breaking parameter $A_0$, and the
ratio of Higgs vevs $\tan \beta$. In addition to previous constraints from
direct sparticle searches, low-energy and flavour observables, we incorporate
constraints based on preliminary results from 13 TeV LHC searches for jets +
MET events and long-lived particles, as well as the latest PandaX-II and LUX
searches for direct Dark Matter detection. In addition to previously-identified
mechanisms for bringing the supersymmetric relic density into the range allowed
by cosmology, we identify a novel ${\tilde u_R}/{\tilde c_R} -
\tilde{\chi}^0_1$ coannihilation mechanism that appears in the supersymmetric
SU(5) GUT model and discuss the role of ${\tilde \nu_\tau}$ coannihilation. We
find complementarity between the prospects for direct Dark Matter detection and
SUSY searches at the LHC.
","[{'version': 'v1', 'created': 'Mon, 31 Oct 2016 19:38:47 GMT'}, {'version': 'v2', 'created': 'Wed, 16 Nov 2016 17:59:24 GMT'}, {'version': 'v3', 'created': 'Wed, 26 Apr 2017 12:01:17 GMT'}]",2017-04-27,"[['Bagnaschi', 'E.', ''], ['Costa', 'J. C.', ''], ['Sakurai', 'K.', ''], ['Borsato', 'M.', ''], ['Buchmueller', 'O.', ''], ['Cavanaugh', 'R.', ''], ['Chobanova', 'V.', ''], ['Citron', 'M.', ''], ['De Roeck', 'A.', ''], ['Dolan', 'M. J.', ''], ['Ellis', 'J. R.', ''], ['Flächer', 'H.', ''], ['Heinemeyer', 'S.', ''], ['Isidori', 'G.', ''], ['Lucio', 'M.', ''], ['Santos', 'D. Martínez', ''], ['Olive', 'K. A.', ''], ['Richards', 'A.', ''], ['de Vries', 'K. J.', ''], ['Weiglein', 'G.', '']]"
2103.14701,Vasilis Gavrielatos,"Vasilis Gavrielatos, Antonios Katsarakis, Vijay Nagarajan",Extending Classic Paxos for High-performance Read-Modify-Write Registers,,,,,cs.DC,http://creativecommons.org/licenses/by/4.0/,"  In this work we provide a detailed specification of how we extended and
implemented Classic Paxos (CP) to execute Read-Modify-Writes. In addition, we
also specify how we implemented All-aboard Paxos over CP and how we use
carstamps, to also add ABD reads and writes, to accelerate the common case,
where RMWs are not needed. Our specification targets a Key-Value-Store that is
deployed within the datacenter, is replicated across 3 to 7 machines and
supports reads, writes and RMWs.
","[{'version': 'v1', 'created': 'Fri, 26 Mar 2021 19:22:37 GMT'}]",2021-03-30,"[['Gavrielatos', 'Vasilis', ''], ['Katsarakis', 'Antonios', ''], ['Nagarajan', 'Vijay', '']]"
2010.05241,Alexander Gorban,"Bogdan Grechuk, Alexander N. Gorban, Ivan Y. Tyukin",General stochastic separation theorems with optimal bounds,"Numerical examples and illustrations are added, minor corrections
  extended discussion and the bibliography","Neural Networks, Volume 138, 2021, Pages 33-56",10.1016/j.neunet.2021.01.034,,cs.AI stat.ML,http://creativecommons.org/licenses/by/4.0/,"  Phenomenon of stochastic separability was revealed and used in machine
learning to correct errors of Artificial Intelligence (AI) systems and analyze
AI instabilities. In high-dimensional datasets under broad assumptions each
point can be separated from the rest of the set by simple and robust Fisher's
discriminant (is Fisher separable). Errors or clusters of errors can be
separated from the rest of the data. The ability to correct an AI system also
opens up the possibility of an attack on it, and the high dimensionality
induces vulnerabilities caused by the same stochastic separability that holds
the keys to understanding the fundamentals of robustness and adaptivity in
high-dimensional data-driven AI. To manage errors and analyze vulnerabilities,
the stochastic separation theorems should evaluate the probability that the
dataset will be Fisher separable in given dimensionality and for a given class
of distributions. Explicit and optimal estimates of these separation
probabilities are required, and this problem is solved in present work. The
general stochastic separation theorems with optimal probability estimates are
obtained for important classes of distributions: log-concave distribution,
their convex combinations and product distributions. The standard i.i.d.
assumption was significantly relaxed. These theorems and estimates can be used
both for correction of high-dimensional data driven AI systems and for analysis
of their vulnerabilities. The third area of application is the emergence of
memories in ensembles of neurons, the phenomena of grandmother's cells and
sparse coding in the brain, and explanation of unexpected effectiveness of
small neural ensembles in high-dimensional brain.
","[{'version': 'v1', 'created': 'Sun, 11 Oct 2020 13:12:41 GMT'}, {'version': 'v2', 'created': 'Sat, 9 Jan 2021 19:10:17 GMT'}]",2021-03-04,"[['Grechuk', 'Bogdan', ''], ['Gorban', 'Alexander N.', ''], ['Tyukin', 'Ivan Y.', '']]"
2005.12197,Christopher Small,C. Small,Spatiotemporal Network Evolution of Anthropogenic Night Light 1992-2015,"25 pages, 15 figures",,,,physics.soc-ph physics.geo-ph stat.AP,http://creativecommons.org/licenses/by/4.0/,"  Satellite imaging of night light provides a global record of lighted
development from 1992 to present. Not all settlements can be detected with
night light, but the continuum of built environments where a rapidly growing
majority of the population lives generally can. Segmenting a continuous field
into discrete spatially contiguous subsets of pixels produces a spatial network
in which each contiguous segment represents a distinct network component.
Representing the continuum of lighted development as spatial networks of
varying spatial connectivity allows the generative conditions for power law
network structure to be applied in a spatial context to provide a general
explanation for similar scaling observed in settlements and other land cover
types. This study introduces a novel methodology to combine complementary
sources of satellite-derived night light observations to quantify the evolution
of the global spatial network structure of lighted development from 1992 to
2015. Area-perimeter distributions of network components show multifractal
scaling with larger components becoming increasingly tortuous. Rank-size
distributions of network components are linear and well described by power laws
with exponents within 0.08 of -1 for all 27 subsets of geography, year and
degree of connectivity - indicating robust scaling properties. Area
distributions of luminance within network components show an abrupt transition
from continuously low-skewed for smaller components to discontinuous, nearly
uniform luminance distributions for larger components, suggesting a fundamental
change in network structure despite a continuum of size and shape. These
results suggest that city size scaling, observed inconsistently for
administratively-defined city populations, is more consistent for
physically-defined settlement network area and can be explained more simply by
a spatial network growth process.
","[{'version': 'v1', 'created': 'Mon, 25 May 2020 16:11:51 GMT'}]",2020-05-26,"[['Small', 'C.', '']]"
2203.04891,Jordan L Shivers,"Jordan L. Shivers, Abhinav Sharma, Fred C. MacKintosh","Nonaffinity controls critical slowing down and rheology near the onset
  of rigidity",,,,,cond-mat.soft physics.bio-ph,http://creativecommons.org/licenses/by/4.0/,"  Fluid-immersed networks and dense suspensions often reside near a boundary
between soft (or fluid-like) and rigid (or solid-like) mechanical regimes. This
boundary can be crossed either by varying the concentration or by deformation.
Near the onset or loss of rigidity, dissipation-limiting nonaffine
rearrangements dominate the macroscopic viscoelastic response, giving rise to
diverging relaxation times and power-law rheology. Here, we derive a simple
relationship between nonaffinity and excess viscosity in fluid-immersed
amorphous materials. We then demonstrate this relationship and its rheological
consequences in simulations of stress relaxation in strained filament networks
and dense suspensions.
","[{'version': 'v1', 'created': 'Wed, 9 Mar 2022 17:06:56 GMT'}]",2022-03-10,"[['Shivers', 'Jordan L.', ''], ['Sharma', 'Abhinav', ''], ['MacKintosh', 'Fred C.', '']]"
2103.17215,Alexandre Krajenbrink,"Alexandre Krajenbrink, Pierre Le Doussal","The inverse scattering of the Zakharov-Shabat system solves the weak
  noise theory of the Kardar-Parisi-Zhang equation",35 pages - V2 corrected a typo for the general initial condition,"Phys. Rev. Lett. 127, 064101 (2021)",10.1103/PhysRevLett.127.064101,,cond-mat.stat-mech math-ph math.DS math.MP math.PR nlin.SI,http://creativecommons.org/licenses/by/4.0/,"  We solve the large deviations of the Kardar-Parisi-Zhang (KPZ) equation in
one dimension at short time by introducing an approach which combines field
theoretical, probabilistic and integrable techniques. We expand the program of
the weak noise theory, which maps the large deviations onto a non-linear
hydrodynamic problem, and unveil its complete solvability through a connection
to the integrability of the Zakharov-Shabat system. Exact solutions, depending
on the initial condition of the KPZ equation, are obtained using the inverse
scattering method and a Fredholm determinant framework recently developed.
These results, explicit in the case of the droplet geometry, open the path to
obtain the complete large deviations for general initial conditions.
","[{'version': 'v1', 'created': 'Wed, 31 Mar 2021 16:59:43 GMT'}, {'version': 'v2', 'created': 'Sun, 9 May 2021 16:40:24 GMT'}]",2021-08-11,"[['Krajenbrink', 'Alexandre', ''], ['Doussal', 'Pierre Le', '']]"
2105.01253,Wei Guo,Toshiaki Kanai and Wei Guo,"The true mechanism of spontaneous order from turbulence in
  two-dimensional superfluid manifolds","6 pages, 6 figures","Phys. Rev. Lett. 127, 095301 (2021)",10.1103/PhysRevLett.127.095301,,cond-mat.quant-gas nlin.CD physics.flu-dyn,http://creativecommons.org/licenses/by/4.0/,"  In a two-dimensional (2D) turbulent fluid containing point-like vortices,
Lars Onsager predicted that adding energy to the fluid can lead to the
formation of persistent clusters of like-signed vortices, i.e., Onsager vortex
(OV) clusters. In the evolution of 2D superfluid turbulence in a uniform
disk-shaped Bose-Einstein condensate (BEC), it was discovered that a pair of OV
clusters with opposite signs can form without any energy input. This striking
spontaneous order was explained as due to a vortex evaporative-heating
mechanism, i.e., annihilations of vortex-antivortex pairs which remove the
lowest-energy vortices and thereby boost the mean energy per vortex. However,
in our search for exotic OV states in a boundaryless 2D spherical BEC, we found
that OV clusters never form despite the annihilations of vortex pairs. Our
analysis reveals that contrary to the general belief, vortex-pair annihilation
emits intense sound waves, which damp the motion of all vortices and hence
suppress the formation of OV clusters. We also present unequivocal evidences
showing that the true mechanism underlying the observed spontaneous OV state is
the escaping of vortices from the BEC boundary. Uncovering this mechanism paves
the way for a comprehensive understanding of emergent vortex orders in 2D
manifolds of superfluids driven far from equilibrium.
","[{'version': 'v1', 'created': 'Tue, 4 May 2021 02:21:08 GMT'}]",2021-09-01,"[['Kanai', 'Toshiaki', ''], ['Guo', 'Wei', '']]"
2110.03130,Olivier Monga Om,"Olivier Monga, Fr\'ed\'eric Hecht, Serge Moto, Bruno Mbe, Patricia
  Garnier, Val\'erie Pot","Generic tool for numerical simulation of transformation-diffusion
  processes in complex volume geometric shapes: application to microbial
  decomposition of organic matter","This paper represents, in my opinion, a breakthrough and then is
  worthing to be online before the end of the review process",,,,eess.IV cs.CV physics.comp-ph physics.med-ph,http://creativecommons.org/licenses/by/4.0/,"  This paper presents a generic framework for the numerical simulation of
transformation-diffusion processes in complex volume geometric shapes. This
work follows a previous one devoted to the simulation of microbial degradation
of organic matter in porous system at microscopic scale. We generalized and
improved the MOSAIC method significantly and thus yielding a much more generic
and efficient numerical simulation scheme. In particular, regarding the
simulation of diffusion processes from the graph, in this study we proposed a
completely explicit and semi-implicit numerical scheme that can significantly
reduce the computational complexity. We validated our method by comparing the
results to the one provided by classical Lattice Boltzmann Method (LBM) within
the context of microbial decomposition simulation. For the same datasets, we
obtained similar results in a significantly shorter computing time (i.e., 10-15
minutes) than the prior work (several hours). Besides the classical LBM method
takes around 3 weeks computing time.
","[{'version': 'v1', 'created': 'Thu, 7 Oct 2021 01:01:48 GMT'}, {'version': 'v2', 'created': 'Sat, 6 Nov 2021 14:44:31 GMT'}]",2021-11-09,"[['Monga', 'Olivier', ''], ['Hecht', 'Frédéric', ''], ['Moto', 'Serge', ''], ['Mbe', 'Bruno', ''], ['Garnier', 'Patricia', ''], ['Pot', 'Valérie', '']]"
2107.13473,Nicolas Valenchon,"Nicolas Valenchon, Yann Bouteiller, Hugo R. Jourde, Emily B.J. Coffey
  and Giovanni Beltrame","The Portiloop: a deep learning-based open science tool for closed-loop
  brain stimulation","12 pages, 13 Figures, journal paper. Open source code at
  https://github.com/mistlab/portiloop",,,,eess.SP cs.LG cs.NE q-bio.NC,http://creativecommons.org/licenses/by/4.0/,"  Electroencephalography (EEG) is a method of measuring the brain's electrical
activity, using non-invasive scalp electrodes. In this article, we propose the
Portiloop, a deep learning-based portable and low-cost device enabling the
neuroscience community to capture EEG, process it in real time, detect patterns
of interest, and respond with precisely-timed stimulation. The core of the
Portiloop is a System on Chip composed of an Analog to Digital Converter (ADC)
and a Field-Programmable Gate Array (FPGA). After being converted to digital by
the ADC, the EEG signal is processed in the FPGA. The FPGA contains an ad-hoc
Artificial Neural Network (ANN) with convolutional and recurrent units,
directly implemented in hardware. The output of the ANN is then used to trigger
the user-defined feedback. We use the Portiloop to develop a real-time sleep
spindle stimulating application, as a case study. Sleep spindles are a specific
type of transient oscillation ($\sim$2.5 s, 12-16 Hz) that are observed in EEG
recordings, and are related to memory consolidation during sleep. We tested the
Portiloop's capacity to detect and stimulate sleep spindles in real time using
an existing database of EEG sleep recordings. With 71% for both precision and
recall as compared with expert labels, the system is able to stimulate spindles
within $\sim$300 ms of their onset, enabling experimental manipulation of early
the entire spindle. The Portiloop can be extended to detect and stimulate other
neural events in EEG. It is fully available to the research community as an
open science project.
","[{'version': 'v1', 'created': 'Wed, 28 Jul 2021 16:29:58 GMT'}, {'version': 'v2', 'created': 'Fri, 30 Jul 2021 20:49:01 GMT'}]",2021-08-03,"[['Valenchon', 'Nicolas', ''], ['Bouteiller', 'Yann', ''], ['Jourde', 'Hugo R.', ''], ['Coffey', 'Emily B. J.', ''], ['Beltrame', 'Giovanni', '']]"
2109.05276,Muhammad Fahad Saleem,Muhammad Fahad Saleem,"Benchmarking Processor Performance by Multi-Threaded Machine Learning
  Algorithms","The research paper consists of seven pages and contains twenty nine
  figures",,,,cs.DC cs.AI cs.AR cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Machine learning algorithms have enabled computers to predict things by
learning from previous data. The data storage and processing power are
increasing rapidly, thus increasing machine learning and Artificial
intelligence applications. Much of the work is done to improve the accuracy of
the models built in the past, with little research done to determine the
computational costs of machine learning acquisitions. In this paper, I will
proceed with this later research work and will make a performance comparison of
multi-threaded machine learning clustering algorithms. I will be working on
Linear Regression, Random Forest, and K-Nearest Neighbors to determine the
performance characteristics of the algorithms as well as the computation costs
to the obtained results. I will be benchmarking system hardware performance by
running these multi-threaded algorithms to train and test the models on a
dataset to note the differences in performance matrices of the algorithms. In
the end, I will state the best performing algorithms concerning the performance
efficiency of these algorithms on my system.
","[{'version': 'v1', 'created': 'Sat, 11 Sep 2021 13:26:58 GMT'}]",2021-09-14,"[['Saleem', 'Muhammad Fahad', '']]"
1903.09053,Janet Drew,"J. E. Drew, M. Mongui\'o, N. J. Wright","The O star hinterland of the Galactic starburst, NGC 3603","11 pages, with a 6-page table (Appendix B). Accepted by MNRAS, 21st
  March 2019",,10.1093/mnras/stz864,,astro-ph.SR astro-ph.GA,http://creativecommons.org/licenses/by/4.0/,"  The very bright and compact massive young cluster, NGC 3603, has been cited
as an example of a starburst in the Milky Way and compared with the
much-studied R136/30 Doradus region in the Large Magellanic Cloud. Here we
build on the discovery by Mohr-Smith et al. (2017) of a large number of
reddened O stars around this cluster. We construct a list of 288 candidate O
stars with proper motions, in a region of sky spanning 1.5x1.5 square degrees
centered on NGC 3603, by cross-matching the Mohr-Smith et al. (2017) catalogue
with Gaia DR2 (Gaia Collaboration et al. 2018). This provides the basis for a
first comprehensive examination of the proper motions of these massive stars in
the halo of NGC 3603, relative to the much better studied central region. We
identify up to 11 likely O star ejections -- 8 of which would have been ejected
between 0.60 and 0.95 Myr ago (supporting the age of c.1 Myr that has been
attributed to the bright cluster centre). Seven candidate ejections are
arranged in a partial ring to the south of the cluster core spanning radii of
9-18 arcmin (18-36 pc if the cluster is 7 kpc away). We also show that the
cluster has a halo of a further 100 O stars extending to a radius of at least 5
arcmin, adding to the picture of NGC 3603 as a scaled down version of the
R136/30 Dor region.
","[{'version': 'v1', 'created': 'Thu, 21 Mar 2019 15:23:00 GMT'}]",2019-04-10,"[['Drew', 'J. E.', ''], ['Monguió', 'M.', ''], ['Wright', 'N. J.', '']]"
2108.11446,Manh-Huong Phan,"Hongxian Shen, Lin Luo, Sida Jiang, Jingshun Liu, Yanfen Liu,
  Yongjiang Huang, Lunyong Zhang, Jianfei Sun, Hillary Belliveau, and
  Manh-Huong Phan","A perspective magnetic bed comprising Gd alloy multi-microwires for
  energy-efficient magnetic refrigeration",,,,,physics.app-ph,http://creativecommons.org/licenses/by/4.0/,"  We have designed a new magnetic bed structure with desirable table-like
magnetocaloric effect (MCE) by using three kinds of soft ferromagnetic Gd-Al-Co
microwire arrays with different Curie temperatures ($T_C$). The $T_C$ interval
of these three wires is ~10 K and the designed new structure named Sample A.
This sample shows a smooth table-like magnetic entropy change ($\Delta S_M$) at
high applied field change ($\mu_0 \Delta H=5 T$) ranging from ~92 K to ~107 K.
The maximum entropy change ($-\Delta S_M^{\rm max}$) and refrigerant capacity
(RC) for Sample A at $\mu_0 \Delta H=5 T$ are calculated to be ~9.42
Jkg$^{-1}$K$^{-1}$ and ~676 Jkg$^{-1}$. The calculated curves of $-\Delta
S_M(T)$ and the corresponding experimental data match well with each other,
suggesting that the desirable magnetocaloric properties of the microwire arrays
can be designed. Simulation shows that the RC values of the designed systems
increase when increasing the interval of $T_C$. The table-like MCE and the
enhanced heat-transfer efficiency due to the enhanced surface areas of the
microwires make this newly designed magnetic bed very promising for use in
energy-efficient magnetic refrigerators.
","[{'version': 'v1', 'created': 'Wed, 25 Aug 2021 19:31:00 GMT'}]",2021-08-29,"[['Shen', 'Hongxian', ''], ['Luo', 'Lin', ''], ['Jiang', 'Sida', ''], ['Liu', 'Jingshun', ''], ['Liu', 'Yanfen', ''], ['Huang', 'Yongjiang', ''], ['Zhang', 'Lunyong', ''], ['Sun', 'Jianfei', ''], ['Belliveau', 'Hillary', ''], ['Phan', 'Manh-Huong', '']]"
1710.03784,Wenxiang Cong,"Wenxiang Cong, Ge Wang","Monochromatic CT Image Reconstruction from Current-Integrating Data via
  Deep Learning",,,,,physics.med-ph,http://creativecommons.org/licenses/by/4.0/,"  In clinical CT, the x-ray source emits polychromatic x-rays, which are
detected in the current-integrating mode. This physical process is accurately
described by an energy-dependent non-linear integral model on the basis of the
Beer-Lambert law. However, the non-linear model is too complicated to be
directly solved for the image reconstruction, and is often approximated to a
linear integral model in the form of the Radon transform, basically ignoring
energy-dependent information. This model approximation would generate
inaccurate quantification of attenuation image and significant beam-hardening
artifacts. In this paper, we develop a deep-learning-based CT image
reconstruction method to address the mismatch of computing model to physical
model. Our method learns a nonlinear transformation from big data to correct
measured projection data to accurately match the linear integral model, realize
monochromatic imaging and overcome beam hardening effectively. The
deep-learning network is trained and tested using clinical dual-energy dataset
to demonstrate the feasibility of the proposed methodology. Results show that
the proposed method can achieve a high accuracy of the projection correction
with a relative error of less than 0.2%.
","[{'version': 'v1', 'created': 'Tue, 10 Oct 2017 18:59:48 GMT'}, {'version': 'v2', 'created': 'Tue, 9 Jan 2018 19:03:15 GMT'}]",2018-01-11,"[['Cong', 'Wenxiang', ''], ['Wang', 'Ge', '']]"
2006.10256,K. Jarrod Millman,"Charles R. Harris, K. Jarrod Millman, St\'efan J. van der Walt, Ralf
  Gommers, Pauli Virtanen, David Cournapeau, Eric Wieser, Julian Taylor,
  Sebastian Berg, Nathaniel J. Smith, Robert Kern, Matti Picus, Stephan Hoyer,
  Marten H. van Kerkwijk, Matthew Brett, Allan Haldane, Jaime Fern\'andez del
  R\'io, Mark Wiebe, Pearu Peterson, Pierre G\'erard-Marchant, Kevin Sheppard,
  Tyler Reddy, Warren Weckesser, Hameer Abbasi, Christoph Gohlke, Travis E.
  Oliphant",Array Programming with NumPy,,"Nature 585, 357 (2020)",10.1038/s41586-020-2649-2,,cs.MS stat.CO,http://creativecommons.org/licenses/by/4.0/,"  Array programming provides a powerful, compact, expressive syntax for
accessing, manipulating, and operating on data in vectors, matrices, and
higher-dimensional arrays. NumPy is the primary array programming library for
the Python language. It plays an essential role in research analysis pipelines
in fields as diverse as physics, chemistry, astronomy, geoscience, biology,
psychology, material science, engineering, finance, and economics. For example,
in astronomy, NumPy was an important part of the software stack used in the
discovery of gravitational waves and the first imaging of a black hole. Here we
show how a few fundamental array concepts lead to a simple and powerful
programming paradigm for organizing, exploring, and analyzing scientific data.
NumPy is the foundation upon which the entire scientific Python universe is
constructed. It is so pervasive that several projects, targeting audiences with
specialized needs, have developed their own NumPy-like interfaces and array
objects. Because of its central position in the ecosystem, NumPy increasingly
plays the role of an interoperability layer between these new array computation
libraries.
","[{'version': 'v1', 'created': 'Thu, 18 Jun 2020 03:39:27 GMT'}]",2020-09-22,"[['Harris', 'Charles R.', ''], ['Millman', 'K. Jarrod', ''], ['van der Walt', 'Stéfan J.', ''], ['Gommers', 'Ralf', ''], ['Virtanen', 'Pauli', ''], ['Cournapeau', 'David', ''], ['Wieser', 'Eric', ''], ['Taylor', 'Julian', ''], ['Berg', 'Sebastian', ''], ['Smith', 'Nathaniel J.', ''], ['Kern', 'Robert', ''], ['Picus', 'Matti', ''], ['Hoyer', 'Stephan', ''], ['van Kerkwijk', 'Marten H.', ''], ['Brett', 'Matthew', ''], ['Haldane', 'Allan', ''], ['del Río', 'Jaime Fernández', ''], ['Wiebe', 'Mark', ''], ['Peterson', 'Pearu', ''], ['Gérard-Marchant', 'Pierre', ''], ['Sheppard', 'Kevin', ''], ['Reddy', 'Tyler', ''], ['Weckesser', 'Warren', ''], ['Abbasi', 'Hameer', ''], ['Gohlke', 'Christoph', ''], ['Oliphant', 'Travis E.', '']]"
1909.07232,Evgeny Pchelintsev,"Evgeny A. Pchelintsev, Serguei M. Pergamenshchikov, Maria A. Povzun","Improved estimation via model selection method for semimartingale
  regressions based on discrete data","38 pages, 6 figure, 2 tables",,,,math.ST math.PR stat.TH,http://creativecommons.org/licenses/by/4.0/,"  We consider the robust adaptive nonparametric estimation problem for a
periodic function observed in the framework of a continuous time regression
model with semimartingale noises.
","[{'version': 'v1', 'created': 'Mon, 16 Sep 2019 14:23:22 GMT'}, {'version': 'v2', 'created': 'Sat, 23 May 2020 10:21:34 GMT'}]",2020-05-26,"[['Pchelintsev', 'Evgeny A.', ''], ['Pergamenshchikov', 'Serguei M.', ''], ['Povzun', 'Maria A.', '']]"
2101.10121,Mu Zhu,"Mu Zhu, Ahmed H. Anwar, Zelin Wan, Jin-Hee Cho, Charles Kamhoua, and
  Munindar P. Singh","Game-Theoretic and Machine Learning-based Approaches for Defensive
  Deception: A Survey","37 pages, 184 citations",,,,cs.CR cs.GT cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Defensive deception is a promising approach for cyber defense. Via defensive
deception, the defender can anticipate attacker actions; it can mislead or lure
attacker, or hide real resources. Although defensive deception is increasingly
popular in the research community, there has not been a systematic
investigation of its key components, the underlying principles, and its
tradeoffs in various problem settings. This survey paper focuses on defensive
deception research centered on game theory and machine learning, since these
are prominent families of artificial intelligence approaches that are widely
employed in defensive deception. This paper brings forth insights, lessons, and
limitations from prior work. It closes with an outline of some research
directions to tackle major gaps in current defensive deception research.
","[{'version': 'v1', 'created': 'Thu, 21 Jan 2021 21:55:43 GMT'}, {'version': 'v2', 'created': 'Sat, 8 May 2021 18:57:26 GMT'}]",2021-05-11,"[['Zhu', 'Mu', ''], ['Anwar', 'Ahmed H.', ''], ['Wan', 'Zelin', ''], ['Cho', 'Jin-Hee', ''], ['Kamhoua', 'Charles', ''], ['Singh', 'Munindar P.', '']]"
1503.03434,Krzysztof Sokalski prof,"Krzysztof Sokalski, Barbara \'Slusarek, Bartosz Jankowski and Marek
  Przybylski","Bicriteria Optimization of Technological Parameters in Algorithm for
  Designing Magnetic Composites","17 pages, 6 figures",,,,physics.gen-ph,http://creativecommons.org/licenses/by/4.0/,"  Novel algorithm for designing values of technological parameters for
production of Soft Magnetic Composites (SMC) has been created. These parameters
are the following magnitudes: hardening temperature $T$ and compaction pressure
$p$. They enable us to optimize of power losses and induction. The advantage of
the presented algorithm consists in the bicriteria optimization. The crucial
role in the presented algorithm play scaling and notion of pseudo-state
equation. On the base of these items the mathematical models of the power
losses and induction have been created. The models parameters have been
calculated on the basis of the power losses characteristics and hysteresis
loops. The created optimization system has been applied to specimens of Somaloy
500. Obtained output consists of finite set of feasible solutions. In order to
select unique solution an example of additional criterion has been formulated.
","[{'version': 'v1', 'created': 'Wed, 11 Mar 2015 18:12:16 GMT'}, {'version': 'v2', 'created': 'Sat, 20 Jun 2015 18:08:25 GMT'}, {'version': 'v3', 'created': 'Mon, 27 Jul 2015 07:05:15 GMT'}]",2015-07-28,"[['Sokalski', 'Krzysztof', ''], ['Ślusarek', 'Barbara', ''], ['Jankowski', 'Bartosz', ''], ['Przybylski', 'Marek', '']]"
2109.02679,Tobias Dieselhorst,"Tobias Dieselhorst, William Cook, Sebastiano Bernuzzi, David Radice","Machine Learning for Conservative-to-Primitive in Relativistic
  Hydrodynamics","17 pages, 12 figures, 2 tables","Symmetry 2021, 13(11), 2157",10.3390/sym13112157,,astro-ph.IM physics.comp-ph physics.flu-dyn,http://creativecommons.org/licenses/by/4.0/,"  The numerical solution of relativistic hydrodynamics equations in
conservative form requires root-finding algorithms that invert the
conservative-to-primitive variables map. These algorithms employ the equation
of state of the fluid and can be computationally demanding for applications
involving sophisticated microphysics models, such as those required to
calculate accurate gravitational wave signals in numerical relativity
simulations of binary neutron stars. This work explores the use of machine
learning methods to speed up the recovery of primitives in relativistic
hydrodynamics. Artificial neural networks are trained to replace either the
interpolations of a tabulated equation of state or directly the
conservative-to-primitive map. The application of these neural networks to
simple benchmark problems shows that both approaches improve over traditional
root finders with tabular equation-of-state and multi-dimensional
interpolations. In particular, the neural networks for the
conservative-to-primitive map accelerate the variable recovery by more than an
order of magnitude over standard methods while maintaining accuracy. Neural
networks are thus an interesting option to improve the speed and robustness of
relativistic hydrodynamics algorithms.
","[{'version': 'v1', 'created': 'Mon, 6 Sep 2021 18:03:12 GMT'}, {'version': 'v2', 'created': 'Fri, 12 Nov 2021 16:10:20 GMT'}]",2021-11-15,"[['Dieselhorst', 'Tobias', ''], ['Cook', 'William', ''], ['Bernuzzi', 'Sebastiano', ''], ['Radice', 'David', '']]"
2104.02713,Amin Ebrahimi,"Amin Ebrahimi, Chris R. Kleijn, Marcel J.M. Hermans, Ian M. Richardson","The Effects of Process Parameters on Melt-pool Oscillatory Behaviour in
  Gas Tungsten Arc Welding","28 pages, 12 figures",J. Phys. D: Appl. Phys. 54 275303 (2021),10.1088/1361-6463/abf808,,physics.flu-dyn physics.app-ph,http://creativecommons.org/licenses/by/4.0/,"  Internal flow behaviour and melt-pool surface oscillations during arc welding
are complex and not yet fully understood. In the present work, high-fidelity
numerical simulations are employed to describe the effects of welding position,
sulphur concentration (60-300 ppm) and travel speed (1.25-5 mm/s) on molten
metal flow dynamics in fully-penetrated melt-pools. A wavelet transform is
implemented to obtain time-resolved frequency spectra of the oscillation
signals, which overcomes the shortcomings of the Fourier transform in rendering
time resolution of the frequency spectra. Comparing the results of the present
numerical calculations with available analytical and experimental datasets, the
robustness of the proposed approach in predicting melt-pool oscillations is
demonstrated. The results reveal that changes in the surface morphology of the
pool resulting from a change in welding position alter the spatial distribution
of arc forces and power-density applied to the molten material, and in turn
affect flow patterns in the pool. Under similar welding conditions, changing
the sulphur concentration affects the Marangoni flow pattern, and increasing
the travel speed decreases the size of the pool and increases the offset
between top and bottom melt-pool surfaces, affecting the flow structures
(vortex formation) on the surface. Variations in the internal flow pattern
affect the evolution of melt-pool shape and its surface oscillations.
","[{'version': 'v1', 'created': 'Tue, 6 Apr 2021 13:23:38 GMT'}]",2021-04-30,"[['Ebrahimi', 'Amin', ''], ['Kleijn', 'Chris R.', ''], ['Hermans', 'Marcel J. M.', ''], ['Richardson', 'Ian M.', '']]"
2203.03288,Cas Van Der Rest,Cas van der Rest and Jaro Reinders and Casper Bach Poulsen,Handling Higher-Order Effects,"25 pages, excluding references and appendices (33 pages total).
  Submitted draft",,,,cs.PL,http://creativecommons.org/licenses/by/4.0/,"  Algebraic effect handlers is a programming paradigm where programmers can
declare their own syntactic operations, and modularly define the semantics of
these using effect handlers.
  However, we cannot directly define algebraic effect handlers for many
higher-order operations (or higher-order effects) -- i.e., operations that have
computations as parameters.
  Examples of such higher-order effects include common programming features,
such as try-catch exception handlers, function abstraction, and more.
  In this paper we present a new kind of effect handler that addresses this
shortcoming.
  Our effect handler approach is closely related to previous work on scoped
effect handlers, which also supports higher-order effects.
  A key difference is that our effect handlers make it easy to understand
separate (higher-order) effects as separate concerns, since effects do not
interact.
  In contrast, effect interaction is the default with scoped effect handlers.
  While separate concerns is the default with our handlers, it is also possible
to define handlers where effects interact.
","[{'version': 'v1', 'created': 'Mon, 7 Mar 2022 11:04:25 GMT'}]",2022-03-08,"[['van der Rest', 'Cas', ''], ['Reinders', 'Jaro', ''], ['Poulsen', 'Casper Bach', '']]"
2006.00268,Yujie Hu,"Yujie Hu, Joni Downs",Measuring and Visualizing Place-Based Space-Time Job Accessibility,,"Journal of Transport Geography, 74, 278-288 (2019)",10.1016/j.jtrangeo.2018.12.002,,cs.CY econ.GN q-fin.EC stat.AP,http://creativecommons.org/licenses/by/4.0/,"  Place-based accessibility measures, such as the gravity-based model, are
widely applied to study the spatial accessibility of workers to job
opportunities in cities. However, gravity-based measures often suffer from
three main limitations: (1) they are sensitive to the spatial configuration and
scale of the units of analysis, which are not specifically designed for
capturing job accessibility patterns and are often too coarse; (2) they omit
the temporal dynamics of job opportunities and workers in the calculation,
instead assuming that they remain stable over time; and (3) they do not lend
themselves to dynamic geovisualization techniques. In this paper, a new
methodological framework for measuring and visualizing place-based job
accessibility in space and time is presented that overcomes these three
limitations. First, discretization and dasymetric mapping approaches are used
to disaggregate counts of jobs and workers over specific time intervals to a
fine-scale grid. Second, Shen (1998) gravity-based accessibility measure is
modified to account for temporal fluctuations in the spatial distributions of
the supply of jobs and the demand of workers and is used to estimate hourly job
accessibility at each cell. Third, a four-dimensional volumetric rendering
approach is employed to integrate the hourly job access estimates into a
space-time cube environment, which enables the users to interactively visualize
the space-time job accessibility patterns. The integrated framework is
demonstrated in the context of a case study of the Tampa Bay region of Florida.
The findings demonstrate the value of the proposed methodology in job
accessibility analysis and the policy-making process.
","[{'version': 'v1', 'created': 'Sat, 30 May 2020 13:39:07 GMT'}]",2020-06-02,"[['Hu', 'Yujie', ''], ['Downs', 'Joni', '']]"
2007.04265,Rafael Fuentes,J. R. Fuentes and A. Cumming,"Penetration of a cooling convective layer into a stably-stratified
  composition gradient: entrainment at low Prandtl number","Published in Physical Review Fluids. The published version has some
  minor typos. We fixed them in this version","Vol. 5, Iss. 12 - December 2020",10.1103/PhysRevFluids.5.124501,,astro-ph.SR astro-ph.EP physics.flu-dyn,http://creativecommons.org/licenses/by/4.0/,"  We study the formation and evolution of a convective layer when a
stably-stratified fluid with a composition gradient is cooled from above. We
perform a series of 2D simulations using the Bousinessq approximation with
Prandtl number ranging from Pr = 0.1 to 7, extending previous work on salty
water to low Pr. We show that the evolution of the convection zone is
well-described by an entrainment prescription in which a fixed fraction of the
kinetic energy of convective motions is used to mix fluid at the interface with
the stable layer. We measure the entrainment efficiency and find that it grows
with decreasing Prandtl number or increased applied heat flux. The kinetic
energy flux that determines the entrainment rate is a small fraction of the
total convective luminosity. In this time-dependent situation, the density
ratio at the interface is driven to a narrow range that depends on the value of
Pr, and with low enough values that advection dominates the interfacial
transport. We characterize the interfacial flux ratio and how it depends on the
interface stability. We present an analytic model that accounts for the growth
of the convective layer with two parameters, the entrainment efficiency and the
interfacial heat transport, both of which can be measure from the simulations.
","[{'version': 'v1', 'created': 'Wed, 8 Jul 2020 16:58:14 GMT'}, {'version': 'v2', 'created': 'Tue, 10 Nov 2020 00:59:25 GMT'}, {'version': 'v3', 'created': 'Tue, 13 Apr 2021 21:14:37 GMT'}, {'version': 'v4', 'created': 'Mon, 28 Jun 2021 20:34:27 GMT'}]",2021-06-30,"[['Fuentes', 'J. R.', ''], ['Cumming', 'A.', '']]"
1804.07508,Georgios Deskos Mr,"Georgios Deskos, Sylvain Laizet and Matthew D. Piggott",Turbulence-resolving simulations of wind turbine wakes,,,10.1016/j.renene.2018.11.084,,physics.flu-dyn,http://creativecommons.org/licenses/by/4.0/,"  Turbulence-resolving simulations of wind turbine wakes are presented using a
high--order flow solver combined with both a standard and a novel dynamic
implicit spectral vanishing viscosity (iSVV and dynamic iSVV) model to account
for subgrid-scale (SGS) stresses. The numerical solutions are compared against
wind tunnel measurements, which include mean velocity and turbulent intensity
profiles, as well as integral rotor quantities such as power and thrust
coefficients. For the standard (also termed static) case the magnitude of the
spectral vanishing viscosity is selected via a heuristic analysis of the wake
statistics, while in the case of the dynamic model the magnitude is adjusted
both in space and time at each time step. The study focuses on examining the
ability of the two approaches, standard (static) and dynamic, to accurately
capture the wake features, both qualitatively and quantitatively. The results
suggest that the static method can become over-dissipative when the magnitude
of the spectral viscosity is increased, while the dynamic approach which
adjusts the magnitude of dissipation locally is shown to be more appropriate
for a non-homogeneous flow such that of a wind turbine wake.
","[{'version': 'v1', 'created': 'Fri, 20 Apr 2018 09:20:05 GMT'}]",2018-12-07,"[['Deskos', 'Georgios', ''], ['Laizet', 'Sylvain', ''], ['Piggott', 'Matthew D.', '']]"
2112.08477,Sourav Sur,Mohit Kumar Sharma and Sourav Sur,Imprints of interacting dark energy on cosmological perturbations,"28 pages, 14 figures, 1 table. To appear in Int. J. Mod. Phys. D",,,,astro-ph.CO gr-qc hep-th,http://creativecommons.org/licenses/by/4.0/,"  We investigate the characteristic modifications in the evolving cosmological
perturbations when dark energy interacts with dust-like matter, causing the
latter's background energy density fall off with time faster than usual.
Focusing in particular to the late-time cosmic evolution, we show that such an
interaction (of a specific form, arising naturally in a scalar-tensor
formulation, or a wide range of modified gravity equivalents thereof), can have
a rather significant effect on the perturbative spectrum, than on the
background configuration which is not expected to get distorted much from
$\L$CDM. Specifically, the matter density contrast, which is by and large
scale-invariant in the deep sub-horizon limit, not only gets dragged as the
interaction affects the background Hubble expansion rate, but also receives a
contribution from the perturbation in the (scalar field induced) dark energy,
which oscillates about a non-zero mean value. As such, the standard
parametrization ansatz for the the matter density growth factor becomes
inadequate. So we modify it suitably, and also find a numerical fit of the
growth index in terms of the background parameters, in order to alleviate the
problems that arise otherwise. Such a fit enables direct estimations of the
background parameters, as well as the growth parameter and the reduced Hubble
parameter, which we duly carry out using a redshift space distortion (RSD)
subsample and its combination with the observational Hubble data. On the whole,
the parametric estimates show consistency with the general observational
constraints on the background level cosmology, as well as the constraints on
scalar-tensor gravity from astrophysical observations, apart from having
significance in the domain of cosmological perturbations.
","[{'version': 'v1', 'created': 'Wed, 15 Dec 2021 20:57:43 GMT'}]",2021-12-17,"[['Sharma', 'Mohit Kumar', ''], ['Sur', 'Sourav', '']]"
2203.06787,Xinhua Zhang,Xinhua Zhang and Lance R. Williams,"Euclidean Invariant Recognition of 2D Shapes Using Histograms of
  Magnitudes of Local Fourier-Mellin Descriptors","9 pages, 5 figures","2019 IEEE Winter Conference on Applications of Computer Vision
  (WACV), 2019, pp. 303-311",10.1109/WACV.2019.00038,,cs.CV,http://creativecommons.org/licenses/by/4.0/,"  Because the magnitude of inner products with its basis functions are
invariant to rotation and scale change, the Fourier-Mellin transform has long
been used as a component in Euclidean invariant 2D shape recognition systems.
Yet Fourier-Mellin transform magnitudes are only invariant to rotation and
scale changes about a known center point, and full Euclidean invariant shape
recognition is not possible except when this center point can be consistently
and accurately identified. In this paper, we describe a system where a
Fourier-Mellin transform is computed at every point in the image. The spatial
support of the Fourier-Mellin basis functions is made local by multiplying them
with a polynomial envelope. Significantly, the magnitudes of convolutions with
these complex filters at isolated points are not (by themselves) used as
features for Euclidean invariant shape recognition because reliable
discrimination would require filters with spatial support large enough to fully
encompass the shapes. Instead, we rely on the fact that normalized histograms
of magnitudes are fully Euclidean invariant. We demonstrate a system based on
the VLAD machine learning method that performs Euclidean invariant recognition
of 2D shapes and requires an order of magnitude less training data than
comparable methods based on convolutional neural networks.
","[{'version': 'v1', 'created': 'Sun, 13 Mar 2022 23:54:56 GMT'}]",2022-03-15,"[['Zhang', 'Xinhua', ''], ['Williams', 'Lance R.', '']]"
2108.02941,Vukosi Marivate,"Harm de Wet, Vukosi Marivate",Is it Fake? News Disinformation Detection on South African News Websites,"6 pages, Accepted and to be published in AFRICON 2021",,,,cs.CL cs.CY cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Disinformation through fake news is an ongoing problem in our society and has
become easily spread through social media. The most cost and time effective way
to filter these large amounts of data is to use a combination of human and
technical interventions to identify it. From a technical perspective, Natural
Language Processing (NLP) is widely used in detecting fake news. Social media
companies use NLP techniques to identify the fake news and warn their users,
but fake news may still slip through undetected. It is especially a problem in
more localised contexts (outside the United States of America). How do we
adjust fake news detection systems to work better for local contexts such as in
South Africa. In this work we investigate fake news detection on South African
websites. We curate a dataset of South African fake news and then train
detection models. We contrast this with using widely available fake news
datasets (from mostly USA website). We also explore making the datasets more
diverse by combining them and observe the differences in behaviour in writing
between nations' fake news using interpretable machine learning.
","[{'version': 'v1', 'created': 'Fri, 6 Aug 2021 04:54:03 GMT'}, {'version': 'v2', 'created': 'Mon, 9 Aug 2021 17:23:05 GMT'}]",2021-08-10,"[['de Wet', 'Harm', ''], ['Marivate', 'Vukosi', '']]"
2105.04848,Fouad Trad,"Salah El Falou, Fouad Trad","Forecast Analysis of the COVID-19 Incidence in Lebanon: Prediction of
  Future Epidemiological Trends to Plan More Effective Control Programs",,,10.1109/ICABME53305.2021.9604861,,cs.AI cs.CY,http://creativecommons.org/licenses/by/4.0/,"  Ever since the COVID-19 pandemic started, all the governments have been
trying to limit its effects on their citizens and countries. This pandemic was
harsh on different levels for almost all populations worldwide and this is what
drove researchers and scientists to get involved and work on several kinds of
simulations to get a better insight into this virus and be able to stop it the
earliest possible. In this study, we simulate the spread of COVID-19 in Lebanon
using an Agent-Based Model where people are modeled as agents that have
specific characteristics and behaviors determined from statistical
distributions using Monte Carlo Algorithm. These agents can go into the world,
interact with each other, and thus, infect each other. This is how the virus
spreads. During the simulation, we can introduce different Non-Pharmaceutical
Interventions - or more commonly NPIs - that aim to limit the spread of the
virus (wearing a mask, closing locations, etc). Our Simulator was first
validated on concepts (e.g. Flattening the Curve and Second Wave scenario), and
then it was applied on the case of Lebanon. We studied the effect of opening
schools and universities on the pandemic situation in the country since the
Lebanese Ministry of Education is planning to do so progressively, starting
from 21 April 2021. Based on the results we obtained, we conclude that it would
be better to delay the school openings while the vaccination campaign is still
slow in the country.
","[{'version': 'v1', 'created': 'Tue, 11 May 2021 08:07:03 GMT'}, {'version': 'v2', 'created': 'Tue, 22 Jun 2021 11:56:46 GMT'}]",2021-11-15,"[['Falou', 'Salah El', ''], ['Trad', 'Fouad', '']]"
2111.11154,Emma La Malfa Ribolla Dr.,"Martin Hor\'ak, Emma La Malfa Ribolla, Milan Jir\'asek","Efficient formulation of a two-noded curved beam element under finite
  rotations",,,,,cs.CE,http://creativecommons.org/licenses/by/4.0/,"  The paper extends the formulation of a 2D geometrically exact beam element
proposed in our previous paper [1] to curved elastic beams. This formulation is
based on equilibrium equations in their integrated form, combined with the
kinematic relations and sectional equations that link the internal forces to
sectional deformation variables. The resulting first-order differential
equations are approximated by the finite difference scheme and the boundary
value problem is converted to an initial value problem using the shooting
method. The paper develops the theoretical framework based on the
Navier-Bernoulli hypothesis but the approach could be extended to
shear-flexible beams. The initial shape of the beam is captured with high
accuracy, for certain shapes including the circular one even exactly. Numerical
procedures for the evaluation of equivalent nodal forces and of the element
tangent stiffness are presented in detail. Unlike standard finite element
formulations, the present approach can increase accuracy by refining the
integration scheme on the element level while the number of global degrees of
freedom is kept constant. The efficiency and accuracy of the developed scheme
are documented by five examples that cover circular and parabolic arches and a
spiral-shaped beam. It is also shown that, for initially curved beams, a cross
effect in the relations between internal forces and deformation variables
arises, i.e., the bending moment affects axial stretching and the normal force
affects the curvature.
","[{'version': 'v1', 'created': 'Mon, 22 Nov 2021 12:39:02 GMT'}, {'version': 'v2', 'created': 'Tue, 7 Dec 2021 09:48:58 GMT'}]",2021-12-08,"[['Horák', 'Martin', ''], ['Ribolla', 'Emma La Malfa', ''], ['Jirásek', 'Milan', '']]"
2202.04602,Tongyang Xu,"Tongyang Xu, Fan Liu, Christos Masouros and Izzat Darwazeh","An Experimental Proof of Concept for Integrated Sensing and
  Communications Waveform Design",,,,,eess.SP cs.SY eess.SY,http://creativecommons.org/licenses/by/4.0/,"  The integration of sensing and communication (ISAC) functionalities have
recently gained significant research interest as a hardware-, power-, spectrum-
and cost- efficient solution. This experimental work focuses on a
dual-functional radar sensing and communication framework where a single
radiation waveform, either omnidirectional or directional, can realize both
radar sensing and communication functions. We study a trade-off approach that
can balance the performance of communications and radar sensing. We design an
orthogonal frequency division multiplexing (OFDM) based multi-user multiple
input multiple output (MIMO) software-defined radio (SDR) testbed to validate
the dual-functional model. We carry out over-the-air experiments to investigate
the optimal trade-off factor to balance the performance for both functions. On
the radar performance, we measure the output beampatterns of our transmission
to examine their similarity to simulation based beampatterns. On the
communication side, we obtain bit error rate (BER) results from the testbed to
show the communication performance using the dual-functional waveform. Our
experiment reveals that the dual-functional approach can achieve comparable BER
performance with pure communication-based solutions while maintaining fine
radar beampatterns simultaneously.
","[{'version': 'v1', 'created': 'Wed, 9 Feb 2022 17:52:55 GMT'}]",2022-02-10,"[['Xu', 'Tongyang', ''], ['Liu', 'Fan', ''], ['Masouros', 'Christos', ''], ['Darwazeh', 'Izzat', '']]"
2107.10372,Mikhail Burov,"Mikhail Burov, Murat Arcak and Alexander Kurzhanskiy","Speed Advisory System Using Real-Time Actuated Traffic Light Phase
  Length Prediction",This work has been submitted to IEEE Transactions on ITS,,,,eess.SY cs.SY,http://creativecommons.org/licenses/by/4.0/,"  Speed advisory systems for connected vehicles rely on the estimation of green
(or red) light duration at signalized intersections. A particular challenge is
to predict the signal phases of semi- and fully-actuated traffic lights. In
this paper, we introduce an algorithm that processes traffic measurement data
collected from advanced detectors on road links and assigns ""PASS""/""WAIT""
labels to connected vehicles according to their predicted ability to go through
the upcoming signalized intersection within the current phase. Additional
computations provide an estimate for the duration of the current green phase
that can be used by the Speed Advisory System to minimize fuel consumption.
Simulation results show 95% prediction accuracy, which yields up to 30%
reduction in fuel consumption when used in a driver-assistance system. Traffic
progression quality also benefits from our algorithm demonstrating an
improvement of 20% at peak for medium traffic demand, reducing delays and
idling at intersections.
","[{'version': 'v1', 'created': 'Wed, 21 Jul 2021 22:09:46 GMT'}]",2021-07-23,"[['Burov', 'Mikhail', ''], ['Arcak', 'Murat', ''], ['Kurzhanskiy', 'Alexander', '']]"
1612.08960,"Neuffer, David V.","David Neuffer (Fermilab), Hisham Sayed (Brookhaven), Terry Hart, Don
  Summers (Mississippi U.)",Final Cooling for a High-Energy High-Luminosity Lepton Collider,16 pp,,10.1088/1748-0221/12/07/T07003,Fermilab-Pub-15-524-AD-APC,physics.acc-ph,http://creativecommons.org/licenses/by/4.0/,"  A high-energy muon collider scenario require a ""final cooling"" system that
reduces transverse emittance by a factor of ~10 while allowing longitudinal
emittance increase. The baseline approach has low-energy transverse cooling
within high-field solenoids, with strong longitudinal heating. This approach
and its recent simulation are discussed. Alternative approaches which more
explicitly include emittance exchange are also presented. Round-to-flat beam
transform, transverse slicing, and longitudinal bunch coalescence are possible
components of an alternative approach. Wedge-based emittance exchange could
provide much of the required transverse cooling with longitudinal heating.
Li-lens and quadrupole focusing systems could also provide much of the required
final cooling.
","[{'version': 'v1', 'created': 'Wed, 28 Dec 2016 19:45:09 GMT'}]",2017-08-02,"[['Neuffer', 'David', '', 'Fermilab'], ['Sayed', 'Hisham', '', 'Brookhaven'], ['Hart', 'Terry', '', 'Mississippi U.'], ['Summers', 'Don', '', 'Mississippi U.']]"
2108.06624,Harish S. Bhat,Harish S. Bhat and Majerle E. Reeves and Sidra Goldman-Mellor,Equity-Directed Bootstrapping: Examples and Analysis,17 pages,,,,stat.ML cs.LG stat.CO,http://creativecommons.org/licenses/by/4.0/,"  When faced with severely imbalanced binary classification problems, we often
train models on bootstrapped data in which the number of instances of each
class occur in a more favorable ratio, e.g., one. We view algorithmic inequity
through the lens of imbalanced classification: in order to balance the
performance of a classifier across groups, we can bootstrap to achieve training
sets that are balanced with respect to both labels and group identity. For an
example problem with severe class imbalance---prediction of suicide death from
administrative patient records---we illustrate how an equity-directed bootstrap
can bring test set sensitivities and specificities much closer to satisfying
the equal odds criterion. In the context of na\""ive Bayes and logistic
regression, we analyze the equity-directed bootstrap, demonstrating that it
works by bringing odds ratios close to one, and linking it to methods involving
intercept adjustment, thresholding, and weighting.
","[{'version': 'v1', 'created': 'Sat, 14 Aug 2021 22:09:27 GMT'}]",2021-08-17,"[['Bhat', 'Harish S.', ''], ['Reeves', 'Majerle E.', ''], ['Goldman-Mellor', 'Sidra', '']]"
1807.05826,Cm Pintea,"Camelia-M. Pintea, Andreea Camelia Tripon, Anca Avram, Gloria-Cerasela
  Crisan",Multi-agents features on Android platforms,"6 pages, 2 figures",Complex Adaptive Systems Modeling 6(10):1-12 (2018),10.1186/s40294-018-0061-7,,cs.MA cs.CY,http://creativecommons.org/licenses/by/4.0/,"  The current paper shows the multi-agents capabilities to make a valid and
flexible application when using a framework. Agent-based functions were used
within JADE framework to make an Android messenger application with all
requirements included. In the paper are described the architecture, the main
functions and the databases integration of the user friendly agent-based
application. There are included existing and possible multi-agents
characteristics to provide integration with mobile platforms and storage
challenges to improve the user experience through data mining.
","[{'version': 'v1', 'created': 'Mon, 16 Jul 2018 12:57:00 GMT'}]",2020-07-28,"[['Pintea', 'Camelia-M.', ''], ['Tripon', 'Andreea Camelia', ''], ['Avram', 'Anca', ''], ['Crisan', 'Gloria-Cerasela', '']]"
2202.05752,Julia Dyck,Julia Dyck and Odile Sauzet,"Parameter uncertainty estimation for exponential semi-variogram models:
  Two generalized bootstrap methods with check- and quantile-based filtering","25 pages, 4 figures",,,,stat.ME stat.CO,http://creativecommons.org/licenses/by/4.0/,"  The estimation of parameter standard errors for semi-variogram models is
challenging, given the two-step process required to fit a parametric model to
spatially correlated data. Motivated by an application in the
social-epidemiology, we focus on exponential semi-variogram models fitted to
data between 500 to 2000 observations and little control over the sampling
design. Previously proposed methods for the estimation of standard errors
cannot be applied in this context. Approximate closed form solutions are too
costly using generalized least squares in terms of memory capacities. The
generalized bootstrap proposed by Olea and Pardo-Ig\'uzquiza is nonetheless
applicable with weighted instead of generalized least squares. However, the
standard error estimates are hugely biased and imprecise. Therefore, we propose
a filtering method added to the generalized bootstrap. The new development is
presented and evaluated with a simulation study which shows that the
generalized bootstrap with check-based filtering leads to massively improved
results compared to the quantile-based filter method and previously developed
approaches. We provide a case study using birthweight data.
","[{'version': 'v1', 'created': 'Fri, 11 Feb 2022 16:46:23 GMT'}]",2022-02-14,"[['Dyck', 'Julia', ''], ['Sauzet', 'Odile', '']]"
2104.10454,Petr Marek,"Petr Marek, \v{S}t\v{e}p\'an M\""uller, Jakub Konr\'ad, Petr Lorenc,
  Jan Pichl and Jan \v{S}ediv\'y",Text Summarization of Czech News Articles Using Named Entities,,The Prague Bulletin of Mathematical Linguistics 2021 116,10.14712/00326585.012,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  The foundation for the research of summarization in the Czech language was
laid by the work of Straka et al. (2018). They published the SumeCzech, a large
Czech news-based summarization dataset, and proposed several baseline
approaches. However, it is clear from the achieved results that there is a
large space for improvement. In our work, we focus on the impact of named
entities on the summarization of Czech news articles. First, we annotate
SumeCzech with named entities. We propose a new metric ROUGE_NE that measures
the overlap of named entities between the true and generated summaries, and we
show that it is still challenging for summarization systems to reach a high
score in it. We propose an extractive summarization approach Named Entity
Density that selects a sentence with the highest ratio between a number of
entities and the length of the sentence as the summary of the article. The
experiments show that the proposed approach reached results close to the solid
baseline in the domain of news articles selecting the first sentence. Moreover,
we demonstrate that the selected sentence reflects the style of reports
concisely identifying to whom, when, where, and what happened. We propose that
such a summary is beneficial in combination with the first sentence of an
article in voice applications presenting news articles. We propose two
abstractive summarization approaches based on Seq2Seq architecture. The first
approach uses the tokens of the article. The second approach has access to the
named entity annotations. The experiments show that both approaches exceed
state-of-the-art results previously reported by Straka et al. (2018), with the
latter achieving slightly better results on SumeCzech's out-of-domain testing
set.
","[{'version': 'v1', 'created': 'Wed, 21 Apr 2021 10:48:14 GMT'}]",2021-04-22,"[['Marek', 'Petr', ''], ['Müller', 'Štěpán', ''], ['Konrád', 'Jakub', ''], ['Lorenc', 'Petr', ''], ['Pichl', 'Jan', ''], ['Šedivý', 'Jan', '']]"
2011.08281,Aditya Devarakonda,"Aditya Devarakonda, James Demmel",Avoiding Communication in Logistic Regression,,,,,cs.LG cs.DC,http://creativecommons.org/licenses/by/4.0/,"  Stochastic gradient descent (SGD) is one of the most widely used optimization
methods for solving various machine learning problems. SGD solves an
optimization problem by iteratively sampling a few data points from the input
data, computing gradients for the selected data points, and updating the
solution. However, in a parallel setting, SGD requires interprocess
communication at every iteration. We introduce a new communication-avoiding
technique for solving the logistic regression problem using SGD. This technique
re-organizes the SGD computations into a form that communicates every $s$
iterations instead of every iteration, where $s$ is a tuning parameter. We
prove theoretical flops, bandwidth, and latency upper bounds for SGD and its
new communication-avoiding variant. Furthermore, we show experimental results
that illustrate that the new Communication-Avoiding SGD (CA-SGD) method can
achieve speedups of up to $4.97\times$ on a high-performance Infiniband cluster
without altering the convergence behavior or accuracy.
","[{'version': 'v1', 'created': 'Mon, 16 Nov 2020 21:14:39 GMT'}]",2020-11-18,"[['Devarakonda', 'Aditya', ''], ['Demmel', 'James', '']]"
2012.01908,Sabah Al-Fedaghi Dr.,Sabah Al-Fedaghi,Exploration in Algorithm Engineering: Modeling Algorithms,"13 pages, 27 figures","IJCSNS International Journal of Computer Science and Network
  Security, VOL.20 No.11, 159-171, November 2020",,,cs.SE,http://creativecommons.org/licenses/by/4.0/,"  According to some algorithmicists, algorithmics traditionally uses algorithm
theory, which stems from mathematics. The growing need for innovative
algorithms has caused increasing gaps between theory and practice. Originally,
this motivated the development of algorithm engineering, which is viewed as
experimental techniques related to software engineering. Currently, algorithm
engineering is a methodology for algorithmic research that combines theory with
implementation and experimentation in order to produce better algorithms with
high practical impact. Still, researchers have questioned whether the notion of
algorithms can be defined in a fully generable way and discussed what kinds of
entities algorithms actually are. They have also struggled to maintain a view
that formulates algorithms mathematically (e.g., Turing machines and
finite-state machines [FSMs]) while adapting a more applied view. Answering the
question of what algorithms have practical applications in software
specifications in particular, this paper proposes a diagrammatical definition
of an algorithm based on a new modeling machine called a thinging machine (TM).
The machine has five actions (e.g., create, process, release, transfer, and
receive) that can form a network of machines. The paper explores the
application of the definition in Turing machines and FSMs. The results point to
the fact that the proposed definition can serve as a middle-ground
representation of algorithms, a definition which is between formal
specification and the commonly used informal definition (e.g., set of
instructions).
","[{'version': 'v1', 'created': 'Thu, 3 Dec 2020 13:39:28 GMT'}]",2020-12-04,"[['Al-Fedaghi', 'Sabah', '']]"
1802.04363,Kiril Shterev,Kiril S. Shterev,"On convective terms approximation approach that corresponds to pure
  convection","20 pages, 14 figures; keywords: Discrete Strea(line) Method, pure
  convection, second-order scheme, advection of a step profile, Smith and
  Hutton problem",,,,math.NA physics.comp-ph,http://creativecommons.org/licenses/by/4.0/,"  Recent decades are put lots of efforts to develop a higher-order scheme for
convective terms approximation that is stable and reliable. The idea presented
here is that approximation approach has to correspond to the physical
phenomenon described by approximated terms. Pure convection (advection) that is
described by convective terms is transporting a property along the streamline,
and the information propagation is unidirectional, i.e., transported property
depends on previous values along the streamline but does not depend on the next
ones. The proposed approach represents streamlines on mesh as discrete
streamlines and is called Discrete Stream(line) Method (DStreaM). A discrete
streamline here is represented as a narrow triangle with one vertex of the
approximated node and two others neighbor upstream nodes. Discrete streamlines
are orientated using local flow direction as skew upwind schemes. DStreaM
corresponds to pure convection. Here are considered standard test problems:
advection of a step profile, advection of a double-step profile, advection of a
sinusoidal profile, and Smith and Hutton problem. DStreaM solutions were
compared with upwind-first order scheme and second-order Total Variation
Diminishing (TVD) schemes with limiters Min-Mod, QUICK, and SUPERBEE solutions.
DStreaM demonstrated second-order accuracy and rapid convergence. Upwind and
DStreaM need 2 or 4 iterations to reach a final solution while TVD schemes need
from 15 to 93.5 more iterations. DStreaM approach looks promising for
calculation of convective-dominated problems because it approximates naturally
first derivatives and is straightforwardly applicable as a meshfree method or
on unstructured meshes.
","[{'version': 'v1', 'created': 'Mon, 12 Feb 2018 21:17:24 GMT'}, {'version': 'v2', 'created': 'Mon, 29 Oct 2018 16:26:32 GMT'}]",2018-10-30,"[['Shterev', 'Kiril S.', '']]"
2106.14110,Amartya Mukherjee,"Amartya Mukherjee, Yusuf Aydogdu, Thambirajah Ravichandran and
  Navaratnam Sri Namachchivaya","Stochastic Parameterization using Compressed Sensing: Application to the
  Lorenz-96 Atmospheric Model","21 pages. 8 figures. Submitted to Tellus A: Dynamic Meteorology and
  Oceanography",,,,math.DS math.OC physics.ao-ph stat.CO,http://creativecommons.org/licenses/by/4.0/,"  Growing set of optimization and regression techniques, based upon sparse
representations of signals, to build models from data sets has received
widespread attention recently with the advent of compressed sensing. This paper
deals with the parameterization of the Lorenz-96 model with two time-scales
that mimics mid-latitude atmospheric dynamics with microscopic convective
processes. Compressed sensing is used to build models (vector fields) to
emulate the behavior of the fine-scale process, so that explicit simulations
become an online benchmark for parameterization. We apply compressed sensing,
where the sparse recovery is achieved by constructing a sensing/dictionary
matrix from ergodic samples generated by the Lorenz-96 atmospheric model, to
parameterize the unresolved variables in terms of resolved variables.
Stochastic parameterization is achieved by auto-regressive modelling of noise.
We utilize the ensemble Kalman filter for data assimilation, where observations
(direct measurements) are assimilated in the low-dimensional stochastic
parameterized model to provide predictions. Finally, we compare the predictions
of compressed sensing and Wilk's polynomial regression to demonstrate the
potential effectiveness of the proposed methodology.
","[{'version': 'v1', 'created': 'Sat, 26 Jun 2021 23:25:55 GMT'}, {'version': 'v2', 'created': 'Fri, 22 Oct 2021 19:49:09 GMT'}]",2021-10-26,"[['Mukherjee', 'Amartya', ''], ['Aydogdu', 'Yusuf', ''], ['Ravichandran', 'Thambirajah', ''], ['Namachchivaya', 'Navaratnam Sri', '']]"
2104.11102,Nicos Makris,Eleftheria Efthymiou and Nicos Makris,"Pulse-Period--Moment-Magnitude Relations Derived with Wavelet Analysis
  and their Relevance to Estimate Structural Deformations",,,,,physics.geo-ph,http://creativecommons.org/licenses/by/4.0/,"  Motivated from the quadratic dependence of peak structural displacements to
the pulse period, $T_p$, of pulse-like ground motions, this paper revisits the
$T_p$--$M_\text{W}$ relations of ground motions generated from near-source
earthquakes with epicentral distances, $D\leq$ 20 km. A total of 1260 ground
motions are interrogated with wavelet analysis to identify energetic
acceleration pulses (not velocity pulses) and extract their optimal period,
$T_p$, amplitude, $a_p$, phase, $\phi$ and number of half-cycles, $\gamma$. The
interrogation of acceleration records with wavelet analysis is capable of
extracting shorter-duration distinguishable pulses with engineering
significance, which override the longer near-source pulses. Our wavelet
analysis identified 109 pulse-like records from normal faults, 188 records from
reverse faults and 125 records from strike-slip faults, all with epicentral
distances $D\leq$ 20 km. Regression analysis on the extracted data concluded
that the same $T_p$--$M_\text{W}$ relation can be used for pulse-like ground
motions generated either from strike-slip faults or from normal faults;
whereas, a different $T_p$--$M_{\text{W}}$ relation is proposed for reverse
faults. The study concludes that for the same moment magnitude, $M_{\text{W}}$,
the pulse periods of ground motions generated from strike-slip faults are on
average larger than these from reverse faults. Most importantly, our wavelet
analysis on acceleration records produces $T_p$--$M_{\text{W}}$ relations with
a lower slope than the slopes of the $T_p$--$M_{\text{W}}$ relations presented
by past investigators after merely fitting velocity pulses. As a result, our
proposed $T_p$--$M_{\text{W}}$ relations yield lower $T_p$ values for
larger-magnitude earthquakes (say $M_{\text{W}}>$ 6), allowing for the
estimation of dependable peak structural displacements that scale invariably
with $a_pT_p^{\text{2}}$.
","[{'version': 'v1', 'created': 'Thu, 22 Apr 2021 14:36:45 GMT'}]",2021-04-23,"[['Efthymiou', 'Eleftheria', ''], ['Makris', 'Nicos', '']]"
2203.04592,Matthias Samwald,"Adriano Barbosa-Silva, Simon Ott, Kathrin Blagec, Jan Brauner,
  Matthias Samwald","Mapping global dynamics of benchmark creation and saturation in
  artificial intelligence",,,,,cs.AI cs.CL cs.CV,http://creativecommons.org/licenses/by/4.0/,"  Benchmarks are crucial to measuring and steering progress in artificial
intelligence (AI). However, recent studies raised concerns over the state of AI
benchmarking, reporting issues such as benchmark overfitting, benchmark
saturation and increasing centralization of benchmark dataset creation. To
facilitate monitoring of the health of the AI benchmarking ecosystem, we
introduce methodologies for creating condensed maps of the global dynamics of
benchmark creation and saturation. We curated data for 1688 benchmarks covering
the entire domains of computer vision and natural language processing, and show
that a large fraction of benchmarks quickly trended towards near-saturation,
that many benchmarks fail to find widespread utilization, and that benchmark
performance gains for different AI tasks were prone to unforeseen bursts. We
conclude that future work should focus on large-scale community collaboration
and on mapping benchmark performance gains to real-world utility and impact of
AI.
","[{'version': 'v1', 'created': 'Wed, 9 Mar 2022 09:16:49 GMT'}]",2022-03-10,"[['Barbosa-Silva', 'Adriano', ''], ['Ott', 'Simon', ''], ['Blagec', 'Kathrin', ''], ['Brauner', 'Jan', ''], ['Samwald', 'Matthias', '']]"
2105.08549,Anthony Perez,"Ma\""el Dumas, Anthony Perez, Ioan Todinca",A cubic vertex-kernel for Trivially Perfect Editing,,,,,cs.DS cs.CC,http://creativecommons.org/licenses/by/4.0/,"  We consider the Trivially Perfect Editing problem, where one is given an
undirected graph $G = (V,E)$ and a parameter $k \in \mathbb{N}$ and seeks to
edit (add or delete) at most $k$ edges from $G$ to obtain a trivially perfect
graph. The related Trivially Perfect Completion and Trivially Perfect Deletion
problems are obtained by only allowing edge additions or edge deletions,
respectively. Trivially perfect graphs are both chordal and cographs, and have
applications related to the tree-depth width parameter and to social network
analysis. All variants of the problem are known to be NP-Complete and to admit
so-called polynomial kernels. More precisely, the existence of an $O(k^3)$
vertex-kernel for Trivially Perfect Completion was announced by Guo (ISAAC
2007) but without a stand-alone proof. More recently, Drange and Pilipczuk
(Algorithmica 2018) provided $O(k^7)$ vertex-kernels for these problems and
left open the existence of cubic vertex-kernels. In this work, we answer
positively to this question for all three variants of the problem.
","[{'version': 'v1', 'created': 'Tue, 18 May 2021 14:35:12 GMT'}]",2021-05-19,"[['Dumas', 'Maël', ''], ['Perez', 'Anthony', ''], ['Todinca', 'Ioan', '']]"
2008.11802,Ibrahim Abdel-Motaleb,Sakib Islam and Ibrahim Abdel-Motaleb,Thermal Stress Analysis of Liquid-Cooled 3D-ICs,"This article has been accepted for presentation in the IEEE-EIT 2020
  conference. The article is 4 pages and 11 Figures",,,,physics.app-ph,http://creativecommons.org/licenses/by/4.0/,"  It is known that 3D-ICs suffer from hot spot temperatures that can reach
thousands of degrees, if they are not cooled to reasonable operating
temperatures. The problem of hot spots is not limited to the high temperatures
of the IC; thermal stress can also pose severe problems, even after cooling the
chip. This study investigates thermal stress resulting from a 3D-IC hot spot
with 20 W power dissipation. The IC is cooled using SiO2 and diamond cooling
blocks. The study is performed using three cooling liquids: water, Freon (R22),
and Liquid Nitrogen (LN). As expected, the study shows that metal layers on the
chip suffer from high thermal stress due to rising the chip temperature to
values higher than the room temperature. It is also noticed that the stress
becomes more severe, if cooling is done using LN. In fact, the stress exceeded
the maximum tensile strength of aluminum, which means failure of the chip. This
indicates that cooling 3D-IC may not ensure acceptable operation or
reliability. Thermal stress must be investigated at both high and low
temperatures to ensure high performance and acceptable reliability.
","[{'version': 'v1', 'created': 'Wed, 26 Aug 2020 20:40:44 GMT'}]",2020-08-28,"[['Islam', 'Sakib', ''], ['Abdel-Motaleb', 'Ibrahim', '']]"
2107.14085,Pavel Ginzburg,"S. Kosulnikov, D. Filonov, A. Boag, and P. Ginzburg","Volumetric Metamaterials versus Impedance Surfaces in Scattering
  Applications",,,,,physics.app-ph physics.optics,http://creativecommons.org/licenses/by/4.0/,"  Artificially created media allow employing material parameters as additional
valuable degrees of freedom in tailoring electromagnetic scattering. In
particular, metamaterials with either negative permeability or permittivity
allow creating deeply subwavelength resonant structures with relatively high
scattering crosssections. However, the equivalence principle allows replacing
volumetric structures with properly designed curved impedance surfaces,
ensuring the same electromagnetic properties. Here, we examine this statement
from a practical standpoint, considering two structures, having a dipolar
electric resonance at the same frequency. The first realization is based on
arrays of inductively loaded electric dipoles printed on stacked circuit boards
(a volumetric metamaterial), while the second structure utilizes a 4-wire
spiral on a spherical surface (surface impedance realization). An intermediate
conclusion is that the surface implementation tends to outperform the
volumetric counterparts in the scenario when a single resonance is involved.
However, in the case where multiple resonances are overlapping and lossy
materials are involved, volumetric realization can have an advantage. The
discussed structures are of significant importance to the field of electrically
small antennas, superdirective antennas, and superscatterers, which find use in
wireless communications and radar applications, to name just a few.
","[{'version': 'v1', 'created': 'Thu, 1 Jul 2021 19:51:45 GMT'}]",2021-07-30,"[['Kosulnikov', 'S.', ''], ['Filonov', 'D.', ''], ['Boag', 'A.', ''], ['Ginzburg', 'P.', '']]"
2103.11811,David Adelani,"David Ifeoluwa Adelani, Jade Abbott, Graham Neubig, Daniel D'souza,
  Julia Kreutzer, Constantine Lignos, Chester Palen-Michel, Happy Buzaaba,
  Shruti Rijhwani, Sebastian Ruder, Stephen Mayhew, Israel Abebe Azime,
  Shamsuddeen Muhammad, Chris Chinenye Emezue, Joyce Nakatumba-Nabende, Perez
  Ogayo, Anuoluwapo Aremu, Catherine Gitau, Derguene Mbaye, Jesujoba Alabi,
  Seid Muhie Yimam, Tajuddeen Gwadabe, Ignatius Ezeani, Rubungo Andre
  Niyongabo, Jonathan Mukiibi, Verrah Otiende, Iroro Orife, Davis David, Samba
  Ngom, Tosin Adewumi, Paul Rayson, Mofetoluwa Adeyemi, Gerald Muriuki,
  Emmanuel Anebi, Chiamaka Chukwuneke, Nkiruka Odu, Eric Peter Wairagala,
  Samuel Oyerinde, Clemencia Siro, Tobius Saul Bateesa, Temilola Oloyede,
  Yvonne Wambui, Victor Akinode, Deborah Nabagereka, Maurice Katusiime, Ayodele
  Awokoya, Mouhamadane MBOUP, Dibora Gebreyohannes, Henok Tilaye, Kelechi
  Nwaike, Degaga Wolde, Abdoulaye Faye, Blessing Sibanda, Orevaoghene Ahia,
  Bonaventure F. P. Dossou, Kelechi Ogueji, Thierno Ibrahima DIOP, Abdoulaye
  Diallo, Adewale Akinfaderin, Tendai Marengereke, and Salomey Osei",MasakhaNER: Named Entity Recognition for African Languages,"Accepted to TACL 2021, pre-MIT Press publication version",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  We take a step towards addressing the under-representation of the African
continent in NLP research by creating the first large publicly available
high-quality dataset for named entity recognition (NER) in ten African
languages, bringing together a variety of stakeholders. We detail
characteristics of the languages to help researchers understand the challenges
that these languages pose for NER. We analyze our datasets and conduct an
extensive empirical evaluation of state-of-the-art methods across both
supervised and transfer learning settings. We release the data, code, and
models in order to inspire future research on African NLP.
","[{'version': 'v1', 'created': 'Mon, 22 Mar 2021 13:12:44 GMT'}, {'version': 'v2', 'created': 'Mon, 5 Jul 2021 15:14:32 GMT'}]",2021-07-06,"[['Adelani', 'David Ifeoluwa', ''], ['Abbott', 'Jade', ''], ['Neubig', 'Graham', ''], [""D'souza"", 'Daniel', ''], ['Kreutzer', 'Julia', ''], ['Lignos', 'Constantine', ''], ['Palen-Michel', 'Chester', ''], ['Buzaaba', 'Happy', ''], ['Rijhwani', 'Shruti', ''], ['Ruder', 'Sebastian', ''], ['Mayhew', 'Stephen', ''], ['Azime', 'Israel Abebe', ''], ['Muhammad', 'Shamsuddeen', ''], ['Emezue', 'Chris Chinenye', ''], ['Nakatumba-Nabende', 'Joyce', ''], ['Ogayo', 'Perez', ''], ['Aremu', 'Anuoluwapo', ''], ['Gitau', 'Catherine', ''], ['Mbaye', 'Derguene', ''], ['Alabi', 'Jesujoba', ''], ['Yimam', 'Seid Muhie', ''], ['Gwadabe', 'Tajuddeen', ''], ['Ezeani', 'Ignatius', ''], ['Niyongabo', 'Rubungo Andre', ''], ['Mukiibi', 'Jonathan', ''], ['Otiende', 'Verrah', ''], ['Orife', 'Iroro', ''], ['David', 'Davis', ''], ['Ngom', 'Samba', ''], ['Adewumi', 'Tosin', ''], ['Rayson', 'Paul', ''], ['Adeyemi', 'Mofetoluwa', ''], ['Muriuki', 'Gerald', ''], ['Anebi', 'Emmanuel', ''], ['Chukwuneke', 'Chiamaka', ''], ['Odu', 'Nkiruka', ''], ['Wairagala', 'Eric Peter', ''], ['Oyerinde', 'Samuel', ''], ['Siro', 'Clemencia', ''], ['Bateesa', 'Tobius Saul', ''], ['Oloyede', 'Temilola', ''], ['Wambui', 'Yvonne', ''], ['Akinode', 'Victor', ''], ['Nabagereka', 'Deborah', ''], ['Katusiime', 'Maurice', ''], ['Awokoya', 'Ayodele', ''], ['MBOUP', 'Mouhamadane', ''], ['Gebreyohannes', 'Dibora', ''], ['Tilaye', 'Henok', ''], ['Nwaike', 'Kelechi', ''], ['Wolde', 'Degaga', ''], ['Faye', 'Abdoulaye', ''], ['Sibanda', 'Blessing', ''], ['Ahia', 'Orevaoghene', ''], ['Dossou', 'Bonaventure F. P.', ''], ['Ogueji', 'Kelechi', ''], ['DIOP', 'Thierno Ibrahima', ''], ['Diallo', 'Abdoulaye', ''], ['Akinfaderin', 'Adewale', ''], ['Marengereke', 'Tendai', ''], ['Osei', 'Salomey', '']]"
2008.08045,Arash Azhand,"Dr. Arash Azhand, Dr. Sophie Rabe, Dr. Swantje M\""uller, Igor Sattler,
  Dr. Anika Steinert","Algorithm Based on One Monocular Video Delivers Highly Valid and
  Reliable Gait Parameters",,,,,eess.SP cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Despite its paramount importance for manifold use cases (e.g., in the health
care industry, sports, rehabilitation and fitness assessment), sufficiently
valid and reliable gait parameter measurement is still limited to high-tech
gait laboratories mostly. Here, we demonstrate the excellent validity and
test-retest repeatability of a novel gait assessment system which is built upon
modern convolutional neural networks to extract three-dimensional skeleton
joints from monocular frontal-view videos of walking humans. The validity study
is based on a comparison to the GAITRite pressure-sensitive walkway system. All
measured gait parameters (gait speed, cadence, step length and step time)
showed excellent concurrent validity for multiple walk trials at normal and
fast gait speeds. The test-retest-repeatability is on the same level as the
GAITRite system. In conclusion, we are convinced that our results can pave the
way for cost, space and operationally effective gait analysis in broad
mainstream applications. Most sensor-based systems are costly, must be operated
by extensively trained personnel (e.g., motion capture systems) or - even if
not quite as costly - still possess considerable complexity (e.g., wearable
sensors). In contrast, a video sufficient for the assessment method presented
here can be obtained by anyone, without much training, via a smartphone camera.
","[{'version': 'v1', 'created': 'Wed, 5 Aug 2020 12:02:22 GMT'}, {'version': 'v2', 'created': 'Wed, 19 Aug 2020 14:04:52 GMT'}, {'version': 'v3', 'created': 'Tue, 25 Aug 2020 16:08:21 GMT'}, {'version': 'v4', 'created': 'Tue, 8 Sep 2020 14:48:22 GMT'}, {'version': 'v5', 'created': 'Wed, 23 Jun 2021 08:34:15 GMT'}]",2021-06-24,"[['Azhand', 'Dr. Arash', ''], ['Rabe', 'Dr. Sophie', ''], ['Müller', 'Dr. Swantje', ''], ['Sattler', 'Igor', ''], ['Steinert', 'Dr. Anika', '']]"
2107.04291,Yiqun Lin,"Yiqun Lin, Lichang Chen, Haibin Huang, Chongyang Ma, Xiaoguang Han and
  Shuguang Cui",Beyond Farthest Point Sampling in Point-Wise Analysis,"12 pages, 13 figures and 13 tables",,,,cs.CV,http://creativecommons.org/licenses/by/4.0/,"  Sampling, grouping, and aggregation are three important components in the
multi-scale analysis of point clouds. In this paper, we present a novel
data-driven sampler learning strategy for point-wise analysis tasks. Unlike the
widely used sampling technique, Farthest Point Sampling (FPS), we propose to
learn sampling and downstream applications jointly. Our key insight is that
uniform sampling methods like FPS are not always optimal for different tasks:
sampling more points around boundary areas can make the point-wise
classification easier for segmentation. Towards the end, we propose a novel
sampler learning strategy that learns sampling point displacement supervised by
task-related ground truth information and can be trained jointly with the
underlying tasks. We further demonstrate our methods in various point-wise
analysis architectures, including semantic part segmentation, point cloud
completion, and keypoint detection. Our experiments show that jointly learning
of the sampler and task brings remarkable improvement over previous baseline
methods.
","[{'version': 'v1', 'created': 'Fri, 9 Jul 2021 08:08:44 GMT'}, {'version': 'v2', 'created': 'Mon, 12 Jul 2021 03:04:09 GMT'}]",2021-07-13,"[['Lin', 'Yiqun', ''], ['Chen', 'Lichang', ''], ['Huang', 'Haibin', ''], ['Ma', 'Chongyang', ''], ['Han', 'Xiaoguang', ''], ['Cui', 'Shuguang', '']]"
2108.04729,Giuseppe Re,"Flavio Chierichetti, Alessandro Panconesi, Giuseppe Re, Luca Trevisan","Spectral Robustness for Correlation Clustering Reconstruction in
  Semi-Adversarial Models",,,,,cs.DS cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Correlation Clustering is an important clustering problem with many
applications. We study the reconstruction version of this problem in which one
is seeking to reconstruct a latent clustering that has been corrupted by random
noise and adversarial modifications. Concerning the latter, there is a standard
""post-adversarial"" model in the literature, in which adversarial modifications
come after the noise. Here, we introduce and analyse a ""pre-adversarial"" model
in which adversarial modifications come before the noise. Given an input coming
from such a semi-adversarial generative model, the goal is to reconstruct
almost perfectly and with high probability the latent clustering. We focus on
the case where the hidden clusters have nearly equal size and show the
following. In the pre-adversarial setting, spectral algorithms are optimal, in
the sense that they reconstruct all the way to the information-theoretic
threshold beyond which no reconstruction is possible. This is in contrast to
the post-adversarial setting, in which their ability to restore the hidden
clusters stops before the threshold, but the gap is optimally filled by
SDP-based algorithms. These results highlight a heretofore unknown robustness
of spectral algorithms, showing them less brittle than previously thought.
","[{'version': 'v1', 'created': 'Tue, 10 Aug 2021 14:46:17 GMT'}, {'version': 'v2', 'created': 'Thu, 20 Jan 2022 17:34:32 GMT'}, {'version': 'v3', 'created': 'Wed, 2 Feb 2022 15:32:27 GMT'}, {'version': 'v4', 'created': 'Tue, 8 Feb 2022 11:36:38 GMT'}]",2022-02-09,"[['Chierichetti', 'Flavio', ''], ['Panconesi', 'Alessandro', ''], ['Re', 'Giuseppe', ''], ['Trevisan', 'Luca', '']]"
2103.01703,Tomoyuki Maruyama,"Tomoyuki Maruyama, A. Baha Balantekind, Myung-Ki Cheoung, Toshitaka
  Kajino, Motohiko Kusakabef, Grant J. Mathewsh","A Relativistic Quantum Approach to Neutrino and Antineutrino Emissions
  via the Direct Urca Process in Strongly Magnetized Neutron-Star Matter","15 pages, 5 figures",,10.1016/j.physletb.2021.136813,,nucl-th astro-ph.HE,http://creativecommons.org/licenses/by/4.0/,"  We study neutrino and antineutrino emission from the direct Urca process in
neutron-star matter in the presence of strong magnetic fields. We calculate the
neutrino emissivity of the direct Urca process, whereby a neutron converts to a
proton, an electron and an antineutrino, or a proton-electron pair converts to
a neutron-neutrino pair. We solve exact wave functions for protons and
electrons in the states described with Landau levels. We find that the direct
Urca process can satisfy the kinematic constraints even in density regions
where this process could not normally occur in the absence of a magnetic field.
","[{'version': 'v1', 'created': 'Tue, 2 Mar 2021 13:19:29 GMT'}, {'version': 'v2', 'created': 'Wed, 3 Mar 2021 08:45:37 GMT'}, {'version': 'v3', 'created': 'Fri, 5 Mar 2021 06:13:33 GMT'}, {'version': 'v4', 'created': 'Wed, 3 Nov 2021 05:06:07 GMT'}, {'version': 'v5', 'created': 'Mon, 6 Dec 2021 06:52:33 GMT'}, {'version': 'v6', 'created': 'Sat, 11 Dec 2021 12:28:10 GMT'}]",2021-12-14,"[['Maruyama', 'Tomoyuki', ''], ['Balantekind', 'A. Baha', ''], ['Cheoung', 'Myung-Ki', ''], ['Kajino', 'Toshitaka', ''], ['Kusakabef', 'Motohiko', ''], ['Mathewsh', 'Grant J.', '']]"
2105.02917,Gino Chacon,"Gino Chacon, Tapojyoti Mandal, Johann Knechtel, Ozgur Sinanoglu, Paul
  Gratz, Vassos Soteriou",Coherence Attacks and Countermeasures in Interposer-Based Systems,,,,,cs.AR cs.CR,http://creativecommons.org/licenses/by/4.0/,"  Industry is moving towards large-scale systems where processor cores,
memories, accelerators, etc.\ are bundled via 2.5D integration. These various
components are fabricated separately as chiplets and then integrated using an
interconnect carrier, a so-called interposer. This new design style provides
benefits in terms of yield as well as economies of scale, as chiplets may come
from various third-party vendors, and be integrated into one sophisticated
system. The benefits of this approach, however, come at the cost of new
challenges for the system's security and integrity when many third-party
component chiplets, some from not fully trusted vendors, are integrated.
  Here, we explore these challenges, but also promises, for modern
interposer-based systems of cache-coherent, multi-core chiplets. First, we
introduce a new, coherence-based attack, GETXspy, wherein a single compromised
chiplet can expose a high-bandwidth side/covert-channel in an ostensibly secure
system. We further show that prior art is insufficient to stop this new attack.
Second, we propose using an active interposer as generic,
secure-by-construction platform that forms a physical root of trust for modern
2.5D systems. Our scheme has limited overhead, restricted to the active
interposer, allowing the chiplets and the coherence system to remain untouched.
We show that our scheme prevents a wide range of attacks, including but not
limited to our GETXspy attack, with little overhead on system performance,
$\sim$4\%. This overhead reduces as workloads increase, ensuring scalability of
the scheme.
","[{'version': 'v1', 'created': 'Thu, 6 May 2021 19:06:04 GMT'}, {'version': 'v2', 'created': 'Fri, 7 Jan 2022 17:58:16 GMT'}]",2022-01-10,"[['Chacon', 'Gino', ''], ['Mandal', 'Tapojyoti', ''], ['Knechtel', 'Johann', ''], ['Sinanoglu', 'Ozgur', ''], ['Gratz', 'Paul', ''], ['Soteriou', 'Vassos', '']]"
2101.07304,Brendan Lucier,"Nicole Immorlica, Ian Kash, Brendan Lucier","Buying Data Over Time: Approximately Optimal Strategies for Dynamic
  Data-Driven Decisions",,,,,cs.GT,http://creativecommons.org/licenses/by/4.0/,"  We consider a model where an agent has a repeated decision to make and wishes
to maximize their total payoff. Payoffs are influenced by an action taken by
the agent, but also an unknown state of the world that evolves over time.
Before choosing an action each round, the agent can purchase noisy samples
about the state of the world. The agent has a budget to spend on these samples,
and has flexibility in deciding how to spread that budget across rounds. We
investigate the problem of choosing a sampling algorithm that optimizes total
expected payoff. For example: is it better to buy samples steadily over time,
or to buy samples in batches? We solve for the optimal policy, and show that it
is a natural instantiation of the latter. Under a more general model that
includes per-round fixed costs, we prove that a variation on this batching
policy is a 2-approximation.
","[{'version': 'v1', 'created': 'Mon, 18 Jan 2021 19:50:20 GMT'}]",2021-01-20,"[['Immorlica', 'Nicole', ''], ['Kash', 'Ian', ''], ['Lucier', 'Brendan', '']]"
1512.05503,Bogdan Vasile Mihalcea,"Bogdan M. Mihalcea, Liviu C. Giurgiu, Cristina Stan, Gina T. Visan,
  Mihai Ganciu, Vladimir E. Filinov, Dmitry S. Lapitsky, Lidiya V. Deputatova,
  Roman A. Syrovatka","Multipole Electrodynamic Ion Trap Geometries for Microparticle
  Confinement under Standard Ambient Temperature and Pressure Conditions","24 pages, 11 figures","J. Appl. Phys. 119, 114303 (2016)",10.1063/1.4943933,,physics.plasm-ph astro-ph.IM physics.atm-clus physics.atom-ph,http://creativecommons.org/licenses/by/4.0/,"  Trapping of microparticles and aerosols is of great interest for physics and
chemistry. We report microparticle trapping in multipole linear Paul trap
geometries, operating under Standard Ambient Temperature and Pressure (SATP)
conditions. An 8-electrode and a 12-electrode linear trap geometries have been
designed and tested with an aim to achieve trapping for larger number of
particles and to study microparticle dynamical stability in electrodynamic
fields. We report emergence of planar and volume ordered structures of the
microparticles, depending on the a.c. trapping frequency and particle specific
charge ratio. The electric potential within the trap was mapped using the
electrolytic tank method. Particle dynamics was simulated using a stochastic
Langevin equation. We emphasize extended regions of stable trapping with
respect to quadrupole traps, as well as good agreement between experiment and
numerical simulations.
","[{'version': 'v1', 'created': 'Thu, 17 Dec 2015 09:18:39 GMT'}, {'version': 'v2', 'created': 'Thu, 7 Jan 2016 08:16:23 GMT'}, {'version': 'v3', 'created': 'Mon, 11 Jan 2016 11:59:43 GMT'}, {'version': 'v4', 'created': 'Mon, 14 Mar 2016 11:03:19 GMT'}]",2016-09-29,"[['Mihalcea', 'Bogdan M.', ''], ['Giurgiu', 'Liviu C.', ''], ['Stan', 'Cristina', ''], ['Visan', 'Gina T.', ''], ['Ganciu', 'Mihai', ''], ['Filinov', 'Vladimir E.', ''], ['Lapitsky', 'Dmitry S.', ''], ['Deputatova', 'Lidiya V.', ''], ['Syrovatka', 'Roman A.', '']]"
2111.14587,Jean Besbas Dr.,"Zexiang Hu, Jean Besbas, Ross Smith, Niclas Teichert, Gwenael
  Atcheson, Karsten Rode, Plamen Stamenov and J. M. D. Coey","Single-pulse all-optical switching in amorphous Dy$_x$Co$_{1-x}\text{ }$
  and Tb$_x$Co$_{1-x}$","The following article has been submitted to Applied Physics Letters -
  Special Issue",,,,cond-mat.mtrl-sci physics.app-ph physics.optics,http://creativecommons.org/licenses/by/4.0/,"  Repeated uniform switching of the magnetization of thin films of
ferrimagnetic amorphous Gd$_{x}$(FeCo)$_{1-x}$ in response to single fast laser
pulses is well established. Here we report unusual toggle switching in thin
films of sperimagnetic amorphous Dy$_x$Co$_{1-x}$ and Tb$_x$Co$_{1-x}$ with
$\it{x} \simeq$ 0.25 irradiated with single 200 fs pulses of 800 nm laser
light. The samples have strong local random anisotropy due to the non-S state
rare earth. The compensation temperature of the films is $\le$ 180 K and their
Curie temperature is $\simeq$ 500 K. They are mostly switched by the first
pulse, and subsequent pulses lead to partial re-switching of a decreasing
amount of the irradiated area, with a granular structure of submicron regions
of switched and unswitched material. Individual switched domains about 700 nm
in size are observed around the edge of the irradiated spots where the fluence
is at the threshold for switching. Results are discussed in terms of a random
anisotropy model where the ratio of local anisotropy to exchange is temperature
dependent and close to the threshold for strong pinning.
","[{'version': 'v1', 'created': 'Mon, 29 Nov 2021 15:20:28 GMT'}]",2021-11-30,"[['Hu', 'Zexiang', ''], ['Besbas', 'Jean', ''], ['Smith', 'Ross', ''], ['Teichert', 'Niclas', ''], ['Atcheson', 'Gwenael', ''], ['Rode', 'Karsten', ''], ['Stamenov', 'Plamen', ''], ['Coey', 'J. M. D.', '']]"
2110.13017,Charles Margossian,"Charles C. Margossian, Matthew D. Hoffman, Pavel Sountsov","Nested $\hat R$: Assessing Convergence for Markov chain Monte Carlo when
  using many short chains",,,,,stat.ME,http://creativecommons.org/licenses/by/4.0/,"  When using Markov chain Monte Carlo (MCMC) algorithms, we can increase the
number of samples either by running longer chains or by running more chains.
Practitioners often prefer the first approach because chains need an initial
``warmup'' phase to forget their initial states; the number of operations
needed for warmup is constant with respect to chain length but increases
linearly with the number of chains. However, highly parallel hardware
accelerators such as GPUs may allow us to run many chains in parallel almost as
quickly as a single chain. This makes it more attractive to run many chains
with a short sampling phase. Unfortunately, existing diagnostics are not
designed for the ``many short chains'' regime. This is notably the case for the
popular $\hat R$ statistic which claims convergence only if the effective
sample size \textit{per chain} is sufficiently large. We present $\mathfrak
n\hat R$, a generalization of $\hat R$, which does not conflate short chains
and poor mixing, and offers a useful diagnostic provided we run enough chains
and meet certain initialization conditions. We define what constitutes a proper
warmup in the many-chains regime and recommend a threshold for $\mathfrak n
\hat R$. Furthermore we use $\mathfrak n \hat R$ to construct a warmup scheme
with an adaptive length, allowing users to avoid running their MCMC algorithms
longer than necessary.
","[{'version': 'v1', 'created': 'Mon, 25 Oct 2021 14:53:55 GMT'}]",2021-10-26,"[['Margossian', 'Charles C.', ''], ['Hoffman', 'Matthew D.', ''], ['Sountsov', 'Pavel', '']]"
1903.09358,Hsien-Chih Chang,"Pankaj K. Agarwal, Hsien-Chih Chang, Allen Xiao",Efficient Algorithms for Geometric Partial Matching,,,,,cs.DS cs.CG,http://creativecommons.org/licenses/by/4.0/,"  Let $A$ and $B$ be two point sets in the plane of sizes $r$ and $n$
respectively (assume $r \leq n$), and let $k$ be a parameter. A matching
between $A$ and $B$ is a family of pairs in $A \times B$ so that any point of
$A \cup B$ appears in at most one pair. Given two positive integers $p$ and
$q$, we define the cost of matching $M$ to be $c(M) = \sum_{(a, b) \in
M}\|{a-b}\|_p^q$ where $\|{\cdot}\|_p$ is the $L_p$-norm. The geometric partial
matching problem asks to find the minimum-cost size-$k$ matching between $A$
and $B$.
  We present efficient algorithms for geometric partial matching problem that
work for any powers of $L_p$-norm matching objective: An exact algorithm that
runs in $O((n + k^2) {\mathop{\mathrm{polylog}}} n)$ time, and a $(1 +
\varepsilon)$-approximation algorithm that runs in $O((n + k\sqrt{k})
{\mathop{\mathrm{polylog}}} n \cdot \log\varepsilon^{-1})$ time. Both
algorithms are based on the primal-dual flow augmentation scheme; the main
improvements involve using dynamic data structures to achieve efficient flow
augmentations. With similar techniques, we give an exact algorithm for the
planar transportation problem running in $O(\min\{n^2, rn^{3/2}\}
{\mathop{\mathrm{polylog}}} n)$ time.
","[{'version': 'v1', 'created': 'Fri, 22 Mar 2019 05:03:14 GMT'}]",2019-03-25,"[['Agarwal', 'Pankaj K.', ''], ['Chang', 'Hsien-Chih', ''], ['Xiao', 'Allen', '']]"
2202.12277,Julien Grand-Cl\'ement,Julien Grand-Cl\'ement and Christian Kroer,Solving optimization problems with Blackwell approachability,arXiv admin note: text overlap with arXiv:2105.13203,,,,math.OC cs.LG,http://creativecommons.org/licenses/by/4.0/,"  We introduce the Conic Blackwell Algorithm$^+$ (CBA$^+$) regret minimizer, a
new parameter- and scale-free regret minimizer for general convex sets. CBA$^+$
is based on Blackwell approachability and attains $O(\sqrt{T})$ regret. We show
how to efficiently instantiate CBA$^+$ for many decision sets of interest,
including the simplex, $\ell_{p}$ norm balls, and ellipsoidal confidence
regions in the simplex. Based on CBA$^+$, we introduce SP-CBA$^+$, a new
parameter-free algorithm for solving convex-concave saddle-point problems,
which achieves a $O(1/\sqrt{T})$ ergodic rate of convergence. In our
simulations, we demonstrate the wide applicability of SP-CBA$^+$ on several
standard saddle-point problems, including matrix games, extensive-form games,
distributionally robust logistic regression, and Markov decision processes. In
each setting, SP-CBA$^+$ achieves state-of-the-art numerical performance, and
outperforms classical methods, without the need for any choice of step sizes or
other algorithmic parameters.
","[{'version': 'v1', 'created': 'Thu, 24 Feb 2022 18:19:21 GMT'}]",2022-02-25,"[['Grand-Clément', 'Julien', ''], ['Kroer', 'Christian', '']]"
2106.05258,Ali Jahanian,"Ali Jahanian, Xavier Puig, Yonglong Tian, Phillip Isola",Generative Models as a Data Source for Multiview Representation Learning,,,,,cs.CV,http://creativecommons.org/licenses/by/4.0/,"  Generative models are now capable of producing highly realistic images that
look nearly indistinguishable from the data on which they are trained. This
raises the question: if we have good enough generative models, do we still need
datasets? We investigate this question in the setting of learning
general-purpose visual representations from a black-box generative model rather
than directly from data. Given an off-the-shelf image generator without any
access to its training data, we train representations from the samples output
by this generator. We compare several representation learning methods that can
be applied to this setting, using the latent space of the generator to generate
multiple ""views"" of the same semantic content. We show that for contrastive
methods, this multiview data can naturally be used to identify positive pairs
(nearby in latent space) and negative pairs (far apart in latent space). We
find that the resulting representations rival or even outperform those learned
directly from real data, but that good performance requires care in the
sampling strategy applied and the training method. Generative models can be
viewed as a compressed and organized copy of a dataset, and we envision a
future where more and more ""model zoos"" proliferate while datasets become
increasingly unwieldy, missing, or private. This paper suggests several
techniques for dealing with visual representation learning in such a future.
Code is available on our project page https://ali-design.github.io/GenRep/.
","[{'version': 'v1', 'created': 'Wed, 9 Jun 2021 17:54:55 GMT'}, {'version': 'v2', 'created': 'Tue, 15 Mar 2022 01:20:44 GMT'}, {'version': 'v3', 'created': 'Wed, 16 Mar 2022 02:14:39 GMT'}]",2022-03-17,"[['Jahanian', 'Ali', ''], ['Puig', 'Xavier', ''], ['Tian', 'Yonglong', ''], ['Isola', 'Phillip', '']]"
2108.07633,Samuel Pearson Mr,"Samuel Pearson, Aleks Scholz, Paula S Teixeira, Koraljka Mu\v{z}i\'c,
  V\'ictor Almendros-Abad",The first spectroscopically confirmed brown dwarfs in NGC 2264,"Accepted for publication in MNRAS; 12 pages, 13 figures",,10.1093/mnras/stab2394,,astro-ph.SR astro-ph.GA,http://creativecommons.org/licenses/by/4.0/,"  We present spectroscopic follow-up observations of 68 red, faint candidates
from our multi-epoch, multi-wavelength, previously published survey of NGC
2264. Using near-infrared spectra from VLT/KMOS, we measure spectral types and
extinction for 32 young low-mass sources. We confirm 13 as brown dwarfs in NGC
2264, with spectral types between M6 and M8, corresponding to masses between
0.02 and 0.08$M_{\odot}$. These are the first spectroscopically confirmed brown
dwarfs in this benchmark cluster. 19 more objects are found to be young M-type
stars of NGC 2264 with masses of 0.08 to 0.3$\,M_{\odot}$. 7 of the confirmed
brown dwarfs as well as 15 of the M-stars have IR excess caused by a disc.
Comparing with isochrones, the typical age of the confirmed brown dwarfs is
$<$0.5 to 5Myr. More than half of the newly identified brown dwarfs and very
low mass stars have ages $<$0.5Myr, significantly younger than the bulk of the
known cluster population. Based on the success rate of our spectroscopic
follow-up, we estimate that NGC 2264 hosts 200-600 brown dwarfs in total (in
the given mass range). This would correspond to a star-to-brown dwarf ratio
between 2.5:1 and 7.5:1. We determine the slope of the substellar mass function
as $\alpha = 0.43^{+0.41}_{-0.56}$, these values are consistent with those
measured for other young clusters. This points to a uniform substellar mass
function across all star forming environments.
","[{'version': 'v1', 'created': 'Tue, 17 Aug 2021 13:55:34 GMT'}]",2021-09-01,"[['Pearson', 'Samuel', ''], ['Scholz', 'Aleks', ''], ['Teixeira', 'Paula S', ''], ['Mužić', 'Koraljka', ''], ['Almendros-Abad', 'Víctor', '']]"
1706.01102,Aniket Bera,"Aniket Bera, Tanmay Randhavane, Rohan Prinja and Dinesh Manocha","SocioSense: Robot Navigation Amongst Pedestrians with Social and
  Psychological Constraints",,,,,cs.RO cs.MA,http://creativecommons.org/licenses/by/4.0/,"  We present a real-time algorithm, SocioSense, for socially-aware navigation
of a robot amongst pedestrians. Our approach computes time-varying behaviors of
each pedestrian using Bayesian learning and Personality Trait theory. These
psychological characteristics are used for long-term path prediction and
generating proximic characteristics for each pedestrian. We combine these
psychological constraints with social constraints to perform human-aware robot
navigation in low- to medium-density crowds. The estimation of time-varying
behaviors and pedestrian personalities can improve the performance of long-term
path prediction by 21%, as compared to prior interactive path prediction
algorithms. We also demonstrate the benefits of our socially-aware navigation
in simulated environments with tens of pedestrians.
","[{'version': 'v1', 'created': 'Sun, 4 Jun 2017 16:41:52 GMT'}]",2017-06-06,"[['Bera', 'Aniket', ''], ['Randhavane', 'Tanmay', ''], ['Prinja', 'Rohan', ''], ['Manocha', 'Dinesh', '']]"
2102.04802,Yufei Zhang,Yufei Zhang and Wenjuan Fang,"Geometrical constraints on curvature from galaxy-lensing
  cross-correlations","13 pages, 4 figures, 3 tables, minor modifications reflect PRD
  accepted version","Phys. Rev. D 103, 043539(2021)",10.1103/PhysRevD.103.043539,,astro-ph.CO,http://creativecommons.org/licenses/by/4.0/,"  Accurate constraints on curvature provide a powerful probe of inflation.
However, curvature constraints based on specific assumptions of dark energy may
lead to unreliable conclusions when used to test inflation models. To avoid
this, it is important to obtain constraints that are independent on assumptions
for dark energy. In this paper, we investigate such constraints on curvature
from the geometrical probe constructed from galaxy-lensing cross-correlations.
We study comprehensively the cross-correlations of galaxy with magnification,
measured from type Ia supernovae's brightnesses (""$g\kappa^{\rm SN}$""), with
shear (""$g\kappa^{\rm g}$""), and with CMB lensing (""$g\kappa^{\rm CMB}$""). We
find for the LSST and Stage IV CMB surveys, ""$g\kappa^{\rm SN}$"" ,
""$g\kappa^{\rm g}$"" and ""$g\kappa^{\rm CMB}$"" can be detected with
signal-to-noise ratio $S/N=104,\ 2291,\ 1842$ respectively. When combined with
supernovae Hubble diagram (""SN"") to constrain curvature, we find galaxy-lensing
cross-correlation becomes increasingly important with more degrees of freedom
allowed in dark energy. Without any priors, we obtain error on $\Omega_K$ of
$0.723$ from ""SN + $g\kappa^{\rm SN}$"", $0.0417$ from ""SN + $g\kappa^{\rm g}$"",
and $0.04$ from ""SN + $g\kappa^{\rm g}$ + $g\kappa^{\rm CMB}$"" for the LSST and
Stage IV CMB surveys. The last one is more competitive than a Stage IV BAO
survey (""BAO""). When galaxy-lensing cross-correlations are added to the
combined probe of ""SN + BAO + CMB"", where ""CMB"" stands for Planck measurement
for the CMB acoustic scale, we obtain constraint on $\Omega_K$ of $0.0013$,
which is a factor of 7 improvement from ""SN + BAO + CMB"". We study improvements
in these results from increasing the high redshift extension of supernovae.
","[{'version': 'v1', 'created': 'Tue, 9 Feb 2021 12:47:01 GMT'}, {'version': 'v2', 'created': 'Wed, 24 Feb 2021 08:19:58 GMT'}]",2021-03-02,"[['Zhang', 'Yufei', ''], ['Fang', 'Wenjuan', '']]"
2107.14674,Fernanda Leticia Dos Santos,"Fernanda L. dos Santos, Nikolaj A. P. Even, Laura Botero-Bol\'ivar,
  Cornelis H. Venner, Leandro D. de Santana","Influence of Surface Roughness Geometry on Trailing Edge Wall Pressure
  Fluctuations and Noise",,AIAA 2021-2294. AIAA AVIATION 2021 FORUM. August 2021,10.2514/6.2021-2294,,physics.flu-dyn,http://creativecommons.org/licenses/by/4.0/,"  Surface roughness elements are commonly used in wind tunnel testing to hasten
the laminar-turbulent transition of the boundary layer in model tests to mimic
the aerodynamic effects present in the full-scale application. These devices
can alter the characteristics of the turbulent boundary layer, such as the
spanwise correlation length, the boundary layer thickness, etc. This not only
affects the aerodynamic performance but also the aeroacoustic characteristics
of the tested model. Few studies have investigated the effects of surface
roughness elements on the trailing edge near- and far-field noise. So far, the
influence of roughness on the wall pressure fluctuations and spanwise coherence
at the trailing edge has been left unexplored. Thus, this research addresses
the effects of surface roughness geometries of different heights on the
trailing edge wall pressure fluctuations, the spanwise coherence, and the
far-field noise. Wind tunnel experiments were performed adopting zigzag strips
and novel sharkskin-like surface roughness installed in a NACA 0012 at zero
angle of attack. The tested surface roughness heights ranged from 29% to 233%
of the undisturbed boundary layer thickness. The wall pressure fluctuations and
the far-field noise were measured for Reynolds numbers from 1.3x10^5 to
3.3x10^5. It was observed that the surface roughness affects the low- and
high-frequency range of the wall pressure spectrum, with trip heights in the
range from 50% to 110% of the undisturbed boundary layer thickness having a
slight level increase for low frequencies and no difference for high
frequencies. The far-field noise increased for low and high frequencies as the
trip height increased. The low-frequency increase is a consequence of the trip
effects on the trailing edge wall pressure fluctuations, whereas for high
frequencies the increase is due to the noise generated by the trip itself.
","[{'version': 'v1', 'created': 'Fri, 30 Jul 2021 14:51:39 GMT'}]",2021-08-02,"[['Santos', 'Fernanda L. dos', ''], ['Even', 'Nikolaj A. P.', ''], ['Botero-Bolívar', 'Laura', ''], ['Venner', 'Cornelis H.', ''], ['de Santana', 'Leandro D.', '']]"
2103.04867,Peter Kirwan,"Peter D. Kirwan, Suzanne Elgohari, Christopher H. Jackson, Brian D. M.
  Tom, Sema Mandal, Daniela De Angelis, Anne M. Presanis","Trends in risks of severe events and lengths of stay for COVID-19
  hospitalisations in England over the pre-vaccination era: results from the
  Public Health England SARI-Watch surveillance scheme","45 pages, 12 figures",,,,stat.AP,http://creativecommons.org/licenses/by/4.0/,"  Background: Trends in hospitalised case-fatality risk (HFR), risk of
intensive care unit (ICU) admission and lengths of stay for patients
hospitalised for COVID-19 in England over the pre-vaccination era are unknown.
  Methods: Data on hospital and ICU admissions with COVID-19 at 31 NHS trusts
in England were collected by Public Health England's Severe Acute Respiratory
Infections surveillance system and linked to death information. We applied
parametric multi-state mixture models, accounting for censored outcomes and
regressing risks and times between events on month of admission, geography, and
baseline characteristics.
  Findings: 20,785 adults were admitted with COVID-19 in 2020. Between March
and June/July/August estimated HFR reduced from 31.9% (95% confidence interval
30.3-33.5%) to 10.9% (9.4-12.7%), then rose steadily from 21.6% (18.4-25.5%) in
September to 25.7% (23.0-29.2%) in December, with steeper increases among older
patients, those with multi-morbidity and outside London/South of England. ICU
admission risk reduced from 13.9% (12.8-15.2%) in March to 6.2% (5.3-7.1%) in
May, rising to a high of 14.2% (11.1-17.2%) in September. Median length of stay
in non-critical care increased during 2020, from 6.6 to 12.3 days for those
dying, and from 6.1 to 9.3 days for those discharged.
  Interpretation: Initial improvements in patient outcomes, corresponding to
developments in clinical practice, were not sustained throughout 2020, with HFR
in December approaching the levels seen at the start of the pandemic, whilst
median hospital stays have lengthened. The role of increased transmission, new
variants, case-mix and hospital pressures in increasing COVID-19 severity
requires urgent further investigation.
","[{'version': 'v1', 'created': 'Mon, 8 Mar 2021 16:19:21 GMT'}, {'version': 'v2', 'created': 'Mon, 22 Mar 2021 13:49:45 GMT'}]",2021-03-23,"[['Kirwan', 'Peter D.', ''], ['Elgohari', 'Suzanne', ''], ['Jackson', 'Christopher H.', ''], ['Tom', 'Brian D. M.', ''], ['Mandal', 'Sema', ''], ['De Angelis', 'Daniela', ''], ['Presanis', 'Anne M.', '']]"
2110.07128,Bohdan Khomtchouk,Bohdan B. Khomtchouk,"WebAssembly enables low latency interoperable augmented and virtual
  reality software","9 pages, 2 figures",,,,cs.HC,http://creativecommons.org/licenses/by/4.0/,"  There is a clear difference in runtime performance between native
applications that use augmented/virtual reality (AR/VR) device-specific
hardware and comparable web-based implementations. Here we show that
WebAssembly (Wasm) offers a promising developer solution that can bring
near-native low latency performance to web-based applications, enabling
hardware-agnostic interoperability at scale through portable bytecode that runs
on any WiFi or cellular data network-enabled AR/VR device. Many software
application areas have begun to realize Wasm's potential as a key enabling
technology, but it has yet to establish a robust presence in the AR/VR domain.
When considering the limitations of current web-based AR/VR development
technologies such as WebXR, which provides an existing application programming
interface (API) that enables AR/VR capabilities for web-based programs, Wasm
can resolve critical issues faced with just-in-time (JIT) compilation, slow
run-times, large file sizes and big data, among other challenges. Existing
applications using Wasm-based WebXR are sparse but growing, and the potential
for porting native applications to use this emerging framework will benefit the
web-based AR/VR application space and bring it closer to its native
counterparts in terms of performance. Taken together, this kind of standardized
""write-once-deploy-everywhere"" software framework for AR/VR applications has
the potential to consolidate user experiences across different head-mounted
displays and other compatible hardware devices to ultimately create an
interoperable AR/VR ecosystem.
","[{'version': 'v1', 'created': 'Thu, 14 Oct 2021 03:17:07 GMT'}]",2021-10-15,"[['Khomtchouk', 'Bohdan B.', '']]"
2105.06291,Christian Bartolo Burlò,"Christian Batrolo Burl\`o, Adrian Francalanza, Alceste Scalas","On the Monitorability of Session Types, in Theory and Practice (Extended
  Version)",,,10.4230/LIPIcs.ECOOP.2021.22,,cs.PL,http://creativecommons.org/licenses/by/4.0/,"  In concurrent and distributed systems, software components are expected to
communicate according to predetermined protocols and APIs - and if a component
does not observe them, the system's reliability is compromised. Furthermore,
isolating and fixing protocol/API errors can be very difficult. Many methods
have been proposed to check the correctness of communicating systems, ranging
from compile-time to run-time verification; among such methods, session types
have been applied for both static type-checking, and run-time monitoring. This
work takes a fresh look at the run-time verification of communicating systems
using session types, in theory and in practice. On the theoretical side, we
develop a novel formal model of session-monitored processes; with it, we
formulate and prove new results on the monitorability of session types,
connecting their run-time and static verification - in terms of soundness
(i.e., whether monitors only flag ill-typed processes) and completeness (i.e.,
whether all ill-typed processes can be flagged by a monitor). On the practical
side, we show that our monitoring theory is indeed realisable: building upon
our formal model, we develop a Scala toolkit for the automatic generation of
session monitors. Our executable monitors can be used to instrument black-box
processes written in any programming language; we assess the viability of our
approach with a series of benchmarks.
","[{'version': 'v1', 'created': 'Thu, 13 May 2021 13:36:42 GMT'}, {'version': 'v2', 'created': 'Sat, 22 May 2021 09:10:16 GMT'}]",2021-05-25,"[['Burlò', 'Christian Batrolo', ''], ['Francalanza', 'Adrian', ''], ['Scalas', 'Alceste', '']]"
2106.03463,Brandon Panos Mr,Brandon Panos and Lucia Kleint,"Exploring mutual information between IRIS spectral lines. II.
  Calculating the most probable response in all spectral windows",,,10.3847/1538-4357/ac00c0,,astro-ph.SR,http://creativecommons.org/licenses/by/4.0/,"  A three-dimensional picture of the solar atmosphere's thermodynamics can be
obtained by jointly analyzing multiple spectral lines that span many formation
heights. In paper I, we found strong correlations between spectral shapes from
a variety of different ions during solar flares in comparison to the quiet Sun.
We extend these techniques to address the following questions: which regions of
the solar atmosphere are most connected during a solar flare, and what are the
most likely responses across several spectral windows based on the observation
of a single Mg II spectrum? Our models are derived from several million IRIS
spectra collected from 21 M- and X-class flares. We applied this framework to
archetypal Mg II flare spectra, and analyzed the results from a multi-line
perspective. We find that (1) the line correlations from the photosphere to the
transition region are highest in flare ribbons. (2) Blue-shifted reversals
appear simultaneously in Mg II, C II, and Si IV during the impulsive phase,
with Si IV displaying possible optical depth effects. Fe II shows signs of
strong emission, indicating deep early heating. (3) The Mg II line appears to
typically evolve a blue-shifted reversal that later returns to line center and
becomes single peaked within 1-3 minutes. The widths of these single peaked
profiles slowly erode with time. During the later flare stages, strong red wing
enhancements indicating coronal rain are evident in Mg II, C II, and Si IV. Our
framework is easily adaptable to any multi-line data set, and enables
comprehensive statistical analyses of the atmospheric behavior in different
spectral windows.
","[{'version': 'v1', 'created': 'Mon, 7 Jun 2021 09:45:00 GMT'}]",2021-07-21,"[['Panos', 'Brandon', ''], ['Kleint', 'Lucia', '']]"
2203.09191,Samuel Coward,"Samuel Coward, George A. Constantinides, Theo Drane",Abstract Interpretation on E-Graphs,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Recent e-graph applications have typically considered concrete semantics of
expressions, where the notion of equivalence stems from concrete interpretation
of expressions. However, equivalences that hold over one interpretation may not
hold in an alternative interpretation. Such an observation can be exploited. We
consider the application of abstract interpretation to e-graphs, and show that
within an e-graph, the lattice meet operation associated with the abstract
domain has a natural interpretation for an e-class, leading to improved
precision in over-approximation. In this extended abstract, we use Interval
Arithmetic (IA) to illustrate this point.
","[{'version': 'v1', 'created': 'Thu, 17 Mar 2022 09:29:44 GMT'}]",2022-03-18,"[['Coward', 'Samuel', ''], ['Constantinides', 'George A.', ''], ['Drane', 'Theo', '']]"
2112.09822,Saeed Saremi,"Saeed Saremi, Rupesh Kumar Srivastava",Multimeasurement Generative Models,,,,,stat.ML cs.LG,http://creativecommons.org/licenses/by/4.0/,"  We formally map the problem of sampling from an unknown distribution with
density $p_X$ in $\mathbb{R}^d$ to the problem of learning and sampling
$p_\mathbf{Y}$ in $\mathbb{R}^{Md}$ obtained by convolving $p_X$ with a fixed
factorial kernel: $p_\mathbf{Y}$ is referred to as M-density and the factorial
kernel as multimeasurement noise model (MNM). The M-density is smoother than
$p_X$, easier to learn and sample from, yet for large $M$ the two problems are
mathematically equivalent since $X$ can be estimated exactly given
$\mathbf{Y}=\mathbf{y}$ using the Bayes estimator
$\widehat{x}(\mathbf{y})=\mathbb{E}[X\vert\mathbf{Y}=\mathbf{y}]$. To formulate
the problem, we derive $\widehat{x}(\mathbf{y})$ for Poisson and Gaussian MNMs
expressed in closed form in terms of unnormalized $p_\mathbf{Y}$. This leads to
a simple least-squares objective for learning parametric energy and score
functions. We present various parametrization schemes of interest, including
one in which studying Gaussian M-densities directly leads to multidenoising
autoencoders--this is the first theoretical connection made between denoising
autoencoders and empirical Bayes in the literature. Samples from $p_X$ are
obtained by walk-jump sampling (Saremi & Hyvarinen, 2019) via underdamped
Langevin MCMC (walk) to sample from $p_\mathbf{Y}$ and the multimeasurement
Bayes estimation of $X$ (jump). We study permutation invariant Gaussian
M-densities on MNIST, CIFAR-10, and FFHQ-256 datasets, and demonstrate the
effectiveness of this framework for realizing fast-mixing stable Markov chains
in high dimensions.
","[{'version': 'v1', 'created': 'Sat, 18 Dec 2021 02:11:36 GMT'}]",2021-12-21,"[['Saremi', 'Saeed', ''], ['Srivastava', 'Rupesh Kumar', '']]"
2111.15655,G\'abor B\'ir\'o,"G\'abor B\'ir\'o and Bence Tank\'o-Bartalis and Gergely G\'abor
  Barnaf\""oldi",Studying Hadronization by Machine Learning Techniques,,,,,hep-ph cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Hadronization is a non-perturbative process, which theoretical description
can not be deduced from first principles. Modeling hadron formation requires
several assumptions and various phenomenological approaches. Utilizing
state-of-the-art Computer Vision and Deep Learning algorithms, it is eventually
possible to train neural networks to learn non-linear and non-perturbative
features of the physical processes. In this study, results of two ResNet
networks are presented by investigating global and kinematical quantities,
indeed jet- and event-shape variables. The widely used Lund string
fragmentation model is applied as a baseline in $\sqrt{s}= 7$ TeV proton-proton
collisions to predict the most relevant observables at further LHC energies.
","[{'version': 'v1', 'created': 'Tue, 30 Nov 2021 18:38:32 GMT'}, {'version': 'v2', 'created': 'Mon, 10 Jan 2022 09:06:44 GMT'}]",2022-01-11,"[['Bíró', 'Gábor', ''], ['Tankó-Bartalis', 'Bence', ''], ['Barnaföldi', 'Gergely Gábor', '']]"
2103.00535,Gabriela Cavalcante da Silva,"Gabriela Cavalcante da Silva, Fernanda Monteiro de Almeida, Sabrina
  Oliveira, Leonardo C. T. Bezerra, Elizabeth F. Wanner, Ricardo H. C.
  Takahashi","A multi-objective time series analysis of community mobility reduction
  comparing first and second COVID-19 waves",,,,,cs.SI,http://creativecommons.org/licenses/by/4.0/,"  With the logistic challenges faced by most countries for the production,
distribution, and application of vaccines for the novel coronavirus
disease~(COVID-19), social distancing~(SD) remains the most tangible approach
to mitigate the spread of the virus. To assist SD monitoring, several tech
companies have made publicly available anonymized mobility data. In this work,
we conduct a multi-objective mobility reduction rate comparison between the
first and second COVID-19 waves in several localities from America and Europe
using Google community mobility reports~(CMR) data. Through multi-dimensional
visualization, we are able to compare in a Pareto-compliant way the reduction
in mobility from the different lockdown periods for each locality selected,
simultaneously considering all place categories provided in CMR. In addition,
our analysis comprises a 56-day lockdown period for each locality and COVID-19
wave, which we analyze both as 56-day periods and as 14-day consecutive
windows. Results vary considerably as a function of the locality considered,
particularly when the temporal evolution of the mobility reduction is
considered. We thus discuss each locality individually, relating social
distancing measures and the reduction observed.
","[{'version': 'v1', 'created': 'Sun, 28 Feb 2021 15:21:35 GMT'}]",2021-03-02,"[['da Silva', 'Gabriela Cavalcante', ''], ['de Almeida', 'Fernanda Monteiro', ''], ['Oliveira', 'Sabrina', ''], ['Bezerra', 'Leonardo C. T.', ''], ['Wanner', 'Elizabeth F.', ''], ['Takahashi', 'Ricardo H. C.', '']]"
2102.04528,Daniel Frisch,Daniel Frisch and Uwe D. Hanebeck,"Deterministic Sampling on the Circle using Projected Cumulative
  Distributions","11 pages, 5 figures",,,,eess.SY cs.SY,http://creativecommons.org/licenses/by/4.0/,"  We propose a method for deterministic sampling of arbitrary continuous
angular density functions. With deterministic sampling, good estimation results
can typically be achieved with much smaller numbers of samples compared to the
commonly used random sampling. While the Unscented Kalman Filter uses
deterministic sampling as well, it only takes the absolute minimum number of
samples. Our method can draw arbitrary numbers of deterministic samples and
therefore improve the quality of state estimation. Conformity between the
continuous density function (reference) and the Dirac mixture density, i.e.,
sample locations (approximation) is established by minimizing the difference of
the cumulatives of many univariate projections. In other words, we compare
cumulatives of probability densities in the Radon space.
","[{'version': 'v1', 'created': 'Mon, 8 Feb 2021 20:59:23 GMT'}]",2021-02-10,"[['Frisch', 'Daniel', ''], ['Hanebeck', 'Uwe D.', '']]"
2105.11273,Bingli Jiao,"Bingli Jiao, Mingxi Yin and Yuli Yang",Application of Opportunistic Bit to Multilevel Codes,,,,,cs.IT eess.SP math.IT,http://creativecommons.org/licenses/by/4.0/,"  In this paper, we propose a new signal organization method to work in the
structure of the multi level coding (MLC). The transmit bits are divided into
opportunistic bit (OB) and conventional bit (CB), which are mapped to the lower
level- and higher level signal in parallel to the MLC, respectively. Because
the OB's mapping does not require signal power explicitly, the energy of the CB
modulated symbol can be doubled. As the result, the overall mutual information
of the proposed method is found higher than that of the conventional BPSK in
one dimensional case. Moreover, the extension of the method to the
two-complex-dimension shows the better performance over the QPSK. The numerical
results confirm this approach.
","[{'version': 'v1', 'created': 'Mon, 24 May 2021 13:42:57 GMT'}, {'version': 'v2', 'created': 'Tue, 25 May 2021 09:22:28 GMT'}]",2021-05-26,"[['Jiao', 'Bingli', ''], ['Yin', 'Mingxi', ''], ['Yang', 'Yuli', '']]"
2102.02966,Ramy Shahin,Ramy Shahin,Towards Modal Software Engineering,ICSE'21 NIER pre-print,,,,cs.SE cs.PL,http://creativecommons.org/licenses/by/4.0/,"  In this paper we introduce the notion of Modal Software Engineering:
automatically turning sequential, deterministic programs into semantically
equivalent programs efficiently operating on inputs coming from multiple
overlapping worlds. We are drawing an analogy between modal logics, and
software application domains where multiple sets of inputs (multiple worlds)
need to be processed efficiently. Typically those sets highly overlap, so
processing them independently would involve a lot of redundancy, resulting in
lower performance, and in many cases intractability. Three application domains
are presented: reasoning about feature-based variability of Software Product
Lines (SPLs), probabilistic programming, and approximate programming.
","[{'version': 'v1', 'created': 'Fri, 5 Feb 2021 02:45:29 GMT'}, {'version': 'v2', 'created': 'Fri, 12 Feb 2021 23:03:15 GMT'}]",2021-02-16,"[['Shahin', 'Ramy', '']]"
2007.04561,Joel Ye,"Joel Ye, Dhruv Batra, Erik Wijmans, Abhishek Das",Auxiliary Tasks Speed Up Learning PointGoal Navigation,8 pages. Accepted to CoRL 2020,,,,cs.CV cs.LG cs.RO,http://creativecommons.org/licenses/by/4.0/,"  PointGoal Navigation is an embodied task that requires agents to navigate to
a specified point in an unseen environment. Wijmans et al. showed that this
task is solvable but their method is computationally prohibitive, requiring 2.5
billion frames and 180 GPU-days. In this work, we develop a method to
significantly increase sample and time efficiency in learning PointNav using
self-supervised auxiliary tasks (e.g. predicting the action taken between two
egocentric observations, predicting the distance between two observations from
a trajectory,etc.).We find that naively combining multiple auxiliary tasks
improves sample efficiency,but only provides marginal gains beyond a point. To
overcome this, we use attention to combine representations learnt from
individual auxiliary tasks. Our best agent is 5.5x faster to reach the
performance of the previous state-of-the-art, DD-PPO, at 40M frames, and
improves on DD-PPO's performance at 40M frames by 0.16 SPL. Our code is
publicly available at https://github.com/joel99/habitat-pointnav-aux.
","[{'version': 'v1', 'created': 'Thu, 9 Jul 2020 05:22:40 GMT'}, {'version': 'v2', 'created': 'Wed, 4 Nov 2020 20:29:06 GMT'}]",2020-11-06,"[['Ye', 'Joel', ''], ['Batra', 'Dhruv', ''], ['Wijmans', 'Erik', ''], ['Das', 'Abhishek', '']]"
2111.15549,Tianzhe Xu,"Tianzhe Xu, Scott Doran, Wanming Liu, Philippe Piot, John Power,
  Charles Whiteford and Eric Wisniewski","Direct Measurement of Eigenemittances Transfer to Projected Emittances
  via Phase-Space Decoupling for an Electron Beam","5 pages, 4 figures",,,,physics.acc-ph,http://creativecommons.org/licenses/by/4.0/,"  Phase-space partitioning offers an attractive path for the precise tailoring
of complex dynamical systems. In Beam Physics, the proposed approach involves
(i) producing beams with cross-plane correlations to control kinematical
invariants known as eigenemittances and (ii) mapping them to invariants of
motion associated with given degrees of freedom via a decoupling
transformation. Here we report on the direct experimental demonstration of the
mapping of eigenemittances to transverse emittances for an electron beam.
Measured phase space density confirms the generation of beams with asymmetric
transverse emittance ratio> 200 consistent with the initiated eigenemittance
values. The results could have broad applications to other fields where
invariants are sometimes used to describe coupled classical system quantum
systems with mixed states.
","[{'version': 'v1', 'created': 'Tue, 30 Nov 2021 16:40:57 GMT'}]",2021-12-01,"[['Xu', 'Tianzhe', ''], ['Doran', 'Scott', ''], ['Liu', 'Wanming', ''], ['Piot', 'Philippe', ''], ['Power', 'John', ''], ['Whiteford', 'Charles', ''], ['Wisniewski', 'Eric', '']]"
2010.12933,Dmitry Ignatov,"Dmitry Egurnov, Dmitry I. Ignatov, and Dmitry Tochilkin",Triclustering in Big Data Setting,"The paper contains an extended version of the prior work presented at
  the workshop on FCA in the Big Data Era held on June 25, 2019 at Frankfurt
  University of Applied Sciences, Frankfurt, Germany",LNCS (2020),,,cs.DC cs.LG,http://creativecommons.org/licenses/by/4.0/,"  In this paper, we describe versions of triclustering algorithms adapted for
efficient calculations in distributed environments with MapReduce model or
parallelisation mechanism provided by modern programming languages. OAC-family
of triclustering algorithms shows good parallelisation capabilities due to the
independent processing of triples of a triadic formal context. We provide the
time and space complexity of the algorithms and justify their relevance. We
also compare performance gain from using a distributed system and scalability.
","[{'version': 'v1', 'created': 'Sat, 24 Oct 2020 16:55:55 GMT'}]",2020-10-27,"[['Egurnov', 'Dmitry', ''], ['Ignatov', 'Dmitry I.', ''], ['Tochilkin', 'Dmitry', '']]"
1807.08937,Oksana Markova,O. Markova,"The model of methodical system and learning objectives of the
  foundations of mathematical informatics for students of technical
  universities","7 pages, 3 figures, 1 table, in Ukrainian",Cherkasy University Bulletin: Pedagogical Sciences 7 (2016) 36-42,,,cs.CY,http://creativecommons.org/licenses/by/4.0/,"  Introduction. Development of methodical system for training course
""Foundations of mathematical informatics"" plays a key role in forming the
students' of technical universities competencies in mathematical informatics.
So it is very important to analyze of the components of methodical system,
identify the weaknesses and problems that can significantly impair its quality
and which can not be overcome without its further development. Purpose. Develop
a model of methodical system of training course ""Foundations of mathematical
informatics"" for students of technical universities and specify its target
component. Methods. Using cloud technologies at learning the foundations of
mathematical informatics requires the construction technology training, which
results in the selection of appropriate cloudoriented forms of organization and
teaching methods. On the other hand, the theory, methods and tools for cloud
significantly affect the primary content of learning and its goals. Thus, the
cloud technology theory, methods and tools are the basis for constructing
methodical system of training course ""Foundations of mathematical informatics"".
Results. Development of methodical system of training course ""Foundations of
mathematical informatics"" plays a leading role in forming the students' of
technical universities competencies in mathematical informatics due to its
fundamental impact and technology improvement. Conclusion. The model of
methodical system of training course ""Foundations of mathematical informatics""
includes content, objectives and learning technology. The last one contains
forms of organization, methods and teaching tools, including leading cloud
technologies. The main purpose of training course ""Foundations of mathematical
informatics"" is developing of students competencies of technical universities
in mathematical informatics.
","[{'version': 'v1', 'created': 'Tue, 24 Jul 2018 07:45:43 GMT'}]",2018-07-25,"[['Markova', 'O.', '']]"
2103.04907,Fan Li,"Fan Li, Ashley L. Buchanan, Stephen R. Cole","Generalizing trial evidence to target populations in non-nested designs:
  Applications to AIDS clinical trials","43 pages, 3 tables and 2 figures",,,,stat.ME stat.AP,http://creativecommons.org/licenses/by/4.0/,"  Comparative effectiveness evidence from randomized trials may not be directly
generalizable to a target population of substantive interest when, as in most
cases, trial participants are not randomly sampled from the target population.
Motivated by the need to generalize evidence from two trials conducted in the
AIDS Clinical Trials Group (ACTG), we consider weighting, regression and doubly
robust estimators to estimate the causal effects of HIV interventions in a
specified population of people living with HIV in the USA. We focus on a
non-nested trial design and discuss strategies for both point and variance
estimation of the target population average treatment effect. Specifically in
the generalizability context, we demonstrate both analytically and empirically
that estimating the known propensity score in trials does not increase the
variance for each of the weighting, regression and doubly robust estimators. We
apply these methods to generalize the average treatment effects from two ACTG
trials to specified target populations and operationalize key practical
considerations. Finally, we report on a simulation study that investigates the
finite-sample operating characteristics of the generalizability estimators and
their sandwich variance estimators.
","[{'version': 'v1', 'created': 'Mon, 8 Mar 2021 17:10:22 GMT'}]",2021-03-09,"[['Li', 'Fan', ''], ['Buchanan', 'Ashley L.', ''], ['Cole', 'Stephen R.', '']]"
2109.04113,Barbara Ercolano Prof,"Barbara Ercolano (LMU), Giovanni Picogna (LMU), Kristina Monsch (LMU,
  CfA), Jeremy J. Drake (CfA), Thomas Preibisch (LMU)","The dispersal of protoplanetary discs. II: Photoevaporation models with
  observationally derived irradiating spectra","12 pages, 7 tables, 9 figures, accepted for publication in MNRAS",,10.1093/mnras/stab2590,,astro-ph.EP astro-ph.SR,http://creativecommons.org/licenses/by/4.0/,"  Young solar-type stars are known to be strong X-ray emitters and their X-ray
spectra have been widely studied. X-rays from the central star may play a
crucial role in the thermodynamics and chemistry of the circumstellar material
as well as in the atmospheric evolution of young planets. In this paper we
present model spectra based on spectral parameters derived from the
observations of young stars in the Orion Nebula Cluster from the Chandra Orion
Ultradeep Project (COUP). The spectra are then used to calculate new
photoevaporation prescriptions that can be used in disc and planet population
synthesis models. Our models clearly show that disc wind mass loss rates are
controlled by the stellar luminosity in the soft (100 eV - 1 keV) X- ray band.
New analytical relations are provided for the mass loss rates and profiles of
photoevaporative winds as a function of the luminosity in the soft X-ray band.
The agreement between observed and predicted transition disc statistics
moderately improved using the new spectra, but the observed population of
strongly accreting large cavity discs can still not be reproduced by these
models. Furthermore, our models predict a population of non-accreting
transition discs that are not observed. This highlights the importance of
considering the depletion of millimeter-sized dust grains from the outer disc,
which is a likely reason why such discs have not been detected yet.
","[{'version': 'v1', 'created': 'Thu, 9 Sep 2021 09:09:13 GMT'}]",2021-09-29,"[['Ercolano', 'Barbara', '', 'LMU'], ['Picogna', 'Giovanni', '', 'LMU'], ['Monsch', 'Kristina', '', 'LMU,\n  CfA'], ['Drake', 'Jeremy J.', '', 'CfA'], ['Preibisch', 'Thomas', '', 'LMU']]"
2109.12078,Maritza A. Lara-L\'opez Mall,"D. Sotillo-Ramos, M. A. Lara-Lopez, A.M. Perez-Garcia, R.
  Perez-Martinez, A. M. Hopkins, B. W. Holwerda, J. Liske, A. R. Lopez-Sanchez,
  M. S. Owers, K. A. Pimbblet","Galaxy And Mass Assembly (GAMA): The environmental impact on SFR and
  metallicity in galaxy groups",Accepted by MNRAS,,10.1093/mnras/stab2641,,astro-ph.GA,http://creativecommons.org/licenses/by/4.0/,"  We present a study of the relationships and environmental dependencies
between stellar mass, star formation rate, and gas metallicity for more than
700 galaxies in groups up to redshift 0.35 from the Galaxy And Mass Assembly
(GAMA) survey. To identify the main drivers, our sample was analyzed as a
function of group-centric distance, projected galaxy number density, and
stellar mass. By using control samples of more than 16000 star-forming field
galaxies and volume limited samples, we find that the highest enhancement in
SFR (0.3 dex) occurs in galaxies with the lowest local density. In contrast to
previous work, our data show small enhancements of $\sim$0.1 dex in SFR for
galaxies at the highest local densities or group-centric distances. Our data
indicates quenching in SFR only for massive galaxies, suggesting that stellar
mass might be the main driver of quenching processes for star forming galaxies.
We can discard a morphological driven quenching, since the S\'ersic index
distribution for group and control galaxies are similar. The gas metallicity
does not vary drastically. It increases $\sim$0.08 dex for galaxies at the
highest local densities, and decreases for galaxies at the highest
group-centric distances, in agreement with previous work. Altogether, the local
density, rather than group-centric distance, shows the stronger impact in
enhancing both, the SFR and gas metallicity. We applied the same methodology to
galaxies from the IllustrisTNG simulations, and although we were able to
reproduce the general observational trends, the differences between group and
control samples only partially agree with the observations
","[{'version': 'v1', 'created': 'Fri, 24 Sep 2021 17:02:33 GMT'}]",2021-10-13,"[['Sotillo-Ramos', 'D.', ''], ['Lara-Lopez', 'M. A.', ''], ['Perez-Garcia', 'A. M.', ''], ['Perez-Martinez', 'R.', ''], ['Hopkins', 'A. M.', ''], ['Holwerda', 'B. W.', ''], ['Liske', 'J.', ''], ['Lopez-Sanchez', 'A. R.', ''], ['Owers', 'M. S.', ''], ['Pimbblet', 'K. A.', '']]"
2106.08456,Matthew Anderson,"Matthew D Anderson, Fabien Baron, Misty C Bentz",TLDR: Time Lag/Delay Reconstructor,,"TLDR: time lag/delay reconstructor, Monthly Notices of the Royal
  Astronomical Society, Volume 505, Issue 2, August 2021, Pages 2903-2912",10.1093/mnras/stab1394,,astro-ph.IM,http://creativecommons.org/licenses/by/4.0/,"  We present the Time Lag/Delay Reconstructor (TLDR), an algorithm for
reconstructing velocity delay maps in the Maximum A Posteriori framework for
reverberation mapping. Reverberation mapping is a tomographical method for
studying the kinematics and geometry of the broad-line region of active
galactic nuclei at high spatial resolution. Leveraging modern image
reconstruction techniques, including Total Variation and Compressed Sensing,
TLDR applies multiple regularization schemes to re-construct velocity delay
maps using the Alternating Direction Method of Multipliers. Along with the
detailed description of the TLDR algorithm we present test reconstructions from
TLDR applied to synthetic reverberation mapping spectra as well as a
preliminary reconstruction of the H\b{eta}feature of Arp 151 from the 2008 Lick
Active Galactic Nuclei Monitoring Project.
","[{'version': 'v1', 'created': 'Tue, 15 Jun 2021 22:04:15 GMT'}]",2021-06-17,"[['Anderson', 'Matthew D', ''], ['Baron', 'Fabien', ''], ['Bentz', 'Misty C', '']]"
2109.05558,Xugang Wu,"Xugang Wu, Huijun Wu, Xu Zhou, Kai Lu","CoG: a Two-View Co-training Framework for Defending Adversarial Attacks
  on Graph",,,,,cs.LG cs.CR,http://creativecommons.org/licenses/by/4.0/,"  Graph neural networks exhibit remarkable performance in graph data analysis.
However, the robustness of GNN models remains a challenge. As a result, they
are not reliable enough to be deployed in critical applications. Recent studies
demonstrate that GNNs could be easily fooled with adversarial perturbations,
especially structural perturbations. Such vulnerability is attributed to the
excessive dependence on the structure information to make predictions. To
achieve better robustness, it is desirable to build the prediction of GNNs with
more comprehensive features. Graph data, in most cases, has two views of
information, namely structure information and feature information. In this
paper, we propose CoG, a simple yet effective co-training framework to combine
these two views for the purpose of robustness. CoG trains sub-models from the
feature view and the structure view independently and allows them to distill
knowledge from each other by adding their most confident unlabeled data into
the training set. The orthogonality of these two views diversifies the
sub-models, thus enhancing the robustness of their ensemble. We evaluate our
framework on three popular datasets, and results show that CoG significantly
improves the robustness of graph models against adversarial attacks without
sacrificing their performance on clean data. We also show that CoG still
achieves good robustness when both node features and graph structures are
perturbed.
","[{'version': 'v1', 'created': 'Sun, 12 Sep 2021 16:45:30 GMT'}]",2021-09-14,"[['Wu', 'Xugang', ''], ['Wu', 'Huijun', ''], ['Zhou', 'Xu', ''], ['Lu', 'Kai', '']]"
2202.06736,Charly Robinson La Rocca,"Charly Robinson La Rocca, Emma Frejinger, Jean-Fran\c{c}ois Cordeau","Minimizing Entropy to Discover Good Solutions to Recurrent Mixed Integer
  Programs","8 pages, 4 figures",,,,math.OC cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Current state-of-the-art solvers for mixed-integer programming (MIP) problems
are designed to perform well on a wide range of problems. However, for many
real-world use cases, problem instances come from a narrow distribution. This
has motivated the development of specialized methods that can exploit the
information in historical datasets to guide the design of heuristics. Recent
works have shown that machine learning (ML) can be integrated with an MIP
solver to inject domain knowledge and efficiently close the optimality gap.
This hybridization is usually done with deep learning (DL), which requires a
large dataset and extensive hyperparameter tuning to perform well. This paper
proposes an online heuristic that uses the notion of entropy to efficiently
build a model with minimal training data and tuning. We test our method on the
locomotive assignment problem (LAP), a recurring real-world problem that is
challenging to solve at scale. Experimental results show a speed up of an order
of magnitude compared to a general purpose solver (CPLEX) with a relative gap
of less than 2%. We also observe that for some instances our method can
discover better solutions than CPLEX within the time limit.
","[{'version': 'v1', 'created': 'Mon, 7 Feb 2022 18:52:56 GMT'}]",2022-02-15,"[['La Rocca', 'Charly Robinson', ''], ['Frejinger', 'Emma', ''], ['Cordeau', 'Jean-François', '']]"
2110.10200,Drago Plecko,"Drago Ple\v{c}ko, Nicolas Bennett, Nicolai Meinshausen",fairadapt: Causal Reasoning for Fair Data Pre-processing,"Keywords: algorithmic fairness, causal inference, machine learning",,,,cs.LG cs.AI cs.CY stat.ML,http://creativecommons.org/licenses/by/4.0/,"  Machine learning algorithms are useful for various predictions tasks, but
they can also learn how to discriminate, based on gender, race or other
sensitive attributes. This realization gave rise to the field of fair machine
learning, which aims to measure and mitigate such algorithmic bias. This
manuscript describes the R-package fairadapt, which implements a causal
inference pre-processing method. By making use of a causal graphical model and
the observed data, the method can be used to address hypothetical questions of
the form ""What would my salary have been, had I been of a different
gender/race?"". Such individual level counterfactual reasoning can help
eliminate discrimination and help justify fair decisions. We also discuss
appropriate relaxations which assume certain causal pathways from the sensitive
attribute to the outcome are not discriminatory.
","[{'version': 'v1', 'created': 'Tue, 19 Oct 2021 18:48:28 GMT'}]",2021-10-22,"[['Plečko', 'Drago', ''], ['Bennett', 'Nicolas', ''], ['Meinshausen', 'Nicolai', '']]"
1901.10431,Jus Lozej,"Ju\v{s} Lozej, Dejan \v{S}tepec, Vitomir \v{S}truc and Peter Peer",Influence of segmentation on deep iris recognition performance,"6 pages, 3 figures, 3 tables, submitted to IWBF 2019",,10.1109/IWBF.2019.8739225,,cs.CV,http://creativecommons.org/licenses/by/4.0/,"  Despite the rise of deep learning in numerous areas of computer vision and
image processing, iris recognition has not benefited considerably from these
trends so far. Most of the existing research on deep iris recognition is
focused on new models for generating discriminative and robust iris
representations and relies on methodologies akin to traditional iris
recognition pipelines. Hence, the proposed models do not approach iris
recognition in an end-to-end manner, but rather use standard heuristic iris
segmentation (and unwrapping) techniques to produce normalized inputs for the
deep learning models. However, because deep learning is able to model very
complex data distributions and nonlinear data changes, an obvious question
arises. How important is the use of traditional segmentation methods in a deep
learning setting? To answer this question, we present in this paper an
empirical analysis of the impact of iris segmentation on the performance of
deep learning models using a simple two stage pipeline consisting of a
segmentation and a recognition step. We evaluate how the accuracy of
segmentation influences recognition performance but also examine if
segmentation is needed at all. We use the CASIA Thousand and SBVPI datasets for
the experiments and report several interesting findings.
","[{'version': 'v1', 'created': 'Tue, 29 Jan 2019 18:01:42 GMT'}, {'version': 'v2', 'created': 'Fri, 8 May 2020 18:25:29 GMT'}]",2020-05-12,"[['Lozej', 'Juš', ''], ['Štepec', 'Dejan', ''], ['Štruc', 'Vitomir', ''], ['Peer', 'Peter', '']]"
2101.12203,Deep Jariwala,"Kiyoung Jo, Pawan Kumar, Joseph Orr, Surendra B. Anantharaman, Jinshui
  Miao, Michael Motala, Arkamita Bandyopadhyay, Kim Kisslinger, Christopher
  Muratore, Vivek B. Shenoy, Eric Stach, Nicholas Glavin, Deep Jariwala","Direct Opto-Electronic Imaging of 2D Semiconductor - 3D Metal Buried
  Interfaces",6 figures + supplement,ACS Nano 2021,10.1021/acsnano.1c00708,,cond-mat.mes-hall cond-mat.mtrl-sci physics.app-ph physics.optics,http://creativecommons.org/licenses/by/4.0/,"  The semiconductor-metal junction is one of the most critical factors for high
performance electronic devices. In two-dimensional (2D) semiconductor devices,
minimizing the voltage drop at this junction is particularly challenging and
important. Despite numerous studies concerning contact resistance in 2D
semiconductors, the exact nature of the buried interface under a
three-dimensional (3D) metal remains unclear. Herein, we report the direct
measurement of electrical and optical responses of 2D semiconductor-metal
buried interfaces using a recently developed metal-assisted transfer technique
to expose the buried interface which is then directly investigated using
scanning probe techniques. We characterize the spatially varying electronic and
optical properties of this buried interface with < 20 nm resolution. To be
specific, potential, conductance and photoluminescence at the buried
metal/MoS$_2$ interface are correlated as a function of a variety of metal
deposition conditions as well as the type of metal contacts. We observe that
direct evaporation of Au on MoS$_2$ induces a large strain of ~5% in the
MoS$_2$ which, coupled with charge transfer, leads to degenerate doping of the
MoS$_2$ underneath the contact. These factors lead to improvement of contact
resistance to record values of 138 kohm-um, as measured using local conductance
probes. This approach was adopted to characterize MoS$_2$-In/Au alloy
interfaces, demonstrating contact resistance as low as 63 kohm-um. Our results
highlight that the MoS$_2$/Metal interface is sensitive to device fabrication
methods, and provides a universal strategy to characterize buried contact
interfaces involving 2D semiconductors.
","[{'version': 'v1', 'created': 'Thu, 28 Jan 2021 18:59:13 GMT'}]",2022-02-17,"[['Jo', 'Kiyoung', ''], ['Kumar', 'Pawan', ''], ['Orr', 'Joseph', ''], ['Anantharaman', 'Surendra B.', ''], ['Miao', 'Jinshui', ''], ['Motala', 'Michael', ''], ['Bandyopadhyay', 'Arkamita', ''], ['Kisslinger', 'Kim', ''], ['Muratore', 'Christopher', ''], ['Shenoy', 'Vivek B.', ''], ['Stach', 'Eric', ''], ['Glavin', 'Nicholas', ''], ['Jariwala', 'Deep', '']]"
1911.05395,Christine Bauer,Christine Bauer,Allowing for equal opportunities for artists in music recommendation,"3 pages, position paper, 1st Workshop on Designing Human-Centric MIR
  Systems, Delft, 2019",,,,cs.IR cs.CY,http://creativecommons.org/licenses/by/4.0/,"  Promoting diversity in the music sector is widely discussed on the media.
While the major problem may lie deep in our society, music information
retrieval contributes to promoting diversity or may create unequal
opportunities for artists. For example, considering the known problem of
popularity bias in music recommendation, it is important to investigate whether
the short head of popular music artists and the long tail of less popular ones
show similar patterns of diversity---in terms of, for example, age, gender, or
ethnic origin---or the popularity bias amplifies a positive or negative effect.
I advocate for reasonable opportunities for artists---for (currently) popular
artists and artists in the long-tail alike---in music recommender systems. In
this work, I represent the position that we need to develop a deep
understanding of the biases and inequalities because it is the essential basis
to design approaches for music recommendation that provide reasonable
opportunities. Thus, research needs to investigate the various reasons that
hinder equal opportunity and diversity in music recommendation.
","[{'version': 'v1', 'created': 'Wed, 13 Nov 2019 10:58:30 GMT'}]",2019-11-14,"[['Bauer', 'Christine', '']]"
2012.04859,Sina Alemohammad,"Sina Alemohammad, Randall Balestriero, Zichao Wang, Richard Baraniuk",Enhanced Recurrent Neural Tangent Kernels for Non-Time-Series Data,,,,,cs.LG stat.ML,http://creativecommons.org/licenses/by/4.0/,"  Kernels derived from deep neural networks (DNNs) in the infinite-width regime
provide not only high performance in a range of machine learning tasks but also
new theoretical insights into DNN training dynamics and generalization. In this
paper, we extend the family of kernels associated with recurrent neural
networks (RNNs), which were previously derived only for simple RNNs, to more
complex architectures including bidirectional RNNs and RNNs with average
pooling. We also develop a fast GPU implementation to exploit the full
practical potential of the kernels. Though RNNs are typically only applied to
time-series data, we demonstrate that classifiers using RNN-based kernels
outperform a range of baseline methods on 90 non-time-series datasets from the
UCI data repository.
","[{'version': 'v1', 'created': 'Wed, 9 Dec 2020 04:36:34 GMT'}, {'version': 'v2', 'created': 'Wed, 20 Oct 2021 00:17:27 GMT'}]",2021-10-22,"[['Alemohammad', 'Sina', ''], ['Balestriero', 'Randall', ''], ['Wang', 'Zichao', ''], ['Baraniuk', 'Richard', '']]"
2107.02754,Paul Van Der Hulst,"Paul van der Hulst, Jan van der Kuur, Ad Nieuwenhuizen, Davide
  Vaccaro, Hiroki Akamatsu, Patrick van Winden, Bert-Joost van Leeuwen, and
  Jan-Willem den Herder","Frequency Shift Algorithm: Design of a Baseband Phase Locked Loop for
  Frequency-Domain Multiplexing Readout of X-ray Transition-Edge Sensor
  Microcalorimeters",,,10.1063/5.0044968,,physics.ins-det astro-ph.IM cs.SY eess.SY,http://creativecommons.org/licenses/by/4.0/,"  The Transition-Edge Sensor (TES) is an extremely sensitive device which is
used to measure the energy of individual X-ray photons. For astronomical
spectrometry applications, SRON develops a Frequency Domain Multiplexing (FDM)
read-out system for kilopixel arrays of such TESs. Each TES is voltage biased
at a specific frequency in the range 1 to 5 MHz. Isolation between the
individual pixels is obtained through very narrow-band (high-Q) lithographic LC
resonators. To prevent energy resolution degradation due to intermodulation
line noise, the bias frequencies are distributed on a regular grid. The
requirements on the accuracy of the LC resonance frequency are very high. The
deviation of the resonance frequencies due to production tolerances is
significant with respect to the bandwidth, and a controller is necessary to
compensate for the LC series impedance. We present two such controllers: a
simple orthogonal proportional-integrating (PI) controller and a more complex
impedance estimator. Both controllers operate in baseband and try to make the
TES current in-phase with the bias voltage, effectively operating as
phase-locked loops (PLL). They allow off-LC-resonance operation of the TES
pixels, while preserving TES thermal response and energy resolution. Extensive
experimental results -- published in a companion paper recently -- with the
proposed methods, show that these controllers allow the preservation of single
pixel energy resolution in multiplexed operation.
","[{'version': 'v1', 'created': 'Fri, 2 Jul 2021 18:00:18 GMT'}]",2021-07-28,"[['van der Hulst', 'Paul', ''], ['van der Kuur', 'Jan', ''], ['Nieuwenhuizen', 'Ad', ''], ['Vaccaro', 'Davide', ''], ['Akamatsu', 'Hiroki', ''], ['van Winden', 'Patrick', ''], ['van Leeuwen', 'Bert-Joost', ''], ['Herder', 'Jan-Willem den', '']]"
2112.08386,Damir Gasymov,"Damir Gasymov, Ivan Katkov",Non-parametric stellar LOSVD analysis,"4 pages, 3 figure; to appear in the proceedings of the XXXI
  Astronomical Data Analysis Software and Systems (ADASS) conference (published
  by ASP); python pip package https://pypi.org/project/sla/",,,,astro-ph.IM astro-ph.GA,http://creativecommons.org/licenses/by/4.0/,"  Ill-posed inverse problems are common in astronomy, and their solutions are
unstable with respect to noise in the data. Solutions of such problems are
typically found using two classes of methods: parametrization and fitting the
data against some predefined function or a solution with a non-parametrical
function using regularization. Here we are focusing on the latter
non-parametric approach applied for the recovery of complex stellar
line-of-sight velocity distribution (LOSVD) from the observed galaxy spectra.
Development of such an approach is crucial for galaxies hosting multiple
kinematically misaligned stellar components, such as 2 stellar counter-rotating
disks, thin and thick disks, kinematically decoupled cores, and others.
  Stellar LOSVD recovery from the observed galaxy spectra is equivalent to a
deconvolution and can be solved as a linear inverse problem. To overcome its
ill-posed nature we apply smoothing regularization. Searching for an optimal
degree of smoothing regularization is a challenging part of this approach. Here
we present a non-parametric fitting technique, discuss its potential caveats,
perform numerous tests based on synthetic mock spectra, and show real-world
application to MaNGA spectral data cubes and some long-slit spectra of stellar
counter-rotating galaxies.
  GitHub repository: https://github.com/gasymovdf/sla
","[{'version': 'v1', 'created': 'Wed, 15 Dec 2021 19:00:01 GMT'}]",2021-12-17,"[['Gasymov', 'Damir', ''], ['Katkov', 'Ivan', '']]"
2106.01064,Shahbaz Syed,"Shahbaz Syed, Khalid Al-Khatib, Milad Alshomary, Henning Wachsmuth,
  and Martin Potthast",Generating Informative Conclusions for Argumentative Texts,,,10.18653/v1/2021.findings-acl.306,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  The purpose of an argumentative text is to support a certain conclusion. Yet,
they are often omitted, expecting readers to infer them rather. While
appropriate when reading an individual text, this rhetorical device limits
accessibility when browsing many texts (e.g., on a search engine or on social
media). In these scenarios, an explicit conclusion makes for a good candidate
summary of an argumentative text. This is especially true if the conclusion is
informative, emphasizing specific concepts from the text. With this paper we
introduce the task of generating informative conclusions: First,
Webis-ConcluGen-21 is compiled, a large-scale corpus of 136,996 samples of
argumentative texts and their conclusions. Second, two paradigms for conclusion
generation are investigated; one extractive, the other abstractive in nature.
The latter exploits argumentative knowledge that augment the data via control
codes and finetuning the BART model on several subsets of the corpus. Third,
insights are provided into the suitability of our corpus for the task, the
differences between the two generation paradigms, the trade-off between
informativeness and conciseness, and the impact of encoding argumentative
knowledge. The corpus, code, and the trained models are publicly available.
","[{'version': 'v1', 'created': 'Wed, 2 Jun 2021 10:35:59 GMT'}]",2021-08-05,"[['Syed', 'Shahbaz', ''], ['Al-Khatib', 'Khalid', ''], ['Alshomary', 'Milad', ''], ['Wachsmuth', 'Henning', ''], ['Potthast', 'Martin', '']]"
2106.15448,Caleb Robinson,"Caleb Robinson, Anthony Ortiz, Lacey Hughey, Jared A. Stabach, Juan M.
  Lavista Ferres",Detecting Cattle and Elk in the Wild from Space,Presented at the KDD 2021 Fragile Earth Workshop,,,,cs.CV cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Localizing and counting large ungulates -- hoofed mammals like cows and elk
-- in very high-resolution satellite imagery is an important task for
supporting ecological studies. Prior work has shown that this is feasible with
deep learning based methods and sub-meter multi-spectral satellite imagery. We
extend this line of work by proposing a baseline method, CowNet, that
simultaneously estimates the number of animals in an image (counts), as well as
predicts their location at a pixel level (localizes). We also propose an
methodology for evaluating such models on counting and localization tasks
across large scenes that takes the uncertainty of noisy labels and the
information needed by stakeholders in ecological monitoring tasks into account.
Finally, we benchmark our baseline method with state of the art vision methods
for counting objects in scenes. We specifically test the temporal
generalization of the resulting models over a large landscape in Point Reyes
Seashore, CA. We find that the LC-FCN model performs the best and achieves an
average precision between 0.56 and 0.61 and an average recall between 0.78 and
0.92 over three held out test scenes.
","[{'version': 'v1', 'created': 'Tue, 29 Jun 2021 14:35:23 GMT'}]",2021-06-30,"[['Robinson', 'Caleb', ''], ['Ortiz', 'Anthony', ''], ['Hughey', 'Lacey', ''], ['Stabach', 'Jared A.', ''], ['Ferres', 'Juan M. Lavista', '']]"
2107.01415,Cong Wang,Cong Wang,"Rates of convergence of the partial-wave expansion beyond Kato's cusp
  condition II: evaluations for the prefactors on the ground state of the
  helium atom","26 pages, 2 figures",,,,physics.atom-ph,http://creativecommons.org/licenses/by/4.0/,"  This article is a continuation of our previous work (Phys. Rev. A 88, 032511
(2013)). The prefactors for the partial-wave expansion of the helium atom are
derived. Due to series of cancellations, the partial-wave increments of the
energy converge as $L^{-2N-6}$. The origin of these cancellations is identified
from alternative expressions of the partial-wave energies. There is some
evidence that the assumptions of regularities for the exact wavefunction can be
reduced.
","[{'version': 'v1', 'created': 'Sat, 3 Jul 2021 11:57:56 GMT'}]",2021-07-06,"[['Wang', 'Cong', '']]"
2103.15351,Shengheng Liu,"Shengheng Liu, Zihuan Mao, Yimin D. Zhang, Yongming Huang","Rank Minimization-based Toeplitz Reconstruction for DoA Estimation Using
  Coprime Array","6 pages, 5 figures, under review with the IEEE Communications Letters",,,,eess.SP,http://creativecommons.org/licenses/by/4.0/,"  In this paper, we address the problem of direction finding using coprime
array, which is one of the most preferred sparse array configurations.
Motivated by the fact that non-uniform element spacing hinders full utilization
of the underlying information in the receive signals, we propose a
direction-of-arrival (DoA) estimation algorithm based on low-rank
reconstruction of the Toeplitz covariance matrix. The atomic-norm
representation of the measurements from the interpolated virtual array is
considered, and the equivalent dual-variable rank minimization problem is
formulated and solved using a cyclic optimization approach. The recovered
covariance matrix enables the application of conventional subspace-based
spectral estimation algorithms, such as MUSIC, to achieve enhanced DoA
estimation performance. The estimation performance of the proposed approach, in
terms of the degrees-of-freedom and spatial resolution, is examined. We also
show the superiority of the proposed method over the competitive approaches in
the root-mean-square error sense.
","[{'version': 'v1', 'created': 'Mon, 29 Mar 2021 05:58:44 GMT'}]",2021-03-30,"[['Liu', 'Shengheng', ''], ['Mao', 'Zihuan', ''], ['Zhang', 'Yimin D.', ''], ['Huang', 'Yongming', '']]"
2106.09635,Shaokai Jian,"Shao-Kai Jian, Chunxiao Liu, Xiao Chen, Brian Swingle, Pengfei Zhang",Quantum error as an emergent magnetic field,"4.4 pages + supplemental material, 4 figures",,,,quant-ph cond-mat.stat-mech cond-mat.str-el hep-th,http://creativecommons.org/licenses/by/4.0/,"  We investigate the effect of quantum errors on a monitored Brownian
Sachdev-Ye-Kitaev (SYK) model featuring a measurement-induced phase transition
that can be understood as a symmetry-breaking transition of an effective $Z_4$
magnet in the replica space. The errors describe the loss of information about
the measurement outcomes and are applied during the non-unitary evolution or at
the end of the evolution. In the former case, we find that this error can be
mapped to an emergent magnetic field in the $Z_4$ magnet, and as a consequence,
the symmetry is explicitly broken independent of the measurement rate. R\'enyi
entropies computed by twisting boundary conditions now generate domain walls
even in the would-be symmetric phase at a high measurement rate. The entropy is
therefore volume-law irrespective of the measurement rate. In the latter case,
the error-induced magnetic field only exists near the boundary of the magnet.
Varying the magnetic field leads to a pinning transition of domain walls,
corresponding to error threshold of the quantum code prepared by the
non-unitary SYK dynamics.
","[{'version': 'v1', 'created': 'Thu, 17 Jun 2021 16:24:58 GMT'}]",2021-06-18,"[['Jian', 'Shao-Kai', ''], ['Liu', 'Chunxiao', ''], ['Chen', 'Xiao', ''], ['Swingle', 'Brian', ''], ['Zhang', 'Pengfei', '']]"
2105.10551,Xinzhong Chen,"Xinzhong Chen, Ziheng Yao, Suheng Xu, A. S. McLeod, Stephanie N.
  Gilbert Corder, Yueqi Zhao, Makoto Tsuneto, Hans A. Bechtel, Michael C.
  Martin, G. L. Carr, M. M. Fogler, Stefan G. Stanciu, D. N. Basov, Mengkun Liu",Hybrid Machine Learning for Scanning Near-field Optical Spectroscopy,,,10.1021/acsphotonics.1c00915,,physics.optics physics.data-an physics.ins-det,http://creativecommons.org/licenses/by/4.0/,"  The underlying physics behind an experimental observation often lacks a
simple analytical description. This is especially the case for scanning probe
microscopy techniques, where the interaction between the probe and the sample
is nontrivial. Realistic modeling to include the details of the probe is always
exponentially more difficult than its ""spherical cow"" counterparts. On the
other hand, a well-trained artificial neural network based on real data can
grasp the hidden correlation between the signal and sample properties. In this
work, we show that, via a combination of model calculation and experimental
data acquisition, a physics-infused hybrid neural network can predict the
tip-sample interaction in the widely used scattering-type scanning near-field
optical microscope. This hybrid network provides a long-sought solution for
accurate extraction of material properties from tip-specific raw data. The
methodology can be extended to other scanning probe microscopy techniques as
well as other data-oriented physical problems in general.
","[{'version': 'v1', 'created': 'Fri, 21 May 2021 19:52:59 GMT'}]",2021-09-16,"[['Chen', 'Xinzhong', ''], ['Yao', 'Ziheng', ''], ['Xu', 'Suheng', ''], ['McLeod', 'A. S.', ''], ['Corder', 'Stephanie N. Gilbert', ''], ['Zhao', 'Yueqi', ''], ['Tsuneto', 'Makoto', ''], ['Bechtel', 'Hans A.', ''], ['Martin', 'Michael C.', ''], ['Carr', 'G. L.', ''], ['Fogler', 'M. M.', ''], ['Stanciu', 'Stefan G.', ''], ['Basov', 'D. N.', ''], ['Liu', 'Mengkun', '']]"
2111.12504,Eric Burkholder,"Eric Burkholder, Shima Salehi, Sarah Sackeyfio, Nicel Mohamed-Hinds,
  Carl Wieman",An equitable and effective approach to introductory mechanics,,,,,physics.ed-ph,http://creativecommons.org/licenses/by/4.0/,"  Introductory mechanics (""physics 1"") is a critical gateway course for
students desiring to pursue a STEM career. A major challenge with this course
is that there is a large spread in the students' incoming physics preparation,
and this level of preparation is strongly predictive of a students'
performance. The level of incoming preparation is also largely determined by a
student's educational privilege, and so this course can amplify inequities in
K-12 education and provide a barrier to a STEM career for students from
marginalized groups. Here, we present a novel introductory course design to
address such equity challenges in physics 1. We designed the course based on
the concept of deliberate practice to give students targeted, scaffolded, and
repeated opportunities to engage in research-identified practices and decisions
required for effective problem-solving. We used real-world problems, as they
carry less resemblance to physics high school problems, and so even the
students with the best high school physics instruction have little experience
or skill in solving them. The students learned the physics content knowledge
they needed in future courses, particularly in engineering, and their
problem-solving skills improved substantially. Furthermore, the success in the
course was not correlated with incoming physics preparation, in stark contrast
to the outcomes from traditional physics 1 courses. These findings suggest that
we made physics 1 more equitable by employing a deliberate practice approach in
the context of real-world problem-solving.
","[{'version': 'v1', 'created': 'Wed, 24 Nov 2021 14:01:22 GMT'}]",2021-11-25,"[['Burkholder', 'Eric', ''], ['Salehi', 'Shima', ''], ['Sackeyfio', 'Sarah', ''], ['Mohamed-Hinds', 'Nicel', ''], ['Wieman', 'Carl', '']]"
2012.13475,Amy X. Lu,"Amy X. Lu, Alex X. Lu, Alan Moses","Evolution Is All You Need: Phylogenetic Augmentation for Contrastive
  Learning",Machine Learning in Computational Biology (MLCB) 2020,,,,q-bio.BM cs.LG cs.NE,http://creativecommons.org/licenses/by/4.0/,"  Self-supervised representation learning of biological sequence embeddings
alleviates computational resource constraints on downstream tasks while
circumventing expensive experimental label acquisition. However, existing
methods mostly borrow directly from large language models designed for NLP,
rather than with bioinformatics philosophies in mind. Recently, contrastive
mutual information maximization methods have achieved state-of-the-art
representations for ImageNet. In this perspective piece, we discuss how viewing
evolution as natural sequence augmentation and maximizing information across
phylogenetic ""noisy channels"" is a biologically and theoretically desirable
objective for pretraining encoders. We first provide a review of current
contrastive learning literature, then provide an illustrative example where we
show that contrastive learning using evolutionary augmentation can be used as a
representation learning objective which maximizes the mutual information
between biological sequences and their conserved function, and finally outline
rationale for this approach.
","[{'version': 'v1', 'created': 'Fri, 25 Dec 2020 01:35:06 GMT'}]",2020-12-29,"[['Lu', 'Amy X.', ''], ['Lu', 'Alex X.', ''], ['Moses', 'Alan', '']]"
2110.12738,Vladimir Sidorenko,"V. Sidorenko (1), I. Fr\""ohlich (2), W.F.J. M\""uller (2), D.
  Emschermann (2), S. B\""ahr (1), C. Sturm (2), J. Becker (1) (for the CBM
  collaboration, (1) Karlsruhe Institute of Technology, (2) GSI Helmholtz
  Centre for Heavy Ion Research)","Prototype Design of a Timing and Fast Control system in the CBM
  Experiment",,,,,physics.ins-det,http://creativecommons.org/licenses/by/4.0/,"  The Compressed Baryonic Matter (CBM) experiment is designed to handle
interaction rates of up to 10 MHz and up to 1 TB/s of raw data generated. With
triggerless streaming data acquisition in the experiment and beam intensity
fluctuations, it is expected that occasional data bursts will surpass bandwidth
capabilities of the Data Acquisition System (DAQ) system. In order to preserve
integrity of event data, the bandwidth of DAQ must be throttled in an organised
way with minimum information loss. The Timing and Fast Control (TFC) system
provides a latency-optimised datapath for throttling commands and distributes a
system clock together with a global timestamp. This paper describes a prototype
design of the system with focus on synchronisation and its evaluation.
","[{'version': 'v1', 'created': 'Mon, 25 Oct 2021 08:54:28 GMT'}, {'version': 'v2', 'created': 'Mon, 20 Dec 2021 13:04:48 GMT'}]",2021-12-21,"[['Sidorenko', 'V.', ''], ['Fröhlich', 'I.', ''], ['Müller', 'W. F. J.', ''], ['Emschermann', 'D.', ''], ['Bähr', 'S.', ''], ['Sturm', 'C.', ''], ['Becker', 'J.', '']]"
1704.00605,Daniel Lemire,Wojciech Mu{\l}a and Daniel Lemire,Faster Base64 Encoding and Decoding Using AVX2 Instructions,software at https://github.com/lemire/fastbase64,"ACM Transactions on the Web 12 (3), 2018",10.1145/3132709,,cs.MS cs.PF,http://creativecommons.org/licenses/by/4.0/,"  Web developers use base64 formats to include images, fonts, sounds and other
resources directly inside HTML, JavaScript, JSON and XML files. We estimate
that billions of base64 messages are decoded every day. We are motivated to
improve the efficiency of base64 encoding and decoding. Compared to
state-of-the-art implementations, we multiply the speeds of both the encoding
(~10x) and the decoding (~7x). We achieve these good results by using the
single-instruction-multiple-data (SIMD) instructions available on recent Intel
processors (AVX2). Our accelerated software abides by the specification and
reports errors when encountering characters outside of the base64 set. It is
available online as free software under a liberal license.
","[{'version': 'v1', 'created': 'Thu, 30 Mar 2017 19:04:09 GMT'}, {'version': 'v2', 'created': 'Mon, 24 Apr 2017 00:25:35 GMT'}, {'version': 'v3', 'created': 'Sat, 12 Aug 2017 03:04:27 GMT'}, {'version': 'v4', 'created': 'Wed, 17 Jan 2018 19:27:41 GMT'}, {'version': 'v5', 'created': 'Thu, 14 Jun 2018 21:02:13 GMT'}]",2019-01-08,"[['Muła', 'Wojciech', ''], ['Lemire', 'Daniel', '']]"
2104.03829,Abhijit Guha Roy,"Abhijit Guha Roy, Jie Ren, Shekoofeh Azizi, Aaron Loh, Vivek
  Natarajan, Basil Mustafa, Nick Pawlowski, Jan Freyberg, Yuan Liu, Zach
  Beaver, Nam Vo, Peggy Bui, Samantha Winter, Patricia MacWilliams, Greg S.
  Corrado, Umesh Telang, Yun Liu, Taylan Cemgil, Alan Karthikesalingam, Balaji
  Lakshminarayanan, Jim Winkens","Does Your Dermatology Classifier Know What It Doesn't Know? Detecting
  the Long-Tail of Unseen Conditions","Under Review, 19 Pages",,,,cs.CV cs.LG,http://creativecommons.org/licenses/by/4.0/,"  We develop and rigorously evaluate a deep learning based system that can
accurately classify skin conditions while detecting rare conditions for which
there is not enough data available for training a confident classifier. We
frame this task as an out-of-distribution (OOD) detection problem. Our novel
approach, hierarchical outlier detection (HOD) assigns multiple abstention
classes for each training outlier class and jointly performs a coarse
classification of inliers vs. outliers, along with fine-grained classification
of the individual classes. We demonstrate the effectiveness of the HOD loss in
conjunction with modern representation learning approaches (BiT, SimCLR, MICLe)
and explore different ensembling strategies for further improving the results.
We perform an extensive subgroup analysis over conditions of varying risk
levels and different skin types to investigate how the OOD detection
performance changes over each subgroup and demonstrate the gains of our
framework in comparison to baselines. Finally, we introduce a cost metric to
approximate downstream clinical impact. We use this cost metric to compare the
proposed method against a baseline system, thereby making a stronger case for
the overall system effectiveness in a real-world deployment scenario.
","[{'version': 'v1', 'created': 'Thu, 8 Apr 2021 15:15:22 GMT'}]",2021-04-09,"[['Roy', 'Abhijit Guha', ''], ['Ren', 'Jie', ''], ['Azizi', 'Shekoofeh', ''], ['Loh', 'Aaron', ''], ['Natarajan', 'Vivek', ''], ['Mustafa', 'Basil', ''], ['Pawlowski', 'Nick', ''], ['Freyberg', 'Jan', ''], ['Liu', 'Yuan', ''], ['Beaver', 'Zach', ''], ['Vo', 'Nam', ''], ['Bui', 'Peggy', ''], ['Winter', 'Samantha', ''], ['MacWilliams', 'Patricia', ''], ['Corrado', 'Greg S.', ''], ['Telang', 'Umesh', ''], ['Liu', 'Yun', ''], ['Cemgil', 'Taylan', ''], ['Karthikesalingam', 'Alan', ''], ['Lakshminarayanan', 'Balaji', ''], ['Winkens', 'Jim', '']]"
2203.08160,Ariel Zhitnitsky,Ariel Zhitnitsky,The Pierre Auger Exotic Events and Axion Quark Nuggets,17 pages,,,,hep-ph astro-ph.IM physics.ao-ph,http://creativecommons.org/licenses/by/4.0/,"  The Pierre Auger Observatory have reported [1-3] observation of several
exotic events (EE) which apparently related to thunderstorms. These events are
much larger in size than conventional cosmic ray (CR) events, and they have
very distinct timing features. A possible nature of the observed phenomenon is
still a matter of active research and debates as many unusual features of these
exotic events are hard to explain. In particular, the frequency of appearance
of these EE is very low (less than 2 events/year), in huge contrast with a
typical rate of a conventional lightning strikes in the area. We propose that
the observed EE can be explained within the so-called axion quark nugget (AQN)
dark matter model. The idea is that the AQNs may trigger and initiate a special
and unique class of lightning strikes during a thunderstorm as a result of
ionization of the atmospheric molecules along its path. The corresponding
AQN-induced lighting flashes may show some specific features not shared by
typical and much more frequent conventional flashes. We support this proposal
by demonstrating that the observations[1-3], including the frequency of
appearance and time duration are consistent with observations. We also comment
on possible relation of AUGER EEs with the Telescope Array bursts and the
terrestrial gamma ray flashes (TGF). We list a number of features of the
AQN-induced EE (such as specific radio pulses synchronized with these events)
which can be directly tested by future experiments. We also suggest to use
distributed acoustic sensing (DAS) instruments to detect the acoustic pulses
which must be synchronized with AUGER EEs.
","[{'version': 'v1', 'created': 'Tue, 15 Mar 2022 18:00:01 GMT'}]",2022-03-17,"[['Zhitnitsky', 'Ariel', '']]"
2110.12807,Shilpa Kastha,Shilpa Kastha,"Linear momentum flux from inspiralling compact binaries in
  quasi-elliptical orbits at 2.5 Post-Newtonian order",19 pages,,,,gr-qc astro-ph.HE,http://creativecommons.org/licenses/by/4.0/,"  Emission of anisotropic gravitational radiation from compact binary system
leads to a flux of linear momentum. This results in the recoil of the system.
We investigate the rate of loss of Linear momentum flux in the far zone of the
source using various mass type and current type multipole moments for
inspiralling compact binary mergers in quasi-elliptical orbits at 2.5 Post
Newtonian order. We compute the linear momentum flux accurate up to
$\mathcal{O}(e_t)$ in harmonic coordinate. A 2.5 Post Newtonian Quasi-Keplarian
representation of the parametric solution to the Post Newtonian equation of
motion for the compact binary system has been adopted here. We also provide a
closed-form expression for the accumulated linear momentum from the remote past
through the binary evolution.
","[{'version': 'v1', 'created': 'Mon, 25 Oct 2021 11:06:47 GMT'}]",2021-10-26,"[['Kastha', 'Shilpa', '']]"
2108.07448,Hari Gaur Dr.,"Hari Mohan Gaur, Ashutosh Kumar Singh and Umesh Ghanekar",Testable Designs of Toffoli Fredkin Reversible Circuits,"8 pages, 8 Figures, 6 sections and for conference",,,,cs.AR,http://creativecommons.org/licenses/by/4.0/,"  Loss of every bit in traditional logic circuits involves dissipation of power
in the form of heat that evolve to the environment. Reversible logic is one of
the alternatives that have capabilities to mitigate this dissipation by
preventing the loss of bits. It also have the potential to broaden the horizon
of futuristic reckon with its applications to quantum computation. Application
of testing strategies to the logic circuits is a necessity that guarantees
their true functioning where the researchers are at par with solutions for the
upcoming challenges and agreements for reversible logic circuits. Novel methods
of designing Toffoli, Fredkin and mixed Toffoli-Fredkin gates based reversible
circuits for testability are put fourth in this article. The proposed designs
are independent of the implementation techniques and can be brought into real
hardware devices after obtaining a stable fabrication environment. The
experimentation for the proposed models are performed on RCViewer and RevKit
tools to verify the functionality and computation of cost metrics. Fault
simulations are carried out using C++ and Java to calculate fault coverage in
respective methodologies. The results confirmed that all the presented work
outperforms existing state-of-art approaches.
","[{'version': 'v1', 'created': 'Tue, 17 Aug 2021 05:03:30 GMT'}]",2021-08-24,"[['Gaur', 'Hari Mohan', ''], ['Singh', 'Ashutosh Kumar', ''], ['Ghanekar', 'Umesh', '']]"
2107.06690,Silvan Toet,"S. E. B. Toet, H. K. Vedantham, J. R. Callingham, K. C. Veken, T. W.
  Shimwell, P. Zarka, H. J. A. R\""ottgering, A. Drabent","Coherent radio emission from a population of RS Canum Venaticorum
  systems","This article consists of 14 pages, 10 normal figures and 4 gifs. The
  gifs themselves each consist of 32 figures. This article is to be published
  in Astronomy and Astrophysics, section 8. 'Stellar Atmospheres'","A&A 654, A21 (2021)",10.1051/0004-6361/202141163,,astro-ph.SR,http://creativecommons.org/licenses/by/4.0/,"  Coherent radio emission from stars can be used to constrain fundamental
coronal plasma parameters, such as plasma density and magnetic field strength.
It is also a probe of chromospheric and magnetospheric acceleration mechanisms.
Close stellar binaries, such as RS Canum Venaticorum (RS CVn) systems, are
particularly interesting as their heightened level of chromospheric activity
and possible direct magnetic interaction make them a unique laboratory to study
coronal and magnetospheric acceleration mechanisms. RS CVn binaries are known
to be radio-bright but coherent radio emission has only conclusively been
detected previously in one system. Here, we present a population of 14 coherent
radio emitting RS CVn systems. We identified the population in the ongoing
LOFAR Two Metre Sky Survey as circularly polarised sources at 144MHz that are
astrometrically associated with known RS CVn binaries. We show that the
observed emission is powered by the electron cyclotron maser instability. We
use numerical calculations of the maser's beaming geometry to argue that the
commonly invoked 'loss-cone' maser cannot generate the necessary brightness
temperature in some of our detections and that a more efficient instability,
such as the shell or horseshoe maser, must be invoked. Such maser
configurations are known to operate in planetary magnetospheres. We also
outline two acceleration mechanisms that could produce coherent radio emission,
one where the acceleration occurs in the chromosphere and one where the
acceleration is due to an electrodynamic interaction between the stars. We
propose radio and optical monitoring observations that can differentiate
between these two mechanisms.
","[{'version': 'v1', 'created': 'Wed, 14 Jul 2021 13:26:47 GMT'}]",2021-10-04,"[['Toet', 'S. E. B.', ''], ['Vedantham', 'H. K.', ''], ['Callingham', 'J. R.', ''], ['Veken', 'K. C.', ''], ['Shimwell', 'T. W.', ''], ['Zarka', 'P.', ''], ['Röttgering', 'H. J. A.', ''], ['Drabent', 'A.', '']]"
1605.09514,David Brooks,"David H. Brooks, Ignacio Ugarte-Urra, Harry P. Warren",Full-Sun observations for identifying the source of the slow solar wind,"Published in Nature Communications in 2015 and can be found at
  http://www.nature.com/ncomms/2015/150106/ncomms6947/full/ncomms6947.html",,10.1038/ncomms6947,,astro-ph.SR,http://creativecommons.org/licenses/by/4.0/,"  Fast (>700 km/s) and slow (~400 km/s) winds stream from the Sun, permeate the
heliosphere and influence the near-Earth environment. While the fast wind is
known to emanate primarily from polar coronal holes, the source of the slow
wind remains unknown. Here we identify possible sites of origin using a slow
solar wind source map of the entire Sun, which we construct from specially
designed, full- disk observations from the Hinode satellite, and a magnetic
field model. Our map provides a full-Sun observation that combines three key
ingredients for identifying the sources: velocity, plasma composition and
magnetic topology and shows them as solar wind composition plasma outflowing on
open magnetic field lines. The area coverage of the identified sources is large
enough that the sum of their mass contributions can explain a significant
fraction of the mass loss rate of the solar wind.
","[{'version': 'v1', 'created': 'Tue, 31 May 2016 07:33:34 GMT'}]",2016-06-01,"[['Brooks', 'David H.', ''], ['Ugarte-Urra', 'Ignacio', ''], ['Warren', 'Harry P.', '']]"
2112.12133,Gourav Datta,Gourav Datta and Peter A. Beerel,"Can Deep Neural Networks be Converted to Ultra Low-Latency Spiking
  Neural Networks?",Accepted to DATE 2022,,,,cs.CV,http://creativecommons.org/licenses/by/4.0/,"  Spiking neural networks (SNNs), that operate via binary spikes distributed
over time, have emerged as a promising energy efficient ML paradigm for
resource-constrained devices. However, the current state-of-the-art (SOTA) SNNs
require multiple time steps for acceptable inference accuracy, increasing
spiking activity and, consequently, energy consumption. SOTA training
strategies for SNNs involve conversion from a non-spiking deep neural network
(DNN). In this paper, we determine that SOTA conversion strategies cannot yield
ultra low latency because they incorrectly assume that the DNN and SNN
pre-activation values are uniformly distributed. We propose a new training
algorithm that accurately captures these distributions, minimizing the error
between the DNN and converted SNN. The resulting SNNs have ultra low latency
and high activation sparsity, yielding significant improvements in compute
efficiency. In particular, we evaluate our framework on image recognition tasks
from CIFAR-10 and CIFAR-100 datasets on several VGG and ResNet architectures.
We obtain top-1 accuracy of 64.19% with only 2 time steps on the CIFAR-100
dataset with ~159.2x lower compute energy compared to an iso-architecture
standard DNN. Compared to other SOTA SNN models, our models perform inference
2.5-8x faster (i.e., with fewer time steps).
","[{'version': 'v1', 'created': 'Wed, 22 Dec 2021 18:47:45 GMT'}]",2021-12-23,"[['Datta', 'Gourav', ''], ['Beerel', 'Peter A.', '']]"
2111.10912,Karthik C. S.,"Vincent Cohen-Addad, Karthik C. S., and Euiwoong Lee","Johnson Coverage Hypothesis: Inapproximability of k-means and k-median
  in L_p metrics",Abstract in metadata shortened to meet arxiv requirements,,,,cs.CC cs.CG cs.DS cs.LG,http://creativecommons.org/licenses/by/4.0/,"  K-median and k-means are the two most popular objectives for clustering
algorithms. Despite intensive effort, a good understanding of the
approximability of these objectives, particularly in $\ell_p$-metrics, remains
a major open problem. In this paper, we significantly improve upon the hardness
of approximation factors known in literature for these objectives in
$\ell_p$-metrics.
  We introduce a new hypothesis called the Johnson Coverage Hypothesis (JCH),
which roughly asserts that the well-studied max k-coverage problem on set
systems is hard to approximate to a factor greater than 1-1/e, even when the
membership graph of the set system is a subgraph of the Johnson graph. We then
show that together with generalizations of the embedding techniques introduced
by Cohen-Addad and Karthik (FOCS '19), JCH implies hardness of approximation
results for k-median and k-means in $\ell_p$-metrics for factors which are
close to the ones obtained for general metrics. In particular, assuming JCH we
show that it is hard to approximate the k-means objective:
  $\bullet$ Discrete case: To a factor of 3.94 in the $\ell_1$-metric and to a
factor of 1.73 in the $\ell_2$-metric; this improves upon the previous factor
of 1.56 and 1.17 respectively, obtained under UGC.
  $\bullet$ Continuous case: To a factor of 2.10 in the $\ell_1$-metric and to
a factor of 1.36 in the $\ell_2$-metric; this improves upon the previous factor
of 1.07 in the $\ell_2$-metric obtained under UGC.
  We also obtain similar improvements under JCH for the k-median objective.
Additionally, we prove a weak version of JCH using the work of Dinur et al.
(SICOMP '05) on Hypergraph Vertex Cover, and recover all the results stated
above of Cohen-Addad and Karthik (FOCS '19) to (nearly) the same
inapproximability factors but now under the standard NP$\neq$P assumption
(instead of UGC).
","[{'version': 'v1', 'created': 'Sun, 21 Nov 2021 22:42:42 GMT'}]",2021-11-23,"[['Cohen-Addad', 'Vincent', ''], ['S.', 'Karthik C.', ''], ['Lee', 'Euiwoong', '']]"
2112.13289,Jacques Balayla,Jacques Balayla,"Prevalence Threshold and bounds in the Accuracy of Binary Classification
  Systems",,,,,stat.ML cs.LG,http://creativecommons.org/licenses/by/4.0/,"  The accuracy of binary classification systems is defined as the proportion of
correct predictions - both positive and negative - made by a classification
model or computational algorithm. A value between 0 (no accuracy) and 1
(perfect accuracy), the accuracy of a classification model is dependent on
several factors, notably: the classification rule or algorithm used, the
intrinsic characteristics of the tool used to do the classification, and the
relative frequency of the elements being classified. Several accuracy metrics
exist, each with its own advantages in different classification scenarios. In
this manuscript, we show that relative to a perfect accuracy of 1, the positive
prevalence threshold ($\phi_e$), a critical point of maximum curvature in the
precision-prevalence curve, bounds the $F{_{\beta}}$ score between 1 and
1.8/1.5/1.2 for $\beta$ values of 0.5/1.0/2.0, respectively; the $F_1$ score
between 1 and 1.5, and the Fowlkes-Mallows Index (FM) between 1 and $\sqrt{2}
\approx 1.414$. We likewise describe a novel $negative$ prevalence threshold
($\phi_n$), the level of sharpest curvature for the negative predictive
value-prevalence curve, such that $\phi_n$ $>$ $\phi_e$. The area between both
these thresholds bounds the Matthews Correlation Coefficient (MCC) between
$\sqrt{2}/2$ and $\sqrt{2}$. Conversely, the ratio of the maximum possible
accuracy to that at any point below the prevalence threshold, $\phi_e$, goes to
infinity with decreasing prevalence. Though applications are numerous, the
ideas herein discussed may be used in computational complexity theory,
artificial intelligence, and medical screening, amongst others. Where
computational time is a limiting resource, attaining the prevalence threshold
in binary classification systems may be sufficient to yield levels of accuracy
comparable to that under maximum prevalence.
","[{'version': 'v1', 'created': 'Sat, 25 Dec 2021 21:22:32 GMT'}]",2021-12-28,"[['Balayla', 'Jacques', '']]"
2105.13500,Jan Janak,"Jan Janak, Teresa Tseng, Aliza Isaacs, Henning Schulzrinne",An Analysis of Amazon Echo's Network Behavior,"6 pages, 7 figures, to be published in the proceedings of IEEE
  GLOBECOM 2021",,,,cs.NI,http://creativecommons.org/licenses/by/4.0/,"  With over 20 million units sold since 2015, Amazon Echo, the Alexa-enabled
smart speaker developed by Amazon, is probably one of the most widely deployed
Internet of Things consumer devices. Despite the very large installed base,
surprisingly little is known about the device's network behavior. We modify a
first generation Echo device, decrypt its communication with Amazon cloud, and
analyze the device pairing, Alexa Voice Service, and drop-in calling protocols.
We also describe our methodology and the experimental setup. We find a minor
shortcoming in the device pairing protocol and learn that drop-in calls are
end-to-end encrypted and based on modern open standards. Overall, we find the
Echo to be a well-designed device from the network communication perspective.
","[{'version': 'v1', 'created': 'Thu, 27 May 2021 23:26:18 GMT'}, {'version': 'v2', 'created': 'Sun, 22 Aug 2021 20:22:43 GMT'}]",2021-08-24,"[['Janak', 'Jan', ''], ['Tseng', 'Teresa', ''], ['Isaacs', 'Aliza', ''], ['Schulzrinne', 'Henning', '']]"
2201.10413,Janni Yuval,"Rei Chemke, Yi Ming and Janni Yuval","The intensification of winter mid-latitude storms in the Southern
  Hemisphere","40 pages, 3 figures in main, 15 figures in SI",,,,physics.ao-ph,http://creativecommons.org/licenses/by/4.0/,"  The strength of mid-latitude storms shapes weather and climate phenomena in
the extra-tropics, as these storms control the daily to multi-decadal
variability of precipitation, temperature and winds. By the end of this
century, winter mid-latitude storms are projected to intensify in the Southern
Hemisphere, with large consequences over the entire extra-tropics. It is thus
critical to accurately assess the impacts of anthropogenic emissions on
wintertime mid-latitude storms, in order to improve our preparedness to future
climate changes. However, here we find that climate models severely
underestimate the intensification in mid-latitude storms in recent decades.
Specifically, the intensification obtained from reanalyses has already reached
the model-projected intensification by the end of the century. Our results
question the ability of climate models to accurately predict the future climate
impacts of anthropogenic emissions in the Southern Hemisphere mid-latitudes.
","[{'version': 'v1', 'created': 'Tue, 25 Jan 2022 15:59:51 GMT'}]",2022-01-26,"[['Chemke', 'Rei', ''], ['Ming', 'Yi', ''], ['Yuval', 'Janni', '']]"
1707.03622,Jacopo Bertolotti,"I. Starshynov, A. M. Paniagua-Diaz, N. Fayard, A. Goetschy, R.
  Pierrat, R. Carminati, J. Bertolotti","Correlations between reflected and transmitted intensity patterns
  emerging from opaque disordered media","6 pages, 4 figures","Phys. Rev. X 8, 021041 (2018)",10.1103/PhysRevX.8.021041,,physics.optics,http://creativecommons.org/licenses/by/4.0/,"  The propagation of monochromatic light through a scattering medium produces
speckle patterns in reflection and transmission, and the apparent randomness of
these patterns prevents direct imaging through thick turbid media. Yet, since
elastic multiple scattering is fundamentally a linear and deterministic
process, information is not lost but distributed among many degrees of freedom
that can be resolved and manipulated. Here we demonstrate experimentally that
the reflected and transmitted speckle patterns are correlated, even for opaque
media with thickness much larger than the transport mean free path, proving
that information survives the multiple scattering process and can be recovered.
The existence of mutual information between the two sides of a scattering
medium opens up new possibilities for the control of transmitted light without
any feedback from the target side, but using only information gathered from the
reflected speckle.
","[{'version': 'v1', 'created': 'Wed, 12 Jul 2017 10:01:05 GMT'}]",2018-05-16,"[['Starshynov', 'I.', ''], ['Paniagua-Diaz', 'A. M.', ''], ['Fayard', 'N.', ''], ['Goetschy', 'A.', ''], ['Pierrat', 'R.', ''], ['Carminati', 'R.', ''], ['Bertolotti', 'J.', '']]"
2105.06361,Ziyue Xiang,"Ziyue Xiang, J\'anos Horv\'ath, Sriram Baireddy, Paolo Bestagini,
  Stefano Tubaro, Edward J. Delp",Forensic Analysis of Video Files Using Metadata,"v2: fixed a typo in Section 3.4; added page number; added IEEE
  copyright notice",,10.1109/CVPRW53098.2021.00115,,cs.MM cs.CV,http://creativecommons.org/licenses/by/4.0/,"  The unprecedented ease and ability to manipulate video content has led to a
rapid spread of manipulated media. The availability of video editing tools
greatly increased in recent years, allowing one to easily generate
photo-realistic alterations. Such manipulations can leave traces in the
metadata embedded in video files. This metadata information can be used to
determine video manipulations, brand of video recording device, the type of
video editing tool, and other important evidence. In this paper, we focus on
the metadata contained in the popular MP4 video wrapper/container. We describe
our method for metadata extractor that uses the MP4's tree structure. Our
approach for analyzing the video metadata produces a more compact
representation. We will describe how we construct features from the metadata
and then use dimensionality reduction and nearest neighbor classification for
forensic analysis of a video file. Our approach allows one to visually inspect
the distribution of metadata features and make decisions. The experimental
results confirm that the performance of our approach surpasses other methods.
","[{'version': 'v1', 'created': 'Thu, 13 May 2021 15:40:39 GMT'}, {'version': 'v2', 'created': 'Sat, 22 Jan 2022 05:33:37 GMT'}]",2022-01-25,"[['Xiang', 'Ziyue', ''], ['Horváth', 'János', ''], ['Baireddy', 'Sriram', ''], ['Bestagini', 'Paolo', ''], ['Tubaro', 'Stefano', ''], ['Delp', 'Edward J.', '']]"
2011.08305,Guilherme Limberg,"Guilherme Limberg, Silvia Rossi, Timothy C. Beers, H\'elio D.
  Perottoni, Angeles P\'erez-Villegas, Rafael M. Santucci, Yuri Abuchaim,
  Vinicius M. Placco, Young Sun Lee, Norbert Christlieb, John E. Norris,
  Michael S. Bessell, Sean G. Ryan, Ronald Wilhelm, Jaehyon Rhee, Anna Frebel","Dynamically Tagged Groups of Very Metal-poor Halo Stars from the HK and
  Hamburg/ESO Surveys","Accepted for ApJ. Tables 5 and 6 available in the online journal.
  Minor typos fixed and references updated to match published version",,10.3847/1538-4357/abcb87,,astro-ph.GA astro-ph.SR,http://creativecommons.org/licenses/by/4.0/,"  We analyze the dynamical properties of $\sim$1500 very metal-poor (VMP;
[Fe/H] $\lesssim -2.0$) halo stars, based primarily on medium-resolution
spectroscopic data from the HK and Hamburg/ESO surveys. These data, collected
over the past thirty years, are supplemented by a number of calibration stars
and other small samples, along with astrometric information from $Gaia$ DR2. We
apply a clustering algorithm to the 4-D energy-action space of the sample, and
identify a set of 38 Dynamically Tagged Groups (DTGs), containing between 5 and
30 member stars. Many of these DTGs can be associated with previously known
prominent substructures such as $Gaia$-Sausage/Enceladus (GSE), Sequoia, the
Helmi Stream (HStr), and Thamnos. Others are associated with previously
identified smaller dynamical groups of stars and streams. We identify 10 new
DTGs as well, many of which have strongly retrograde orbits. We also
investigate possible connections between our DTGs and $\sim$300 individual
$r$-process-enhanced (RPE) stars from a recent literature compilation. We find
that several of these objects have similar dynamical properties to GSE (5), the
HStr (4), Sequoia (1), and Rg5 (1), indicating that their progenitors might
have been important sources of RPE stars in the Galaxy. Additionally, a number
of our newly identified DTGs are shown to be associated with at least two RPE
stars each (DTG-2: 3, DTG-7: 2; DTG-27: 2). Taken as a whole, these results are
consistent with ultra-faint and/or dwarf spheroidal galaxies as birth
environments in which $r$-process nucleosynthesis took place, and then were
disrupted by the Milky Way.
","[{'version': 'v1', 'created': 'Mon, 16 Nov 2020 22:05:39 GMT'}, {'version': 'v2', 'created': 'Thu, 10 Dec 2020 14:11:46 GMT'}, {'version': 'v3', 'created': 'Mon, 26 Apr 2021 16:54:51 GMT'}]",2021-04-27,"[['Limberg', 'Guilherme', ''], ['Rossi', 'Silvia', ''], ['Beers', 'Timothy C.', ''], ['Perottoni', 'Hélio D.', ''], ['Pérez-Villegas', 'Angeles', ''], ['Santucci', 'Rafael M.', ''], ['Abuchaim', 'Yuri', ''], ['Placco', 'Vinicius M.', ''], ['Lee', 'Young Sun', ''], ['Christlieb', 'Norbert', ''], ['Norris', 'John E.', ''], ['Bessell', 'Michael S.', ''], ['Ryan', 'Sean G.', ''], ['Wilhelm', 'Ronald', ''], ['Rhee', 'Jaehyon', ''], ['Frebel', 'Anna', '']]"
2012.04565,Nikola Besinovic,"Jordi Zomer, Nikola Be\v{s}inovi\'c, Mathijs M. de Weerdt, Rob M.P.
  Goverde",The Maintenance Location Choice Problem for Railway Rolling Stock,"16 pages, 5 figures",,,,math.OC cs.DM cs.SY eess.SY,http://creativecommons.org/licenses/by/4.0/,"  Due to increasing railway use, the capacity at railway yards and maintenance
locations is becoming limiting to accommodate existing rolling stock. To reduce
capacity issues at maintenance locations during nighttime, railway undertakings
consider performing more daytime maintenance, but the choice at which locations
personnel needs to be stationed for daytime maintenance is not straightforward.
Among other things, it depends on the planned rolling stock circulation and the
maintenance activities that need to be performed. This paper presents the
Maintenance Location Choice Problem (MLCP) and provides a Mixed Integer Linear
Programming model for this problem. The model demonstrates that for a
representative rolling stock circulation from the Dutch railways a substantial
amount of maintenance activities can be performed during daytime. Also, it is
shown that the location choice delivered by the model is robust under various
time horizons and rolling stock circulations. Moreover, the running time for
optimizing the model is considered acceptable for planning purposes.
","[{'version': 'v1', 'created': 'Tue, 8 Dec 2020 17:07:44 GMT'}]",2020-12-09,"[['Zomer', 'Jordi', ''], ['Bešinović', 'Nikola', ''], ['de Weerdt', 'Mathijs M.', ''], ['Goverde', 'Rob M. P.', '']]"
2110.11975,Shikhar Mittal,Shikhar Mittal (TIFR) and Girish Kulkarni (TIFR),Background of radio photons from primordial black holes,Published,MNRAS 510 (2022) 4992,10.1093/mnras/stac005,TIFR/TH/21-16,astro-ph.CO hep-ph hep-th,http://creativecommons.org/licenses/by/4.0/,"  We compute the isotropic radiation background due to Hawking emission from
primordial black holes (PBHs), and examine if this background is a viable
option in explaining the excess radiowave background observed by the ARCADE2
and LWA1 experiments at $\lesssim 1\,$GHz. We find that even under the extreme
assumption that all of the dark matter is in the form of PBHs, the radio
brightness temperature induced by Hawking evaporation of PBHs is
$\mathcal{O}(10^{-46})\,$K, highly subdominant compared to the cosmic microwave
background. The main reason for this is that for PBHs in the mass range
$\sim10^{12}$-$10^{14}\,$kg, which can be constrained by Hawking emission, the
spectrum peaks at $10^7$ to $10^5\,$eV. As the Hawking spectrum is power law
suppressed towards lower energies, negligible flux of $\mu$eV photons is
obtained. The peak of the Hawking spectrum shifts to lower energies for higher
masses, but the number density is low and so is the specific intensity. Because
Hawking emission from PBHs is thus unable to explain the observed excess radio
background, we also consider the alternative possibility of radio emission from
gas accretion onto supermassive PBHs. These PBHs can readily produce strong
radio emission that could easily explain the ARCADE2/LWA1 excess.
","[{'version': 'v1', 'created': 'Fri, 22 Oct 2021 18:00:03 GMT'}, {'version': 'v2', 'created': 'Wed, 5 Jan 2022 15:19:44 GMT'}, {'version': 'v3', 'created': 'Thu, 20 Jan 2022 14:57:01 GMT'}]",2022-01-21,"[['Mittal', 'Shikhar', '', 'TIFR'], ['Kulkarni', 'Girish', '', 'TIFR']]"
2111.11213,Zhiqiang Cai,Zhiqiang Cai and Ling Lin and Xiang Zhou,Learn Quasi-stationary Distributions of Finite State Markov Chain,"18 pages, 5 figures",,10.3390/e24010133,,cs.LG,http://creativecommons.org/licenses/by/4.0/,"  We propose a reinforcement learning (RL) approach to compute the expression
of quasi-stationary distribution. Based on the fixed-point formulation of
quasi-stationary distribution, we minimize the KL-divergence of two Markovian
path distributions induced by the candidate distribution and the true target
distribution. To solve this challenging minimization problem by gradient
descent, we apply the reinforcement learning technique by introducing the
reward and value functions. We derive the corresponding policy gradient theorem
and design an actor-critic algorithm to learn the optimal solution and the
value function. The numerical examples of finite state Markov chain are tested
to demonstrate the new method.
","[{'version': 'v1', 'created': 'Fri, 19 Nov 2021 02:56:34 GMT'}, {'version': 'v2', 'created': 'Tue, 18 Jan 2022 02:53:38 GMT'}]",2022-02-02,"[['Cai', 'Zhiqiang', ''], ['Lin', 'Ling', ''], ['Zhou', 'Xiang', '']]"
2109.03763,Mario Ballardini Dr.,"Mario Ballardini, Roy Maartens","Constraining the neutrino mass using a multi-tracer combination of two
  galaxy surveys and CMB lensing","3 figures, 3 tables, 7 pages",MNRAS 510 (2022) 4295,10.1093/mnras/stab3480,,astro-ph.CO,http://creativecommons.org/licenses/by/4.0/,"  Measuring the total neutrino mass is one of the most exciting opportunities
available with next-generation cosmological data sets. We study the possibility
of detecting the total neutrino mass using large-scale clustering in 21cm
intensity mapping and photometric galaxy surveys, together with CMB
information. We include the scale-dependent halo bias contribution due to the
presence of massive neutrinos, and use a multi-tracer analysis in order to
reduce cosmic variance. The multi-tracer combination of an SKAO-MID 21cm
intensity map with Stage~4 CMB dramatically shrinks the uncertainty on total
neutrino mass to $\sigma(M_\nu) \simeq 45\,$meV, using only linear clustering
information ($k_{\rm max} = 0.1\, h/$Mpc) and without a prior on optical depth.
When we add to the multi-tracer the clustering information expected from LSST,
the forecast is $\sigma(M_\nu) \simeq 12\,$meV.
","[{'version': 'v1', 'created': 'Wed, 8 Sep 2021 16:38:51 GMT'}, {'version': 'v2', 'created': 'Fri, 26 Nov 2021 14:14:29 GMT'}]",2022-01-19,"[['Ballardini', 'Mario', ''], ['Maartens', 'Roy', '']]"
2106.04018,Adam B. Block,"Adam Block, Zeyu Jia, Yury Polyanskiy, and Alexander Rakhlin",Intrinsic Dimension Estimation,,,,,stat.ML cs.LG,http://creativecommons.org/licenses/by/4.0/,"  It has long been thought that high-dimensional data encountered in many
practical machine learning tasks have low-dimensional structure, i.e., the
manifold hypothesis holds. A natural question, thus, is to estimate the
intrinsic dimension of a given population distribution from a finite sample. We
introduce a new estimator of the intrinsic dimension and provide finite sample,
non-asymptotic guarantees. We then apply our techniques to get new sample
complexity bounds for Generative Adversarial Networks (GANs) depending only on
the intrinsic dimension of the data.
","[{'version': 'v1', 'created': 'Tue, 8 Jun 2021 00:05:39 GMT'}]",2021-06-09,"[['Block', 'Adam', ''], ['Jia', 'Zeyu', ''], ['Polyanskiy', 'Yury', ''], ['Rakhlin', 'Alexander', '']]"
2106.10532,Amit Verma Dr.,Amit Verma and Mark Lewis,QUBO transformation using Eigenvalue Decomposition,Preprint submitted to Springer,,,,math.OC cs.AI cs.ET,http://creativecommons.org/licenses/by/4.0/,"  Quadratic Unconstrained Binary Optimization (QUBO) is a general-purpose
modeling framework for combinatorial optimization problems and is a requirement
for quantum annealers. This paper utilizes the eigenvalue decomposition of the
underlying Q matrix to alter and improve the search process by extracting the
information from dominant eigenvalues and eigenvectors to implicitly guide the
search towards promising areas of the solution landscape. Computational results
on benchmark datasets illustrate the efficacy of our routine demonstrating
significant performance improvements on problems with dominant eigenvalues.
","[{'version': 'v1', 'created': 'Sat, 19 Jun 2021 16:58:15 GMT'}]",2021-06-22,"[['Verma', 'Amit', ''], ['Lewis', 'Mark', '']]"
2109.04933,Erika Palmerio,"Erika Palmerio, Christina Kay, Nada Al-Haddad, Benjamin J. Lynch,
  Wenyuan Yu, Michael L. Stevens, Sanchita Pal, Christina O. Lee","Predicting the Magnetic Fields of a Stealth CME Detected by Parker Solar
  Probe at 0.5 AU","9 pages, 4 figures, 1 table, accepted for publication in The
  Astrophysical Journal",,10.3847/1538-4357/ac25f4,,astro-ph.SR physics.space-ph,http://creativecommons.org/licenses/by/4.0/,"  Stealth coronal mass ejection (CMEs) are eruptions from the Sun that are not
associated with appreciable low-coronal signatures. Because they often cannot
be linked to a well-defined source region on the Sun, analysis of their initial
magnetic configuration and eruption dynamics is particularly problematic. In
this manuscript, we address this issue by undertaking the first attempt at
predicting the magnetic fields of a stealth CME that erupted in 2020 June from
the Earth-facing Sun. We estimate its source region with the aid of off-limb
observations from a secondary viewpoint and photospheric magnetic field
extrapolations. We then employ the Open Solar Physics Rapid Ensemble
Information (OSPREI) modelling suite to evaluate its early evolution and
forward-model its magnetic fields up to Parker Solar Probe, which detected the
CME in situ at a heliocentric distance of 0.5 AU. We compare our hindcast
prediction with in-situ measurements and a set of flux rope reconstructions,
obtaining encouraging agreement on arrival time, spacecraft crossing location,
and magnetic field profiles. This work represents a first step towards reliable
understanding and forecasting of the magnetic configuration of stealth CMEs and
slow, streamer-blowout events.
","[{'version': 'v1', 'created': 'Fri, 10 Sep 2021 15:25:59 GMT'}]",2021-10-19,"[['Palmerio', 'Erika', ''], ['Kay', 'Christina', ''], ['Al-Haddad', 'Nada', ''], ['Lynch', 'Benjamin J.', ''], ['Yu', 'Wenyuan', ''], ['Stevens', 'Michael L.', ''], ['Pal', 'Sanchita', ''], ['Lee', 'Christina O.', '']]"
2106.15785,Abdul Haseeb Ahmed,"Abdul Haseeb Ahmed, Prashant Nagpal, and Mathews Jacob","Dynamic Imaging using Deep Bi-linear Unsupervised Regularization
  (DEBLUR)",,,,,eess.IV,http://creativecommons.org/licenses/by/4.0/,"  Bilinear models that decompose dynamic data to spatial and temporal factors
are powerful and memory-efficient tools for the recovery of dynamic MRI data.
These methods rely on sparsity and energy compaction priors on the factors to
regularize the recovery. The quality of the recovered images depend on the
specific priors. Motivated by deep image prior, we introduce a novel bilinear
model whose factors are represented using convolutional neural networks (CNNs).
The CNN parameters are learned from the undersampled data off the same subject.
To reduce the run time and to improve performance, we initialize the CNN
parameters. We use sparsity regularization of the network parameters to
minimize the overfitting of the network to measurement noise. Our experiments
on free breathing and ungated cardiac cine data acquired using a navigated
golden-angle gradient-echo radial sequence show the ability of our method to
provide reduced spatial blurring as compared to low-rank and SToRM
reconstructions.
","[{'version': 'v1', 'created': 'Wed, 30 Jun 2021 02:49:14 GMT'}]",2021-07-01,"[['Ahmed', 'Abdul Haseeb', ''], ['Nagpal', 'Prashant', ''], ['Jacob', 'Mathews', '']]"
2012.15420,Amir Hossein Afsharinejad,"Amir Hossein Afsharinejad, Chuanyi Ji and Robert Wilcox",Heterogeneous recovery from large scale power failures,"31 pages, 4 figures",,,,cs.CE cs.SY eess.SY,http://creativecommons.org/licenses/by/4.0/,"  Large-scale power failures are induced by nearly all natural disasters from
hurricanes to wild fires. A fundamental problem is whether and how recovery
guided by government policies is able to meet the challenge of a wide range of
disruptions. Prior research on this problem is scant due to lack of sharing
large-scale granular data at the operational energy grid, stigma of revealing
limitations of services, and complex recovery coupled with policies and
customers. As such, both quantification and firsthand information are lacking
on capabilities and fundamental limitation of energy services in response to
extreme events. Furthermore, government policies that guide recovery are often
sidelined by prior study. This work studies the fundamental problem through the
lens of recovery guided by two commonly adopted policies. We develop data
analysis on unsupervised learning from non-stationary data. The data span
failure events, from moderate to extreme, at the operational distribution grid
during the past nine years in two service regions at the state of New York and
Massachusetts. We show that under the prioritization policy favoring large
failures, recovery exhibits a surprising scaling property which counteracts
failure scaling on the infrastructure vulnerability. However, heterogeneous
recovery widens with the severity of failure events: large failures that cannot
be prioritized increase customer interruption time by 47 folds. And, prolonged
small failures dominate the entire temporal evolution of recovery.
","[{'version': 'v1', 'created': 'Thu, 31 Dec 2020 03:12:46 GMT'}]",2021-01-01,"[['Afsharinejad', 'Amir Hossein', ''], ['Ji', 'Chuanyi', ''], ['Wilcox', 'Robert', '']]"
2011.13347,Catarina Lopes-Dias,"Catarina Lopes-Dias, Andreea I. Sburlea, Katharina Breitegger, Daniela
  Wyss, Harald Drescher, Renate Wildburger and Gernot R. M\""uller-Putz","Online asynchronous detection of error-related potentials in
  participants with a spinal cord injury using a generic classifier",,J. Neural Eng. 18 046022 (2021),10.1088/1741-2552/abd1eb,,cs.HC,http://creativecommons.org/licenses/by/4.0/,"  A BCI user awareness of an error is associated with a cortical signature
named error-related potential (ErrP). The incorporation of ErrPs' detection in
BCIs can improve BCIs' performance. This work is three-folded. First, we
investigate if an ErrP classifier is transferable from able-bodied participants
to participants with spinal cord injury (SCI). Second, we test this generic
ErrP classifier with SCI and control participants, in an online experiment
without offline calibration. Third, we investigate the morphology of ErrPs in
both groups of participants. We used previously recorded
electroencephalographic (EEG) data from able-bodied participants to train an
ErrP classifier. We tested the classifier asynchronously, in an online
experiment with 16 new participants: 8 participants with SCI and 8 able-bodied
control participants. The experiment had no offline calibration and
participants received feedback regarding the ErrPs' detection from its start.
The generic classifier was not trained with the user's brain signals. Still,
its performance was optimized during the online experiment with the use of
personalized decision thresholds. Participants with SCI presented a
non-homogenous ErrP morphology, and four of them did not present clear ErrP
signals. The generic classifier performed above chance level in participants
with clear ErrP signals, independently of the SCI (11 out of 16 participants).
Three out of the five participants that obtained chance level results with the
generic classifier would have not benefited from the use of a personalized
classifier. This work shows the feasibility of transferring an ErrP classifier
from able-bodied participants to participants with SCI, for asynchronous
detection of ErrPs in an online experiment without offline calibration, which
provided immediate feedback to the users.
","[{'version': 'v1', 'created': 'Thu, 26 Nov 2020 15:24:41 GMT'}, {'version': 'v2', 'created': 'Sun, 6 Dec 2020 08:08:22 GMT'}, {'version': 'v3', 'created': 'Fri, 2 Apr 2021 16:15:12 GMT'}]",2021-04-05,"[['Lopes-Dias', 'Catarina', ''], ['Sburlea', 'Andreea I.', ''], ['Breitegger', 'Katharina', ''], ['Wyss', 'Daniela', ''], ['Drescher', 'Harald', ''], ['Wildburger', 'Renate', ''], ['M\x7füller-Putz', 'Gernot R.', '']]"
2202.07787,Shuhan Yuan,Shuhan Yuan and Xintao Wu,Trustworthy Anomaly Detection: A Survey,"Paper list, see
  https://github.com/yuan-shuhan/trustworthy-anomaly-detection-papers",,,,cs.LG cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Anomaly detection has a wide range of real-world applications, such as bank
fraud detection and cyber intrusion detection. In the past decade, a variety of
anomaly detection models have been developed, which lead to big progress
towards accurately detecting various anomalies. Despite the successes, anomaly
detection models still face many limitations. The most significant one is
whether we can trust the detection results from the models. In recent years,
the research community has spent a great effort to design trustworthy machine
learning models, such as developing trustworthy classification models. However,
the attention to anomaly detection tasks is far from sufficient. Considering
that many anomaly detection tasks are life-changing tasks involving human
beings, labeling someone as anomalies or fraudsters should be extremely
cautious. Hence, ensuring the anomaly detection models conducted in a
trustworthy fashion is an essential requirement to deploy the models to conduct
automatic decisions in the real world. In this brief survey, we summarize the
existing efforts and discuss open problems towards trustworthy anomaly
detection from the perspectives of interpretability, fairness, robustness, and
privacy-preservation.
","[{'version': 'v1', 'created': 'Tue, 15 Feb 2022 23:25:37 GMT'}]",2022-02-17,"[['Yuan', 'Shuhan', ''], ['Wu', 'Xintao', '']]"
2104.03155,Antonis Sidiropoulos,"Antonis Sidiropoulos, Yiannis Karayiannidis and Zoe Doulgeri","Human-robot collaborative object transfer using human motion prediction
  based on Cartesian pose Dynamic Movement Primitives",,"2021 IEEE International Conference on Robotics and Automation
  (ICRA), 2021, pp. 3758-3764",10.1109/ICRA48506.2021.9562035,,cs.RO,http://creativecommons.org/licenses/by/4.0/,"  In this work, the problem of human-robot collaborative object transfer to
unknown target poses is addressed. The desired pattern of the end-effector pose
trajectory to a known target pose is encoded using DMPs (Dynamic Movement
Primitives). During transportation of the object to new unknown targets, a
DMP-based reference model and an EKF (Extended Kalman Filter) for estimating
the target pose and time duration of the human's intended motion is proposed. A
stability analysis of the overall scheme is provided. Experiments using a Kuka
LWR4+ robot equipped with an ATI sensor at its end-effector validate its
efficacy with respect to the required human effort and compare it with an
admittance control scheme.
","[{'version': 'v1', 'created': 'Wed, 7 Apr 2021 14:38:09 GMT'}, {'version': 'v2', 'created': 'Wed, 27 Oct 2021 14:02:19 GMT'}]",2021-10-28,"[['Sidiropoulos', 'Antonis', ''], ['Karayiannidis', 'Yiannis', ''], ['Doulgeri', 'Zoe', '']]"
1903.03509,David Castells-Rufas,"David Castells-Rufas, Jordi Carrabina","OpenCL-based FPGA accelerator for disparity map generation with
  stereoscopic event cameras","Presented at HIP3ES, 2019",,,HIP3ES/2019/5,cs.CV,http://creativecommons.org/licenses/by/4.0/,"  Although event-based cameras are already commercially available. Vision
algorithms based on them are still not common. As a consequence, there are few
Hardware Accelerators for them. In this work we present some experiments to
create FPGA accelerators for a well-known vision algorithm using event-based
cameras. We present a stereo matching algorithm to create a stream of disparity
events disparity map and implement several accelerators using the Intel FPGA
OpenCL tool-chain. The results show that multiple designs can be easily tested
and that a performance speedup of more than 8x can be achieved with simple code
transformations.
","[{'version': 'v1', 'created': 'Fri, 8 Mar 2019 15:39:27 GMT'}]",2019-03-11,"[['Castells-Rufas', 'David', ''], ['Carrabina', 'Jordi', '']]"
2104.06444,Pieter Hartel,"Pieter Hartel, Rolf van Wegberg","Going dark? Analysing the impact of end-to-end encryption on the outcome
  of Dutch criminal court cases",,,,,cs.CR cs.CY,http://creativecommons.org/licenses/by/4.0/,"  Former US attorney general William Barr and law enforcement colleagues from
other countries have published a statement on end-to-end encryption from which
we quote: ""while encryption is vital and privacy and cybersecurity must be
protected, that should not come at the expense of wholly precluding law
enforcement"". The main argument put forward by law enforcement is that
end-to-end encryption (E2EE) hampers authorities prosecuting criminals who rely
on encrypted communication - ranging from drug syndicates to child sexual abuse
material (CSAM) platforms. This statement, however, is not supported by
empirical evidence, and therefore not suitable as the sole basis of
policymaking. That is why, in our work, we analyse public court data from the
Netherlands to show to what extent law enforcement agencies and the public
prosecution service are impacted by the use of E2EE in bringing cases to court
and their outcome. Our results show that Dutch law enforcement appears to be as
successful in prosecuting offenders who rely on encrypted communication as
those who do not. In contrast to what the US attorney general wants us to
believe, at least the prosecution of cases does not seem hampered by E2EE.
","[{'version': 'v1', 'created': 'Tue, 13 Apr 2021 18:38:22 GMT'}]",2021-04-15,"[['Hartel', 'Pieter', ''], ['van Wegberg', 'Rolf', '']]"
2106.04536,\'Etienne Artigau,"\'Etienne Artigau, Guillaume H\'ebrard, Charles Cadieux, Thomas
  Vandal, Neil J. Cook, Ren\'e Doyon, Jonathan Gagn\'e, Claire Moutou, Eder
  Martioli, Antonio Frasca, Farbod Jahandar, David Lafreni\`ere, Lison Malo,
  Jean-Fran\c{c}ois Donati, Pia Cortes-Zuleta, Isabelle Boisse, Xavier
  Delfosse, Andres Carmona, Pascal Fouqu\'e, Julien Morin, Jason Rowe, Giuseppe
  Marino, Riccardo Papini, David R. Ciardi, Michael B. Lund, Jorge H. C.
  Martins, Stefan Pelletier, Luc Arnold, Fran\c{c}ois Bouchy, Thierry
  Forveille, Nuno C. Santos, Xavier Bonfils, Pedro Figueira, Michael Fausnaugh,
  George Ricker, David W. Latham, Sara Seager, Joshua N. Winn, Jon M. Jenkins,
  Eric B. Ting, Guillermo Torres, Jo\~ao Gomes da Silva","TOI-1278 B: SPIRou unveils a rare Brown Dwarf Companion in Close-In
  Orbit around an M dwarf",accepted for publication in The Astronomical Journal,,10.3847/1538-3881/ac096d,,astro-ph.SR astro-ph.EP,http://creativecommons.org/licenses/by/4.0/,"  We present the discovery of an $18.5\pm0.5$M$_{\rm Jup}$ brown dwarf (BD)
companion to the M0V star TOI-1278. The system was first identified through a
percent-deep transit in TESS photometry; further analysis showed it to be a
grazing transit of a Jupiter-sized object. Radial velocity (RV) follow-up with
the SPIRou near-infrared high-resolution velocimeter and spectropolarimeter in
the framework of the 300-night SPIRou Legacy Survey (SLS) carried out at the
Canada-France-Hawaii Telescope (CFHT) led to the detection of a Keplerian RV
signal with a semi-amplitude of $2306\pm10$ m/s in phase with the 14.5-day
transit period, having a slight but non-zero eccentricity. The
intermediate-mass ratio ($M_\star/M_{\rm{comp}} \sim31$) is unique for having
such a short separation ($0.095\pm0.001$ AU) among known M-dwarf systems.
Interestingly, M dwarf-brown dwarf systems with similar mass ratios exist with
separations of tens to thousands of AUs.
","[{'version': 'v1', 'created': 'Tue, 8 Jun 2021 17:19:04 GMT'}]",2021-09-22,"[['Artigau', 'Étienne', ''], ['Hébrard', 'Guillaume', ''], ['Cadieux', 'Charles', ''], ['Vandal', 'Thomas', ''], ['Cook', 'Neil J.', ''], ['Doyon', 'René', ''], ['Gagné', 'Jonathan', ''], ['Moutou', 'Claire', ''], ['Martioli', 'Eder', ''], ['Frasca', 'Antonio', ''], ['Jahandar', 'Farbod', ''], ['Lafrenière', 'David', ''], ['Malo', 'Lison', ''], ['Donati', 'Jean-François', ''], ['Cortes-Zuleta', 'Pia', ''], ['Boisse', 'Isabelle', ''], ['Delfosse', 'Xavier', ''], ['Carmona', 'Andres', ''], ['Fouqué', 'Pascal', ''], ['Morin', 'Julien', ''], ['Rowe', 'Jason', ''], ['Marino', 'Giuseppe', ''], ['Papini', 'Riccardo', ''], ['Ciardi', 'David R.', ''], ['Lund', 'Michael B.', ''], ['Martins', 'Jorge H. C.', ''], ['Pelletier', 'Stefan', ''], ['Arnold', 'Luc', ''], ['Bouchy', 'François', ''], ['Forveille', 'Thierry', ''], ['Santos', 'Nuno C.', ''], ['Bonfils', 'Xavier', ''], ['Figueira', 'Pedro', ''], ['Fausnaugh', 'Michael', ''], ['Ricker', 'George', ''], ['Latham', 'David W.', ''], ['Seager', 'Sara', ''], ['Winn', 'Joshua N.', ''], ['Jenkins', 'Jon M.', ''], ['Ting', 'Eric B.', ''], ['Torres', 'Guillermo', ''], ['da Silva', 'João Gomes', '']]"
2112.02399,Longtian Qiu,"Renrui Zhang, Longtian Qiu, Wei Zhang, Ziyao Zeng",VT-CLIP: Enhancing Vision-Language Models with Visual-guided Texts,,,,,cs.CV cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Contrastive Vision-Language Pre-training (CLIP) has drown increasing
attention recently for its transferable visual representation learning.
Supervised by large-scale image-text pairs, CLIP is able to align paired images
and texts and thus conduct zero-shot recognition in open-vocabulary scenarios.
However, there exists semantic gap between the specific application and
generally pre-trained knowledge, which makes the matching sub-optimal on
downstream tasks. In this paper, we propose VT-CLIP to enhance vision-language
modeling via visual-guided texts. Specifically, we guide the text feature to
adaptively explore informative regions on the image and aggregate the visual
feature by cross-attention machanism. In this way, the visual-guided text
become more semantically correlated with the image, which greatly benefits the
matching process. In few-shot settings, we evaluate our VT-CLIP on 11
well-known classification datasets and experiment extensive ablation studies to
demonstrate the effectiveness of VT-CLIP. The code will be released soon.
","[{'version': 'v1', 'created': 'Sat, 4 Dec 2021 18:34:24 GMT'}]",2021-12-07,"[['Zhang', 'Renrui', ''], ['Qiu', 'Longtian', ''], ['Zhang', 'Wei', ''], ['Zeng', 'Ziyao', '']]"
2203.01035,Henning Petzka,"Henning Petzka, Ted Kronvall, Cristian Sminchisescu","Discriminating Against Unrealistic Interpolations in Generative
  Adversarial Networks",The first two authors made equal contribution,,,,cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Interpolations in the latent space of deep generative models is one of the
standard tools to synthesize semantically meaningful mixtures of generated
samples. As the generator function is non-linear, commonly used linear
interpolations in the latent space do not yield the shortest paths in the
sample space, resulting in non-smooth interpolations. Recent work has therefore
equipped the latent space with a suitable metric to enforce shortest paths on
the manifold of generated samples. These are often, however, susceptible of
veering away from the manifold of real samples, resulting in smooth but
unrealistic generation that requires an additional method to assess the sample
quality along paths. Generative Adversarial Networks (GANs), by construction,
measure the sample quality using its discriminator network. In this paper, we
establish that the discriminator can be used effectively to avoid regions of
low sample quality along shortest paths. By reusing the discriminator network
to modify the metric on the latent space, we propose a lightweight solution for
improved interpolations in pre-trained GANs.
","[{'version': 'v1', 'created': 'Wed, 2 Mar 2022 11:27:56 GMT'}]",2022-03-03,"[['Petzka', 'Henning', ''], ['Kronvall', 'Ted', ''], ['Sminchisescu', 'Cristian', '']]"
2111.06757,J.-M. Chauvet,J.-M. Chauvet,Multiway Storage Modification Machines,"15 pages, 6 figures",,,,cs.AI cs.CC,http://creativecommons.org/licenses/by/4.0/,"  We present a parallel version of Sch\""onhage's Storage Modification Machine,
the Multiway Storage Modification Machine (MWSMM). Like the alternative
Association Storage Modification Machine of Tromp and van Emde Boas, MWSMMs
recognize in polynomial time what Turing Machines recognize in polynomial
space. Falling thus into the Second Machine Class, the MWSMM is a parallel
machine model conforming to the Parallel Computation Thesis. We illustrate
MWSMMs by a simple implementation of Wolfram's String Substitution System.
","[{'version': 'v1', 'created': 'Fri, 12 Nov 2021 15:06:48 GMT'}]",2021-11-15,"[['Chauvet', 'J. -M.', '']]"
2111.01318,Johnatan Cardona Jim\'enez,Johnatan Cardona Jim\'enez,"BayesDLMfMRI: Bayesian Matrix-Variate Dynamic Linear Models for
  Task-based fRMI Modeling in R",,,,,stat.AP,http://creativecommons.org/licenses/by/4.0/,"  This article introduces an R package to perform statistical analysis for
task-based fMRI data at both individual and group levels. The analysis to
detect brain activation at the individual level is based on modeling the fMRI
signal using Matrix-Variate Dynamic Linear Models (MDLM). Therefore, the
analysis for the group stage is based on posterior distributions of the state
parameter obtained from the modeling at the individual level. In this way, this
package offers several R functions with different algorithms to perform
inference on the state parameter to assess brain activation for both individual
and group stages. Those functions allow for parallel computation when the
analysis is performed for the entire brain as well as analysis at specific
voxels when it is required.
","[{'version': 'v1', 'created': 'Tue, 2 Nov 2021 01:34:50 GMT'}]",2021-11-03,"[['Jiménez', 'Johnatan Cardona', '']]"
2106.15890,Khizar Hameed,"Khizar Hameed, Saurabh Garg, Muhammad Bilal Amin, Byeong Kang, Abid
  Khan","A Context-Aware Information-Based Clone Node Attack Detection Scheme in
  Internet of Things",,,,,cs.CR,http://creativecommons.org/licenses/by/4.0/,"  The rapidly expanding nature of the Internet of Things (IoT) networks is
beginning to attract interest across a range of applications, including smart
homes, smart transportation, smart health, and industrial contexts. This
cutting-edge technology enables individuals to track and control their
integrated environment in real-time and remotely via a thousand IoT devices
comprised of sensors and actuators that actively participate in sensing,
processing, storing, and sharing information. Nonetheless, IoT devices are
frequently deployed in hostile environments, wherein adversaries attempt to
capture and breach them in order to seize control of the entire network. One
such example of potentially malicious behaviour is the cloning of IoT devices,
in which an attacker can physically capture the devices, obtain some sensitive
information, duplicate the devices, and intelligently deploy them in desired
locations to conduct various insider attacks. A device cloning attack on IoT
networks is a significant security concern since it allows for selective
forwarding, sink-hole, and black-hole attacks. To address this issue, this
paper provides an efficient scheme for detecting clone node attacks on IoT
networks that makes use of semantic information about IoT devices known as
context information sensed from the deployed environment to locate them
securely. We design a location proof mechanism by combining location proofs and
batch verification of the extended elliptic curve digital signature technique
to accelerate the verification process at selected trusted nodes. We
demonstrate the security of our scheme and its resilience to secure clone node
attack detection by conducting a comprehensive security analysis. The
performance of our proposed scheme provides a high degree of detection accuracy
with minimal detection time and significantly reduces the computation,
communication and storage overhead.
","[{'version': 'v1', 'created': 'Wed, 30 Jun 2021 08:32:33 GMT'}]",2021-07-01,"[['Hameed', 'Khizar', ''], ['Garg', 'Saurabh', ''], ['Amin', 'Muhammad Bilal', ''], ['Kang', 'Byeong', ''], ['Khan', 'Abid', '']]"
2104.12539,Nicholas Dacre PhD,"Vasilis Gkogkidis, Nicholas Dacre","Exploratory Learning Environments for Responsible Management Education
  Using Lego Serious Play",SBS Working Paper Series,,,,cs.CY,http://creativecommons.org/licenses/by/4.0/,"  Research into responsible management education has largely focused on the
merits, attributes, and transformation opportunities to enhance responsible
business school education aims. As such, a prominent part of the literature has
occupied itself with examining if responsible management modules are inherently
considered a non-crucial element of the curriculum and determining the extent
to which business schools have introduced such learning content into their
curriculum. However, there has been scant research into how to apply novel
teaching approaches to engage students and promote responsible management
education endeavours. As such, this paper seeks to address this gap through the
development of a teaching framework to support educators in designing effective
learning environments focused on responsible management education. We will draw
on constructivist learning theories and Lego Serious Play (LSP) as a learning
enhancement approach to develop a pedagogical framework. LSP is selected due to
its increasing application in learning environments to help promote critical
discourse, and engage with highly complex problems, whether these are social,
economic, environmental, or organisational.
","[{'version': 'v1', 'created': 'Sat, 27 Mar 2021 22:28:34 GMT'}]",2021-04-27,"[['Gkogkidis', 'Vasilis', ''], ['Dacre', 'Nicholas', '']]"
2002.08908,Xingyu Zhou,"Xingyu Zhou, Ness Shroff and Adam Wierman","Asymptotically Optimal Load Balancing in Large-scale Heterogeneous
  Systems with Multiple Dispatchers",2 figures,,,,cs.PF cs.DC math.PR,http://creativecommons.org/licenses/by/4.0/,"  We consider the load balancing problem in large-scale heterogeneous systems
with multiple dispatchers. We introduce a general framework called
Local-Estimation-Driven (LED). Under this framework, each dispatcher keeps
local (possibly outdated) estimates of queue lengths for all the servers, and
the dispatching decision is made purely based on these local estimates. The
local estimates are updated via infrequent communications between dispatchers
and servers. We derive sufficient conditions for LED policies to achieve
throughput optimality and delay optimality in heavy-traffic, respectively.
These conditions directly imply delay optimality for many previous local-memory
based policies in heavy traffic. Moreover, the results enable us to design new
delay optimal policies for heterogeneous systems with multiple dispatchers.
Finally, the heavy-traffic delay optimality of the LED framework directly
resolves a recent open problem on how to design optimal load balancing schemes
using delayed information.
","[{'version': 'v1', 'created': 'Thu, 20 Feb 2020 17:52:53 GMT'}]",2020-02-21,"[['Zhou', 'Xingyu', ''], ['Shroff', 'Ness', ''], ['Wierman', 'Adam', '']]"
2108.08560,Florian Merkle,"Florian Merkle, Maximilian Samsinger, Pascal Sch\""ottle",Pruning in the Face of Adversaries,,,,,cs.LG cs.CR,http://creativecommons.org/licenses/by/4.0/,"  The vulnerability of deep neural networks against adversarial examples -
inputs with small imperceptible perturbations - has gained a lot of attention
in the research community recently. Simultaneously, the number of parameters of
state-of-the-art deep learning models has been growing massively, with
implications on the memory and computational resources required to train and
deploy such models. One approach to control the size of neural networks is
retrospectively reducing the number of parameters, so-called neural network
pruning. Available research on the impact of neural network pruning on the
adversarial robustness is fragmentary and often does not adhere to established
principles of robustness evaluation. We close this gap by evaluating the
robustness of pruned models against L-0, L-2 and L-infinity attacks for a wide
range of attack strengths, several architectures, data sets, pruning methods,
and compression rates. Our results confirm that neural network pruning and
adversarial robustness are not mutually exclusive. Instead, sweet spots can be
found that are favorable in terms of model size and adversarial robustness.
Furthermore, we extend our analysis to situations that incorporate additional
assumptions on the adversarial scenario and show that depending on the
situation, different strategies are optimal.
","[{'version': 'v1', 'created': 'Thu, 19 Aug 2021 09:06:16 GMT'}]",2021-08-20,"[['Merkle', 'Florian', ''], ['Samsinger', 'Maximilian', ''], ['Schöttle', 'Pascal', '']]"
1612.05706,Philip Edwards,B. Glenn Piner and Philip G. Edwards,Parsec-scale Structure and Kinematics of Faint TeV HBLs,"7 pages, proceedings contribution for Blazars through Sharp
  Multi-Wavelength Eyes","Galaxies, vol. 4, issue 4, p. 44 (2016)",10.3390/galaxies4040044,,astro-ph.GA astro-ph.HE,http://creativecommons.org/licenses/by/4.0/,"  We present new multi-epoch Very Long Baseline Array (VLBA) observations of a
set of TeV blazars drawn from our VLBA program to monitor all TeV-detected
high-frequency peaked BL Lac objects (HBLs) at parsec scales. Most of these
sources are faint in the radio, so they have not been well observed with VLBI
by other surveys. Our previous measurements of apparent jet speeds in TeV HBLs
showed apparent jet speeds that were subluminal or barely superluminal,
suggesting jets with velocity structures at the parsec-scale. Here we present
apparent jet speed measurements for eight new TeV HBLs, which for the first
time show a superluminal tail to the apparent speed distribution for the TeV
HBLs.
","[{'version': 'v1', 'created': 'Sat, 17 Dec 2016 05:15:37 GMT'}]",2016-12-31,"[['Piner', 'B. Glenn', ''], ['Edwards', 'Philip G.', '']]"
2106.13275,Lesia Semenova,"Alex Oesterling, Angikar Ghosal, Haoyang Yu, Rui Xin, Yasa Baig, Lesia
  Semenova, Cynthia Rudin",Multitask Learning for Citation Purpose Classification,Second Workshop on Scholarly Document Processing,,,,cs.LG stat.ML,http://creativecommons.org/licenses/by/4.0/,"  We present our entry into the 2021 3C Shared Task Citation Context
Classification based on Purpose competition. The goal of the competition is to
classify a citation in a scientific article based on its purpose. This task is
important because it could potentially lead to more comprehensive ways of
summarizing the purpose and uses of scientific articles, but it is also
difficult, mainly due to the limited amount of available training data in which
the purposes of each citation have been hand-labeled, along with the
subjectivity of these labels. Our entry in the competition is a multi-task
model that combines multiple modules designed to handle the problem from
different perspectives, including hand-generated linguistic features, TF-IDF
features, and an LSTM-with-attention model. We also provide an ablation study
and feature analysis whose insights could lead to future work.
","[{'version': 'v1', 'created': 'Thu, 24 Jun 2021 18:57:26 GMT'}]",2021-06-28,"[['Oesterling', 'Alex', ''], ['Ghosal', 'Angikar', ''], ['Yu', 'Haoyang', ''], ['Xin', 'Rui', ''], ['Baig', 'Yasa', ''], ['Semenova', 'Lesia', ''], ['Rudin', 'Cynthia', '']]"
2104.05188,James Evans,"Jamshid Sourati, James Evans",Accelerating science with human versus alien artificial intelligences,32 pages,,,,cs.AI cond-mat.mtrl-sci q-bio.BM,http://creativecommons.org/licenses/by/4.0/,"  Data-driven artificial intelligence models fed with published scientific
findings have been used to create powerful prediction engines for scientific
and technological advance, such as the discovery of novel materials with
desired properties and the targeted invention of new therapies and vaccines.
These AI approaches typically ignore the distribution of human prediction
engines -- scientists and inventor -- who continuously alter the landscape of
discovery and invention. As a result, AI hypotheses are designed to substitute
for human experts, failing to complement them for punctuated collective
advance. Here we show that incorporating the distribution of human expertise
into self-supervised models by training on inferences cognitively available to
experts dramatically improves AI prediction of future human discoveries and
inventions. Including expert-awareness into models that propose (a) valuable
energy-relevant materials increases the precision of materials predictions by
~100%, (b) repurposing thousands of drugs to treat new diseases increases
precision by 43%, and (c) COVID-19 vaccine candidates examined in clinical
trials by 260%. These models succeed by predicting human predictions and the
scientists who will make them. By tuning AI to avoid the crowd, however, it
generates scientifically promising ""alien"" hypotheses unlikely to be imagined
or pursued without intervention, not only accelerating but punctuating
scientific advance. By identifying and correcting for collective human bias,
these models also suggest opportunities to improve human prediction by
reformulating science education for discovery.
","[{'version': 'v1', 'created': 'Mon, 12 Apr 2021 03:50:30 GMT'}]",2021-04-13,"[['Sourati', 'Jamshid', ''], ['Evans', 'James', '']]"
2202.05457,Shahrukh Khan,Shahrukh Khan and Mahnoor Shahid,"Hindi/Bengali Sentiment Analysis Using Transfer Learning and Joint Dual
  Input Learning with Self Attention",,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Sentiment Analysis typically refers to using natural language processing,
text analysis and computational linguistics to extract affect and emotion based
information from text data. Our work explores how we can effectively use deep
neural networks in transfer learning and joint dual input learning settings to
effectively classify sentiments and detect hate speech in Hindi and Bengali
data. We start by training Word2Vec word embeddings for Hindi \textbf{HASOC
dataset} and Bengali hate speech and then train LSTM and subsequently, employ
parameter sharing based transfer learning to Bengali sentiment classifiers by
reusing and fine-tuning the trained weights of Hindi classifiers with both
classifier being used as baseline in our study. Finally, we use BiLSTM with
self attention in joint dual input learning setting where we train a single
neural network on Hindi and Bengali dataset simultaneously using their
respective embeddings.
","[{'version': 'v1', 'created': 'Fri, 11 Feb 2022 05:36:11 GMT'}]",2022-02-14,"[['Khan', 'Shahrukh', ''], ['Shahid', 'Mahnoor', '']]"
2109.03585,Wenzheng Song,"Wenzheng Song, Masanori Suganuma, Xing Liu, Noriyuki Shimobayashi,
  Daisuke Maruta, Takayuki Okatani","Matching in the Dark: A Dataset for Matching Image Pairs of Low-light
  Scenes","15 pages, 14 figures, ICCV2021",,,,cs.CV,http://creativecommons.org/licenses/by/4.0/,"  This paper considers matching images of low-light scenes, aiming to widen the
frontier of SfM and visual SLAM applications. Recent image sensors can record
the brightness of scenes with more than eight-bit precision, available in their
RAW-format image. We are interested in making full use of such high-precision
information to match extremely low-light scene images that conventional methods
cannot handle. For extreme low-light scenes, even if some of their brightness
information exists in the RAW format images' low bits, the standard raw image
processing on cameras fails to utilize them properly. As was recently shown by
Chen et al., CNNs can learn to produce images with a natural appearance from
such RAW-format images. To consider if and how well we can utilize such
information stored in RAW-format images for image matching, we have created a
new dataset named MID (matching in the dark). Using it, we experimentally
evaluated combinations of eight image-enhancing methods and eleven image
matching methods consisting of classical/neural local descriptors and
classical/neural initial point-matching methods. The results show the advantage
of using the RAW-format images and the strengths and weaknesses of the above
component methods. They also imply there is room for further research.
","[{'version': 'v1', 'created': 'Wed, 8 Sep 2021 12:30:04 GMT'}, {'version': 'v2', 'created': 'Tue, 14 Sep 2021 06:30:53 GMT'}]",2021-09-15,"[['Song', 'Wenzheng', ''], ['Suganuma', 'Masanori', ''], ['Liu', 'Xing', ''], ['Shimobayashi', 'Noriyuki', ''], ['Maruta', 'Daisuke', ''], ['Okatani', 'Takayuki', '']]"
2110.09248,Hossein A. Rahmani,"Hossein A. Rahmani, Jie Yang",Demographic Biases of Crowd Workers in Key Opinion Leaders Finding,"3 pages, CSCW 2021 Workshop - Investigating and Mitigating Biases in
  Crowdsourced Data",,,,cs.IR,http://creativecommons.org/licenses/by/4.0/,"  Key Opinion Leaders (KOLs) are people that have a strong influence and their
opinions are listened to by people when making important decisions.
Crowdsourcing provides an efficient and cost-effective means to gather data for
the KOL finding task. However, data collected through crowdsourcing is affected
by the inherent demographic biases of crowd workers. To avoid such demographic
biases, we need to measure how biased each crowd worker is. In this paper, we
propose a simple yet effective approach based on demographic information of
candidate KOLs and their counterfactual value. We argue that it is
effectiveness because of the extra information that we can consider together
with labeled data to curate a less biased dataset.
","[{'version': 'v1', 'created': 'Mon, 18 Oct 2021 12:51:12 GMT'}, {'version': 'v2', 'created': 'Tue, 19 Oct 2021 06:39:09 GMT'}]",2021-10-20,"[['Rahmani', 'Hossein A.', ''], ['Yang', 'Jie', '']]"
2201.10526,Thomas Chen,Thomas Y. Chen,"MonarchNet: Differentiating Monarch Butterflies from Butterflies Species
  with Similar Phenotypes","5 pages, 2 figures, Proceedings of NeurIPS 2020 - Learning Meaningful
  Representations of Life (LMRL) Workshop. The FASEB Journal","CVPR 2021 Workshop on CV4Animals (Computer Vision for Animal
  Behavior Tracking and Modeling)",10.1096/fasebj.2021.35.S1.05504,,cs.CV cs.AI q-bio.PE stat.AP,http://creativecommons.org/licenses/by/4.0/,"  In recent years, the monarch butterfly's iconic migration patterns have come
under threat from a number of factors, from climate change to pesticide use. To
track trends in their populations, scientists as well as citizen scientists
must identify individuals accurately. This is uniquely key for the study of
monarch butterflies because there exist other species of butterfly, such as
viceroy butterflies, that are ""look-alikes"" (coined by the Convention on
International Trade in Endangered Species of Wild Fauna and Flora), having
similar phenotypes. To tackle this problem and to aid in more efficient
identification, we present MonarchNet, the first comprehensive dataset
consisting of butterfly imagery for monarchs and five look-alike species. We
train a baseline deep-learning classification model to serve as a tool for
differentiating monarch butterflies and its various look-alikes. We seek to
contribute to the study of biodiversity and butterfly ecology by providing a
novel method for computational classification of these particular butterfly
species. The ultimate aim is to help scientists track monarch butterfly
population and migration trends in the most precise and efficient manner
possible.
","[{'version': 'v1', 'created': 'Mon, 24 Jan 2022 17:51:42 GMT'}]",2022-02-01,"[['Chen', 'Thomas Y.', '']]"
2110.05279,Kristjan Greenewald,"Ziv Goldfeld, Kristjan Greenewald",Sliced Mutual Information: A Scalable Measure of Statistical Dependence,,,,,cs.IT math.IT,http://creativecommons.org/licenses/by/4.0/,"  Mutual information (MI) is a fundamental measure of statistical dependence,
with a myriad of applications to information theory, statistics, and machine
learning. While it possesses many desirable structural properties, the
estimation of high-dimensional MI from samples suffers from the curse of
dimensionality. Motivated by statistical scalability to high dimensions, this
paper proposes sliced MI (SMI) as a surrogate measure of dependence. SMI is
defined as an average of MI terms between one-dimensional random projections.
We show that it preserves many of the structural properties of classic MI,
while gaining scalable computation and efficient estimation from samples.
Furthermore, and in contrast to classic MI, SMI can grow as a result of
deterministic transformations. This enables leveraging SMI for feature
extraction by optimizing it over processing functions of raw data to identify
useful representations thereof. Our theory is supported by numerical studies of
independence testing and feature extraction, which demonstrate the potential
gains SMI offers over classic MI for high-dimensional inference.
","[{'version': 'v1', 'created': 'Mon, 11 Oct 2021 13:54:46 GMT'}, {'version': 'v2', 'created': 'Mon, 18 Oct 2021 14:23:41 GMT'}]",2021-10-19,"[['Goldfeld', 'Ziv', ''], ['Greenewald', 'Kristjan', '']]"
2201.05081,Dmitry Shaposhnikov S,"Dmitry S. Shaposhnikov, Alexander S. Medvedev, Alexander V. Rodin,
  Erdal Yi\u{g}it, Paul Hartogh","Martian Dust Storms and Gravity Waves: Disentangling Water Transport to
  the Upper Atmosphere",,,10.1029/2021JE007102,,astro-ph.EP physics.ao-ph,http://creativecommons.org/licenses/by/4.0/,"  Simulations with the Max Planck Institute Martian general circulation model
for Martian years 28 and 34 reveal details of the water ""pump"" mechanism and
the role of gravity wave (GW) forcing. Water is advected to the upper
atmosphere mainly by upward branches of the meridional circulation: in low
latitudes during equinoxes and over the south pole during solstices. Molecular
diffusion plays little role in water transport in the middle atmosphere and
across the mesopause. GWs modulate the circulation and temperature during
global dust storms, thus changing the timing and intensity of the transport. At
equinoxes, they facilitate water accumulation in the polar warming regions in
the middle atmosphere followed by stronger upwelling over the equator. As
equinoctial storms decay, GWs tend to accelerate the reduction of water in the
thermosphere. GWs delay the onset of the transport during solstitial storms and
change the globally averaged amount of water in the upper atmosphere by 10-25%.
","[{'version': 'v1', 'created': 'Thu, 13 Jan 2022 17:07:23 GMT'}]",2022-01-14,"[['Shaposhnikov', 'Dmitry S.', ''], ['Medvedev', 'Alexander S.', ''], ['Rodin', 'Alexander V.', ''], ['Yiğit', 'Erdal', ''], ['Hartogh', 'Paul', '']]"
2105.11680,Michael Arnold,Michael Arnold and Ramil Nigmatullin,Dynamics of vortex defect formation in two dimensional Coulomb crystals,,,,,cond-mat.stat-mech,http://creativecommons.org/licenses/by/4.0/,"  We study the non-equilibrium dynamics of two dimensional planar ion Coulomb
crystals undergoing a structural buckling transition to a three plane
configuration, driven by a reduction of the transverse confining frequency.
This phase transition can be theoretically modeled using a mapping to a two
dimensional Ginzburg-Landau theory with complex order parameter field. We
demonstrate that finite rate quenches result in creation of stable topological
vortices, which are localized point regions around which the phase of the order
parameter field winds a multiple of $2\pi$. The density of the defects as a
function of quench rate is investigated using molecular dynamics simulations
and its scaling is shown to be consistent with Kibble-Zurek theory of defect
formation. Following the quench, the annihilation of vortex and anti-vortex
pairs results in the relaxation of defect density that follows a diffusive
scaling with a logarithmic correction. This work highlights the potential for
investigating complex non-equilibrium statistical physics of topological
defects in an experimentally accessible ion trap setting.
","[{'version': 'v1', 'created': 'Tue, 25 May 2021 05:36:08 GMT'}, {'version': 'v2', 'created': 'Mon, 31 May 2021 09:20:50 GMT'}, {'version': 'v3', 'created': 'Thu, 3 Jun 2021 08:25:44 GMT'}]",2021-06-04,"[['Arnold', 'Michael', ''], ['Nigmatullin', 'Ramil', '']]"
2110.12594,Seung-Min Kim,"Seungmin Kim, EunChan Na and Seong Baeg Kim",Developing a Meta-suggestion Engine for Search Query,,,,,cs.IR,http://creativecommons.org/licenses/by/4.0/,"  With the development of the Internet and the accumulation of information on
the web, users use a search engine to easily obtain the desired information. A
query suggestion is one of the main services provided by a search engine, and
is very important for improving search performance, creating efficient queries,
and reducing search time. However, there are search engines that do not support
the query suggestion service. Under such engines, if users want to perform a
search, they would have much difficulties in effectively performing the search.
In this paper, to tackle the problem, we propose and develop a metasuggestion
engine that crawls suggested search queries from search engines with a
suggestion service, applies a re-ranking algorithm, and provides the suggested
search queries in the form of an extension program on a web browser.
Meta-suggestion engine are useful for users searching in engines that do not
provide query suggestions, as they provide query suggestions wherever the user
searches. We evaluate engines with relevance-based and predictive hit-based
evaluation methods, showing that MSE produces good quality suggestions. We
study improvements in target engine selection and re-ranking algorithms in
future studies.
","[{'version': 'v1', 'created': 'Mon, 25 Oct 2021 02:04:41 GMT'}]",2021-10-26,"[['Kim', 'Seungmin', ''], ['Na', 'EunChan', ''], ['Kim', 'Seong Baeg', '']]"
2109.07401,Jan Philipp Portisch,"Sven Hertling, Jan Portisch, Heiko Paulheim",Matching with Transformers in MELT,"accepted at the Ontology Matching Workshop at the International
  Semantic Web Conference (ISWC 2021)",,,,cs.CL cs.AI cs.IR cs.LG,http://creativecommons.org/licenses/by/4.0/,"  One of the strongest signals for automated matching of ontologies and
knowledge graphs are the textual descriptions of the concepts. The methods that
are typically applied (such as character- or token-based comparisons) are
relatively simple, and therefore do not capture the actual meaning of the
texts. With the rise of transformer-based language models, text comparison
based on meaning (rather than lexical features) is possible. In this paper, we
model the ontology matching task as classification problem and present
approaches based on transformer models. We further provide an easy to use
implementation in the MELT framework which is suited for ontology and knowledge
graph matching. We show that a transformer-based filter helps to choose the
correct correspondences given a high-recall alignment and already achieves a
good result with simple alignment post-processing methods.
","[{'version': 'v1', 'created': 'Wed, 15 Sep 2021 16:07:43 GMT'}]",2021-09-16,"[['Hertling', 'Sven', ''], ['Portisch', 'Jan', ''], ['Paulheim', 'Heiko', '']]"
2009.05045,Jaime Sevilla,"Jaime Sevilla, C. Jess Riedel",Forecasting timelines of quantum computing,,,,,quant-ph cs.ET,http://creativecommons.org/licenses/by/4.0/,"  We consider how to forecast progress in the domain of quantum computing. For
this purpose we collect a dataset of quantum computer systems to date, scored
on their physical qubits and gate error rate, and we define an index combining
both metrics, the generalized logical qubit. We study the relationship between
physical qubits and gate error rate, and tentatively conclude that they are
positively correlated (albeit with some room for doubt), indicating a frontier
of development that trades-off between them. We also apply a log-linear
regression on the metrics to provide a tentative upper bound on how much
progress can be expected over time. Within the (generally optimistic)
assumptions of our model, including the key assumption that exponential
progress in qubit count and gate fidelity will continue, we estimate that that
proof-of-concept fault-tolerant computation based on superconductor technology
is unlikely (<5% confidence) to be exhibited before 2026, and that quantum
devices capable of factoring RSA-2048 are unlikely (<5% confidence) to exist
before 2039. It is of course possible that these milestones will in fact be
reached earlier, but that this would require faster progress than has yet been
seen.
","[{'version': 'v1', 'created': 'Thu, 10 Sep 2020 12:56:45 GMT'}, {'version': 'v2', 'created': 'Wed, 9 Dec 2020 17:57:03 GMT'}]",2020-12-10,"[['Sevilla', 'Jaime', ''], ['Riedel', 'C. Jess', '']]"
2106.05836,Fuqiang Gu,"Fuqiang Gu, Weicong Sng, Xuke Hu, Fangwen Yu",EventDrop: data augmentation for event-based learning,IJCAI 2021,,,,cs.LG cs.RO,http://creativecommons.org/licenses/by/4.0/,"  The advantages of event-sensing over conventional sensors (e.g., higher
dynamic range, lower time latency, and lower power consumption) have spurred
research into machine learning for event data. Unsurprisingly, deep learning
has emerged as a competitive methodology for learning with event sensors; in
typical setups, discrete and asynchronous events are first converted into
frame-like tensors on which standard deep networks can be applied. However,
over-fitting remains a challenge, particularly since event datasets remain
small relative to conventional datasets (e.g., ImageNet). In this paper, we
introduce EventDrop, a new method for augmenting asynchronous event data to
improve the generalization of deep models. By dropping events selected with
various strategies, we are able to increase the diversity of training data
(e.g., to simulate various levels of occlusion). From a practical perspective,
EventDrop is simple to implement and computationally low-cost. Experiments on
two event datasets (N-Caltech101 and N-Cars) demonstrate that EventDrop can
significantly improve the generalization performance across a variety of deep
networks.
","[{'version': 'v1', 'created': 'Mon, 7 Jun 2021 11:53:14 GMT'}]",2021-06-11,"[['Gu', 'Fuqiang', ''], ['Sng', 'Weicong', ''], ['Hu', 'Xuke', ''], ['Yu', 'Fangwen', '']]"
2109.13445,Xavier Boix,"Avi Cooper, Xavier Boix, Daniel Harari, Spandan Madan, Hanspeter
  Pfister, Tomotake Sasaki, Pawan Sinha","To Which Out-Of-Distribution Object Orientations Are DNNs Capable of
  Generalizing?",,,,,cs.CV cs.AI cs.LG q-bio.NC stat.ML,http://creativecommons.org/licenses/by/4.0/,"  The capability of Deep Neural Networks (DNNs) to recognize objects in
orientations outside the distribution of the training data, ie.
out-of-distribution (OoD) orientations, is not well understood. For humans,
behavioral studies showed that recognition accuracy varies across OoD
orientations, where generalization is much better for some orientations than
for others. In contrast, for DNNs, it remains unknown how generalization
abilities are distributed among OoD orientations. In this paper, we investigate
the limitations of DNNs' generalization capacities by systematically inspecting
patterns of success and failure of DNNs across OoD orientations. We use an
intuitive and controlled, yet challenging learning paradigm, in which some
instances of an object category are seen at only a few geometrically restricted
orientations, while other instances are seen at all orientations. The effect of
data diversity is also investigated by increasing the number of instances seen
at all orientations in the training set. We present a comprehensive analysis of
DNNs' generalization abilities and limitations for representative architectures
(ResNet, Inception, DenseNet and CORnet). Our results reveal an intriguing
pattern -- DNNs are only capable of generalizing to instances of objects that
appear like 2D, ie. in-plane, rotations of in-distribution orientations.
","[{'version': 'v1', 'created': 'Tue, 28 Sep 2021 02:48:00 GMT'}]",2021-09-29,"[['Cooper', 'Avi', ''], ['Boix', 'Xavier', ''], ['Harari', 'Daniel', ''], ['Madan', 'Spandan', ''], ['Pfister', 'Hanspeter', ''], ['Sasaki', 'Tomotake', ''], ['Sinha', 'Pawan', '']]"
2101.10511,Mike Zheng Shou,"Mike Zheng Shou, Stan Weixian Lei, Weiyao Wang, Deepti Ghadiyaram,
  Matt Feiszli",Generic Event Boundary Detection: A Benchmark for Event Segmentation,ICCV 2021,,,,cs.CV,http://creativecommons.org/licenses/by/4.0/,"  This paper presents a novel task together with a new benchmark for detecting
generic, taxonomy-free event boundaries that segment a whole video into chunks.
Conventional work in temporal video segmentation and action detection focuses
on localizing pre-defined action categories and thus does not scale to generic
videos. Cognitive Science has known since last century that humans consistently
segment videos into meaningful temporal chunks. This segmentation happens
naturally, without pre-defined event categories and without being explicitly
asked to do so. Here, we repeat these cognitive experiments on mainstream CV
datasets; with our novel annotation guideline which addresses the complexities
of taxonomy-free event boundary annotation, we introduce the task of Generic
Event Boundary Detection (GEBD) and the new benchmark Kinetics-GEBD. Our
Kinetics-GEBD has the largest number of boundaries (e.g. 32 of ActivityNet, 8
of EPIC-Kitchens-100) which are in-the-wild, taxonomy-free, cover generic event
change, and respect human perception diversity. We view GEBD as an important
stepping stone towards understanding the video as a whole, and believe it has
been previously neglected due to a lack of proper task definition and
annotations. Through experiment and human study we demonstrate the value of the
annotations. Further, we benchmark supervised and un-supervised GEBD approaches
on the TAPOS dataset and our Kinetics-GEBD. We release our annotations and
baseline codes at CVPR'21 LOVEU Challenge:
https://sites.google.com/view/loveucvpr21.
","[{'version': 'v1', 'created': 'Tue, 26 Jan 2021 01:31:30 GMT'}, {'version': 'v2', 'created': 'Wed, 24 Mar 2021 21:24:13 GMT'}, {'version': 'v3', 'created': 'Fri, 26 Mar 2021 04:32:54 GMT'}, {'version': 'v4', 'created': 'Mon, 2 Aug 2021 04:10:26 GMT'}, {'version': 'v5', 'created': 'Thu, 19 Aug 2021 07:46:55 GMT'}]",2021-08-20,"[['Shou', 'Mike Zheng', ''], ['Lei', 'Stan Weixian', ''], ['Wang', 'Weiyao', ''], ['Ghadiyaram', 'Deepti', ''], ['Feiszli', 'Matt', '']]"
2107.07434,Mark S. Marley,"Mark S. Marley, Didier Saumon, Channon Visscher, Roxana Lupu, Richard
  Freedman, Caroline Morley, Jonathan J. Fortney, Christopher Seay, Adam J.R.W.
  Smith, D.J. Teal, Ruoyan Wang","The Sonora Brown Dwarf Atmosphere and Evolution Models I. Model
  Description and Application to Cloudless Atmospheres in Rainout Chemical
  Equilibrium","27 pages, 16 figures, accepted for Astrophysical Journal. Models
  available at https://doi.org/10.5281/zenodo.5063476",,10.3847/1538-4357/ac141d,,astro-ph.SR astro-ph.EP,http://creativecommons.org/licenses/by/4.0/,"  We present a new generation of substellar atmosphere and evolution models,
appropriate for application to studies of L, T, and Y-type brown dwarfs and
self-luminous extrasolar planets. The atmosphere models describe the expected
temperature-pressure profiles and emergent spectra of atmospheres in
radiative-convective equilibrium with effective temperatures and gravities
within the ranges $200\le T_{\rm eff}\le2400\,\rm K$ and $2.5\le \log g \le
5.5$. These ranges encompass masses from about 0.5 to 85 Jupiter masses for a
set of metallicities ($[{\rm M/H}] = -0.5$ to $+0.5$), C/O ratios (from 0.5 to
1.5 times that of solar), and ages. The evolution tables describe the cooling
of these substellar objects through time. These models expand the diversity of
model atmospheres currently available, notably to cooler effective temperatures
and greater ranges in C/O. Notable improvements from past such models include
updated opacities and atmospheric chemistry. Here we describe our modeling
approach and present our initial tranche of models for cloudless, chemical
equilibrium atmospheres. We compare the modeled spectra, photometry, and
evolution to various datasets.
","[{'version': 'v1', 'created': 'Thu, 15 Jul 2021 16:25:59 GMT'}]",2021-10-27,"[['Marley', 'Mark S.', ''], ['Saumon', 'Didier', ''], ['Visscher', 'Channon', ''], ['Lupu', 'Roxana', ''], ['Freedman', 'Richard', ''], ['Morley', 'Caroline', ''], ['Fortney', 'Jonathan J.', ''], ['Seay', 'Christopher', ''], ['Smith', 'Adam J. R. W.', ''], ['Teal', 'D. J.', ''], ['Wang', 'Ruoyan', '']]"
1707.02215,Stephen Burgess,"Stephen Burgess, Verena Zuber, Elsa Valdes-Marquez, Benjamin B Sun,
  Jemma C Hopewell","Mendelian randomization with fine-mapped genetic data: choosing from
  large numbers of correlated instrumental variables",,,,,stat.ME,http://creativecommons.org/licenses/by/4.0/,"  Mendelian randomization uses genetic variants to make causal inferences about
the effect of a risk factor on an outcome. With fine-mapped genetic data, there
may be hundreds of genetic variants in a single gene region any of which could
be used to assess this causal relationship. However, using too many genetic
variants in the analysis can lead to spurious estimates and inflated Type 1
error rates. But if only a few genetic variants are used, then the majority of
the data is ignored and estimates are highly sensitive to the particular choice
of variants. We propose an approach based on summarized data only (genetic
association and correlation estimates) that uses principal components analysis
to form instruments. This approach has desirable theoretical properties: it
takes the totality of data into account and does not suffer from numerical
instabilities. It also has good properties in simulation studies: it is not
particularly sensitive to varying the genetic variants included in the analysis
or the genetic correlation matrix, and it does not have greatly inflated Type 1
error rates. Overall, the method gives estimates that are not so precise as
those from variable selection approaches (such as using a conditional analysis
or pruning approach to select variants), but are more robust to seemingly
arbitrary choices in the variable selection step. Methods are illustrated by an
example using genetic associations with testosterone for 320 genetic variants
to assess the effect of sex hormone-related pathways on coronary artery disease
risk, in which variable selection approaches give inconsistent inferences.
","[{'version': 'v1', 'created': 'Fri, 7 Jul 2017 15:07:06 GMT'}]",2017-07-10,"[['Burgess', 'Stephen', ''], ['Zuber', 'Verena', ''], ['Valdes-Marquez', 'Elsa', ''], ['Sun', 'Benjamin B', ''], ['Hopewell', 'Jemma C', '']]"
2103.03986,Amirhossein Taghvaei,"Amirhossein Taghvaei, Olga Movilla Miangolarra, Rui Fu, Yongxin Chen,
  Tryphon T. Georgiou","On the relation between information and power in stochastic
  thermodynamic engines",,,,,cond-mat.stat-mech cs.SY eess.SY math.OC,http://creativecommons.org/licenses/by/4.0/,"  The common saying, that information is power, takes a rigorous form in
stochastic thermodynamics, where a quantitative equivalence between the two
helps explain the paradox of Maxwell's demon in its ability to reduce entropy.
In the present paper, we build on earlier work on the interplay between the
relative cost and benefits of information in producing work in cyclic operation
of thermodynamic engines (by Sandberg etal. 2014). Specifically, we study the
general case of overdamped particles in a time-varying potential (control
action) in feedback that utilizes continuous measurements (nonlinear filtering)
of a thermodynamic ensemble, to produce suitable adaptations of the second law
of thermodynamics that involve information.
","[{'version': 'v1', 'created': 'Fri, 5 Mar 2021 23:56:13 GMT'}]",2021-03-09,"[['Taghvaei', 'Amirhossein', ''], ['Miangolarra', 'Olga Movilla', ''], ['Fu', 'Rui', ''], ['Chen', 'Yongxin', ''], ['Georgiou', 'Tryphon T.', '']]"
2102.03255,Luca Giovannelli,"Daniele Galuzzo, Chiara Cagnazzo, Francesco Berrilli, Federico Fierli,
  and Luca Giovannelli",3-D climate simulations for the detectability of Proxima Centauri b,"21 pages, 11 figures, accepted in the Astrophysical Journal",,10.3847/1538-4357/abdeb4,,astro-ph.EP,http://creativecommons.org/licenses/by/4.0/,"  The discovery of a planet orbiting around Proxima Centauri, the closest star
to the Sun, opens new avenues for the remote observations of the atmosphere and
surface of an exoplanet, Proxima b. To date, three-dimensional (3D) General
Circulation Models (GCMs) are the best available tools to investigate the
properties of the exo-atmospheres, waiting for the next generation of space and
groundbased telescopes. In this work, we use the PlanetSimulator (PlaSim), an
intermediate complexity 3D GCM, a flexible and fast model, suited to handle all
the orbital and physical parameters of a planet and to study the dynamics of
its atmosphere. Assuming an Earth-like atmosphere and a 1:1 spin/orbit
configuration (tidal locking), our simulations of Proxima b are consistent with
a day-side open ocean planet with a superrotating atmosphere. Moreover, because
of the limited representation of the radiative transfer in PlaSim, we compute
the spectrum of the exoplanet with an offline Radiative Transfer Code with a
spectral resolution of 1 nm. This spectrum is used to derive the thermal phase
curves for different orbital inclination angles. In combination with
instrumental detection sensitivities, the different thermal phase curves are
used to evaluate observation conditions at ground level (e.g., ELT) or in space
(e.g., JWST). We estimated the exposure time to detect Proxima b (assuming an
Earth-like atmosphere) thermal phase curve in the FIR with JWST with
signal-to-noise ratio $\simeq$1. Under the hypothesis of total noise dominated
by shot noise, neglecting other possible extra contribution producing a noise
floor, the exposure time is equal to 5 hours for each orbital epoch.
","[{'version': 'v1', 'created': 'Fri, 5 Feb 2021 16:00:39 GMT'}]",2021-03-24,"[['Galuzzo', 'Daniele', ''], ['Cagnazzo', 'Chiara', ''], ['Berrilli', 'Francesco', ''], ['Fierli', 'Federico', ''], ['Giovannelli', 'Luca', '']]"
2108.02881,Peter Rau B,Peter B. Rau and Armen Sedrakian,"Unstable modes of hypermassive compact stars driven by viscosity and
  gravitational radiation","16 pages, 11 figures. Submitted to MNRAS","Monthly Notices of the Royal Astronomical Society, Volume 509,
  2022, p. 1854-1870",10.1093/mnras/stab3012,,gr-qc astro-ph.HE,http://creativecommons.org/licenses/by/4.0/,"  We study the oscillations modes of differential rotating remnants of binary
neutron star inspirals by modeling them as incompressible Riemann ellipsoids
parametrized by the ratio $f$ of their internal circulation to the rotation
frequency. The effects of viscosity and gravitational wave radiation on the
modes are studied and it is shown that these bodies exhibit generic
instabilities towards gravitational wave radiation akin to the
Chandrasekhar--Friedman--Schutz instabilities for uniformly rotating stars. The
odd-parity modes are unstable for all values of $f$ (except for the spherical
model) and deformations, whereas the even parity unstable modes appear only in
highly eccentric ellipsoids. We quantify the modification of the modes with
varying mass of the model and the magnitude of the viscosity. The modes are
weakly dependent on the range of the masses relevant to the binary neutron star
mergers. Large turbulent viscosity can lead to a suppression of the
gravitational wave instabilities, whereas kinematical viscosity has a
negligible influence on the modes and their damping timescales.
","[{'version': 'v1', 'created': 'Thu, 5 Aug 2021 22:56:42 GMT'}, {'version': 'v2', 'created': 'Wed, 15 Dec 2021 22:32:35 GMT'}]",2021-12-20,"[['Rau', 'Peter B.', ''], ['Sedrakian', 'Armen', '']]"
1811.10758,Mat\'ias Pavez,"Mat\'ias Pavez, Javier Ruiz del Solar, Victoria Amo, Felix Meyer zu
  Driehausen","Towards Long-Term Memory for Social Robots: Proposing a New Challenge
  for the RoboCup@Home League","11 pages, 1 figure, robocup 2018 symposium",,,,cs.RO cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Long-term memory is essential to feel like a continuous being, and to be able
to interact/communicate coherently. Social robots need long-term memories in
order to establish long-term relationships with humans and other robots, and do
not act just for the moment. In this paper this challenge is highlighted, open
questions are identified, the need of addressing this challenge in the
RoboCup@Home League with new tests is motivated, and a new test is proposed.
","[{'version': 'v1', 'created': 'Tue, 27 Nov 2018 00:45:31 GMT'}]",2018-11-28,"[['Pavez', 'Matías', ''], ['del Solar', 'Javier Ruiz', ''], ['Amo', 'Victoria', ''], ['Driehausen', 'Felix Meyer zu', '']]"
2102.03190,Yuri Lyubarsky,"Roy Perry, Yuri Lyubarsky","The role of resonant plasma instabilities in the evolution of blazar
  induced pair beams",To be published in MNRAS,,10.1093/mnras/stab324,,astro-ph.HE,http://creativecommons.org/licenses/by/4.0/,"  The fate of relativistic pair beams produced in the intergalactic medium by
very high energy emission from blazars remains controversial in the literature.
The possible role of resonance beam plasma instability has been studied both
analytically and numerically but no consensus has been reached. In this paper,
we thoroughly analyze the development of this type of instability. This
analysis takes into account that a highly relativistic beam loses energy only
due to interactions with the plasma waves propagating within the opening angle
of the beam (we call them parallel waves), whereas excitation of oblique waves
results merely in an angular spreading of the beam, which reduces the
instability growth rate. For parallel waves, the growth rate is a few times
larger than for oblique ones, so they grow faster than oblique waves and drain
energy from the beam before it expands. However, the specific property of
extragalactic beams is that they are extraordinarily narrow; the opening angle
is only $\Delta\theta\sim 10^{-6}-10^{-5}$. In this case, the width of the
resonance for parallel waves, $\propto\Delta\theta^2$, is too small for them to
grow in realistic conditions. We perform both analytical estimates and
numerical simulations in the quasilinear regime. These show that for
extragalactic beams, the growth of the waves is incapable of taking a
significant portion of the beam's energy. This type of instability could at
best lead to an expansion of the beam by some factor but the beam's energy
remains nearly intact.
","[{'version': 'v1', 'created': 'Fri, 5 Feb 2021 14:22:48 GMT'}]",2021-02-17,"[['Perry', 'Roy', ''], ['Lyubarsky', 'Yuri', '']]"
2201.04625,Niema Moshiri,Niema Moshiri,"NiemaGraphGen: A memory-efficient global-scale contact network
  simulation toolkit","9 pages, 1 figure. Contact: niema@ucsd.edu",,,,physics.soc-ph,http://creativecommons.org/licenses/by/4.0/,"  Epidemic simulations require the ability to sample contact networks from
various random graph models. Existing methods can simulate city-scale or even
country-scale contact networks, but they are unable to feasibly simulate
global-scale contact networks due to high memory consumption. NiemaGraphGen
(NGG) is a memory-efficient graph generation tool that enables the simulation
of global-scale contact networks. NGG avoids storing the entire graph in memory
and is instead intended to be used in a data streaming pipeline, resulting in
memory consumption that is orders of magnitude smaller than existing tools. NGG
provides a massively-scalable solution for simulating social contact networks,
enabling global-scale epidemic simulation studies.
","[{'version': 'v1', 'created': 'Thu, 13 Jan 2022 17:13:49 GMT'}]",2022-01-14,"[['Moshiri', 'Niema', '']]"
1910.10599,Themos Stafylakis,"Elisavet Palogiannidi, Ioannis Gkinis, George Mastrapas, Petr Mizera,
  Themos Stafylakis",End-to-end architectures for ASR-free spoken language understanding,Accepted at ICASSP-2020,,,,eess.AS,http://creativecommons.org/licenses/by/4.0/,"  Spoken Language Understanding (SLU) is the problem of extracting the meaning
from speech utterances. It is typically addressed as a two-step problem, where
an Automatic Speech Recognition (ASR) model is employed to convert speech into
text, followed by a Natural Language Understanding (NLU) model to extract
meaning from the decoded text. Recently, end-to-end approaches were emerged,
aiming at unifying the ASR and NLU into a single SLU deep neural architecture,
trained using combinations of ASR and NLU-level recognition units. In this
paper, we explore a set of recurrent architectures for intent classification,
tailored to the recently introduced Fluent Speech Commands (FSC) dataset, where
intents are formed as combinations of three slots (action, object, and
location). We show that by combining deep recurrent architectures with standard
data augmentation, state-of-the-art results can be attained, without using
ASR-level targets or pretrained ASR models. We also investigate its
generalizability to new wordings, and we show that the model can perform
reasonably well on wordings unseen during training.
","[{'version': 'v1', 'created': 'Wed, 23 Oct 2019 15:05:09 GMT'}, {'version': 'v2', 'created': 'Sat, 15 Feb 2020 09:51:39 GMT'}, {'version': 'v3', 'created': 'Fri, 1 May 2020 07:31:53 GMT'}]",2020-05-04,"[['Palogiannidi', 'Elisavet', ''], ['Gkinis', 'Ioannis', ''], ['Mastrapas', 'George', ''], ['Mizera', 'Petr', ''], ['Stafylakis', 'Themos', '']]"
2102.12865,Xuelei Chen,"Yidong Xu, Bin Yue, Xuelei Chen","Maximum Absorption of the Global 21 cm Spectrum in the Standard
  Cosmological Model","15 pages, 11 figures, ApJ accepted","Astrophysical Journal, 923, 98 (2021)",,,astro-ph.CO,http://creativecommons.org/licenses/by/4.0/,"  The absorption feature in the global spectrum is likely the first 21 cm
observable from the cosmic dawn, which provides valuable insights into the
earliest history of structure formation. We run a set of high-resolution
hydrodynamic simulations of early structure formation to assess the effect of
non-linear structure formation on the maximum absorption level (i.e. assuming
the spin temperature coupling is saturated) of the global 21 cm spectrum in the
standard cosmological framework. We ignore the star formation and feedbacks,
which also tends to reduce the absorption signal, but take into account the
inevitable non-linear density fluctuations in the intergalactic medium (IGM),
shock heating, and Compton heating, which can reduce the absorption level. We
found that the combination of these reduced the maximum absorption signal by
$\sim 15\%$ at redshift 17, as compared with the homogeneous or linearly
fluctuating IGM. These effects have to be carefully accounted for when
interpreting the observational results, especially when considering the
necessity of introducing new physics.
","[{'version': 'v1', 'created': 'Thu, 25 Feb 2021 14:04:46 GMT'}, {'version': 'v2', 'created': 'Mon, 18 Oct 2021 15:47:27 GMT'}]",2021-12-23,"[['Xu', 'Yidong', ''], ['Yue', 'Bin', ''], ['Chen', 'Xuelei', '']]"
2109.07591,Dan Iter,Dan Iter and David Grangier,"On the Complementarity of Data Selection and Fine Tuning for Domain
  Adaptation",,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Domain adaptation of neural networks commonly relies on three training
phases: pretraining, selected data training and then fine tuning. Data
selection improves target domain generalization by training further on
pretraining data identified by relying on a small sample of target domain data.
This work examines the benefit of data selection for language modeling and
machine translation. Our experiments assess the complementarity of selection
with fine tuning and result in practical recommendations: (i) selected data
must be similar to the fine-tuning domain but not so much as to erode the
complementary effect of fine-tuning; (ii) there is a trade-off between
selecting little data for fast but limited progress or much data for slow but
long lasting progress; (iii) data selection can be applied early during
pretraining, with performance gains comparable to long pretraining session;
(iv) data selection from domain classifiers is often more effective than the
popular contrastive data selection method.
","[{'version': 'v1', 'created': 'Wed, 15 Sep 2021 21:49:06 GMT'}]",2021-09-17,"[['Iter', 'Dan', ''], ['Grangier', 'David', '']]"
2103.03421,Zhaohui Wu,"Zhaohui Wu, Xiaoming Zeng, Zhaoli Li, Zhimeng Zhang, Xiaodong Wang,
  Bilong Hu, Xiao Wang, Jie Mu, Jingqin Su, Xiaofeng Wei, and Yanlei Zuo",Laser Compression via fast-extending plasma gratings,,,,,physics.plasm-ph,http://creativecommons.org/licenses/by/4.0/,"  It is proposed a new method of compressing laser pulse by fast extending
plasma gratings(FEPG), which is created by ionizing the hypersound wave
generated by stimulated Brillouin scattering(SBS) in the background gas.
Ionized by a short laser pulse, the phonon forms a light-velocity FEPG to fully
reflect a resonant pump laser. As the reflecting surface moves with a light
velocity, the reflected pulse is temporally overlapped and compressed. This
regime is supported by the simulation results of a fully kinetic
particle-in-cell(PIC) code Opic with a laser wavelength of 1um, displaying a
pump pulse is compressed from 13ps to a few cycles(7.2fs), with an efficiency
close to 80%. It is a promising method to produce critical laser powers due to
several features: high efficiency without a linear stage, robustness to plasma
instabilities, no seed and a wide range of pump intensity.
","[{'version': 'v1', 'created': 'Fri, 5 Mar 2021 01:52:20 GMT'}, {'version': 'v2', 'created': 'Mon, 8 Mar 2021 09:10:55 GMT'}]",2021-03-09,"[['Wu', 'Zhaohui', ''], ['Zeng', 'Xiaoming', ''], ['Li', 'Zhaoli', ''], ['Zhang', 'Zhimeng', ''], ['Wang', 'Xiaodong', ''], ['Hu', 'Bilong', ''], ['Wang', 'Xiao', ''], ['Mu', 'Jie', ''], ['Su', 'Jingqin', ''], ['Wei', 'Xiaofeng', ''], ['Zuo', 'Yanlei', '']]"
2102.04227,Victor Von Wachter,"Victor von Wachter, Johannes Rude Jensen, Omri Ross",Measuring Asset Composability as a Proxy for DeFi Integration,"Blockchain, DeFi, Asset Composability, Ethereum","International Conference on Financial Cryptography and Data
  Security (2021)",10.1007/978-3-662-63958-0,,cs.CY,http://creativecommons.org/licenses/by/4.0/,"  Decentralized financial (DeFi) applications on the Ethereum blockchain are
highly interoperable because they share a single state in a deterministic
computational environment. Stakeholders can deposit claims on assets, referred
to as 'liquidity shares', across applications producing effects equivalent to
rehypothecation in traditional financial systems. We seek to understand the
degree to which this practice may contribute to financial integration on
Ethereum by examining transactions in 'composed' derivatives for the assets
DAI, USDC, USDT, ETH and tokenized BTC for the full set of 344.8 million
Ethereum transactions computed in 2020. We identify a salient trend for
'composing' assets in multiple sequential generations of derivatives and
comment on potential systemic implications for the Ethereum network.
","[{'version': 'v1', 'created': 'Tue, 2 Feb 2021 09:57:33 GMT'}, {'version': 'v2', 'created': 'Mon, 29 Mar 2021 16:47:15 GMT'}]",2021-11-30,"[['von Wachter', 'Victor', ''], ['Jensen', 'Johannes Rude', ''], ['Ross', 'Omri', '']]"
2106.01293,Katepalli Sreenivasan,K.R. Sreenivasan and V. Yakhot,Dynamics of three-dimensional turbulence from Navier-Stokes equations,four figures,,,,physics.flu-dyn cond-mat.stat-mech hep-th,http://creativecommons.org/licenses/by/4.0/,"  We accomplish two major tasks. First, we show that the turbulent motion at
large scales obeys Gaussian statistics in the interval 0 < Rlambda < 8.8, where
Rlambda is the microscale Reynolds number, and that the Gaussian flow breaks
down to yield place to anomalous scaling at the universal Reynolds number
bounding the inequality above. In the inertial range of turbulence that emerges
following the breakdown, the effective Reynolds number based on the turbulent
viscosity, Rlambda* assumes this same constant value of about 9. This scenario
works also for the emergence of turbulence from an initially non-turbulent
state. Second, we derive expressions for the anomalous scaling exponents of
structure functions and moments of spatial derivatives, by analyzing the
Navier-Stokes equations in the form developed by Hopf. We present a novel
procedure to close the Hopf equation, resulting in expressions for zetan in the
entire range of allowable moment-order, n, and demonstrate that accounting for
the temporal dynamics changes the scaling from normal to anomalous. For large
n, the theory predicts the saturation of zetan with n, leading to two
inferences: (a) the smallest length scale etan = LRe-1 << LRe-3/4, where Re is
the large-scale Reynolds number, and (b) velocity excursions across even the
smallest length scales can sometimes be as large as the large scale velocity
itself. Theoretical predictions for each of these aspects are shown to be in
quantitative agreement with available experimental and numerical data.
","[{'version': 'v1', 'created': 'Wed, 2 Jun 2021 16:58:05 GMT'}]",2021-06-23,"[['Sreenivasan', 'K. R.', ''], ['Yakhot', 'V.', '']]"
2202.12083,Armen Sedrakian,"Armen Sedrakian, Arus Harutyunyan",Delta-resonances and hyperons in proto-neutron stars and merger remnants,"12 pages, 7 figures, contribution to the EPJ A topical issue
  ""CompOSE: a repository for Neutron Star Equations of State and Transport
  Properties""",,,,nucl-th astro-ph.HE astro-ph.SR,http://creativecommons.org/licenses/by/4.0/,"  The equation of state (EoS) and composition of dense and hot
$\Delta$-resonance admixed hypernuclear matter is studied under conditions that
are characteristic of neutron star binary merger remnants and supernovas. The
cold, neutrino free regime is also considered as a reference for the
astrophysical constraints on the EoS of dense matter. Our formalism uses the
covariant density functional (CDF) theory successfully adapted to include the
full $J^P=1/2^+$ baryon octet and non-strange members of $J^P=3/2^+$ decouplet
with density-dependent couplings that have been suitably adjusted to the
existing laboratory and astrophysical data in the nuclear and hypernuclear
sectors. The effect of $\Delta$-resonances at finite temperatures is to soften
the EoS of hypernuclear matter at intermediate densities and stiffen it at high
densities. At low temperatures, the heavy baryons $\Lambda$,
$\Delta^-$,$\Xi^-$, $\Xi^0$ and $\Delta^0$ appear in the given order if the
$\Delta$-meson couplings are close to those for the nucleon-meson couplings. As
is the case for hyperons, the thresholds of $\Delta$-resonances move to lower
densities with the increase of temperature indicating a significant fraction of
$\Delta$s in the low-density subnuclear regime. We find that the
$\Delta$-resonances comprise a significant fraction of baryonic matter, of the
order of $10\%$ at temperatures of the order of several tens of MeV in the
neutrino-trapped regime and, thus, may affect the supernova and binary neutron
star dynamics.
","[{'version': 'v1', 'created': 'Thu, 24 Feb 2022 13:08:01 GMT'}]",2022-02-25,"[['Sedrakian', 'Armen', ''], ['Harutyunyan', 'Arus', '']]"
2011.15067,Marlene Berke,"Marlene Berke, Mario Belledonne, and Julian Jara-Ettinger",Learning a metacognition for object perception,SVRHM workshop at NeurIPS,,,,cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Beyond representing the external world, humans also represent their own
cognitive processes. In the context of perception, this metacognition helps us
identify unreliable percepts, such as when we recognize that we are seeing an
illusion. Here we propose MetaGen, a model for the unsupervised learning of
metacognition. In MetaGen, metacognition is expressed as a generative model of
how a perceptual system produces noisy percepts. Using basic principles of how
the world works (such as object permanence, part of infants' core knowledge),
MetaGen jointly infers the objects in the world causing the percepts and a
representation of its own perceptual system. MetaGen can then use this
metacognition to infer which objects are actually present in the world. On
simulated data, we find that MetaGen quickly learns a metacognition and
improves overall accuracy, outperforming models that lack a metacognition.
","[{'version': 'v1', 'created': 'Mon, 30 Nov 2020 18:05:00 GMT'}]",2020-12-01,"[['Berke', 'Marlene', ''], ['Belledonne', 'Mario', ''], ['Jara-Ettinger', 'Julian', '']]"
2102.13411,Lei Wang,"Lei Wang, Christopher M. Kellett","Robust I&I Adaptive Tracking Control of Systems with Nonlinear
  Parameterization: An ISS Perspective","15 pages, 3 figures",,,,math.OC cs.SY eess.SY,http://creativecommons.org/licenses/by/4.0/,"  This paper studies the immersion and invariance (I&I) adaptive tracking
problem for a class of nonlinear systems with nonlinear parameterization in the
ISS framework. Under some mild assumptions, a novel I&I adaptive control
algorithm is proposed,leading to an interconnection of an ISS estimation error
subsystem and an ISS tracking error subsystem. Using an ISS small-gain
condition, the desired uniform global asymptotic stability of the resulting
interconnected ""error"" system can be achieved and a sum-type strict Lyapunov
function can be explicitly constructed. Taking advantage of this ISS-based
design framework,it is shown that the corresponding robustness with respect to
the input perturbation can be rendered to be ISS. To remove the need to solve
the immersion manifold shaping PDE, a new filter-based approach is proposed,
which preserves the ISS-based design framework. Finally, we demonstrate the
validness of the proposed framework on a tracking problem for series elastic
actuators.
","[{'version': 'v1', 'created': 'Fri, 26 Feb 2021 11:41:20 GMT'}]",2021-03-01,"[['Wang', 'Lei', ''], ['Kellett', 'Christopher M.', '']]"
2201.11657,Sourya Dey,"Sourya Dey, Walt Woods",LAGOON: An Analysis Tool for Open Source Communities,"Submitted to the 2022 IEEE/ACM 19th International Conference on
  Mining Software Repositories (MSR)",,,,cs.SI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  This paper presents LAGOON -- an open source platform for understanding the
complex ecosystems of Open Source Software (OSS) communities. The platform
currently utilizes spatiotemporal graphs to store and investigate the artifacts
produced by these communities, and help analysts identify bad actors who might
compromise an OSS project's security. LAGOON provides ingest of artifacts from
several common sources, including source code repositories, issue trackers,
mailing lists and scraping content from project websites. Ingestion utilizes a
modular architecture, which supports incremental updates from data sources and
provides a generic identity fusion process that can recognize the same
community members across disparate accounts. A user interface is provided for
visualization and exploration of an OSS project's complete sociotechnical
graph. Scripts are provided for applying machine learning to identify patterns
within the data. While current focus is on the identification of bad actors in
the Python community, the platform's reusability makes it easily extensible
with new data and analyses, paving the way for LAGOON to become a comprehensive
means of assessing various OSS-based projects and their communities.
","[{'version': 'v1', 'created': 'Wed, 26 Jan 2022 18:52:11 GMT'}]",2022-01-28,"[['Dey', 'Sourya', ''], ['Woods', 'Walt', '']]"
2110.09610,Tushar Sharma,"Tushar Sharma, Maria Kechagia, Stefanos Georgiou, Rohit Tiwari,
  Federica Sarro",A Survey on Machine Learning Techniques for Source Code Analysis,,,,,cs.SE cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Context: The advancements in machine learning techniques have encouraged
researchers to apply these techniques to a myriad of software engineering tasks
that use source code analysis such as testing and vulnerabilities detection. A
large number of studies poses challenges to the community to understand the
current landscape. Objective: We aim to summarize the current knowledge in the
area of applied machine learning for source code analysis. Method: We
investigate studies belonging to twelve categories of software engineering
tasks and corresponding machine learning techniques, tools, and datasets that
have been applied to solve them. To do so, we carried out an extensive
literature search and identified 364 primary studies published between 2002 and
2021. We summarize our observations and findings with the help of the
identified studies. Results: Our findings suggest that the usage of machine
learning techniques for source code analysis tasks is consistently increasing.
We synthesize commonly used steps and the overall workflow for each task, and
summarize the employed machine learning techniques. Additionally, we collate a
comprehensive list of available datasets and tools useable in this context.
Finally, we summarize the perceived challenges in this area that include
availability of standard datasets, reproducibility and replicability, and
hardware resources.
","[{'version': 'v1', 'created': 'Mon, 18 Oct 2021 20:13:38 GMT'}]",2021-10-20,"[['Sharma', 'Tushar', ''], ['Kechagia', 'Maria', ''], ['Georgiou', 'Stefanos', ''], ['Tiwari', 'Rohit', ''], ['Sarro', 'Federica', '']]"
2105.03687,Yangjie Mei,"Yangjie Mei, Hao Wang","Covariance Matrix Adaptation Evolution Strategy Assisted by Principal
  Component Analysis","13 pages, 4 figures",,,,cs.NE,http://creativecommons.org/licenses/by/4.0/,"  Over the past decades, more and more methods gain a giant development due to
the development of technology. Evolutionary Algorithms are widely used as a
heuristic method. However, the budget of computation increases exponentially
when the dimensions increase. In this paper, we will use the dimensionality
reduction method Principal component analysis (PCA) to reduce the dimension
during the iteration of Covariance Matrix Adaptation Evolution Strategy
(CMA-ES), which is a good Evolutionary Algorithm that is presented as the
numeric type and useful for different kinds of problems. We assess the
performance of our new methods in terms of convergence rate on multi-modal
problems from the Black-Box Optimization Benchmarking (BBOB) problem set and we
also use the framework COmparing Continuous Optimizers (COCO) to see how the
new method going and compare it to the other algorithms.
","[{'version': 'v1', 'created': 'Sat, 8 May 2021 12:43:38 GMT'}, {'version': 'v2', 'created': 'Tue, 11 May 2021 11:13:49 GMT'}]",2021-05-12,"[['Mei', 'Yangjie', ''], ['Wang', 'Hao', '']]"
2107.02300,Oliver Friedrich,"Oliver Friedrich, Anik Halder, Aoife Boyle, Cora Uhlemann, Dylan
  Britt, Sandrine Codis, Daniel Gruen, ChangHoon Hahn","The PDF perspective on the tracer-matter connection: Lagrangian bias and
  non-Poissonian shot noise","20 pages, submitted to MNRAS, numerical tools available at
  https://github.com/OliverFHD/CosMomentum",,10.1093/mnras/stab3703,,astro-ph.CO,http://creativecommons.org/licenses/by/4.0/,"  We study the connection of matter density and its tracers from the PDF
perspective. One aspect of this connection is the conditional expectation value
$\langle \delta_{\mathrm{tracer}}|\delta_m\rangle$ when averaging both tracer
and matter density over some scale. We present a new way to incorporate a
Lagrangian bias expansion of this expectation value into standard frameworks
for modelling the PDF of density fluctuations and counts-in-cells statistics.
Using N-body simulations and mock galaxy catalogs we confirm the accuracy of
this expansion and compare it to the more commonly used Eulerian
parametrization. For halos hosting typical luminous red galaxies, the
Lagrangian model provides a significantly better description of $\langle
\delta_{\mathrm{tracer}}|\delta_m\rangle$ at second order in perturbations. A
second aspect of the matter-tracer connection is shot-noise, \ie the scatter of
tracer density around $\langle \delta_{\mathrm{tracer}}|\delta_m\rangle$. It is
well known that this noise can be significantly non-Poissonian and we validate
the performance of a more general, two-parameter shot-noise model for different
tracers and simulations. Both parts of our analysis are meant to pave the way
for forthcoming applications to survey data.
","[{'version': 'v1', 'created': 'Mon, 5 Jul 2021 22:21:35 GMT'}, {'version': 'v2', 'created': 'Fri, 30 Jul 2021 15:37:57 GMT'}]",2022-01-19,"[['Friedrich', 'Oliver', ''], ['Halder', 'Anik', ''], ['Boyle', 'Aoife', ''], ['Uhlemann', 'Cora', ''], ['Britt', 'Dylan', ''], ['Codis', 'Sandrine', ''], ['Gruen', 'Daniel', ''], ['Hahn', 'ChangHoon', '']]"
2009.06864,Thomas Junk,Thomas R. Junk and Louis Lyons,Reproducibility and Replication of Experimental Particle Physics Results,"50 pages, 6 figures. Please see
  https://hdsr.mitpress.mit.edu/pub/32yz0u49/release/1 for a thoughtful comment
  by Andrew Fowlie, and https://hdsr.mitpress.mit.edu/pub/57tywz64/release/1
  for the authors' response","Harvard Data Science Review 2(4), Fall 2020",10.1162/99608f92.250f995b,FERMILAB-PUB-20-649-ND,physics.data-an astro-ph.IM,http://creativecommons.org/licenses/by/4.0/,"  Recently, much attention has been focused on the replicability of scientific
results, causing scientists, statisticians, and journal editors to examine
closely their methodologies and publishing criteria. Experimental particle
physicists have been aware of the precursors of non-replicable research for
many decades and have many safeguards to ensure that the published results are
as reliable as possible. The experiments require large investments of time and
effort to design, construct, and operate. Large collaborations produce and
check the results, and many papers are signed by more than three thousand
authors. This paper gives an introduction to what experimental particle physics
is and to some of the tools that are used to analyze the data. It describes the
procedures used to ensure that results can be computationally reproduced, both
by collaborators and by non-collaborators. It describes the status of publicly
available data sets and analysis tools that aid in reproduction and recasting
of experimental results. It also describes methods particle physicists use to
maximize the reliability of the results, which increases the probability that
they can be replicated by other collaborations or even the same collaborations
with more data and new personnel. Examples of results that were later found to
be false are given, both with failed replication attempts and one with
alarmingly successful replications. While some of the characteristics of
particle physics experiments are unique, many of the procedures and techniques
can be and are used in other fields.
","[{'version': 'v1', 'created': 'Tue, 15 Sep 2020 04:43:47 GMT'}, {'version': 'v2', 'created': 'Sun, 6 Dec 2020 03:59:39 GMT'}, {'version': 'v3', 'created': 'Fri, 8 Jan 2021 22:37:04 GMT'}, {'version': 'v4', 'created': 'Wed, 5 May 2021 21:52:51 GMT'}]",2021-05-07,"[['Junk', 'Thomas R.', ''], ['Lyons', 'Louis', '']]"
2004.00880,Werner Friedl,Werner Friedl and Maximo A. Roa,"CLASH WRIST -- A hardware to increase the capability of CLASH fruit
  gripper to use environment constraints exploration","IROS 2019, Factory of the Future",,,,cs.RO,http://creativecommons.org/licenses/by/4.0/,"  Humans use environmental constraints (EC) in manipulation to compensate for
uncertainties in their world model. The same principle was recently applied to
robotics, so that soft underactuated hands improve their grasping capability by
using environmental constraints exploitation (ECE) [1]. Due to orientation of
the robotic hand for example in the EC wall grasp, the length of the robot
wrist plus the hand length gets quite important, if objects are grasp out of a
box [2] . Most of the modern cobots have quite long wrist, so we have
constructed a two degree of freedom wrist for the CLASH [3], to solve this
problem (Fig. 1).
","[{'version': 'v1', 'created': 'Thu, 2 Apr 2020 08:57:34 GMT'}]",2020-04-03,"[['Friedl', 'Werner', ''], ['Roa', 'Maximo A.', '']]"
2203.02023,Robin Bowers,"Robin Bowers, Bo Waggoner",High Welfare Matching Markets via Descending Price,,,,,cs.GT,http://creativecommons.org/licenses/by/4.0/,"  We consider design of monetary mechanisms for two-sided matching. Mechanisms
in the tradition of the deferred acceptance algorithm, even in variants
incorporating money, tend to focus on the criterion of stability. Instead, in
this work we seek a simple auction-inspired mechanism with social welfare
guarantees. We consider a descending-price mechanism called the Marshallian
Match, proposed (but not analyzed) by Waggoner and Weyl (2019). We show the
Marshallian Match has constant price of anarchy when all values for potential
matches are positive. This result extends to models with costs for acquiring
information about one's values, and also to matching on hypergraphs. With
possibly-negative valuations, which capture e.g. job markets, the problem
becomes harder. We introduce notions of approximate stability and show that
they have beneficial welfare implications. However, the main problem of proving
constant factor welfare guarantees in ""ex ante stable equilibrium"" remains
open.
","[{'version': 'v1', 'created': 'Thu, 3 Mar 2022 21:17:13 GMT'}]",2022-03-07,"[['Bowers', 'Robin', ''], ['Waggoner', 'Bo', '']]"
1905.05959,Partha Mondal,Partha Mondal and Shailendra K. Varshney,"Modal Group Velocity Mismatch Induced Intermodal Modulation Instability
  in Step-index Fiber",,,10.1088/2040-8986/ab5616,,physics.optics,http://creativecommons.org/licenses/by/4.0/,"  We present detailed experimental study on noise-seeded intermodal modulation
instability (IM-MI) in normal dispersion region of a conventional step-index
fiber. The sharp refractive index contrast between core and cladding leads to
large group velocity mismatch between the spatial modes, coaxing to efficient
IM-MI and generation of multiple spectral peaks along with Raman peaks.
Evolution of the spectrum with pump powers and fiber lengths are observed.
Experimental findings are well supported with the theoretical framework based
on bimodal-MI model considering the distinct dispersion parameters of the
participating modes.
","[{'version': 'v1', 'created': 'Wed, 15 May 2019 06:13:01 GMT'}]",2020-01-08,"[['Mondal', 'Partha', ''], ['Varshney', 'Shailendra K.', '']]"
2102.10308,Abhik Ghosh PhD,"Abhik Ghosh, Olivia Mallick, Souvik Chattopadhay, Banasri Basu","Strata-based Quantification of Distributional Uncertainty in
  Socio-Economic Indicators: A Comparative Study of Indian States",Pre-print; Under review,,,,stat.AP physics.soc-ph,http://creativecommons.org/licenses/by/4.0/,"  This paper reports a comprehensive study of distributional uncertainty in a
few socio-economic indicators across the various states of India over the years
2001-2011. We show that the DGB distribution, a typical rank order
distribution, provide excellent fits to the district-wise empirical data for
the population size, literacy rate (LR) and work participation rate (WPR)
within every states in India, through its two distributional parameters.
Moreover, taking resort to the entropy formulation of the DGB distribution, a
proposed uncertainty percentage (UP) unveils the dynamics of the uncertainty of
LR and WPR in all states of India. We have also commented on the changes in the
estimated parameters and the UP values from the years 2001 to 2011.
Additionally, a gender based analysis of the distribution of these important
socio-economic variables within different states of India has also been
discussed. Interestingly, it has been observed that, although the distributions
of the numbers of literate and working people has a direct (linear)
correspondence with that of the population size, the literacy and
work-participation rates are distributed independently of the population
distributions.
","[{'version': 'v1', 'created': 'Sat, 20 Feb 2021 10:20:24 GMT'}]",2021-02-23,"[['Ghosh', 'Abhik', ''], ['Mallick', 'Olivia', ''], ['Chattopadhay', 'Souvik', ''], ['Basu', 'Banasri', '']]"
2105.00674,Heiko Paulheim,Michael Matthias Voit and Heiko Paulheim,"Bias in Knowledge Graphs -- an Empirical Study with Movie Recommendation
  and Different Language Editions of DBpedia","Accepted for publication at 3rd Conference on Language, Data and
  Knowledge (LDK 2021)",,,,cs.IR cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Public knowledge graphs such as DBpedia and Wikidata have been recognized as
interesting sources of background knowledge to build content-based recommender
systems. They can be used to add information about the items to be recommended
and links between those. While quite a few approaches for exploiting knowledge
graphs have been proposed, most of them aim at optimizing the recommendation
strategy while using a fixed knowledge graph. In this paper, we take a
different approach, i.e., we fix the recommendation strategy and observe
changes when using different underlying knowledge graphs. Particularly, we use
different language editions of DBpedia. We show that the usage of different
knowledge graphs does not only lead to differently biased recommender systems,
but also to recommender systems that differ in performance for particular
fields of recommendations.
","[{'version': 'v1', 'created': 'Mon, 3 May 2021 08:07:30 GMT'}]",2021-05-04,"[['Voit', 'Michael Matthias', ''], ['Paulheim', 'Heiko', '']]"
2104.06422,Patrick Breysse,"Patrick C. Breysse, Simon Foreman, Laura C. Keating, Joel Meyers, and
  Norman Murray",Mapping the Universe in HD,"19 pages, 9 figures",,,,astro-ph.CO,http://creativecommons.org/licenses/by/4.0/,"  Hydrogen deuteride (HD) is prevalent in a wide variety of astrophysical
environments, and measuring its large-scale distribution at different epochs
can in principle provide information about the properties of these
environments. In this paper, we explore the prospects for accessing this
distribution using line intensity mapping of emission from the lowest
rotational transition in HD, focusing on observations of the epoch of
reionization ($z\sim6-10$) and earlier. We find the signal from the epoch of
reionization to be strongest most promising, through cross-correlations within
existing [CII] intensity mapping surveys. While the signal we predict is out of
reach for current-generation projects, planned future improvements should be
able to detect reionization-era HD without any additional observations, and
would help to constrain the properties of the star-forming galaxies thought to
play a key role in reionization. We also investigate several avenues for
measuring HD during ""cosmic dawn"" ($z\sim10-30$), a period in which HD could
provide one of the only complementary observables to 21$\,$cm intensity maps.
We conclude that existing and planned facilities are poorly matched to the
specifications desirable for a significant detection, though such a measurement
may be achievable with sustained future effort. Finally, we explain why HD
intensity mapping of the intergalactic medium during the cosmic dark ages
($z\gtrsim 30$) appears to be out of reach of any conceivable experiment.
","[{'version': 'v1', 'created': 'Tue, 13 Apr 2021 18:00:04 GMT'}]",2021-04-15,"[['Breysse', 'Patrick C.', ''], ['Foreman', 'Simon', ''], ['Keating', 'Laura C.', ''], ['Meyers', 'Joel', ''], ['Murray', 'Norman', '']]"
2201.08887,Pichao Wang,Pichao Wang and Fan Wang and Hao Li,"Image-to-Video Re-Identification via Mutual Discriminative Knowledge
  Transfer",accepted by ICASSP 2022,,,,cs.CV,http://creativecommons.org/licenses/by/4.0/,"  The gap in representations between image and video makes Image-to-Video
Re-identification (I2V Re-ID) challenging, and recent works formulate this
problem as a knowledge distillation (KD) process. In this paper, we propose a
mutual discriminative knowledge distillation framework to transfer a
video-based richer representation to an image based representation more
effectively. Specifically, we propose the triplet contrast loss (TCL), a novel
loss designed for KD. During the KD process, the TCL loss transfers the local
structure, exploits the higher order information, and mitigates the
misalignment of the heterogeneous output of teacher and student networks.
Compared with other losses for KD, the proposed TCL loss selectively transfers
the local discriminative features from teacher to student, making it effective
in the ReID. Besides the TCL loss, we adopt mutual learning to regularize both
the teacher and student networks training. Extensive experiments demonstrate
the effectiveness of our method on the MARS, DukeMTMC-VideoReID and VeRi-776
benchmarks.
","[{'version': 'v1', 'created': 'Fri, 21 Jan 2022 21:04:39 GMT'}]",2022-01-25,"[['Wang', 'Pichao', ''], ['Wang', 'Fan', ''], ['Li', 'Hao', '']]"
2011.06159,Amani Abusafia,Amani Abusafia and Athman Bouguettaya,Reliability Model for Incentive-Driven IoT Energy Services,"10 pages, 10 figures, This paper is accepted in the 2020 EAI
  International Conference on Mobile and Ubiquitous Systems: Computing,
  Networking and Services (EAI MobiQuitous 2020)",,,,cs.DC,http://creativecommons.org/licenses/by/4.0/,"  We propose a novel reliability model for composing energy service requests.
The proposed model is based on consumers' behavior and history of energy
requests. The reliability model ensures the maximum incentives to providers.
Incentives are used as a green solution to increase IoT users' participation in
a crowdsourced energy sharing environment. Additionally, adaptive and priority
scheduling compositions are proposed to compose the most reliable energy
requests while maximizing providers' incentives. A set of experiments is
conducted to evaluate the proposed approaches. Experimental results prove the
efficiency of the proposed approaches.
","[{'version': 'v1', 'created': 'Thu, 12 Nov 2020 01:55:34 GMT'}, {'version': 'v2', 'created': 'Wed, 25 Nov 2020 09:09:52 GMT'}, {'version': 'v3', 'created': 'Wed, 20 Jan 2021 01:11:59 GMT'}]",2021-01-21,"[['Abusafia', 'Amani', ''], ['Bouguettaya', 'Athman', '']]"
1902.05200,Sharmila Karumuri,"Sharmila Karumuri, Rohit Tripathy, Ilias Bilionis, Jitesh Panchal","Simulator-free Solution of High-Dimensional Stochastic Elliptic Partial
  Differential Equations using Deep Neural Networks","63 pages, 32 figures",,10.1016/j.jcp.2019.109120,,physics.data-an physics.comp-ph,http://creativecommons.org/licenses/by/4.0/,"  Stochastic partial differential equations (SPDEs) are ubiquitous in
engineering and computational sciences. The stochasticity arises as a
consequence of uncertainty in input parameters, constitutive relations,
initial/boundary conditions, etc. Because of these functional uncertainties,
the stochastic parameter space is often high-dimensional, requiring hundreds,
or even thousands, of parameters to describe it. This poses an insurmountable
challenge to response surface modeling since the number of forward model
evaluations needed to construct an accurate surrogate grows exponentially with
the dimension of the uncertain parameter space; a phenomenon referred to as the
\textit{curse of dimensionality}. State-of-the-art methods for high-dimensional
uncertainty propagation seek to alleviate the curse of dimensionality by
performing dimensionality reduction in the uncertain parameter space. However,
one still needs to perform forward model evaluations that potentially carry a
very high computational burden. We propose a novel methodology for
high-dimensional uncertainty propagation of elliptic SPDEs which lifts the
requirement for a deterministic forward solver. Our approach is as follows. We
parameterize the solution of the elliptic SPDE using a deep residual network
(ResNet). In a departure from the traditional squared residual (SR) based loss
function for training the ResNet, we introduce a novel physics-informed loss
function derived from variational principles. Specifically, our loss function
is the expectation of the energy functional of the PDE over the stochastic
variables. We demonstrate our solver-free approach through various examples
where the elliptic SPDE is subjected to different types of high-dimensional
input uncertainties. Also, we solve high-dimensional uncertainty propagation
and inverse problems.
","[{'version': 'v1', 'created': 'Thu, 14 Feb 2019 03:14:06 GMT'}, {'version': 'v2', 'created': 'Mon, 3 Jun 2019 16:02:32 GMT'}, {'version': 'v3', 'created': 'Wed, 9 Oct 2019 16:55:52 GMT'}]",2020-01-29,"[['Karumuri', 'Sharmila', ''], ['Tripathy', 'Rohit', ''], ['Bilionis', 'Ilias', ''], ['Panchal', 'Jitesh', '']]"
2111.03885,Pallavi Basu,"Pallavi Basu, Luella Fu, Alessio Saretto, and Wenguang Sun","An Empirical Bayes Approach to Controlling the False Discovery
  Exceedance",Minor updates. 34 pages,,,,stat.ME stat.AP,http://creativecommons.org/licenses/by/4.0/,"  In large-scale multiple hypothesis testing problems, the false discovery
exceedance (FDX) provides a desirable alternative to the widely used false
discovery rate (FDR) when the false discovery proportion (FDP) is highly
variable. We develop an empirical Bayes approach to control the FDX. We show
that, for independent hypotheses from a two-group model and dependent
hypotheses from a Gaussian model fulfilling the exchangeability condition, an
oracle decision rule based on ranking and thresholding the local false
discovery rate (lfdr) is optimal in the sense that the power is maximized
subject to the FDX constraint. We propose a data-driven FDX procedure that uses
carefully designed computational shortcuts to emulate the oracle rule. We
investigate the empirical performance of the proposed method using both
simulated and real data and study the merits of FDX control through an
application for identifying abnormal stock trading strategies.
","[{'version': 'v1', 'created': 'Sat, 6 Nov 2021 13:44:13 GMT'}, {'version': 'v2', 'created': 'Fri, 7 Jan 2022 09:36:14 GMT'}]",2022-01-10,"[['Basu', 'Pallavi', ''], ['Fu', 'Luella', ''], ['Saretto', 'Alessio', ''], ['Sun', 'Wenguang', '']]"
2108.02818,Sandhini Agarwal,"Sandhini Agarwal, Gretchen Krueger, Jack Clark, Alec Radford, Jong
  Wook Kim, Miles Brundage","Evaluating CLIP: Towards Characterization of Broader Capabilities and
  Downstream Implications",arXiv admin note: substantial text overlap with arXiv:2103.00020,,,,cs.CV cs.AI cs.CY,http://creativecommons.org/licenses/by/4.0/,"  Recently, there have been breakthroughs in computer vision (""CV"") models that
are more generalizable with the advent of models such as CLIP and ALIGN. In
this paper, we analyze CLIP and highlight some of the challenges such models
pose. CLIP reduces the need for task specific training data, potentially
opening up many niche tasks to automation. CLIP also allows its users to
flexibly specify image classification classes in natural language, which we
find can shift how biases manifest. Additionally, through some preliminary
probes we find that CLIP can inherit biases found in prior computer vision
systems. Given the wide and unpredictable domain of uses for such models, this
raises questions regarding what sufficiently safe behaviour for such systems
may look like. These results add evidence to the growing body of work calling
for a change in the notion of a 'better' model--to move beyond simply looking
at higher accuracy at task-oriented capability evaluations, and towards a
broader 'better' that takes into account deployment-critical features such as
different use contexts, and people who interact with the model when thinking
about model deployment.
","[{'version': 'v1', 'created': 'Thu, 5 Aug 2021 19:05:57 GMT'}]",2021-08-09,"[['Agarwal', 'Sandhini', ''], ['Krueger', 'Gretchen', ''], ['Clark', 'Jack', ''], ['Radford', 'Alec', ''], ['Kim', 'Jong Wook', ''], ['Brundage', 'Miles', '']]"
2106.03794,Tuhin Chakrabarty Mr,"Arkadiy Saakyan, Tuhin Chakrabarty, and Smaranda Muresan","COVID-Fact: Fact Extraction and Verification of Real-World Claims on
  COVID-19 Pandemic",ACL 2021 Camera Ready,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  We introduce a FEVER-like dataset COVID-Fact of $4,086$ claims concerning the
COVID-19 pandemic. The dataset contains claims, evidence for the claims, and
contradictory claims refuted by the evidence. Unlike previous approaches, we
automatically detect true claims and their source articles and then generate
counter-claims using automatic methods rather than employing human annotators.
Along with our constructed resource, we formally present the task of
identifying relevant evidence for the claims and verifying whether the evidence
refutes or supports a given claim. In addition to scientific claims, our data
contains simplified general claims from media sources, making it better suited
for detecting general misinformation regarding COVID-19. Our experiments
indicate that COVID-Fact will provide a challenging testbed for the development
of new systems and our approach will reduce the costs of building
domain-specific datasets for detecting misinformation.
","[{'version': 'v1', 'created': 'Mon, 7 Jun 2021 16:59:46 GMT'}]",2021-06-08,"[['Saakyan', 'Arkadiy', ''], ['Chakrabarty', 'Tuhin', ''], ['Muresan', 'Smaranda', '']]"
1909.11023,Tanwi Mallick,"Tanwi Mallick, Partha Pratim Das, and Arun Kumar Majumdar","Posture and sequence recognition for Bharatanatyam dance performances
  using machine learning approach",,,,,cs.CV cs.LG cs.MM,http://creativecommons.org/licenses/by/4.0/,"  Understanding the underlying semantics of performing arts like dance is a
challenging task. Dance is multimedia in nature and spans over time as well as
space. Capturing and analyzing the multimedia content of the dance is useful
for the preservation of cultural heritage, to build video recommendation
systems, to assist learners to use tutoring systems. To develop an application
for dance, three aspects of dance analysis need to be addressed: 1)
Segmentation of the dance video to find the representative action elements, 2)
Matching or recognition of the detected action elements, and 3) Recognition of
the dance sequences formed by combining a number of action elements under
certain rules. This paper attempts to solve three fundamental problems of dance
analysis for understanding the underlying semantics of dance forms. Our focus
is on an Indian Classical Dance (ICD) form known as Bharatanatyam. As dance is
driven by music, we use the music as well as motion information for key posture
extraction. Next, we recognize the key postures using machine learning as well
as deep learning techniques. Finally, the dance sequence is recognized using
the Hidden Markov Model (HMM). We capture the multi-modal data of Bharatanatyam
dance using Kinect and build an annotated data set for research in ICD.
","[{'version': 'v1', 'created': 'Tue, 24 Sep 2019 16:18:01 GMT'}]",2019-09-25,"[['Mallick', 'Tanwi', ''], ['Das', 'Partha Pratim', ''], ['Majumdar', 'Arun Kumar', '']]"
2110.09066,Zhaohong Sun,"Haris Aziz, Warut Suksompong, Zhaohong Sun, and Toby Walsh",Fairness Concepts for Indivisible Items with Externalities,,,,,cs.GT,http://creativecommons.org/licenses/by/4.0/,"  We study a fair allocation problem of indivisible items under additive
externalities in which each agent also receives values from items that are
assigned to other agents. We propose several new fairness concepts. We extend
the well-studied envy-freeness up to one item (EF1) and envy-freeness up to any
item (EFX) to this setting, and we propose a new fairness concept called
general fair share (GFS). We undertake a detailed study and present algorithms
for finding fair allocations.
","[{'version': 'v1', 'created': 'Mon, 18 Oct 2021 07:20:12 GMT'}]",2021-10-19,"[['Aziz', 'Haris', ''], ['Suksompong', 'Warut', ''], ['Sun', 'Zhaohong', ''], ['Walsh', 'Toby', '']]"
2104.02541,Nicoletta Risi,"Nicoletta Risi, Enrico Calabrese, Giacomo Indiveri","Instantaneous Stereo Depth Estimation of Real-World Stimuli with a
  Neuromorphic Stereo-Vision Setup",,,,,cs.CV cs.AI,http://creativecommons.org/licenses/by/4.0/,"  The stereo-matching problem, i.e., matching corresponding features in two
different views to reconstruct depth, is efficiently solved in biology. Yet, it
remains the computational bottleneck for classical machine vision approaches.
By exploiting the properties of event cameras, recently proposed Spiking Neural
Network (SNN) architectures for stereo vision have the potential of simplifying
the stereo-matching problem. Several solutions that combine event cameras with
spike-based neuromorphic processors already exist. However, they are either
simulated on digital hardware or tested on simplified stimuli. In this work, we
use the Dynamic Vision Sensor 3D Human Pose Dataset (DHP19) to validate a
brain-inspired event-based stereo-matching architecture implemented on a
mixed-signal neuromorphic processor with real-world data. Our experiments show
that this SNN architecture, composed of coincidence detectors and disparity
sensitive neurons, is able to provide a coarse estimate of the input disparity
instantaneously, thereby detecting the presence of a stimulus moving in depth
in real-time.
","[{'version': 'v1', 'created': 'Tue, 6 Apr 2021 14:31:23 GMT'}]",2021-04-07,"[['Risi', 'Nicoletta', ''], ['Calabrese', 'Enrico', ''], ['Indiveri', 'Giacomo', '']]"
2107.10401,Yang Xu,"Yang Xu, Haibin Kan, Guangyue Han",Fourier-Reflexive Partitions Induced by Poset Metric,,,,,cs.IT math.IT,http://creativecommons.org/licenses/by/4.0/,"  Let $\mathbf{H}$ be the cartesian product of a family of finite abelian
groups indexed by a finite set $\Omega$. A given poset (i.e., partially ordered
set) $\mathbf{P}=(\Omega,\preccurlyeq_{\mathbf{P}})$ gives rise to a poset
metric on $\mathbf{H}$, which further leads to a partition
$\mathcal{Q}(\mathbf{H},\mathbf{P})$ of $\mathbf{H}$. We prove that if
$\mathcal{Q}(\mathbf{H},\mathbf{P})$ is Fourier-reflexive, then its dual
partition $\Lambda$ coincides with the partition of $\hat{\mathbf{H}}$ induced
by $\mathbf{\overline{P}}$, the dual poset of $\mathbf{P}$, and moreover,
$\mathbf{P}$ is necessarily hierarchical. This result establishes a conjecture
proposed by Gluesing-Luerssen in \cite{4}. We also show that with some other
assumptions, $\Lambda$ is finer than the partition of $\hat{\mathbf{H}}$
induced by $\mathbf{\overline{P}}$. In addition, we give some necessary and
sufficient conditions for $\mathbf{P}$ to be hierarchical, and for the case
that $\mathbf{P}$ is hierarchical, we give an explicit criterion for
determining whether two codewords in $\hat{\mathbf{H}}$ belong to the same
block of $\Lambda$. We prove these results by relating the involved partitions
with certain family of polynomials, a generalized version of which is also
proposed and studied to generalize the aforementioned results.
","[{'version': 'v1', 'created': 'Thu, 22 Jul 2021 00:03:08 GMT'}]",2021-07-23,"[['Xu', 'Yang', ''], ['Kan', 'Haibin', ''], ['Han', 'Guangyue', '']]"
2104.07542,Mariya Naumova,"Vladimir Gurvich, Mariya Naumova","On Nash-solvability of n-person graphical games under Markov's and a
  priori realizations",,,,,math.CO cs.GT,http://creativecommons.org/licenses/by/4.0/,"  We consider graphical $n$-person games with perfect information that have no
Nash equilibria in pure stationary strategies. Solving these games in mixed
strategies, we introduce probabilistic distributions in all non-terminal
positions. The corresponding plays can be analyzed under two different basic
assumptions: Markov's and a priori realizations. The former one guarantees
existence of a uniformly best response of each player in every situation.
Nevertheless, Nash equilibrium may fail to exist even in mixed strategies. The
classical Nash theorem is not applicable, since Markov's realizations may
result in the limit distributions and effective payoff functions that are not
continuous. The a priori realization does not share many nice properties of the
Markov one (for example, existence of the uniformly best response) but in
return, Nash's theorem is applicable. We illustrate both realizations in
details by two examples with $2$ and $3$ players and also provide some general
results.
","[{'version': 'v1', 'created': 'Thu, 15 Apr 2021 15:54:35 GMT'}]",2021-04-16,"[['Gurvich', 'Vladimir', ''], ['Naumova', 'Mariya', '']]"
2004.01970,Siddhant Garg,"Siddhant Garg, Goutham Ramakrishnan",BAE: BERT-based Adversarial Examples for Text Classification,Accepted at EMNLP 2020 Main Conference,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Modern text classification models are susceptible to adversarial examples,
perturbed versions of the original text indiscernible by humans which get
misclassified by the model. Recent works in NLP use rule-based synonym
replacement strategies to generate adversarial examples. These strategies can
lead to out-of-context and unnaturally complex token replacements, which are
easily identifiable by humans. We present BAE, a black box attack for
generating adversarial examples using contextual perturbations from a BERT
masked language model. BAE replaces and inserts tokens in the original text by
masking a portion of the text and leveraging the BERT-MLM to generate
alternatives for the masked tokens. Through automatic and human evaluations, we
show that BAE performs a stronger attack, in addition to generating adversarial
examples with improved grammaticality and semantic coherence as compared to
prior work.
","[{'version': 'v1', 'created': 'Sat, 4 Apr 2020 16:25:48 GMT'}, {'version': 'v2', 'created': 'Mon, 5 Oct 2020 16:44:29 GMT'}, {'version': 'v3', 'created': 'Thu, 8 Oct 2020 00:41:43 GMT'}]",2020-10-09,"[['Garg', 'Siddhant', ''], ['Ramakrishnan', 'Goutham', '']]"
2110.13458,Ioannis Krikidis,Ioannis Krikidis and Constantinos Psomas,"Estimation-Energy Tradeoff for Scalar Gauss-Markov Signals with Kalman
  Filtering",6 figures,"IEEE Wireless Communications Letters, 2021",,,cs.IT math.IT,http://creativecommons.org/licenses/by/4.0/,"  In this letter, we investigate a receiver architecture, which uses the
received signal in order to simultaneously harvest energy and estimate a
Gauss-Markov linear process. We study three communication scenarios: i) static
channel, ii) Rayleigh block-fading channel, and iii) high power amplifier (HPA)
nonlinearities at the transmitter side. Theoretical results for the minimum
mean square error as well as the average harvested energy are given for all
cases and the fundamental tradeoff between estimation quality and harvested
energy is characterized. We show that channel fading improves the estimation
performance while HPA requires an extended Kalman filter at the receiver and
significantly affects both the estimation and the harvesting efficiency.
","[{'version': 'v1', 'created': 'Tue, 26 Oct 2021 07:44:19 GMT'}]",2021-10-27,"[['Krikidis', 'Ioannis', ''], ['Psomas', 'Constantinos', '']]"
2111.09374,Jialing Pei,Jialing Pei and Vitaly Shmatikov,BigFoot: Exploiting and Mitigating Leakage in Encrypted Write-Ahead Logs,8 pages,,,,cs.CR,http://creativecommons.org/licenses/by/4.0/,"  Modern databases and data-warehousing systems separate query processing and
durable storage. Storage systems have idiosyncratic bugs and security
vulnerabilities, thus attacks that compromise only storage are a realistic
threat. In this paper, we show that encryption alone is not sufficient to
protect databases from compromised storage. Using MongoDB WiredTiger as a
concrete example, we demonstrate that sizes of encrypted writes to a durable
write-ahead log can reveal sensitive information about the inputs and
activities of MongoDB applications. We then design, implement, and evaluate
BigFoot, a WAL modification that mitigates size leakage.
","[{'version': 'v1', 'created': 'Wed, 17 Nov 2021 20:14:31 GMT'}, {'version': 'v2', 'created': 'Mon, 29 Nov 2021 04:35:14 GMT'}]",2021-11-30,"[['Pei', 'Jialing', ''], ['Shmatikov', 'Vitaly', '']]"
2109.07472,Chaitanya Krishna Vallabh,Chaitanya Krishna Prasad Vallabh and Xiayun Zhao,"Single-camera Two-Wavelength Imaging Pyrometry for Melt Pool Temperature
  Measurement and Monitoring in Laser Powder Bed Fusion based Additive
  Manufacturing",,,,,eess.SY cs.SY eess.IV physics.ins-det physics.optics,http://creativecommons.org/licenses/by/4.0/,"  Melt pool (MP) temperature is one of the determining factors and key
signatures for the properties of printed components during metal additive
manufacturing (AM). The state-of-the art measurement systems are hindered by
both the equipment cost and the large-scale data acquisition and processing
demands. In this work, we introduce a novel coaxial high-speed single-camera
two-wavelength imaging pyrometer (STWIP) system as opposed to the typical
utilization of multiple cameras for measuring MP temperature profiles through a
laser powder bed fusion (LPBF) process. Developed on a commercial LPBF machine
(EOS M290), the STWIP system is demonstrated to be able to quantitatively
monitor MP temperature and variation for 50 layers at high framerates (> 30,000
fps) during a print of five standard fatigue specimens. High performance
computing is employed to analyze the acquired big data of MP images for
determining each MPs average temperature and 2D temperature profile. The MP
temperature evolution in the gage section of a fatigue specimen is also
examined at a temporal resolution of 1ms by evaluating the derived MP
temperatures of the printed samples first, middle and last layers. This paper
is first of its kind on monitoring MP temperature distribution and evolution at
such a large, detailed scale for longer durations in practical applications.
Future work includes MP registration and machine learning of MP-Part Property
relations.
","[{'version': 'v1', 'created': 'Tue, 14 Sep 2021 23:30:12 GMT'}]",2021-09-28,"[['Vallabh', 'Chaitanya Krishna Prasad', ''], ['Zhao', 'Xiayun', '']]"
2011.10520,Hugo Tessier,"Hugo Tessier, Vincent Gripon, Mathieu L\'eonardon, Matthieu Arzel,
  Thomas Hannagan, David Bertrand",Rethinking Weight Decay For Efficient Neural Network Pruning,"23 pages, 18 figures, published at Journal of Imaging, update : added
  new results, rewrite","Journal of Imaging 8 (2022), no. 3: 64",10.3390/jimaging8030064,,cs.NE,http://creativecommons.org/licenses/by/4.0/,"  Introduced in the late 1980s for generalization purposes, pruning has now
become a staple for compressing deep neural networks. Despite many innovations
in recent decades, pruning approaches still face core issues that hinder their
performance or scalability. Drawing inspiration from early work in the field,
and especially the use of weight decay to achieve sparsity, we introduce
Selective Weight Decay (SWD), which carries out efficient, continuous pruning
throughout training. Our approach, theoretically grounded on Lagrangian
smoothing, is versatile and can be applied to multiple tasks, networks, and
pruning structures. We show that SWD compares favorably to state-of-the-art
approaches, in terms of performance-to-parameters ratio, on the CIFAR-10, Cora,
and ImageNet ILSVRC2012 datasets.
","[{'version': 'v1', 'created': 'Fri, 20 Nov 2020 17:25:53 GMT'}, {'version': 'v2', 'created': 'Tue, 22 Dec 2020 15:30:19 GMT'}, {'version': 'v3', 'created': 'Tue, 16 Feb 2021 08:28:53 GMT'}, {'version': 'v4', 'created': 'Wed, 9 Mar 2022 15:06:05 GMT'}]",2022-03-10,"[['Tessier', 'Hugo', ''], ['Gripon', 'Vincent', ''], ['Léonardon', 'Mathieu', ''], ['Arzel', 'Matthieu', ''], ['Hannagan', 'Thomas', ''], ['Bertrand', 'David', '']]"
2103.09879,Andrew Carr,"Andrew N Carr, Quentin Berthet, Mathieu Blondel, Olivier Teboul, Neil
  Zeghidour","Self-Supervised Learning of Audio Representations from Permutations with
  Differentiable Ranking",,,10.1109/LSP.2021.3067635,,cs.SD cs.AI eess.AS,http://creativecommons.org/licenses/by/4.0/,"  Self-supervised pre-training using so-called ""pretext"" tasks has recently
shown impressive performance across a wide range of modalities. In this work,
we advance self-supervised learning from permutations, by pre-training a model
to reorder shuffled parts of the spectrogram of an audio signal, to improve
downstream classification performance. We make two main contributions. First,
we overcome the main challenges of integrating permutation inversions into an
end-to-end training scheme, using recent advances in differentiable ranking.
This was heretofore sidestepped by casting the reordering task as
classification, fundamentally reducing the space of permutations that can be
exploited. Our experiments validate that learning from all possible
permutations improves the quality of the pre-trained representations over using
a limited, fixed set. Second, we show that inverting permutations is a
meaningful pretext task for learning audio representations in an unsupervised
fashion. In particular, we improve instrument classification and pitch
estimation of musical notes by reordering spectrogram patches in the
time-frequency space.
","[{'version': 'v1', 'created': 'Wed, 17 Mar 2021 19:36:04 GMT'}]",2021-05-05,"[['Carr', 'Andrew N', ''], ['Berthet', 'Quentin', ''], ['Blondel', 'Mathieu', ''], ['Teboul', 'Olivier', ''], ['Zeghidour', 'Neil', '']]"
2103.14649,Elad Michael Schiller (PhD),"Chryssis Georgiou and Ioannis Marcoullis and Michel Raynal and Elad
  Michael Schiller","Loosely-self-stabilizing Byzantine-tolerant Binary Consensus for
  Signature-free Message-passing Systems",,,,,cs.DC,http://creativecommons.org/licenses/by/4.0/,"  At PODC 2014, A. Most\'efaoui, H. Moumen, and M. Raynal presented a new and
simple randomized signature-free binary consensus algorithm (denoted here MMR)
that copes with the net effect of asynchrony Byzantine behaviors. Assuming
message scheduling is fair and independent from random numbers MMR is optimal
in several respects: it deals with up to t Byzantine processes where t < n/3
and n is the number of processes, O(n\^2) messages and O(1) expected time. The
present article presents a non-trivial extension of MMR to an even more
fault-prone context, namely, in addition to Byzantine processes, it considers
also that the system can experience transient failures. To this end it
considers self-stabilization techniques to cope with communication failures and
arbitrary transient faults (such faults represent any violation of the
assumptions according to which the system was designed to operate).
  The proposed algorithm is the first loosely-self-stabilizing Byzantine
fault-tolerant binary consensus algorithm suited to asynchronous
message-passing systems. This is achieved via an instructive transformation of
MMR to a self-stabilizing solution that can violate safety requirements with
probability Pr= O(1/(2\^M)), where M is a predefined constant that can be set
to any positive integer at the cost of 3 M n + log M bits of local memory. In
addition to making MMR resilient to transient faults, the obtained
self-stabilizing algorithm preserves its properties of optimal resilience and
termination, (i.e., t < n/3, and O(1) expected time). Furthermore, it only
requires a bounded amount of memory.
","[{'version': 'v1', 'created': 'Fri, 26 Mar 2021 13:48:31 GMT'}, {'version': 'v2', 'created': 'Thu, 13 May 2021 15:22:15 GMT'}]",2021-05-14,"[['Georgiou', 'Chryssis', ''], ['Marcoullis', 'Ioannis', ''], ['Raynal', 'Michel', ''], ['Schiller', 'Elad Michael', '']]"
2203.04454,Xinyu Zhou,"Xinyu Zhou, Yijia Ma, Wei Wu","Statistical Depth for Point Process via the Isometric Log-Ratio
  Transformation",,,,,stat.ME,http://creativecommons.org/licenses/by/4.0/,"  Statistical depth, a useful tool to measure the center-outward rank of
multivariate and functional data, is still under-explored in temporal point
processes. Recent studies on point process depth proposed a weighted product of
two terms - one indicates the depth of the cardinality of the process, and the
other characterizes the conditional depth of the temporal events given the
cardinality. The second term is of great challenge because of the apparent
nonlinear structure of event times, and so far only basic parametric
representations such as Gaussian and Dirichlet densities were adopted in the
definitions. However, these simplified forms ignore the underlying distribution
of the process events, which makes the methods difficult to interpret and to
apply to complicated patterns. To deal with these problems, we in this paper
propose a distribution-based approach to the conditional depth via the
well-known Isometric Log-Ratio (ILR) transformation on the inter-event times.
The new depth, called the ILR depth, is at first defined for homogeneous
Poisson process by using the density function on the transformed space. The
definition is then extended to any general point process via a time-rescaling
transformation. We illustrate the ILR depth using simulations of Poisson and
non-Poisson processes and demonstrate its superiority over previous methods. We
also thoroughly examine its mathematical properties and asymptotics in large
samples. Finally, we apply the ILR depth in a real dataset and the result
clearly shows the effectiveness of the new method.
","[{'version': 'v1', 'created': 'Wed, 9 Mar 2022 00:20:15 GMT'}]",2022-03-10,"[['Zhou', 'Xinyu', ''], ['Ma', 'Yijia', ''], ['Wu', 'Wei', '']]"
2103.13194,Benjamin Unger,Tobias Breiten and Benjamin Unger,Passivity preserving model reduction via spectral factorization,,,,,math.DS cs.NA math.NA,http://creativecommons.org/licenses/by/4.0/,"  We present a novel model-order reduction (MOR) method for linear
time-invariant systems that preserves passivity and is thus suited for
structure-preserving MOR for port-Hamiltonian (pH) systems. Our algorithm
exploits the well-known spectral factorization of the Popov function by a
solution of the Kalman-Yakubovich-Popov (KYP) inequality. It performs MOR
directly on the spectral factor inheriting the original system's sparsity
enabling MOR in a large-scale context. Our analysis reveals that the spectral
factorization corresponding to the minimal solution of an associated algebraic
Riccati equation is preferable from a model reduction perspective and benefits
pH-preserving MOR methods such as a modified version of the iterative rational
Krylov algorithm (IRKA). Numerical examples demonstrate that our approach can
produce high-fidelity reduced-order models close to (unstructured)
$\mathcal{H}_2$-optimal reduced-order models.
","[{'version': 'v1', 'created': 'Wed, 24 Mar 2021 13:48:18 GMT'}, {'version': 'v2', 'created': 'Mon, 29 Mar 2021 17:31:02 GMT'}, {'version': 'v3', 'created': 'Fri, 27 Aug 2021 14:19:57 GMT'}]",2021-08-30,"[['Breiten', 'Tobias', ''], ['Unger', 'Benjamin', '']]"
2007.12432,Aina Gar\'i Soler,"Aina Gar\'i Soler, Marianna Apidianaki",MULTISEM at SemEval-2020 Task 3: Fine-tuning BERT for Lexical Meaning,"8 pages, 2 tables. Accepted at the 14th International Workshop on
  Semantic Evaluation (SemEval-2020)",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  We present the MULTISEM systems submitted to SemEval 2020 Task 3: Graded Word
Similarity in Context (GWSC). We experiment with injecting semantic knowledge
into pre-trained BERT models through fine-tuning on lexical semantic tasks
related to GWSC. We use existing semantically annotated datasets and propose to
approximate similarity through automatically generated lexical substitutes in
context. We participate in both GWSC subtasks and address two languages,
English and Finnish. Our best English models occupy the third and fourth
positions in the ranking for the two subtasks. Performance is lower for the
Finnish models which are mid-ranked in the respective subtasks, highlighting
the important role of data availability for fine-tuning.
","[{'version': 'v1', 'created': 'Fri, 24 Jul 2020 09:50:26 GMT'}]",2020-07-27,"[['Soler', 'Aina Garí', ''], ['Apidianaki', 'Marianna', '']]"
2101.03318,Samantha Lynn Stever,"Samantha Lynn Stever, Fran\c{c}ois Couchot, Bruno Maffei","Simulations of athermal phonon propagation in a cryogenic semiconducting
  bolometer","SPIE Conference for Astronomical Telescopes and Instrumentation, 2020",,,,astro-ph.IM physics.ins-det,http://creativecommons.org/licenses/by/4.0/,"  We present three Monte Carlo models for the propagation of athermal phonons
in the diamond absorber of a composite semiconducting bolometer `Bolo 184'.
Previous measurements of the response of this bolometer to impacts by $\alpha$
particles show a strong dependence on the location of particle incidence, and
the shape of the response function is determined by the propagation and
thermalisation of athermal phonons. The specific mechanisms of athermal phonon
propagation at this time were undetermined, and hence we have developed three
models for probing this behaviour by attempting to reproduce the statistical
features seen in the experimental data. The first two models assume a phonon
thermalisation length determined by a mean free path $\lambda$, where the first
model assumes that phonons thermalise at the borders of the disc (with a small
$\lambda$) and the second assumes that they reflect (with a $\lambda$ larger
than the size of the disc). The third model allows athermal photons to
propagate along their geometrical line of sight (similar to ray optics),
gradually losing energy. We find that both the reflective model and the
geometrical model reproduce the features seen in experimental data, whilst the
model assuming phonon thermalisation at the disc border produces unrealistic
results. There is no significant dependence on directionality of energy
absorption in the geometrical model, and in the schema of this thin crystalline
diamond, a reflective absorber law and a geometrical law both produce
consistent results.
","[{'version': 'v1', 'created': 'Sat, 9 Jan 2021 08:39:01 GMT'}]",2021-01-12,"[['Stever', 'Samantha Lynn', ''], ['Couchot', 'François', ''], ['Maffei', 'Bruno', '']]"
2103.14275,Shengkun Tang,"Puyuan Yi, Shengkun Tang and Jian Yao",DDR-Net: Learning Multi-Stage Multi-View Stereo With Dynamic Depth Range,,,,,cs.CV,http://creativecommons.org/licenses/by/4.0/,"  To obtain high-resolution depth maps, some previous learning-based multi-view
stereo methods build a cost volume pyramid in a coarse-to-fine manner. These
approaches leverage fixed depth range hypotheses to construct cascaded plane
sweep volumes. However, it is inappropriate to set identical range hypotheses
for each pixel since the uncertainties of previous per-pixel depth predictions
are spatially varying. Distinct from these approaches, we propose a Dynamic
Depth Range Network (DDR-Net) to determine the depth range hypotheses
dynamically by applying a range estimation module (REM) to learn the
uncertainties of range hypotheses in the former stages. Specifically, in our
DDR-Net, we first build an initial depth map at the coarsest resolution of an
image across the entire depth range. Then the range estimation module (REM)
leverages the probability distribution information of the initial depth to
estimate the depth range hypotheses dynamically for the following stages.
Moreover, we develop a novel loss strategy, which utilizes learned dynamic
depth ranges to generate refined depth maps, to keep the ground truth value of
each pixel covered in the range hypotheses of the next stage. Extensive
experimental results show that our method achieves superior performance over
other state-of-the-art methods on the DTU benchmark and obtains comparable
results on the Tanks and Temples benchmark. The code is available at
https://github.com/Tangshengku/DDR-Net.
","[{'version': 'v1', 'created': 'Fri, 26 Mar 2021 05:52:38 GMT'}]",2021-03-29,"[['Yi', 'Puyuan', ''], ['Tang', 'Shengkun', ''], ['Yao', 'Jian', '']]"
1705.11094,Scientific Information Service CERN,"J. Osterhoff, Z. Najmudin and J. Faure",Case Studies on Plasma Wakefield Accelerator Design,"8 pages, contribution to the CAS - CERN Accelerator School: Plasma
  Wake Acceleration, CERN, Geneva, Switzerland, 23 - 29 Nov 2014. arXiv admin
  note: text overlap with arXiv:1306.6327 by other authors","CERN Yellow Report CERN 2016-001, pp.301-308",10.5170/CERN-2016-001.301,,physics.acc-ph,http://creativecommons.org/licenses/by/4.0/,"  The field of plasma-based particle accelerators has seen tremendous progress
over the past decade and experienced significant growth in the number of
activities. During this process, the involved scientific community has expanded
from traditional university-based research and is now encompassing many large
research laboratories worldwide, such as BNL, CERN, DESY, KEK, LBNL and SLAC.
As a consequence, there is a strong demand for a consolidated effort in
education at the intersection of accelerator, laser and plasma physics. The
CERN Accelerator School on Plasma Wake Acceleration has been organized as a
result of this development. In this paper, we describe the interactive
component of this one-week school, which consisted of three case studies to be
solved in 11 working groups by the participants of the CERN Accelerator School.
","[{'version': 'v1', 'created': 'Tue, 30 May 2017 12:50:06 GMT'}]",2017-06-01,"[['Osterhoff', 'J.', ''], ['Najmudin', 'Z.', ''], ['Faure', 'J.', '']]"
2201.04740,Georgia Karagiorgi,"Yeon-Jae Jwa, Giuseppe Di Guglielmo, Luca P. Carloni, Georgia
  Karagiorgi","Accelerating Deep Neural Networks for Real-time Data Selection for
  High-resolution Imaging Particle Detectors","10 pages, 5 figures, 8 tables","Published in 2019 New York Scientific Data Summit (NYSDS);
  Publisher: IEEE; Date Added to IEEE Xplore: 25 November 2019",10.1109/NYSDS.2019.8909784,,physics.ins-det hep-ex,http://creativecommons.org/licenses/by/4.0/,"  This paper presents the custom implementation, optimization, and performance
evaluation of convolutional neural networks on field programmable gate arrays,
for the purposes of accelerating deep neural network inference on large,
two-dimensional image inputs. The targeted application is that of data
selection for high-resolution particle imaging detectors, and in particular
liquid argon time projection chamber detectors, such as that employed by the
future Deep Underground Neutrino Experiment. We motivate this particular
application based on the excellent performance of deep neural networks on
classifying simulated raw data from the DUNE LArTPC, combined with the need for
power-efficient data processing in the case of remote, long-term, and
limited-access operating detector conditions.
","[{'version': 'v1', 'created': 'Wed, 12 Jan 2022 23:49:33 GMT'}]",2022-01-14,"[['Jwa', 'Yeon-Jae', ''], ['Di Guglielmo', 'Giuseppe', ''], ['Carloni', 'Luca P.', ''], ['Karagiorgi', 'Georgia', '']]"
2103.04768,Liya Wang,"Liya Wang, Panta Lucic, Keith Campbell, and Craig Wanke",Helicopter Track Identification with Autoencoder,"Draft for ICNS conference. arXiv admin note: text overlap with
  arXiv:2011.01464",,,,cs.LG cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Computing power, big data, and advancement of algorithms have led to a
renewed interest in artificial intelligence (AI), especially in deep learning
(DL). The success of DL largely lies on data representation because different
representations can indicate to a degree the different explanatory factors of
variation behind the data. In the last few year, the most successful story in
DL is supervised learning. However, to apply supervised learning, one challenge
is that data labels are expensive to get, noisy, or only partially available.
With consideration that we human beings learn in an unsupervised way;
self-supervised learning methods have garnered a lot of attention recently. A
dominant force in self-supervised learning is the autoencoder, which has
multiple uses (e.g., data representation, anomaly detection, denoise). This
research explored the application of an autoencoder to learn effective data
representation of helicopter flight track data, and then to support helicopter
track identification. Our testing results are promising. For example, at
Phoenix Deer Valley (DVT) airport, where 70% of recorded flight tracks have
missing aircraft types, the autoencoder can help to identify twenty-two times
more helicopters than otherwise detectable using rule-based methods; for Grand
Canyon West Airport (1G4) airport, the autoencoder can identify thirteen times
more helicopters than a current rule-based approach. Our approach can also
identify mislabeled aircraft types in the flight track data and find true types
for records with pseudo aircraft type labels such as HELO. With improved
labelling, studies using these data sets can produce more reliable results.
","[{'version': 'v1', 'created': 'Wed, 3 Mar 2021 22:32:39 GMT'}]",2021-03-09,"[['Wang', 'Liya', ''], ['Lucic', 'Panta', ''], ['Campbell', 'Keith', ''], ['Wanke', 'Craig', '']]"
2201.06545,Piyush Garg,Piyush Kumar Garg and Roshni Chakraborty and Sourav Kumar Dandapat,OntoRealSumm : Ontology based Real-Time Tweet Summarization,,,,,cs.SI,http://creativecommons.org/licenses/by/4.0/,"  The huge popularity of social media platforms, like Twitter, attracts a large
fraction of users to share real-time information and short situational messages
during disasters which belong to different topics/categories. A summary of all
the messages is required by the government organizations, agencies, and
volunteers for efficient and quick disaster response. Therefore, we propose an
ontology based real-time tweet summarization (OntoRealSumm) for disasters which
generates a summary of the tweets related to disasters with minimum human
intervention. Given tweets related to a disaster, OntoRealSumm ensures
fulfilment of the objectives related to disaster tweet summarization, such as
identification of a category of each tweet and summarization of each category
considering the category importance with respect to the disaster and ensuring
information coverage of each category and diversity in summary. Comparing the
performance with state-of-the-art techniques on 10 disaster datasets validates
the effectiveness of OntoRealSumm.
","[{'version': 'v1', 'created': 'Mon, 17 Jan 2022 17:49:39 GMT'}]",2022-01-19,"[['Garg', 'Piyush Kumar', ''], ['Chakraborty', 'Roshni', ''], ['Dandapat', 'Sourav Kumar', '']]"
2105.09772,Marco Attene PhD,Marco Attene,Indirect predicates for geometric constructions,"In Computer-Aided Design, 2020",,10.1016/j.cad.2020.102856,,cs.CG,http://creativecommons.org/licenses/by/4.0/,"  Geometric predicates are a basic ingredient to implement a vast range of
algorithms in computational geometry. Modern implementations employ floating
point filtering techniques to combine efficiency and robustness, and
state-of-the-art predicates are guaranteed to be always exact while being only
slightly slower than corresponding (inexact) floating point implementations.
Unfortunately, if the input to these predicates is an intermediate construction
of an algorithm, its floating point representation may be affected by an
approximation error, and correctness is no longer guaranteed. This paper
introduces the concept of indirect geometric predicate: instead of taking the
intermediate construction as an explicit input, an indirect predicate considers
the primitive geometric elements which are combined to produce such a
construction. This makes it possible to keep track of the floating point
approximation, and thus to exploit efficient filters and expansion arithmetic
to exactly resolve the predicate with minimal overhead with respect to a naive
floating point implementation. As a representative example, we show how to
extend standard predicates to the case of points of intersection of linear
elements (i.e. lines and planes) and show that, on classical problems, this
approach outperforms state-of-the-art solutions based on lazy exact
intermediate representations.
","[{'version': 'v1', 'created': 'Thu, 20 May 2021 14:20:48 GMT'}]",2021-05-21,"[['Attene', 'Marco', '']]"
2011.05516,Yingtao Luo,"Ying-Tao Luo, Peng-Qi Li, Dong-Ting Li, Yu-Gui Peng, Zhi-Guo Geng,
  Shu-Huan Xie, Yong Li, Andrea Alu, Jie Zhu, Xue-Feng Zhu","Probability-Density-Based Deep Learning Paradigm for the Fuzzy Design of
  Functional Metastructures","Published in Research, an AAAS Science Partner Journal","Research, vol. 2020, Article ID 8757403, 2020",10.34133/2020/8757403,,cs.LG,http://creativecommons.org/licenses/by/4.0/,"  In quantum mechanics, a norm squared wave function can be interpreted as the
probability density that describes the likelihood of a particle to be measured
in a given position or momentum. This statistical property is at the core of
the fuzzy structure of microcosmos. Recently, hybrid neural structures raised
intense attention, resulting in various intelligent systems with far-reaching
influence. Here, we propose a probability-density-based deep learning paradigm
for the fuzzy design of functional meta-structures. In contrast to other
inverse design methods, our probability-density-based neural network can
efficiently evaluate and accurately capture all plausible meta-structures in a
high-dimensional parameter space. Local maxima in probability density
distribution correspond to the most likely candidates to meet the desired
performances. We verify this universally adaptive approach in but not limited
to acoustics by designing multiple meta-structures for each targeted
transmission spectrum, with experiments unequivocally demonstrating the
effectiveness and generalization of the inverse design.
","[{'version': 'v1', 'created': 'Wed, 11 Nov 2020 02:22:46 GMT'}]",2020-11-12,"[['Luo', 'Ying-Tao', ''], ['Li', 'Peng-Qi', ''], ['Li', 'Dong-Ting', ''], ['Peng', 'Yu-Gui', ''], ['Geng', 'Zhi-Guo', ''], ['Xie', 'Shu-Huan', ''], ['Li', 'Yong', ''], ['Alu', 'Andrea', ''], ['Zhu', 'Jie', ''], ['Zhu', 'Xue-Feng', '']]"
1802.09884,Avinesh P.V.S.,"Avinesh P.V.S., Maxime Peyrard, Christian M. Meyer",Live Blog Corpus for Summarization,To appear in the Proceedings of LREC 2018,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Live blogs are an increasingly popular news format to cover breaking news and
live events in online journalism. Online news websites around the world are
using this medium to give their readers a minute by minute update on an event.
Good summaries enhance the value of the live blogs for a reader but are often
not available. In this paper, we study a way of collecting corpora for
automatic live blog summarization. In an empirical evaluation using well-known
state-of-the-art summarization systems, we show that live blogs corpus poses
new challenges in the field of summarization. We make our tools publicly
available to reconstruct the corpus to encourage the research community and
replicate our results.
","[{'version': 'v1', 'created': 'Tue, 27 Feb 2018 13:51:30 GMT'}]",2018-02-28,"[['S.', 'Avinesh P. V.', ''], ['Peyrard', 'Maxime', ''], ['Meyer', 'Christian M.', '']]"
2110.08959,Daichi Amagata,"Daichi Amagata, Makoto Onizuka, Takahiro Hara","Fast and Exact Outlier Detection in Metric Spaces: A Proximity
  Graph-based Approach",Accepted to SIGMOD2021,,,,cs.DB,http://creativecommons.org/licenses/by/4.0/,"  Distance-based outlier detection is widely adopted in many fields, e.g., data
mining and machine learning, because it is unsupervised, can be employed in a
generic metric space, and does not have any assumptions of data distributions.
Data mining and machine learning applications face a challenge of dealing with
large datasets, which requires efficient distance-based outlier detection
algorithms. Due to the popularization of computational environments with large
memory, it is possible to build a main-memory index and detect outliers based
on it, which is a promising solution for fast distance-based outlier detection.
Motivated by this observation, we propose a novel approach that exploits a
proximity graph. Our approach can employ an arbitrary proximity graph and
obtains a significant speed-up against state-of-the-art. However, designing an
effective proximity graph raises a challenge, because existing proximity graphs
do not consider efficient traversal for distance-based outlier detection. To
overcome this challenge, we propose a novel proximity graph, MRPG. Our
empirical study using real datasets demonstrates that MRPG detects outliers
significantly faster than the state-of-the-art algorithms.
","[{'version': 'v1', 'created': 'Mon, 18 Oct 2021 01:02:26 GMT'}, {'version': 'v2', 'created': 'Thu, 21 Oct 2021 13:24:31 GMT'}]",2021-10-22,"[['Amagata', 'Daichi', ''], ['Onizuka', 'Makoto', ''], ['Hara', 'Takahiro', '']]"
2110.01378,Santiago Badia Sb,Santiago Badia and Pere A. Martorell and Francesc Verdugo,"Geometrical discretisations for unfitted finite elements on explicit
  boundary representations",,,,,math.NA cs.CE cs.NA,http://creativecommons.org/licenses/by/4.0/,"  Unfitted (also known as embedded or immersed) finite element approximations
of partial differential equations are very attractive because they have much
lower geometrical requirements than standard body-fitted formulations. These
schemes do not require body-fitted unstructured mesh generation. In turn, the
numerical integration becomes more involved, because one has to compute
integrals on portions of cells (only the interior part). In practice, these
methods are restricted to level-set (implicit) geometrical representations,
which drastically limit their application. Complex geometries in industrial and
scientific problems are usually determined by (explicit) boundary
representations. In this work, we propose an automatic computational framework
for the discretisation of partial differential equations on domains defined by
oriented boundary meshes. The geometrical kernel that connects functional and
geometry representations generates a two-level integration mesh and a
refinement of the boundary mesh that enables the straightforward numerical
integration of all the terms in unfitted finite elements. The proposed
framework has been applied with success on all analysis-suitable oriented
boundary meshes (almost 5,000) in the Thingi10K database and combined with an
unfitted finite element formulation to discretise partial differential
equations on the corresponding domains.
","[{'version': 'v1', 'created': 'Thu, 9 Sep 2021 04:43:04 GMT'}]",2021-10-05,"[['Badia', 'Santiago', ''], ['Martorell', 'Pere A.', ''], ['Verdugo', 'Francesc', '']]"
2105.07690,Vincent Chambouleyron,"Vincent Chambouleyron, Olivier Fauvarque, Jean-Fran\c{c}ois Sauvage,
  Kjetil Dohlen, Nicolas Levraud, Arthur Vigan, Mamadou N'Diaye, Beno\^it
  Neichel, Thierry Fusco",Variation on a Zernike wavefront sensor theme: optimal use of photons,,,10.1051/0004-6361/202140870,,astro-ph.IM physics.optics,http://creativecommons.org/licenses/by/4.0/,"  The Zernike wavefront sensor (ZWFS) is a concept belonging to the wide class
Fourier-filtering wavefront sensor (FFWFS). The ZWFS is known for its extremely
high sensitivity while having a low dynamic range, which makes it a unique
sensor for second stage adaptive optics (AO) systems or quasi-static
aberrations calibration sensor. This sensor is composed of a focal plane mask
made of a phase shifting dot fully described by two parameters: its diameter
and depth. In this letter, we aim to improve the performance of this sensor by
changing the diameter of its phase shifting dot. We begin with a general
theoretical framework providing an analytical description of the FFWFS
properties, then we predict the expected ZWFS sensitivity for different
configurations of dot diameters and depths. The analytical predictions are then
validated with end-to-end simulations. From this, we propose a variation of the
classical ZWFS shape which exhibits extremely appealing properties. We show
that the ZWFS sensitivity can be optimized by modifying the dot diameter and
even reach the optimal theoretical limit, with a trade-off for low spatial
frequencies sensitivity. As an example, we show that a ZWFS with a 2{\lambda}/D
dot diameter (where {\lambda} is the sensing wavelength and D the telescope
diameter), hereafter called Z2WFS, exhibits a sensitivity twice higher than the
classical 1.06{\lambda}/D ZWFS for all the phase spatial components except for
tip-tilt modes. Furthermore, this gain in sensitivity does not impact the
dynamic range of the sensor, and the Z2WFS exhibits a similar dynamical range
as the classical 1.06{\lambda}/D ZWFS. This study opens the path to the
conception of diameter-optimized ZWFS.
","[{'version': 'v1', 'created': 'Mon, 17 May 2021 09:19:20 GMT'}]",2021-06-23,"[['Chambouleyron', 'Vincent', ''], ['Fauvarque', 'Olivier', ''], ['Sauvage', 'Jean-François', ''], ['Dohlen', 'Kjetil', ''], ['Levraud', 'Nicolas', ''], ['Vigan', 'Arthur', ''], [""N'Diaye"", 'Mamadou', ''], ['Neichel', 'Benoît', ''], ['Fusco', 'Thierry', '']]"
2102.10931,"Erich Gr\""adel","Rafael Albert and Erich Gr\""adel","Unifying Hidden-Variable Problems from Quantum Mechanics by Logics of
  Dependence and Independence",32 pages,,,,cs.LO math.LO,http://creativecommons.org/licenses/by/4.0/,"  We study hidden-variable models from quantum mechanics, and their
abstractions in purely probabilistic and relational frameworks, by means of
logics of dependence and independence, based on team semantics. We show that
common desirable properties of hidden-variable models can be defined in an
elegant and concise way in dependence and independence logic. The relationship
between different properties, and their simultaneous realisability can thus
been formulated and a proved on a purely logical level, as problems of
entailment and satisfiability of logical formulae. Connections between
probabilistic and relational entailment in dependence and independence logic
allow us to simplify proofs. In many cases, we can establish results on both
probabilistic and relational hidden-variable models by a single proof, because
one case implies the other, depending on purely syntactic criteria. We also
discuss the no-go theorems by Bell and Kochen-Specker and provide a purely
logical variant of the latter, introducing non-contextual choice as a
team-semantical property.
","[{'version': 'v1', 'created': 'Mon, 22 Feb 2021 12:04:36 GMT'}, {'version': 'v2', 'created': 'Thu, 27 Jan 2022 11:54:20 GMT'}]",2022-01-28,"[['Albert', 'Rafael', ''], ['Grädel', 'Erich', '']]"
2106.10123,Vivek Srivastava,"Vivek Srivastava, Mayank Singh","Challenges and Limitations with the Metrics Measuring the Complexity of
  Code-Mixed Text",,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Code-mixing is a frequent communication style among multilingual speakers
where they mix words and phrases from two different languages in the same
utterance of text or speech. Identifying and filtering code-mixed text is a
challenging task due to its co-existence with monolingual and noisy text. Over
the years, several code-mixing metrics have been extensively used to identify
and validate code-mixed text quality. This paper demonstrates several inherent
limitations of code-mixing metrics with examples from the already existing
datasets that are popularly used across various experiments.
","[{'version': 'v1', 'created': 'Fri, 18 Jun 2021 13:26:48 GMT'}]",2021-06-21,"[['Srivastava', 'Vivek', ''], ['Singh', 'Mayank', '']]"
2101.02377,Naoto Yanai,"Nami Ashizawa, Naoto Yanai, Jason Paul Cruz, Shingo Okamura","Eth2Vec: Learning Contract-Wide Code Representations for Vulnerability
  Detection on Ethereum Smart Contracts",,,,,cs.CR cs.LG cs.SE,http://creativecommons.org/licenses/by/4.0/,"  Ethereum smart contracts are programs that run on the Ethereum blockchain,
and many smart contract vulnerabilities have been discovered in the past
decade. Many security analysis tools have been created to detect such
vulnerabilities, but their performance decreases drastically when codes to be
analyzed are being rewritten. In this paper, we propose Eth2Vec, a
machine-learning-based static analysis tool for vulnerability detection, with
robustness against code rewrites in smart contracts. Existing
machine-learning-based static analysis tools for vulnerability detection need
features, which analysts create manually, as inputs. In contrast, Eth2Vec
automatically learns features of vulnerable Ethereum Virtual Machine (EVM)
bytecodes with tacit knowledge through a neural network for language
processing. Therefore, Eth2Vec can detect vulnerabilities in smart contracts by
comparing the code similarity between target EVM bytecodes and the EVM
bytecodes it already learned. We conducted experiments with existing open
databases, such as Etherscan, and our results show that Eth2Vec outperforms the
existing work in terms of well-known metrics, i.e., precision, recall, and
F1-score. Moreover, Eth2Vec can detect vulnerabilities even in rewritten codes.
","[{'version': 'v1', 'created': 'Thu, 7 Jan 2021 05:28:26 GMT'}, {'version': 'v2', 'created': 'Fri, 8 Jan 2021 09:57:47 GMT'}]",2021-01-11,"[['Ashizawa', 'Nami', ''], ['Yanai', 'Naoto', ''], ['Cruz', 'Jason Paul', ''], ['Okamura', 'Shingo', '']]"
1810.09301,Jia-Shu Niu,"Jia-Shu Niu, Tianjun Li, Hui-Fang Xue",Bayesian analysis of the hardening in AMS-02 nuclei spectra,"23 pages, 13 figures, 6 tables. Fitting data updated and discussions
  added","The Astrophysical Journal, 873:77 (19pp), 2019 March 1",10.3847/1538-4357/ab0420,,astro-ph.HE hep-ph,http://creativecommons.org/licenses/by/4.0/,"  Based on the precise nuclei data released by AMS-02, we study the spectra
hardening of both the primary (proton, helium, carbon, oxygen, and the primary
component of nitrogen) and the secondary (anti-proton, lithium, beryllium,
boron and the secondary component of nitrogen) cosmic ray (CR) nuclei. With the
diffusion-reacceleration model, we consider two schemes to reproduce the
hardening in the spectra: (i) A high-rigidity break in primary source
injection; (ii) A high-rigidity break in diffusion coefficient. The global
fitting results show that both schemes could reproduce the spectra hardening in
current status. More precise multi-TV data (especially the data of secondary CR
species) is needed if one wants to distinguish these two schemes. In our global
fitting, each of the nuclei species is allocated an independent solar
modulation potential and a re-scale factor (which accounts for the isotopic
abundance for primary nuclei species and uncertainties of production cross
section or inhomogeneity of CR sources and propagation for secondary nuclei
species). The fitting values of these two parameter classes show us some hints
on some new directions in CR physics. All the fitted re-scale factors of
primary nuclei species have values that systematically smaller than 1.0, while
that of secondary nuclei species are systematically larger than 1.0. Moreover,
both the re-scale factor and solar modulation potential of beryllium have
values which are obviously different from other species. This might indicate
that beryllium has the specificity not only on its propagation in the
heliosphere, but also on its production cross section. All these new results
should be seriously studied in the future.
","[{'version': 'v1', 'created': 'Mon, 22 Oct 2018 14:09:37 GMT'}, {'version': 'v2', 'created': 'Tue, 30 Oct 2018 16:48:19 GMT'}, {'version': 'v3', 'created': 'Sun, 20 Jan 2019 16:52:54 GMT'}]",2019-03-07,"[['Niu', 'Jia-Shu', ''], ['Li', 'Tianjun', ''], ['Xue', 'Hui-Fang', '']]"
2110.12802,Aljoscha Sander,"Aljoscha Sander, Bas Holman and Andreas Haselsteiner","Could mass eccentricity explain the formation of orbits in wind
  turbines?",,,,,physics.ao-ph physics.app-ph physics.class-ph,http://creativecommons.org/licenses/by/4.0/,"  The kinematics of offshore wind turbines are of great importance when
installing the turbines, as the motions of the components during craning
operations are a limiting factor. Most critical is the installation of the
blades: the blade's bolts need to be inserted into the rotor flange, an
operation that requires great precision. Both the blade and the turbine undergo
environmental loading, leading to relative motions between the blade root and
the hub during installation. Results from an offshore wind farm installation
measurement campaign showed, that the partially installed turbines show
intricate patterns of motion (orbits) in the horizontal plane. The mechanism
behind the formation of these orbits remains elusive so far.
  In this paper, we present a novel torsional coupling mechanism linking
motions in the fore-aft and side-side direction. It can explain the formation
of orbits that change direction.
","[{'version': 'v1', 'created': 'Mon, 25 Oct 2021 10:59:36 GMT'}]",2021-10-26,"[['Sander', 'Aljoscha', ''], ['Holman', 'Bas', ''], ['Haselsteiner', 'Andreas', '']]"
1708.09702,Alexander Panchenko,"Alexander Panchenko, Dmitry Ustalov, Nikolay Arefyev, Denis Paperno,
  Natalia Konstantinova, Natalia Loukachevitch, and Chris Biemann",Human and Machine Judgements for Russian Semantic Relatedness,,"In Proceedings of the 5th Conference on Analysis of Images, Social
  Networks, and Texts (AIST'2016): Springer Communications in Computer and
  Information Sciences (CCIS)",10.1007/978-3-319-52920-2_21,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Semantic relatedness of terms represents similarity of meaning by a numerical
score. On the one hand, humans easily make judgments about semantic
relatedness. On the other hand, this kind of information is useful in language
processing systems. While semantic relatedness has been extensively studied for
English using numerous language resources, such as associative norms, human
judgments, and datasets generated from lexical databases, no evaluation
resources of this kind have been available for Russian to date. Our
contribution addresses this problem. We present five language resources of
different scale and purpose for Russian semantic relatedness, each being a list
of triples (word_i, word_j, relatedness_ij). Four of them are designed for
evaluation of systems for computing semantic relatedness, complementing each
other in terms of the semantic relation type they represent. These benchmarks
were used to organize a shared task on Russian semantic relatedness, which
attracted 19 teams. We use one of the best approaches identified in this
competition to generate the fifth high-coverage resource, the first open
distributional thesaurus of Russian. Multiple evaluations of this thesaurus,
including a large-scale crowdsourcing study involving native speakers, indicate
its high accuracy.
","[{'version': 'v1', 'created': 'Thu, 31 Aug 2017 13:33:04 GMT'}]",2018-05-21,"[['Panchenko', 'Alexander', ''], ['Ustalov', 'Dmitry', ''], ['Arefyev', 'Nikolay', ''], ['Paperno', 'Denis', ''], ['Konstantinova', 'Natalia', ''], ['Loukachevitch', 'Natalia', ''], ['Biemann', 'Chris', '']]"
2104.10247,Ian Porada,"Ian Porada, Kaheer Suleman, Adam Trischler, and Jackie Chi Kit Cheung",Modeling Event Plausibility with Consistent Conceptual Abstraction,NAACL-HLT 2021,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Understanding natural language requires common sense, one aspect of which is
the ability to discern the plausibility of events. While distributional models
-- most recently pre-trained, Transformer language models -- have demonstrated
improvements in modeling event plausibility, their performance still falls
short of humans'. In this work, we show that Transformer-based plausibility
models are markedly inconsistent across the conceptual classes of a lexical
hierarchy, inferring that ""a person breathing"" is plausible while ""a dentist
breathing"" is not, for example. We find this inconsistency persists even when
models are softly injected with lexical knowledge, and we present a simple
post-hoc method of forcing model consistency that improves correlation with
human plausibility judgements.
","[{'version': 'v1', 'created': 'Tue, 20 Apr 2021 21:08:32 GMT'}]",2021-04-22,"[['Porada', 'Ian', ''], ['Suleman', 'Kaheer', ''], ['Trischler', 'Adam', ''], ['Cheung', 'Jackie Chi Kit', '']]"
2110.00221,Alexandre Emsenhuber,"Alexandre Emsenhuber, Erik Asphaug, Saverio Cambioni, Travis S. J.
  Gabriel, Stephen R. Schwartz","Collision Chains among the Terrestrial Planets. II. An Asymmetry between
  Earth and Venus","18 pages, 9 figures, 4 tables. Published in PSJ, article available at
  https://iopscience.iop.org/article/10.3847/PSJ/ac19b1",Planet. Sci. J. 2:199 (2021),10.3847/PSJ/ac19b1,,astro-ph.EP,http://creativecommons.org/licenses/by/4.0/,"  During the late stage of terrestrial planet formation, hit-and-run collisions
are about as common as accretionary mergers, for expected velocities and angles
of giant impacts. Average hit-and-runs leave two major remnants plus debris:
the target and impactor, somewhat modified through erosion, escaping at lower
relative velocity. Here we continue our study of the dynamical effects of such
collisions. We compare the dynamical fates of intact runners that start from
hit-and-runs with proto-Venus at 0.7 AU and proto-Earth at 1.0 AU. We follow
the orbital evolutions of the runners, including the other terrestrial planets,
Jupiter, and Saturn, in an N-body code. We find that the accretion of these
runners can take $\gtrsim$10 Myr (depending on the egress velocity of the first
collision) and can involve successive collisions with the original target
planet or with other planets. We treat successive collisions that the runner
experiences using surrogate models from machine learning, as in previous work,
and evolve subsequent hit-and-runs in a similar fashion. We identify
asymmetries in the capture, loss, and interchange of runners in the growth of
Venus and Earth. Hit-and-run is a more probable outcome at proto-Venus, being
smaller and faster orbiting than proto-Earth. But Venus acts as a sink,
eventually accreting most of its runners, assuming typical events, whereas
proto-Earth loses about half, many of those continuing to Venus. This leads to
a disparity in the style of late-stage accretion that could have led to
significant differences in geology, composition, and satellite formation at
Earth and Venus.
","[{'version': 'v1', 'created': 'Fri, 1 Oct 2021 05:30:54 GMT'}]",2021-10-04,"[['Emsenhuber', 'Alexandre', ''], ['Asphaug', 'Erik', ''], ['Cambioni', 'Saverio', ''], ['Gabriel', 'Travis S. J.', ''], ['Schwartz', 'Stephen R.', '']]"
2106.06243,Sevvandi Kandanaarachchi,Sevvandi Kandanaarachchi,Unsupervised Anomaly Detection Ensembles using Item Response Theory,25 pages,,,,stat.ML cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Constructing an ensemble from a heterogeneous set of unsupervised anomaly
detection methods is challenging because the class labels or the ground truth
is unknown. Thus, traditional ensemble techniques that use the response
variable or the class labels cannot be used to construct an ensemble for
unsupervised anomaly detection.
  We use Item Response Theory (IRT) -- a class of models used in educational
psychometrics to assess student and test question characteristics -- to
construct an unsupervised anomaly detection ensemble. IRT's latent trait
computation lends itself to anomaly detection because the latent trait can be
used to uncover the hidden ground truth. Using a novel IRT mapping to the
anomaly detection problem, we construct an ensemble that can downplay noisy,
non-discriminatory methods and accentuate sharper methods. We demonstrate the
effectiveness of the IRT ensemble on an extensive data repository, by comparing
its performance to other ensemble techniques.
","[{'version': 'v1', 'created': 'Fri, 11 Jun 2021 08:51:26 GMT'}]",2021-06-14,"[['Kandanaarachchi', 'Sevvandi', '']]"
2009.12597,Anwaar Ulhaq Dr,"Douglas P. S. Gomes, Anwaar Ulhaq, Manoranjan Paul, Michael J. Horry,
  Subrata Chakraborty, Manas Saha, Tanmoy Debnath, D.M. Motiur Rahaman",Potential Features of ICU Admission in X-ray Images of COVID-19 Patients,,,,,eess.IV cs.CV,http://creativecommons.org/licenses/by/4.0/,"  X-ray images may present non-trivial features with predictive information of
patients that develop severe symptoms of COVID-19. If true, this hypothesis may
have practical value in allocating resources to particular patients while using
a relatively inexpensive imaging technique. The difficulty of testing such a
hypothesis comes from the need for large sets of labelled data, which need to
be well-annotated and should contemplate the post-imaging severity outcome.
This paper presents an original methodology for extracting semantic features
that correlate to severity from a data set with patient ICU admission labels
through interpretable models. The methodology employs a neural network trained
to recognise lung pathologies to extract the semantic features, which are then
analysed with low-complexity models to limit overfitting while increasing
interpretability. This analysis points out that only a few features explain
most of the variance between patients that developed severe symptoms. When
applied to an unrelated larger data set with pathology-related clinical notes,
the method has shown to be capable of selecting images for the learned
features, which could translate some information about their common locations
in the lung. Besides attesting separability on patients that eventually develop
severe symptoms, the proposed methods represent a statistical approach
highlighting the importance of features related to ICU admission that may have
been only qualitatively reported. While handling limited data sets, notable
methodological aspects are adopted, such as presenting a state-of-the-art lung
segmentation network and the use of low-complexity models to avoid overfitting.
The code for methodology and experiments is also available.
","[{'version': 'v1', 'created': 'Sat, 26 Sep 2020 13:48:39 GMT'}, {'version': 'v2', 'created': 'Thu, 21 Jan 2021 12:43:04 GMT'}]",2021-01-22,"[['Gomes', 'Douglas P. S.', ''], ['Ulhaq', 'Anwaar', ''], ['Paul', 'Manoranjan', ''], ['Horry', 'Michael J.', ''], ['Chakraborty', 'Subrata', ''], ['Saha', 'Manas', ''], ['Debnath', 'Tanmoy', ''], ['Rahaman', 'D. M. Motiur', '']]"
2111.08269,Shasha Han,"Shasha Han, Shuangchi He, Hong Choon Oh",Data-Driven Inpatient Bed Assignment Using the P Model,,,,,math.OC stat.ME,http://creativecommons.org/licenses/by/4.0/,"  Problem definition: Emergency department (ED) boarding refers to the practice
of holding patients in the ED after they have been admitted to hospital wards,
usually resulting from insufficient inpatient resources. Boarded patients may
compete with new patients for medical resources in the ED, compromising the
quality of emergency care. A common expedient for mitigating boarding is
patient overflowing, i.e., sending patients to beds in other specialties or
accommodation classes, which may compromise the quality of inpatient care and
bring on operational challenges. We study inpatient bed assignment to shorten
boarding times without excessive patient overflowing.
  Methodology: We use a queue with multiple customer classes and multiple
server pools to model hospital wards. Exploiting patient flow data from a
hospital, we propose a computationally tractable approach to formulating the
bed assignment problem, where the joint probability of all waiting patients
meeting their respective delay targets is maximized.
  Results: By dynamically adjusting the overflow rate, the proposed approach is
capable not only of reducing patients' waiting times, but also of mitigating
the time-of-day effect on boarding times. In numerical experiments, our
approach greatly outperforms both early discharge policies and threshold-based
overflowing policies, which are commonly used in practice.
  Managerial implications: We provide a practicable approach to solving the bed
assignment problem. This data-driven approach captures critical features of
patient flow management, while the resulting optimization problem is
practically solvable. The proposed approach is a useful tool for the control of
queueing systems with time-sensitive service requirements.
","[{'version': 'v1', 'created': 'Tue, 16 Nov 2021 07:39:36 GMT'}]",2021-11-17,"[['Han', 'Shasha', ''], ['He', 'Shuangchi', ''], ['Oh', 'Hong Choon', '']]"
2201.03780,Jinglin Zhao,Jinglin Zhao and Eric B. Ford,"FIESTA II. Disentangling stellar and instrumental variability from
  exoplanetary Doppler shifts in Fourier domain",,,,,astro-ph.EP astro-ph.IM astro-ph.SR,http://creativecommons.org/licenses/by/4.0/,"  The radial velocity (RV) detection of exoplanets is complicated by stellar
spectroscopic variability that can mimic the presence of planets, as well as by
instrumental instability. These distort the spectral line profiles and can be
misinterpreted as apparent RV shifts.
  We present the improved FourIEr phase SpecTrum Analysis (FIESTA a.k.a.
$\mathit{\Phi}$ESTA) to disentangle apparent RV shifts due to a line
deformation from a true Doppler shift.
  $\mathit{\Phi}$ESTA projects stellar spectrum's cross correlation function
(CCF) onto the truncated Fourier basis functions. Using the amplitude and phase
information from each $\mathit{\Phi}$ESTA mode, we can trace the line
variability at different CCF width scale robustly to identify and mitigate
multiple sources of RV contamination.
  We test $\mathit{\Phi}$ESTA metrics on the SOAP 2.0 solar simulations and
find some strong correlations with the apparent RVs induced by sunspots. We
apply $\mathit{\Phi}$ESTA to 3 years HARPS-N solar observations and demonstrate
that $\mathit{\Phi}$ESTA is capable of identifying multiple sources of the
spurious solar RV variations, including stellar rotation, the long-term trend
from the solar magnetic cycle, instrumental instability and apparent solar
rotation rate changes. Applying a simple multi-linear regression model,
$\mathit{\Phi}$ESTA reduces the weighted RMS from 1.89~m/s to 0.98~m/s, a 48%
reduction in the weighted RMS, better than applying a similar multi-linear
regression to FWHM and BIS.
","[{'version': 'v1', 'created': 'Tue, 11 Jan 2022 04:52:28 GMT'}]",2022-01-12,"[['Zhao', 'Jinglin', ''], ['Ford', 'Eric B.', '']]"
2102.07755,Yishay Klein Mr,"Y. Klein, O. Sefi, H. Schwartz, and S. Shwartz",Chemical element mapping by x-ray ghost fluorescence,,,,,physics.optics physics.chem-ph physics.med-ph,http://creativecommons.org/licenses/by/4.0/,"  Chemical element mapping is an imaging tool that provides essential
information on composite materials and it is crucial for a broad range of
fields ranging from fundamental science to numerous applications. Methods that
exploit x-ray fluorescence are very advantageous and are widely used, but
require focusing of the input beam and raster scanning of the sample. Thus the
methods are slow and exhibit limited resolution due to focusing challenges. We
demonstrate a new focusing free x-ray fluorescence method based ghost imaging
that overcomes those limitations. We combine our procedure with compressed
sensing to reduce the measurement time and the exposure to radiation by more
than 80%. Since our method does not require focusing, it opens the possibility
for improving the resolution and image quality of chemical element maps with
tabletop x-ray sources and for extending the applicability of x-ray
fluorescence detection to new fields such as medical imaging and homeland
security applications
","[{'version': 'v1', 'created': 'Mon, 15 Feb 2021 18:51:04 GMT'}]",2021-02-16,"[['Klein', 'Y.', ''], ['Sefi', 'O.', ''], ['Schwartz', 'H.', ''], ['Shwartz', 'S.', '']]"
2111.07574,Ahmed Alkhateeb,"Gouranga Charan, Tawfik Osman, Andrew Hredzak, Ngwe Thawdar, and Ahmed
  Alkhateeb","Vision-Position Multi-Modal Beam Prediction Using Real Millimeter Wave
  Datasets","Dataset and code files will be available on the DeepSense 6G website
  http://deepsense6g.net/",,,,eess.SP cs.IT math.IT,http://creativecommons.org/licenses/by/4.0/,"  Enabling highly-mobile millimeter wave (mmWave) and terahertz (THz) wireless
communication applications requires overcoming the critical challenges
associated with the large antenna arrays deployed at these systems. In
particular, adjusting the narrow beams of these antenna arrays typically incurs
high beam training overhead that scales with the number of antennas. To address
these challenges, this paper proposes a multi-modal machine learning based
approach that leverages positional and visual (camera) data collected from the
wireless communication environment for fast beam prediction. The developed
framework has been tested on a real-world vehicular dataset comprising
practical GPS, camera, and mmWave beam training data. The results show the
proposed approach achieves more than $\approx$ 75\% top-1 beam prediction
accuracy and close to 100\% top-3 beam prediction accuracy in realistic
communication scenarios.
","[{'version': 'v1', 'created': 'Mon, 15 Nov 2021 07:43:43 GMT'}]",2021-11-16,"[['Charan', 'Gouranga', ''], ['Osman', 'Tawfik', ''], ['Hredzak', 'Andrew', ''], ['Thawdar', 'Ngwe', ''], ['Alkhateeb', 'Ahmed', '']]"
2101.11434,Fatemah Husain,Fatemah Husain and Ozlem Uzuner,Exploratory Arabic Offensive Language Dataset Analysis,83 pages,,,,cs.CL cs.CY,http://creativecommons.org/licenses/by/4.0/,"  This paper adding more insights towards resources and datasets used in Arabic
offensive language research. The main goal of this paper is to guide
researchers in Arabic offensive language in selecting appropriate datasets
based on their content, and in creating new Arabic offensive language resources
to support and complement the available ones.
","[{'version': 'v1', 'created': 'Wed, 20 Jan 2021 23:45:33 GMT'}]",2021-01-28,"[['Husain', 'Fatemah', ''], ['Uzuner', 'Ozlem', '']]"
2111.04198,Yixuan Su,"Yixuan Su and Fangyu Liu and Zaiqiao Meng and Tian Lan and Lei Shu and
  Ehsan Shareghi and Nigel Collier",TaCL: Improving BERT Pre-training with Token-aware Contrastive Learning,Work in progress; (v2 added BERT-large results),,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Masked language models (MLMs) such as BERT and RoBERTa have revolutionized
the field of Natural Language Understanding in the past few years. However,
existing pre-trained MLMs often output an anisotropic distribution of token
representations that occupies a narrow subset of the entire representation
space. Such token representations are not ideal, especially for tasks that
demand discriminative semantic meanings of distinct tokens. In this work, we
propose TaCL (Token-aware Contrastive Learning), a novel continual pre-training
approach that encourages BERT to learn an isotropic and discriminative
distribution of token representations. TaCL is fully unsupervised and requires
no additional data. We extensively test our approach on a wide range of English
and Chinese benchmarks. The results show that TaCL brings consistent and
notable improvements over the original BERT model. Furthermore, we conduct
detailed analysis to reveal the merits and inner-workings of our approach.
","[{'version': 'v1', 'created': 'Sun, 7 Nov 2021 22:54:23 GMT'}, {'version': 'v2', 'created': 'Tue, 9 Nov 2021 20:53:09 GMT'}, {'version': 'v3', 'created': 'Fri, 10 Dec 2021 11:40:26 GMT'}]",2021-12-13,"[['Su', 'Yixuan', ''], ['Liu', 'Fangyu', ''], ['Meng', 'Zaiqiao', ''], ['Lan', 'Tian', ''], ['Shu', 'Lei', ''], ['Shareghi', 'Ehsan', ''], ['Collier', 'Nigel', '']]"
2103.06314,Chong-Sun Chu,Chong-Sun Chu and H. S. Tan,Generalized Darmois-Israel junction conditions,56 pages. v2: add more comments on the literature,,,,hep-th astro-ph.CO gr-qc,http://creativecommons.org/licenses/by/4.0/,"  We present a general method to derive the appropriate Darmois-Israel junction
conditions for gravitational theories with higher-order derivative terms by
integrating the bulk equations of motion across the singular hypersurface. In
higher derivative theories, the field equations can contain terms which are
more singular than the Dirac delta distribution. To handle them appropriately,
we formulate a regularization procedure based on representing the delta
function as the limit of a sequence of classical functions. This procedure
involves imposing suitable constraints on the extrinsic curvature such that the
field equations are compatible with the singular source being a delta
distribution. As explicit examples of our approach, we demonstrate in detail
how to obtain the generalized junction conditions for quadratic gravity,
$\mathcal{F}(R)$ theories, a 4D low-energy effective action in string theory
and action terms that are Euler densities. Our results are novel, and refine
the accuracy of previously claimed results in $\mathcal{F} (R)$ theories and
quadratic gravity. In particular, when the coupling constants of quadratic
gravity are those for the Gauss-Bonnet case, our junction conditions reduce to
the known ones for the latter obtained independently by boundary variation of a
surface term in the action. Finally, we briefly discuss a couple of
applications to thin-shell wormholes and stellar models.
","[{'version': 'v1', 'created': 'Wed, 10 Mar 2021 19:43:01 GMT'}, {'version': 'v2', 'created': 'Sat, 24 Apr 2021 04:28:52 GMT'}]",2021-04-27,"[['Chu', 'Chong-Sun', ''], ['Tan', 'H. S.', '']]"
2201.05115,Guillaume Staerman,"Guillaume Staerman, Eric Adjakossa, Pavlo Mozharovskyi, Vera Hofer,
  Jayant Sen Gupta and Stephan Cl\'emen\c{c}on",Functional Anomaly Detection: a Benchmark Study,,,,,stat.ML cs.LG,http://creativecommons.org/licenses/by/4.0/,"  The increasing automation in many areas of the Industry expressly demands to
design efficient machine-learning solutions for the detection of abnormal
events. With the ubiquitous deployment of sensors monitoring nearly
continuously the health of complex infrastructures, anomaly detection can now
rely on measurements sampled at a very high frequency, providing a very rich
representation of the phenomenon under surveillance. In order to exploit fully
the information thus collected, the observations cannot be treated as
multivariate data anymore and a functional analysis approach is required. It is
the purpose of this paper to investigate the performance of recent techniques
for anomaly detection in the functional setup on real datasets. After an
overview of the state-of-the-art and a visual-descriptive study, a variety of
anomaly detection methods are compared. While taxonomies of abnormalities (e.g.
shape, location) in the functional setup are documented in the literature,
assigning a specific type to the identified anomalies appears to be a
challenging task. Thus, strengths and weaknesses of the existing approaches are
benchmarked in view of these highlighted types in a simulation study. Anomaly
detection methods are next evaluated on two datasets, related to the monitoring
of helicopters in flight and to the spectrometry of construction materials
namely. The benchmark analysis is concluded by recommendation guidance for
practitioners.
","[{'version': 'v1', 'created': 'Thu, 13 Jan 2022 18:20:32 GMT'}]",2022-01-14,"[['Staerman', 'Guillaume', ''], ['Adjakossa', 'Eric', ''], ['Mozharovskyi', 'Pavlo', ''], ['Hofer', 'Vera', ''], ['Gupta', 'Jayant Sen', ''], ['Clémençon', 'Stephan', '']]"
2012.14288,Pengtao Xie,"Xingchen Zhao, Xuehai He, Pengtao Xie","Learning by Ignoring, with Application to Domain Adaptation",,,,,cs.LG cs.AI cs.CV,http://creativecommons.org/licenses/by/4.0/,"  Learning by ignoring, which identifies less important things and excludes
them from the learning process, is broadly practiced in human learning and has
shown ubiquitous effectiveness. There has been psychological studies showing
that learning to ignore certain things is a powerful tool for helping people
focus. In this paper, we explore whether this useful human learning methodology
can be borrowed to improve machine learning. We propose a novel machine
learning framework referred to as learning by ignoring (LBI). Our framework
automatically identifies pretraining data examples that have large domain shift
from the target distribution by learning an ignoring variable for each example
and excludes them from the pretraining process. We formulate LBI as a
three-level optimization framework where three learning stages are involved:
pretraining by minimizing the losses weighed by ignoring variables; finetuning;
updating the ignoring variables by minimizing the validation loss. A
gradient-based algorithm is developed to efficiently solve the three-level
optimization problem in LBI. Experiments on various datasets demonstrate the
effectiveness of our framework.
","[{'version': 'v1', 'created': 'Mon, 28 Dec 2020 15:33:41 GMT'}, {'version': 'v2', 'created': 'Thu, 11 Mar 2021 04:56:23 GMT'}]",2021-03-12,"[['Zhao', 'Xingchen', ''], ['He', 'Xuehai', ''], ['Xie', 'Pengtao', '']]"
2112.04489,Lasse Hansen,"Alessa Hering, Lasse Hansen, Tony C. W. Mok, Albert C. S. Chung, Hanna
  Siebert, Stephanie H\""ager, Annkristin Lange, Sven Kuckertz, Stefan Heldmann,
  Wei Shao, Sulaiman Vesal, Mirabela Rusu, Geoffrey Sonn, Th\'eo Estienne,
  Maria Vakalopoulou, Luyi Han, Yunzhi Huang, Mikael Brudfors, Ya\""el
  Balbastre, SamuelJ outard, Marc Modat, Gal Lifshitz, Dan Raviv, Jinxin Lv,
  Qiang Li, Vincent Jaouen, Dimitris Visvikis, Constance Fourcade, Mathieu
  Rubeaux, Wentao Pan, Zhe Xu, Bailiang Jian, Francesca De Benetti, Marek
  Wodzinski, Niklas Gunnarsson, Jens Sj\""olund, Huaqi Qiu, Zeju Li, Christoph
  Gro{\ss}br\""ohmer, Andrew Hoopes, Ingerid Reinertsen, Yiming Xiao, Bennett
  Landman, Yuankai Huo, Keelin Murphy, Nikolas Lessmann, Bram van Ginneken,
  Adrian V. Dalca, Mattias P. Heinrich","Learn2Reg: comprehensive multi-task medical image registration
  challenge, dataset and evaluation in the era of deep learning",,,,,eess.IV cs.CV,http://creativecommons.org/licenses/by/4.0/,"  Image registration is a fundamental medical image analysis task, and a wide
variety of approaches have been proposed. However, only a few studies have
comprehensively compared medical image registration approaches on a wide range
of clinically relevant tasks, in part because of the lack of availability of
such diverse data. This limits the development of registration methods, the
adoption of research advances into practice, and a fair benchmark across
competing approaches. The Learn2Reg challenge addresses these limitations by
providing a multi-task medical image registration benchmark for comprehensive
characterisation of deformable registration algorithms. A continuous evaluation
will be possible at https://learn2reg.grand-challenge.org. Learn2Reg covers a
wide range of anatomies (brain, abdomen, and thorax), modalities (ultrasound,
CT, MR), availability of annotations, as well as intra- and inter-patient
registration evaluation. We established an easily accessible framework for
training and validation of 3D registration methods, which enabled the
compilation of results of over 65 individual method submissions from more than
20 unique teams. We used a complementary set of metrics, including robustness,
accuracy, plausibility, and runtime, enabling unique insight into the current
state-of-the-art of medical image registration. This paper describes datasets,
tasks, evaluation methods and results of the challenge, and the results of
further analysis of transferability to new datasets, the importance of label
supervision, and resulting bias.
","[{'version': 'v1', 'created': 'Wed, 8 Dec 2021 09:46:39 GMT'}, {'version': 'v2', 'created': 'Thu, 23 Dec 2021 10:17:54 GMT'}]",2021-12-24,"[['Hering', 'Alessa', ''], ['Hansen', 'Lasse', ''], ['Mok', 'Tony C. W.', ''], ['Chung', 'Albert C. S.', ''], ['Siebert', 'Hanna', ''], ['Häger', 'Stephanie', ''], ['Lange', 'Annkristin', ''], ['Kuckertz', 'Sven', ''], ['Heldmann', 'Stefan', ''], ['Shao', 'Wei', ''], ['Vesal', 'Sulaiman', ''], ['Rusu', 'Mirabela', ''], ['Sonn', 'Geoffrey', ''], ['Estienne', 'Théo', ''], ['Vakalopoulou', 'Maria', ''], ['Han', 'Luyi', ''], ['Huang', 'Yunzhi', ''], ['Brudfors', 'Mikael', ''], ['Balbastre', 'Yaël', ''], ['outard', 'SamuelJ', ''], ['Modat', 'Marc', ''], ['Lifshitz', 'Gal', ''], ['Raviv', 'Dan', ''], ['Lv', 'Jinxin', ''], ['Li', 'Qiang', ''], ['Jaouen', 'Vincent', ''], ['Visvikis', 'Dimitris', ''], ['Fourcade', 'Constance', ''], ['Rubeaux', 'Mathieu', ''], ['Pan', 'Wentao', ''], ['Xu', 'Zhe', ''], ['Jian', 'Bailiang', ''], ['De Benetti', 'Francesca', ''], ['Wodzinski', 'Marek', ''], ['Gunnarsson', 'Niklas', ''], ['Sjölund', 'Jens', ''], ['Qiu', 'Huaqi', ''], ['Li', 'Zeju', ''], ['Großbröhmer', 'Christoph', ''], ['Hoopes', 'Andrew', ''], ['Reinertsen', 'Ingerid', ''], ['Xiao', 'Yiming', ''], ['Landman', 'Bennett', ''], ['Huo', 'Yuankai', ''], ['Murphy', 'Keelin', ''], ['Lessmann', 'Nikolas', ''], ['van Ginneken', 'Bram', ''], ['Dalca', 'Adrian V.', ''], ['Heinrich', 'Mattias P.', '']]"
2110.14953,Donggyun Kim,"Donggyun Kim, Seongwoong Cho, Wonkwang Lee, Seunghoon Hong",Multi-Task Neural Processes,"33 pages, 13 figures",,,,cs.LG stat.ML,http://creativecommons.org/licenses/by/4.0/,"  Neural Processes (NPs) consider a task as a function realized from a
stochastic process and flexibly adapt to unseen tasks through inference on
functions. However, naive NPs can model data from only a single stochastic
process and are designed to infer each task independently. Since many
real-world data represent a set of correlated tasks from multiple sources
(e.g., multiple attributes and multi-sensor data), it is beneficial to infer
them jointly and exploit the underlying correlation to improve the predictive
performance. To this end, we propose Multi-Task Neural Processes (MTNPs), an
extension of NPs designed to jointly infer tasks realized from multiple
stochastic processes. We build MTNPs in a hierarchical way such that inter-task
correlation is considered by conditioning all per-task latent variables on a
single global latent variable. In addition, we further design our MTNPs so that
they can address multi-task settings with incomplete data (i.e., not all tasks
share the same set of input points), which has high practical demands in
various applications. Experiments demonstrate that MTNPs can successfully model
multiple tasks jointly by discovering and exploiting their correlations in
various real-world data such as time series of weather attributes and
pixel-aligned visual modalities. We release our code at
https://github.com/GitGyun/multi_task_neural_processes.
","[{'version': 'v1', 'created': 'Thu, 28 Oct 2021 08:45:43 GMT'}, {'version': 'v2', 'created': 'Fri, 29 Oct 2021 11:43:39 GMT'}, {'version': 'v3', 'created': 'Sun, 6 Feb 2022 05:44:31 GMT'}, {'version': 'v4', 'created': 'Wed, 16 Feb 2022 03:07:26 GMT'}]",2022-02-17,"[['Kim', 'Donggyun', ''], ['Cho', 'Seongwoong', ''], ['Lee', 'Wonkwang', ''], ['Hong', 'Seunghoon', '']]"
2109.00424,Gavin Lamb P,"Gavin P Lamb, Joseph J Fern\'andez, Fergus Hayes, Albert K H Kong,
  En-Tzu Lin, Nial R Tanvir, Martin Hendry, Ik Siong Heng, Surojit Saha, John
  Veitch",Inclination estimates from off-axis GRB afterglow modelling,"14 pages, 5 figures, Accepted to the special issue of Universe,
  ""Waiting for GODOT -- Present and Future of Multi-Messenger Astronomy""",,10.20944/preprints202108.0033.v1,,astro-ph.HE,http://creativecommons.org/licenses/by/4.0/,"  For gravitational wave (GW) detected neutron star mergers, one of the leading
candidates for electromagnetic (EM) counterparts is the afterglow from an
ultra-relativistic jet. Where this afterglow is observed, it will likely be
viewed off-axis, such as the afterglow following GW170817/GRB 170817A. The
temporal behaviour of an off-axis observed GRB afterglow can be used to reveal
the lateral jet structure, and statistical model fits can put constraints on
the various model free-parameters. Amongst these parameters is the inclination
of the system to the line of sight. Along with the GW detection, the afterglow
modelling provides the best constraint on the inclination to the line-of-sight
and can improve the estimates of cosmological parameters e.g. the Hubble
constant, from GW-EM events. However, modelling of the afterglow depends on the
assumed jet structure and, often overlooked, the effects of lateral spreading.
Here we show how the inclusion of lateral spreading in the afterglow models can
affect the estimated inclination of GW-EM events.
","[{'version': 'v1', 'created': 'Wed, 1 Sep 2021 15:15:46 GMT'}]",2021-09-02,"[['Lamb', 'Gavin P', ''], ['Fernández', 'Joseph J', ''], ['Hayes', 'Fergus', ''], ['Kong', 'Albert K H', ''], ['Lin', 'En-Tzu', ''], ['Tanvir', 'Nial R', ''], ['Hendry', 'Martin', ''], ['Heng', 'Ik Siong', ''], ['Saha', 'Surojit', ''], ['Veitch', 'John', '']]"
2012.06888,The CMS Collaboration,CMS Collaboration,"Electron and photon reconstruction and identification with the CMS
  experiment at the CERN LHC","Replaced with the published version. Added the journal reference and
  the DOI. All the figures and tables can be found at
  http://cms-results.web.cern.ch/cms-results/public-results/publications/EGM-17-001
  (CMS Public Pages)",JINST 16 (2021) P05014,10.1088/1748-0221/16/05/P05014,"CMS-EGM-17-001, CERN-EP-2020-219",hep-ex physics.ins-det,http://creativecommons.org/licenses/by/4.0/,"  The performance is presented of the reconstruction and identification
algorithms for electrons and photons with the CMS experiment at the LHC. The
reported results are based on proton-proton collision data collected at a
center-of-mass energy of 13 TeV and recorded in 2016-2018, corresponding to an
integrated luminosity of 136 fb$^{-1}$. Results obtained from lead-lead
collision data collected at $\sqrt{s_\mathrm{NN}} =$ 5.02 TeV are also
presented. Innovative techniques are used to reconstruct the electron and
photon signals in the detector and to optimize the energy resolution. Events
with electrons and photons in the final state are used to measure the energy
resolution and energy scale uncertainty in the recorded events. The measured
energy resolution for electrons produced in Z boson decays in proton-proton
collision data ranges from 2 to 5%, depending on electron pseudorapidity and
energy loss through bremsstrahlung in the detector material. The energy scale
in the same range of energies is measured with an uncertainty smaller than 0.1
(0.3)% in the barrel (endcap) region in proton-proton collisions and better
than 1 (3)% in the barrel (endcap) region in heavy ion collisions. The timing
resolution for electrons from Z boson decays with the full 2016-2018
proton-proton collision data set is measured to be 200 ps.
","[{'version': 'v1', 'created': 'Sat, 12 Dec 2020 19:08:13 GMT'}, {'version': 'v2', 'created': 'Mon, 17 May 2021 23:09:51 GMT'}]",2021-05-19,"[['CMS Collaboration', '', '']]"
2105.05822,Michiko Ohishi,"Michiko Ohishi, Luan Arbeletche, Vitor de Souza, Gernot Maier, Konrad
  Bernl\""ohr, Abelardo Moralejo Olaizola, Johan Bregeon, Luisa Arrabito,
  Takanori Yoshikoshi","Effect of the uncertainty in the hadronic interaction models on the
  estimation of the sensitivity of the Cherenkov Telescope Array","23 pages, 10 figures, accepted for publication in JPhysG",,10.1088/1361-6471/abfce0,,astro-ph.IM astro-ph.HE,http://creativecommons.org/licenses/by/4.0/,"  Imaging Atmospheric Cherenkov Telescopes (IACTs) are ground-based indirect
detectors for cosmic gamma rays with energies above tens of GeV. The major
backgrounds for gamma-ray observations in IACTs are cosmic-ray charged
particles. The capability to reject these backgrounds is the most important
factor determining the gamma-ray sensitivity of IACT systems. Monte Carlo
simulations are used to estimate the residual background rates and sensitivity
of the systems during the design and construction phase. Uncertainties in the
modeling of high-energy hadronic interactions of cosmic rays with nuclei in the
air propagate into the estimates of residual background rates and subsequently
into the estimated instrument sensitivity. We investigate the influence of the
difference in the current hadronic interaction models on the estimated
gamma-ray sensitivity of the Cherenkov Telescope Array using four interaction
models (QGSJET-II-03, QGSJET-II-04, EPOS-LHC, and SIBYLL2.3c) implemented in
the air shower simulation tool CORSIKA. Variations in background rates of up to
a factor 2 with respect to QGSJET-II-03 are observed between the models, mainly
due to differences in the $\pi^0$ production spectrum. These lead to ~30%
differences in the estimated gamma-ray sensitivity in the 1 - 30 TeV region,
assuming a 50-hour observation of a gamma-ray point-like source. The presented
results also show that IACTs have a significant capability in the verification
of hadronic interaction models.
","[{'version': 'v1', 'created': 'Wed, 12 May 2021 17:34:28 GMT'}]",2021-05-13,"[['Ohishi', 'Michiko', ''], ['Arbeletche', 'Luan', ''], ['de Souza', 'Vitor', ''], ['Maier', 'Gernot', ''], ['Bernlöhr', 'Konrad', ''], ['Olaizola', 'Abelardo Moralejo', ''], ['Bregeon', 'Johan', ''], ['Arrabito', 'Luisa', ''], ['Yoshikoshi', 'Takanori', '']]"
2108.10572,Lihua Ruan PhD,"Lihua Ruan, Lingjie Duan, and Jianwei Huang",Optimal UAV Hitching on Ground Vehicles,,,,,cs.NI eess.SP,http://creativecommons.org/licenses/by/4.0/,"  Due to its mobility and agility, unmanned aerial vehicle (UAV) has emerged as
a promising technology for various tasks, such as sensing, inspection and
delivery. However, a typical UAV has limited energy storage and cannot fly a
long distance without being recharged. This motivates several existing
proposals to use trucks and other ground vehicles to offer riding to help UAVs
save energy and expand the operation radius. We present the first theoretical
study regarding how UAVs should optimally hitch on ground vehicles, considering
vehicles' different travelling patterns and supporting capabilities. For a
single UAV, we derive closed-form optimal vehicle selection and hitching
strategy. When vehicles only support hitching, a UAV would prefer the vehicle
that can carry it closest to its final destination. When vehicles can offer
hitching plus charging, the UAV may hitch on a vehicle that carries it farther
away from its destination and hitch a longer distance. The UAV may also prefer
to hitch on a slower vehicle for the benefit of battery recharging. For
multiple UAVs in need of hitching, we develop the max-saving algorithm (MSA) to
optimally match UAV-vehicle collaboration. We prove that the MSA globally
optimizes the total hitching benefits for the UAVs.
","[{'version': 'v1', 'created': 'Tue, 24 Aug 2021 08:18:25 GMT'}]",2021-08-25,"[['Ruan', 'Lihua', ''], ['Duan', 'Lingjie', ''], ['Huang', 'Jianwei', '']]"
2004.10519,Mathias Louboutin,"Mathias Louboutin, Fabio Luporini, Philipp Witte, Rhodri Nelson,
  George Bisbas, Jan Thorbecke, Felix J. Herrmann, and Gerard Gorman","Scaling through abstractions -- high-performance vectorial wave
  simulations for seismic inversion with Devito","11 pages, 3 figures",,,,physics.comp-ph cs.CL cs.PF physics.ao-ph,http://creativecommons.org/licenses/by/4.0/,"  [Devito] is an open-source Python project based on domain-specific language
and compiler technology. Driven by the requirements of rapid HPC applications
development in exploration seismology, the language and compiler have evolved
significantly since inception. Sophisticated boundary conditions, tensor
contractions, sparse operations and features such as staggered grids and
sub-domains are all supported; operators of essentially arbitrary complexity
can be generated. To accommodate this flexibility whilst ensuring performance,
data dependency analysis is utilized to schedule loops and detect
computational-properties such as parallelism. In this article, the generation
and simulation of MPI-parallel propagators (along with their adjoints) for the
pseudo-acoustic wave-equation in tilted transverse isotropic media and the
elastic wave-equation are presented. Simulations are carried out on industry
scale synthetic models in a HPC Cloud system and reach a performance of
28TFLOP/s, hence demonstrating Devito's suitability for production-grade
seismic inversion problems.
","[{'version': 'v1', 'created': 'Wed, 22 Apr 2020 12:20:07 GMT'}]",2020-04-23,"[['Louboutin', 'Mathias', ''], ['Luporini', 'Fabio', ''], ['Witte', 'Philipp', ''], ['Nelson', 'Rhodri', ''], ['Bisbas', 'George', ''], ['Thorbecke', 'Jan', ''], ['Herrmann', 'Felix J.', ''], ['Gorman', 'Gerard', '']]"
2110.15165,Chun-Hao Chang,"Chun-Hao Chang, George Alexandru Adam, Rich Caruana, Anna Goldenberg",Extracting Clinician's Goals by What-if Interpretable Modeling,,,,,cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Although reinforcement learning (RL) has tremendous success in many fields,
applying RL to real-world settings such as healthcare is challenging when the
reward is hard to specify and no exploration is allowed. In this work, we focus
on recovering clinicians' rewards in treating patients. We incorporate the
what-if reasoning to explain the clinician's actions based on future outcomes.
We use generalized additive models (GAMs) - a class of accurate, interpretable
models - to recover the reward. In both simulation and a real-world hospital
dataset, we show our model outperforms baselines. Finally, our model's
explanations match several clinical guidelines when treating patients while we
found the previously-used linear model often contradicts them.
","[{'version': 'v1', 'created': 'Thu, 28 Oct 2021 14:41:06 GMT'}, {'version': 'v2', 'created': 'Thu, 3 Mar 2022 16:44:22 GMT'}]",2022-03-04,"[['Chang', 'Chun-Hao', ''], ['Adam', 'George Alexandru', ''], ['Caruana', 'Rich', ''], ['Goldenberg', 'Anna', '']]"
2010.14288,Jan Franz,"Jan Franz, Barry Mant, Lola Gonz\'alez-S\'anchez, Roland Wester and
  Franco A. Gianturco","Rotational state-changing collisions of C$_2$H$^-$ and C$_2$N$^-$ anions
  with He under interstellar and cold ion trap conditions: a computational
  comparison",,J. Chem. Phys. 152 (2020) 234303,10.1063/5.0011585,,physics.chem-ph,http://creativecommons.org/licenses/by/4.0/,"  We present an extensive range of quantum calculations for the state-changing
rotational dynamics involving two simple molecular anions which are expected to
play some role in evolutionary analysis of chemical networks in the
Interstellar environments, C$_2$H$^-$($X^1\Sigma^+$) and C$_2$N$^-$ ($X^3
\Sigma^-$) but for which inelastic rates are only known for C$_2$H$^-$. The
same systems are also of direct interest in modelling selective
photo-detachment (PD) experiments in cold ion traps where the He atoms function
as the chief buffer gas at the low trap temperatures. This study employs
accurate, \textit{ab initio} calculations of the interaction potential energy
surfaces (PESs) for these anions, treated as Rigid Rotors (RR) and the He atom
to obtain a wide range of state-changing quantum cross sections and rates at
temperatures up to about 100 K. The results are analysed and compared for the
two systems, to show differences and similarities between their rates of
state-changing dynamics.
","[{'version': 'v1', 'created': 'Tue, 27 Oct 2020 13:41:23 GMT'}]",2020-10-28,"[['Franz', 'Jan', ''], ['Mant', 'Barry', ''], ['González-Sánchez', 'Lola', ''], ['Wester', 'Roland', ''], ['Gianturco', 'Franco A.', '']]"
2112.07702,Austin Kay MPhys,"Austin M. Kay, Oskar J. Sandberg, Nasim Zarrabi, Wei Li, Stefan
  Zeiske, Christina Kaiser, Paul Meredith, and Ardalan Armin",Quantifying the Excitonic Static Disorder in Organic Semiconductors,"21 pages, 6 figures. 9 supplementary pages, 3 supplementary figures,
  and 4 supplementary tables. Submitted to Advanced Functional Materials",,,,physics.app-ph,http://creativecommons.org/licenses/by/4.0/,"  Organic semiconductors are disordered molecular solids and as a result, their
internal charge dynamics and ultimately, the performance of the optoelectronic
devices they constitute, are governed by energetic disorder. To ascertain how
energetic disorder impacts charge generation, exciton transport, charge
transport, and the performance of organic semiconductor devices, an accurate
approach is first required to measure this critical parameter. In this work, we
show that the static disorder has no relation with the so-called Urbach energy
in organic semiconductors. Instead, it can be obtained from photovoltaic
external quantum efficiency spectra at wavelengths near the absorption onset.
We then present a detailed methodology, alongside a computational framework,
for quantifying the static energetic disorder associated with singlet excitons.
Moreover, the role of optical interference in this analysis is considered to
achieve a high-accuracy quantification. Finally, the excitonic static disorder
was quantified in several technologically-relevant donor-acceptor blends,
including high-efficiency PM6:Y6.
","[{'version': 'v1', 'created': 'Tue, 14 Dec 2021 19:09:59 GMT'}]",2021-12-16,"[['Kay', 'Austin M.', ''], ['Sandberg', 'Oskar J.', ''], ['Zarrabi', 'Nasim', ''], ['Li', 'Wei', ''], ['Zeiske', 'Stefan', ''], ['Kaiser', 'Christina', ''], ['Meredith', 'Paul', ''], ['Armin', 'Ardalan', '']]"
1805.05531,Tan Zhixin,"Zhixin Tan, Xuejin Li, Yuzhi Chen, Ping Fan","Improving the Sensitivity of Fiber Surface Plasmon Resonance Sensor by
  Filling Liquid in a Hollow Core Photonic Crystal Fiber",7 figures,"Plasmonics, February 2014, 9(1):167-173",10.1007/s11468-013-9609-8,,physics.app-ph,http://creativecommons.org/licenses/by/4.0/,"  Inspired by the classic theory, we suggest that the performance of a D-shaped
fiber optical surface plasmon resonance (SPR) sensor can be improved by
manipulating the fiber core mode. To demonstrate this, we propose a novel fiber
SPR sensor based on a hollow core photonic crystal fiber with liquid mixture
filled in the core. The fiber sensor design involves a side-polished fiber with
gold film deposited on the polished plane and liquid filling. Numerical
simulation results suggest that by tuning the refractive index of the liquid
mixture, the predicted sensitivity will be over 6,430 nm/refractive index unit
for an aqueous environment, which is competitive for fiber chemical sensing.
This optimization method may lead to an ultrahigh sensitivityfiber optical
biosensor.
","[{'version': 'v1', 'created': 'Tue, 15 May 2018 02:25:48 GMT'}]",2018-05-16,"[['Tan', 'Zhixin', ''], ['Li', 'Xuejin', ''], ['Chen', 'Yuzhi', ''], ['Fan', 'Ping', '']]"
2111.14871,Saniya Heeba,"Torsten Bringmann, Saniya Heeba, Felix Kahlhoefer and Kristian
  Vangsnes","Freezing-in a hot bath: resonances, medium effects and phase transitions","35 pages, 7 figures",,10.1007/JHEP02(2022)110,,hep-ph astro-ph.CO,http://creativecommons.org/licenses/by/4.0/,"  Relic density calculations of dark matter freezing out from the primordial
plasma have reached a high level of sophistication, with several numerical
tools readily available that match the observationally required accuracy. Dark
matter production via the freeze-in mechanism, on the other hand, is sensitive
to much higher temperatures than in the freeze-out case, implying both
technical and computational difficulties when aiming for the same level of
precision. We revisit the formulation of freeze-in production in a way that
facilitates the inclusion of in-medium corrections like plasma effects and the
spin statistics of relativistic quantum gases, as well as the temperature
dependence of dark matter production rates induced by the electroweak and
strong phase transitions, and we discuss in detail the additional complications
arising in the presence of $s$-channel resonances. We illustrate our approach
in the context of Higgs portal models, and provide the most accurate
calculation to date of the freeze-in abundance of Scalar Singlet dark matter.
We explore in particular the case of small reheating temperatures, for which
the couplings implied by the freeze-in mechanism may be testable at the LHC.
Together with this article we present a major update 6.3 of DarkSUSY with the
added capability of performing general freeze-in calculations, including all
complications mentioned above.
","[{'version': 'v1', 'created': 'Mon, 29 Nov 2021 19:00:03 GMT'}]",2022-03-02,"[['Bringmann', 'Torsten', ''], ['Heeba', 'Saniya', ''], ['Kahlhoefer', 'Felix', ''], ['Vangsnes', 'Kristian', '']]"
2202.05701,Thorsten Wi{\ss}mann,Thorsten Wi{\ss}mann,Minimality Notions via Factorization Systems and Examples,"Extended journal version of the conference paper arXiv:2106.07233,
  and thus, expected substantial text overlap",,,,cs.FL,http://creativecommons.org/licenses/by/4.0/,"  For the minimization of state-based systems (i.e. the reduction of the number
of states while retaining the system's semantics), there are two obvious
aspects: removing unnecessary states of the system and merging redundant states
in the system. In the present article, we relate the two aspects on coalgebras
by defining an abstract notion of minimality.
  The abstract notions minimality and minimization live in a general category
with a factorization system. We will find criteria on the category that ensure
uniqueness, existence, and functoriality of the minimization aspects. The
proofs of these results instantiate to those for reachability and observability
minimization in the standard coalgebra literature. Finally, we will see how the
two aspects of minimization interact and under which criteria they can be
sequenced in any order, like in automata minimization.
","[{'version': 'v1', 'created': 'Fri, 11 Feb 2022 15:34:46 GMT'}]",2022-02-14,"[['Wißmann', 'Thorsten', '']]"
2101.02067,James Meech,James T. Meech and Phillip Stanley-Marbell,An Algorithm for Sensor Data Uncertainty Quantification,"5 pages, 5 figures, 1 table",,,,eess.SP,http://creativecommons.org/licenses/by/4.0/,"  This article presents an algorithm for reducing measurement uncertainty of
one physical quantity when given oversampled measurements of two physical
quantities with correlated noise. The algorithm assumes that the aleatoric
measurement uncertainty in both physical quantities follows a Gaussian
distribution and relies on sampling faster than it is possible for the
measurand (the true value of the physical quantity that we are trying to
measure) to change (due to the system thermal time constant) to calculate the
parameters of the noise distribution. In contrast to the Kalman and particle
filters, which respectively require state update equations and a map of one
physical quality, our algorithm requires only the oversampled sensor
measurements. When applied to temperature-compensated humidity sensors, it
provides reduced uncertainty in humidity estimates from correlated temperature
and humidity measurements. In an experimental evaluation, the algorithm
achieves average uncertainty reduction of 10.3 %. The algorithm incurs an
execution time overhead of 5.3 % when compared to the minimum algorithm
required to measure and calculate the uncertainty. Detailed instruction-level
emulation of a C-language implementation compiled to the RISC-V architecture
shows that the uncertainty reduction program required 0.05 % more instructions
per iteration than the minimum operations required to calculate the
uncertainty.
","[{'version': 'v1', 'created': 'Sun, 27 Dec 2020 12:28:02 GMT'}, {'version': 'v2', 'created': 'Fri, 2 Apr 2021 14:42:44 GMT'}, {'version': 'v3', 'created': 'Mon, 29 Nov 2021 12:26:09 GMT'}]",2021-11-30,"[['Meech', 'James T.', ''], ['Stanley-Marbell', 'Phillip', '']]"
2105.01605,Xiaojun Chang,"Xiangtan Lin and Pengzhen Ren and Yun Xiao and Xiaojun Chang and Alex
  Hauptmann",Person Search Challenges and Solutions: A Survey,8 pages; Accepted by IJCAI 2021 Survey Track,,,,cs.CV cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Person search has drawn increasing attention due to its real-world
applications and research significance. Person search aims to find a probe
person in a gallery of scene images with a wide range of applications, such as
criminals search, multicamera tracking, missing person search, etc. Early
person search works focused on image-based person search, which uses person
image as the search query. Text-based person search is another major person
search category that uses free-form natural language as the search query.
Person search is challenging, and corresponding solutions are diverse and
complex. Therefore, systematic surveys on this topic are essential. This paper
surveyed the recent works on image-based and text-based person search from the
perspective of challenges and solutions. Specifically, we provide a brief
analysis of highly influential person search methods considering the three
significant challenges: the discriminative person features, the query-person
gap, and the detection-identification inconsistency. We summarise and compare
evaluation results. Finally, we discuss open issues and some promising future
research directions.
","[{'version': 'v1', 'created': 'Sat, 1 May 2021 11:10:20 GMT'}]",2021-05-05,"[['Lin', 'Xiangtan', ''], ['Ren', 'Pengzhen', ''], ['Xiao', 'Yun', ''], ['Chang', 'Xiaojun', ''], ['Hauptmann', 'Alex', '']]"
1809.05379,Illia Teplytskyi,"Illia O. Teplytskyi, Serhiy O. Semerikov",Simulation using random numbers,"5 pages, 7 figures, in Ukrainian","Zbirnyk naukovykh prats Kamianets-Podilskoho natsionalnoho
  universytetu, Seriia pedahohichna 17 (2011) 248-252",,,physics.ed-ph cs.CY math.HO,http://creativecommons.org/licenses/by/4.0/,"  This article is devoted to methods of construction and study of stochastic
models based on Monte Carlo method. A model of Brownian motion, the
construction and processing which brings to a world of random numbers and
mathematical statistics, promotes understanding of the probability
distribution, in particular illustrates two common distributions: uniform and
normal.
","[{'version': 'v1', 'created': 'Fri, 3 Aug 2018 17:40:54 GMT'}]",2018-09-18,"[['Teplytskyi', 'Illia O.', ''], ['Semerikov', 'Serhiy O.', '']]"
2111.12292,Yi Xu,"Ziquan Liu, Yi Xu, Yuanhong Xu, Qi Qian, Hao Li, Antoni Chan, Rong Jin","Improved Fine-tuning by Leveraging Pre-training Data: Theory and
  Practice",,,,,cs.CV cs.LG stat.ML,http://creativecommons.org/licenses/by/4.0/,"  As a dominant paradigm, fine-tuning a pre-trained model on the target data is
widely used in many deep learning applications, especially for small data sets.
However, recent studies have empirically shown that training from scratch has
the final performance that is no worse than this pre-training strategy once the
number of training iterations is increased in some vision tasks. In this work,
we revisit this phenomenon from the perspective of generalization analysis
which is popular in learning theory. Our result reveals that the final
prediction precision may have a weak dependency on the pre-trained model
especially in the case of large training iterations. The observation inspires
us to leverage pre-training data for fine-tuning, since this data is also
available for fine-tuning. The generalization result of using pre-training data
shows that the final performance on a target task can be improved when the
appropriate pre-training data is included in fine-tuning. With the insight of
the theoretical finding, we propose a novel selection strategy to select a
subset from pre-training data to help improve the generalization on the target
task. Extensive experimental results for image classification tasks on 8
benchmark data sets verify the effectiveness of the proposed data selection
based fine-tuning pipeline.
","[{'version': 'v1', 'created': 'Wed, 24 Nov 2021 06:18:32 GMT'}]",2021-11-25,"[['Liu', 'Ziquan', ''], ['Xu', 'Yi', ''], ['Xu', 'Yuanhong', ''], ['Qian', 'Qi', ''], ['Li', 'Hao', ''], ['Chan', 'Antoni', ''], ['Jin', 'Rong', '']]"
1601.02539,Zhizheng Wu,"Zhizheng Wu, Simon King",Investigating gated recurrent neural networks for speech synthesis,Accepted by ICASSP 2016,,,,cs.CL cs.NE,http://creativecommons.org/licenses/by/4.0/,"  Recently, recurrent neural networks (RNNs) as powerful sequence models have
re-emerged as a potential acoustic model for statistical parametric speech
synthesis (SPSS). The long short-term memory (LSTM) architecture is
particularly attractive because it addresses the vanishing gradient problem in
standard RNNs, making them easier to train. Although recent studies have
demonstrated that LSTMs can achieve significantly better performance on SPSS
than deep feed-forward neural networks, little is known about why. Here we
attempt to answer two questions: a) why do LSTMs work well as a sequence model
for SPSS; b) which component (e.g., input gate, output gate, forget gate) is
most important. We present a visual analysis alongside a series of experiments,
resulting in a proposal for a simplified architecture. The simplified
architecture has significantly fewer parameters than an LSTM, thus reducing
generation complexity considerably without degrading quality.
","[{'version': 'v1', 'created': 'Mon, 11 Jan 2016 17:54:53 GMT'}]",2016-01-12,"[['Wu', 'Zhizheng', ''], ['King', 'Simon', '']]"
1711.03385,Maroua Taghouti,"Maroua Taghouti, Anil Kumar Chorppath, Tobias Waurick, Frank H.P.
  Fitzek","Match Made in Heaven: Practical Compressed Sensing and Network Coding
  for Intelligent Distributed Communication Networks",Submitted to VTC Spring 2018,,,,cs.NI cs.IT math.IT,http://creativecommons.org/licenses/by/4.0/,"  Based on the impressive features that network coding and compressed sensing
paradigms have separately brought, the idea of bringing them together in
practice will result in major improvements and influence in the upcoming 5G
networks. In this context, this paper aims to evaluate the effectiveness of
these key techniques in a cluster-based wireless sensor network, in the
presence of temporal and spatial correlations. Our goal is to achieve better
compression gains by scaling down the total payload carried by applying
temporal compression as well as reducing the total number of transmissions in
the network using real field network coding. In order to further reduce the
number of transmissions, the cluster-heads perform a low complexity spatial
pre-coding consisting of sending the packets with a certain probability.
Furthermore, we compare our approach with benchmark schemes. As expected, our
numerical results run on NS3 simulator show that on overall our scheme
dramatically drops the number of transmitted packets in the considered cluster
topology with a very high reconstruction SNR.
","[{'version': 'v1', 'created': 'Thu, 9 Nov 2017 14:27:14 GMT'}]",2017-11-10,"[['Taghouti', 'Maroua', ''], ['Chorppath', 'Anil Kumar', ''], ['Waurick', 'Tobias', ''], ['Fitzek', 'Frank H. P.', '']]"
1801.08200,Jeffrey Oishi,"Jeffrey S. Oishi and Benjamin P. Brown and Keaton J. Burns and Daniel
  Lecoanet and Geoffrey M. Vasil","Perspectives on Reproducibility and Sustainability of Open-Source
  Scientific Software from Seven Years of the Dedalus Project","A white paper submitted to the National Academies of Sciences,
  Engineering, and Medicine's Best Practices for a Future Open Code Policy for
  NASA Space Science",,,,astro-ph.IM physics.comp-ph,http://creativecommons.org/licenses/by/4.0/,"  As the Science Mission Directorate contemplates establishing an open code
policy, we consider it timely to share our experiences as the developers of the
open-source partial differential equation solver Dedalus. Dedalus is a flexible
framework for solving partial differential equations. Its development team
primarily uses it for studying stellar and planetary astrophysics. Dedalus was
developed originally for astrophysical fluid dynamics (AFD), though it has
found a much broader user base, including applied mathematicians, plasma
physicists, and oceanographers. Here, we will focus on issues related to
open-source software from the perspective of AFD. We use the term AFD with the
understanding that astrophysics simulations are inherently multi-physics: fluid
dynamics coupled with some combination of gravitational dynamics, radiation
transfer, relativity, and magnetic fields. In practice, a few well-known
open-source simulation packages represent a large fraction of published work in
the field. However, we will argue that an open-code policy should encompass not
just these large simulation codes, but also the input files and analysis
scripts. It is our interest that NASA adopt an open-code policy because without
it, reproducibility in computational science is needlessly hampered.
","[{'version': 'v1', 'created': 'Wed, 24 Jan 2018 21:17:46 GMT'}]",2018-01-26,"[['Oishi', 'Jeffrey S.', ''], ['Brown', 'Benjamin P.', ''], ['Burns', 'Keaton J.', ''], ['Lecoanet', 'Daniel', ''], ['Vasil', 'Geoffrey M.', '']]"
2101.05290,Shahar Hod,Shahar Hod,Introducing the inverse hoop conjecture for black holes,7 pages,"The European Physical Journal C (Letter) 80, 1148 (2020)",10.1140/epjc/s10052-020-08732-y,,gr-qc astro-ph.HE hep-th,http://creativecommons.org/licenses/by/4.0/,"  It is conjectured that stationary black holes are characterized by the
inverse hoop relation ${\cal A}\leq {\cal C}^2/\pi$, where ${\cal A}$ and
${\cal C}$ are respectively the black-hole surface area and the circumference
length of the smallest ring that can engulf the black-hole horizon in every
direction. We explicitly prove that generic Kerr-Newman-(anti)-de Sitter black
holes conform to this conjectured area-circumference relation.
","[{'version': 'v1', 'created': 'Wed, 13 Jan 2021 19:00:03 GMT'}]",2021-01-20,"[['Hod', 'Shahar', '']]"
2107.07648,Yutong Wu,"Yutong Wu, Erich D. Jarvis and Abhra Sarkar",Bayesian Markov Renewal Mixed Models for Vocalization Syntax,"35 pages, 10 figures",,,,stat.AP stat.ME,http://creativecommons.org/licenses/by/4.0/,"  Studying the neurological, genetic and evolutionary basis of human vocal
communication mechanisms is an important field of neuroscience. In the absence
of high quality data on humans, mouse vocalization experiments in laboratory
settings have been proven to be useful in providing valuable insights into
mammalian vocal development and evolution, including especially the impact of
certain genetic mutations. Data sets from mouse vocalization experiments
usually consist of categorical syllable sequences along with continuous
inter-syllable interval times for mice of different genotypes vocalizing under
various contexts. Few statistical models have considered the inference for both
transition probabilities and inter-state intervals. The latter is of particular
importance as increased inter-state intervals can be an indication of possible
vocal impairment. In this paper, we propose a class of novel Markov renewal
mixed models that capture the stochastic dynamics of both state transitions and
inter-state interval times. Specifically, we model the transition dynamics and
the inter-state intervals using Dirichlet and gamma mixtures, respectively,
allowing the mixture probabilities in both cases to vary flexibly with fixed
covariate effects as well as random individual-specific effects. We apply our
model to analyze the impact of a mutation in the Foxp2 gene on mouse vocal
behavior. We find that genotypes and social contexts significantly affect the
inter-state interval times but, compared to previous analyses, the influences
of genotype and social context on the syllable transition dynamics are weaker.
","[{'version': 'v1', 'created': 'Fri, 16 Jul 2021 00:06:22 GMT'}, {'version': 'v2', 'created': 'Thu, 22 Jul 2021 22:09:21 GMT'}, {'version': 'v3', 'created': 'Fri, 29 Oct 2021 20:52:56 GMT'}]",2021-11-02,"[['Wu', 'Yutong', ''], ['Jarvis', 'Erich D.', ''], ['Sarkar', 'Abhra', '']]"
2102.03243,Rafael S. Pereira Msc,"Rafael S. Pereira, Alexis Joly, Patrick Valduriez, Fabio Porto",Hyperspherical embedding for novel class classification,9 pages with 10 figures and 6 tables. Not currently published,,,,cs.CV cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Deep learning models have become increasingly useful in many different
industries. On the domain of image classification, convolutional neural
networks proved the ability to learn robust features for the closed set
problem, as shown in many different datasets, such as MNIST FASHIONMNIST,
CIFAR10, CIFAR100, and IMAGENET. These approaches use deep neural networks with
dense layers with softmax activation functions in order to learn features that
can separate classes in a latent space. However, this traditional approach is
not useful for identifying classes unseen on the training set, known as the
open set problem. A similar problem occurs in scenarios involving learning on
small data. To tackle both problems, few-shot learning has been proposed. In
particular, metric learning learns features that obey constraints of a metric
distance in the latent space in order to perform classification. However, while
this approach proves to be useful for the open set problem, current
implementation requires pair-wise training, where both positive and negative
examples of similar images are presented during the training phase, which
limits the applicability of these approaches in large data or large class
scenarios given the combinatorial nature of the possible inputs.In this paper,
we present a constraint-based approach applied to the representations in the
latent space under the normalized softmax loss, proposed by[18]. We
experimentally validate the proposed approach for the classification of unseen
classes on different datasets using both metric learning and the normalized
softmax loss, on disjoint and joint scenarios. Our results show that not only
our proposed strategy can be efficiently trained on larger set of classes, as
it does not require pairwise learning, but also present better classification
results than the metric learning strategies surpassing its accuracy by a
significant margin.
","[{'version': 'v1', 'created': 'Fri, 5 Feb 2021 15:42:13 GMT'}, {'version': 'v2', 'created': 'Mon, 28 Feb 2022 13:18:04 GMT'}]",2022-03-01,"[['Pereira', 'Rafael S.', ''], ['Joly', 'Alexis', ''], ['Valduriez', 'Patrick', ''], ['Porto', 'Fabio', '']]"
2105.06967,Gabriel Salomon,"Gabriel Salomon, Alceu Britto, Rafael H. Vareto, William R. Schwartz,
  David Menotti",Open-set Face Recognition for Small Galleries Using Siamese Networks,,"2020 International Conference on Systems, Signals and Image
  Processing (IWSSIP), 2020, pp. 161-166",10.1109/IWSSIP48289.2020.9145245,,cs.CV,http://creativecommons.org/licenses/by/4.0/,"  Face recognition has been one of the most relevant and explored fields of
Biometrics. In real-world applications, face recognition methods usually must
deal with scenarios where not all probe individuals were seen during the
training phase (open-set scenarios). Therefore, open-set face recognition is a
subject of increasing interest as it deals with identifying individuals in a
space where not all faces are known in advance. This is useful in several
applications, such as access authentication, on which only a few individuals
that have been previously enrolled in a gallery are allowed. The present work
introduces a novel approach towards open-set face recognition focusing on small
galleries and in enrollment detection, not identity retrieval. A Siamese
Network architecture is proposed to learn a model to detect if a face probe is
enrolled in the gallery based on a verification-like approach. Promising
results were achieved for small galleries on experiments carried out on
Pubfig83, FRGCv1 and LFW datasets. State-of-the-art methods like HFCN and HPLS
were outperformed on FRGCv1. Besides, a new evaluation protocol is introduced
for experiments in small galleries on LFW.
","[{'version': 'v1', 'created': 'Fri, 14 May 2021 17:16:37 GMT'}]",2021-05-17,"[['Salomon', 'Gabriel', ''], ['Britto', 'Alceu', ''], ['Vareto', 'Rafael H.', ''], ['Schwartz', 'William R.', ''], ['Menotti', 'David', '']]"
1702.04635,Emre Dil Dr.,Emre Dil and Tugrul Yumak,On the entropic nature of unified interactions,,Emre Dil and Tugrul Yumak 2019 Physica Scripta 94 085002,10.1088/1402-4896/ab1729,,physics.gen-ph,http://creativecommons.org/licenses/by/4.0/,"  In this paper, we generalize Verlinde's entropic gravity proposal on the
other fundamental interactions of nature. We begin by introducing the entropic
origin of the Coulomb's electrostatic force, and then the magnetic force, by
assuming the holographic principle holds when a charged particle approaches a
screen enclosing the emerged part of the spacetime due to a source. We assume
that the entropy of the screen changes when the charge approaches as in the
Verlinde's approach. Thereafter, we obtain the entropic Maxwell equations in
both classical and covariant form by means of the holographic principle hold
for the source. Considering the gauge covariant structure of the fundamental
forces, we implicitly generalize the entropic origin of the electromagnetic
force into the strong and weak nuclear forces. The possibility of the entropic
origin of the all fundamental forces of nature is assumed to make a meaningful
contribution to the unification scheme of the fundamental forces.
","[{'version': 'v1', 'created': 'Sat, 11 Feb 2017 09:22:43 GMT'}, {'version': 'v2', 'created': 'Tue, 25 Apr 2017 20:41:25 GMT'}, {'version': 'v3', 'created': 'Thu, 8 Mar 2018 10:06:45 GMT'}, {'version': 'v4', 'created': 'Fri, 17 May 2019 10:01:29 GMT'}]",2019-05-20,"[['Dil', 'Emre', ''], ['Yumak', 'Tugrul', '']]"
2012.14325,Ljupco Kocarev,Ljupco Kocarev and Jasna Koteska,Digital me ontology and ethics,17 pages,,,,cs.AI cs.CY,http://creativecommons.org/licenses/by/4.0/,"  This paper addresses ontology and ethics of an AI agent called digital me. We
define digital me as autonomous, decision-making, and learning agent,
representing an individual and having practically immortal own life. It is
assumed that digital me is equipped with the big-five personality model,
ensuring that it provides a model of some aspects of a strong AI:
consciousness, free will, and intentionality. As computer-based personality
judgments are more accurate than those made by humans, digital me can judge the
personality of the individual represented by the digital me, other individuals'
personalities, and other digital me-s. We describe seven ontological qualities
of digital me: a) double-layer status of Digital Being versus digital me, b)
digital me versus real me, c) mind-digital me and body-digital me, d) digital
me versus doppelganger (shadow digital me), e) non-human time concept, f)
social quality, g) practical immortality. We argue that with the advancement of
AI's sciences and technologies, there exist two digital me thresholds. The
first threshold defines digital me having some (rudimentarily) form of
consciousness, free will, and intentionality. The second threshold assumes that
digital me is equipped with moral learning capabilities, implying that, in
principle, digital me could develop their own ethics which significantly
differs from human's understanding of ethics. Finally we discuss the
implications of digital me metaethics, normative and applied ethics, the
implementation of the Golden Rule in digital me-s, and we suggest two sets of
normative principles for digital me: consequentialist and duty based digital me
principles.
","[{'version': 'v1', 'created': 'Tue, 22 Dec 2020 09:54:04 GMT'}]",2020-12-29,"[['Kocarev', 'Ljupco', ''], ['Koteska', 'Jasna', '']]"
2110.08664,Xinhai Zhang Dr.,"Xinhai Zhang, Jianbo Tao, Kaige Tan, Martin T\""orngren, Jos\'e Manuel
  Gaspar S\'anchez, Muhammad Rusyadi Ramli, Xin Tao, Magnus Gyllenhammar, Franz
  Wotawa, Naveen Mohan, Mihai Nica, Hermann Felbinger","Finding Critical Scenarios for Automated Driving Systems: A Systematic
  Literature Review","37 pages, 24 figures",,,,cs.SE cs.AI cs.SY eess.SY,http://creativecommons.org/licenses/by/4.0/,"  Scenario-based approaches have been receiving a huge amount of attention in
research and engineering of automated driving systems. Due to the complexity
and uncertainty of the driving environment, and the complexity of the driving
task itself, the number of possible driving scenarios that an ADS or ADAS may
encounter is virtually infinite. Therefore it is essential to be able to reason
about the identification of scenarios and in particular critical ones that may
impose unacceptable risk if not considered. Critical scenarios are particularly
important to support design, verification and validation efforts, and as a
basis for a safety case. In this paper, we present the results of a systematic
literature review in the context of autonomous driving. The main contributions
are: (i) introducing a comprehensive taxonomy for critical scenario
identification methods; (ii) giving an overview of the state-of-the-art
research based on the taxonomy encompassing 86 papers between 2017 and 2020;
and (iii) identifying open issues and directions for further research. The
provided taxonomy comprises three main perspectives encompassing the problem
definition (the why), the solution (the methods to derive scenarios), and the
assessment of the established scenarios. In addition, we discuss open research
issues considering the perspectives of coverage, practicability, and scenario
space explosion.
","[{'version': 'v1', 'created': 'Sat, 16 Oct 2021 21:24:19 GMT'}]",2021-10-19,"[['Zhang', 'Xinhai', ''], ['Tao', 'Jianbo', ''], ['Tan', 'Kaige', ''], ['Törngren', 'Martin', ''], ['Sánchez', 'José Manuel Gaspar', ''], ['Ramli', 'Muhammad Rusyadi', ''], ['Tao', 'Xin', ''], ['Gyllenhammar', 'Magnus', ''], ['Wotawa', 'Franz', ''], ['Mohan', 'Naveen', ''], ['Nica', 'Mihai', ''], ['Felbinger', 'Hermann', '']]"
2108.13917,Brian Slovick,Brian Slovick,Limiting fluctuations in quantum gravity to diffeomorphisms,"6 pages, no figures","Modern Physics Letters A 2150197, 1-6 (2021)",10.1142/S0217732321501972,,physics.gen-ph,http://creativecommons.org/licenses/by/4.0/,"  Within the background field formalism of quantum gravity, I show that if the
quantum fluctuations are limited to diffeomorphic gauge transformations rather
than the physical degrees of freedom, as in conventional quantum field theory,
all the quantum corrections vanish on shell and the effective action is
equivalent to the classical action. In principle, the resulting theory is
finite and unitary, and requires no renormalization. I also show that this is
the unique parameterization that renders the path integral independent of the
on-shell condition for the background field, a form of background independence.
Thus, a connection is established between background independence and
renormalizability and unitarity.
","[{'version': 'v1', 'created': 'Thu, 26 Aug 2021 13:04:46 GMT'}]",2021-09-01,"[['Slovick', 'Brian', '']]"
2111.00589,Zaza Osmanov,"V.I. Berezhiani, Z.N. Osmanov and S.V. Mikeladze","Electromagnetic vortex beam dynamics in degenerate electron-positron
  astrophysical plasmas","6 pages, 3 figures",,,,physics.plasm-ph astro-ph.HE physics.space-ph,http://creativecommons.org/licenses/by/4.0/,"  For degenerate astrophysical electron-positron plasmas we have considered
dynamics of electromagnetic beams carrying angular momentum. It is found for
arbitrary level of degeneracy such a beam having the power exceeding a certain
critical value breaks up into many filaments, eventually leading to the
formation of stable spatial solitons keeping zero field in the center of the
structure.
","[{'version': 'v1', 'created': 'Sun, 31 Oct 2021 20:43:09 GMT'}]",2021-11-02,"[['Berezhiani', 'V. I.', ''], ['Osmanov', 'Z. N.', ''], ['Mikeladze', 'S. V.', '']]"
2112.07876,Isabella Trierweiler,Isabella L. Trierweiler and Hilke E. Schlichting,Atmosphere Loss by Aerial Bursts,"10 pages, 9 figures",,,,astro-ph.EP,http://creativecommons.org/licenses/by/4.0/,"  We present a simple analytic description of atmospheric mass loss by aerial
bursts and demonstrate that mass loss from aerial bursts becomes significant
when the maximum impactor size that leads to an aerial burst rather than a
ground explosion, $r_o$, is larger than the minimum impactor size needed to
achieve atmospheric loss, $r_{min}$. For vertical trajectories, which give the
most stringent limit, this condition is approximately satisfied when
$\rho_o/\rho_i \gtrsim 0.4 v_e/v_\infty$, which implies atmospheric densities
need to be comparable to impactor densities for impactor velocities that are a
few times the escape velocity of the planet. The range of impactor radii
resulting in aerial burst-induced mass loss, $r_o-r_{min}$, increases with the
ratio of the atmosphere to the impactor density and with the trajectory angle
of the impactor. The range of impactor radii that result in aerial
burst-induced mass loss and the atmospheric mass lost is larger in adiabatic
atmospheres than isothermal atmospheres of equivalent total mass, scale height,
and atmospheric surface density. Our results imply that aerial bursts are not
expected to significantly contribute to the atmospheric mass-loss history of
Earth, but are expected to play an important role for planets and exoplanets
similar to Neptune with significant atmospheres. For Neptune-like atmospheres,
the atmospheric mass ejected per impactor mass by aerial bursts is comparable
to that lost by ground explosions, which implies that, for impactors following
a Dohnanyi size distribution, overall loss by aerial busts is expected to
exceed that by ground explosions by a factor of
$(r_{ground}/r_{aerial})^{0.5}$.
","[{'version': 'v1', 'created': 'Wed, 15 Dec 2021 04:33:06 GMT'}]",2021-12-16,"[['Trierweiler', 'Isabella L.', ''], ['Schlichting', 'Hilke E.', '']]"
2104.14516,Adam Zsolt Wagner,Adam Zsolt Wagner,Constructions in combinatorics via neural networks,"23 pages, 13 figures",,,,math.CO cs.LG,http://creativecommons.org/licenses/by/4.0/,"  We demonstrate how by using a reinforcement learning algorithm, the deep
cross-entropy method, one can find explicit constructions and counterexamples
to several open conjectures in extremal combinatorics and graph theory. Amongst
the conjectures we refute are a question of Brualdi and Cao about maximizing
permanents of pattern avoiding matrices, and several problems related to the
adjacency and distance eigenvalues of graphs.
","[{'version': 'v1', 'created': 'Thu, 29 Apr 2021 17:32:56 GMT'}]",2021-04-30,"[['Wagner', 'Adam Zsolt', '']]"
2112.14827,Puru Gujrati,P.D. Gujrati,Nonequilibrium Entropy in an Extended State Space,"22 pages; to appear in the book Encyclopedia of Entropy Across the
  Disciplines \c{opyright} World Scientific Publishing Company. arXiv admin
  note: substantial text overlap with arXiv:2111.07972, arXiv:1304.3768",,,UATP/2106,cond-mat.stat-mech math-ph math.MP physics.chem-ph,http://creativecommons.org/licenses/by/4.0/,"  This chapter deals with our recent attempt to extend the notion of
equilibrium (EQ) entropy to nonequilibrium (NEQ) systems so that it can also
capture memory effects. This is done by enlarging the equilibrium state space
by introducing internal variables. These variables capture the irreversibility
due to internal processes. By a proper choice of the enlarged state space, the
entropy becomes a state function, which shares many properties of the EQ
entropy, except for a nonzero irreversible entropy generation. We give both a
thermodynamic and statistical extension of the entropy and prove their
equivalence in all cases by taking an appropriate state space. This provides a
general nonnegative statistical expression of the entropy for any situation. We
use the statistical formulation to prove the second law. We give several
examples to determine the required internal variables, which we then apply to
several cases of interest to calculate the entropy generation. We also provide
a possible explanation for why the entropy in the classical continuum 1-d Tonks
gas can become negative by considering a lattice model for which the entropy is
always nonnegative.
","[{'version': 'v1', 'created': 'Wed, 29 Dec 2021 21:24:05 GMT'}]",2022-01-03,"[['Gujrati', 'P. D.', '']]"
2111.00003,Jianqin Zhou,"Jianqin Zhou, Sichun Yang, Xifeng Wang and Wanquan Liu",A New Algorithm based on Extent Bit-array for Computing Formal Concepts,,,,,cs.AI cs.CR cs.DS,http://creativecommons.org/licenses/by/4.0/,"  The emergence of Formal Concept Analysis (FCA) as a data analysis technique
has increased the need for developing algorithms which can compute formal
concepts quickly. The current efficient algorithms for FCA are variants of the
Close-By-One (CbO) algorithm, such as In-Close2, In-Close3 and In-Close4, which
are all based on horizontal storage of contexts. In this paper, based on
algorithm In-Close4, a new algorithm based on the vertical storage of contexts,
called In-Close5, is proposed, which can significantly reduce both the time
complexity and space complexity of algorithm In-Close4. Technically, the new
algorithm stores both context and extent of a concept as a vertical bit-array,
while within In-Close4 algorithm the context is stored only as a horizontal
bit-array, which is very slow in finding the intersection of two extent sets.
Experimental results demonstrate that the proposed algorithm is much more
effective than In-Close4 algorithm, and it also has a broader scope of
applicability in computing formal concept in which one can solve the problems
that cannot be solved by the In-Close4 algorithm.
","[{'version': 'v1', 'created': 'Fri, 29 Oct 2021 01:45:41 GMT'}]",2021-11-02,"[['Zhou', 'Jianqin', ''], ['Yang', 'Sichun', ''], ['Wang', 'Xifeng', ''], ['Liu', 'Wanquan', '']]"
1910.02915,Chaitanya Malaviya,"Chaitanya Malaviya, Chandra Bhagavatula, Antoine Bosselut, Yejin Choi","Commonsense Knowledge Base Completion with Structural and Semantic
  Context",AAAI 2020,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Automatic KB completion for commonsense knowledge graphs (e.g., ATOMIC and
ConceptNet) poses unique challenges compared to the much studied conventional
knowledge bases (e.g., Freebase). Commonsense knowledge graphs use free-form
text to represent nodes, resulting in orders of magnitude more nodes compared
to conventional KBs (18x more nodes in ATOMIC compared to Freebase
(FB15K-237)). Importantly, this implies significantly sparser graph structures
- a major challenge for existing KB completion methods that assume densely
connected graphs over a relatively smaller set of nodes. In this paper, we
present novel KB completion models that can address these challenges by
exploiting the structural and semantic context of nodes. Specifically, we
investigate two key ideas: (1) learning from local graph structure, using graph
convolutional networks and automatic graph densification and (2) transfer
learning from pre-trained language models to knowledge graphs for enhanced
contextual representation of knowledge. We describe our method to incorporate
information from both these sources in a joint model and provide the first
empirical results for KB completion on ATOMIC and evaluation with ranking
metrics on ConceptNet. Our results demonstrate the effectiveness of language
model representations in boosting link prediction performance and the
advantages of learning from local graph structure (+1.5 points in MRR for
ConceptNet) when training on subgraphs for computational efficiency. Further
analysis on model predictions shines light on the types of commonsense
knowledge that language models capture well.
","[{'version': 'v1', 'created': 'Mon, 7 Oct 2019 17:16:04 GMT'}, {'version': 'v2', 'created': 'Thu, 19 Dec 2019 20:02:50 GMT'}]",2019-12-23,"[['Malaviya', 'Chaitanya', ''], ['Bhagavatula', 'Chandra', ''], ['Bosselut', 'Antoine', ''], ['Choi', 'Yejin', '']]"
2111.08764,Tom\'as Silva,"T. Azevedo Silva, O. D. S. Demangeon, S. C. C. Barros, D. J.
  Armstrong, J. F. Otegi, D. Bossini, E. Delgado Mena, S. G. Sousa, V.
  Adibekyan, L. D. Nielsen, C. Dorn, J. Lillo-Box, N. C. Santos, S. Hoyer, K.
  G.Stassun, J. M. Almenara, D. Bayliss, D. Barrado, I. Boisse, D. J. A. Brown,
  R. F. D\'iaz, X. Dumusque, P. Figueira, A. Hadjigeorghiou, S. Hojjatpanah, O.
  Mousis, A. Osborn, A. Santerne, P. A. Str{\o}m, S. Udry, P. J. Wheatley","The HD 137496 system: A dense, hot super-Mercury and a cold Jupiter","20 pages, 14 figures, 10 tables. To be published in A&A","A&A 657, A68 (2022)",10.1051/0004-6361/202141520,,astro-ph.EP,http://creativecommons.org/licenses/by/4.0/,"  Most of the currently known planets are small worlds with radii between that
of the Earth and that of Neptune. The characterization of planets in this
regime shows a large diversity in compositions and system architectures, with
distributions hinting at a multitude of formation and evolution scenarios.
Using photometry from the K2 satellite and radial velocities measured with the
HARPS and CORALIE spectrographs, we searched for planets around the bright and
slightly evolved Sun-like star HD 137496. We precisely estimated the stellar
parameters, $M_*$ = 1.035 +/- 0.022 $M_\odot$, $R_*$ = 1.587 +/- 0.028
$R_\odot$, $T_\text{eff}$ = 5799 +/- 61 K, together with the chemical
composition of the slightly evolved star. We detect two planets orbiting HD
137496. The inner planet, HD 137496 b, is a super-Mercury (an Earth-sized
planet with the density of Mercury) with a mass of $M_b$ = 4.04 +/- 0.55
$M_\oplus$, a radius of $R_b = 1.31_{-0.05}^{+0.06} R_\oplus,$ and a density of
$\rho_b = 10.49_{-1.82}^{+2.08}$ $\mathrm{g cm^{-3}}$. With an interior
modeling analysis, we find that the planet is composed mainly of iron, with the
core representing over 70% of the planet's mass ($M_{core}/M_{total} =
0.73^{+0.11}_{-0.12}$). The outer planet, HD 137496 c, is an eccentric ($e$ =
0.477 +/- 0.004), long period ($P$ = $479.9_{-1.1}^{+1.0}$ days) giant planet
($M_c\sin i_c$ = 7.66 +/- 0.11 $M_{Jup}$) for which we do not detect a transit.
HD 137496 b is one of the few super-Mercuries detected to date. The accurate
characterization reported here enhances its role as a key target to better
understand the formation and evolution of planetary systems. The detection of
an eccentric long period giant companion also reinforces the link between the
presence of small transiting inner planets and long period gas giants.
","[{'version': 'v1', 'created': 'Tue, 16 Nov 2021 20:23:34 GMT'}]",2022-01-19,"[['Silva', 'T. Azevedo', ''], ['Demangeon', 'O. D. S.', ''], ['Barros', 'S. C. C.', ''], ['Armstrong', 'D. J.', ''], ['Otegi', 'J. F.', ''], ['Bossini', 'D.', ''], ['Mena', 'E. Delgado', ''], ['Sousa', 'S. G.', ''], ['Adibekyan', 'V.', ''], ['Nielsen', 'L. D.', ''], ['Dorn', 'C.', ''], ['Lillo-Box', 'J.', ''], ['Santos', 'N. C.', ''], ['Hoyer', 'S.', ''], ['Stassun', 'K. G.', ''], ['Almenara', 'J. M.', ''], ['Bayliss', 'D.', ''], ['Barrado', 'D.', ''], ['Boisse', 'I.', ''], ['Brown', 'D. J. A.', ''], ['Díaz', 'R. F.', ''], ['Dumusque', 'X.', ''], ['Figueira', 'P.', ''], ['Hadjigeorghiou', 'A.', ''], ['Hojjatpanah', 'S.', ''], ['Mousis', 'O.', ''], ['Osborn', 'A.', ''], ['Santerne', 'A.', ''], ['Strøm', 'P. A.', ''], ['Udry', 'S.', ''], ['Wheatley', 'P. J.', '']]"
2201.06796,Mina Lee,"Mina Lee, Percy Liang, Qian Yang","CoAuthor: Designing a Human-AI Collaborative Writing Dataset for
  Exploring Language Model Capabilities",Published as a conference paper at CHI 2022,,10.1145/3491102.3502030,,cs.HC cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Large language models (LMs) offer unprecedented language generation
capabilities and exciting opportunities for interaction design. However, their
highly context-dependent capabilities are difficult to grasp and are often
subjectively interpreted. In this paper, we argue that by curating and
analyzing large interaction datasets, the HCI community can foster more
incisive examinations of LMs' generative capabilities. Exemplifying this
approach, we present CoAuthor, a dataset designed for revealing GPT-3's
capabilities in assisting creative and argumentative writing. CoAuthor captures
rich interactions between 63 writers and four instances of GPT-3 across 1445
writing sessions. We demonstrate that CoAuthor can address questions about
GPT-3's language, ideation, and collaboration capabilities, and reveal its
contribution as a writing ""collaborator"" under various definitions of good
collaboration. Finally, we discuss how this work may facilitate a more
principled discussion around LMs' promises and pitfalls in relation to
interaction design. The dataset and an interface for replaying the writing
sessions are publicly available at https://coauthor.stanford.edu.
","[{'version': 'v1', 'created': 'Tue, 18 Jan 2022 07:51:57 GMT'}, {'version': 'v2', 'created': 'Tue, 25 Jan 2022 05:29:58 GMT'}]",2022-01-26,"[['Lee', 'Mina', ''], ['Liang', 'Percy', ''], ['Yang', 'Qian', '']]"
2109.01933,Naoki Egami,"Naoki Egami, Eric J. Tchetgen Tchetgen","Identification and Estimation of Causal Peer Effects Using Double
  Negative Controls for Unmeasured Network Confounding",,,,,stat.ME,http://creativecommons.org/licenses/by/4.0/,"  Scientists have been interested in estimating causal peer effects to
understand how people's behaviors are affected by their network peers. However,
it is well known that identification and estimation of causal peer effects are
challenging in observational studies for two reasons. The first is the
identification challenge due to unmeasured network confounding, for example,
homophily bias and contextual confounding. The second issue is network
dependence of observations, which one must take into account for valid
statistical inference. Negative control variables, also known as placebo
variables, have been widely used in observational studies including peer effect
analysis over networks, although they have been used primarily for bias
detection. In this article, we establish a formal framework which leverages a
pair of negative control outcome and exposure variables (double negative
controls) to nonparametrically identify causal peer effects in the presence of
unmeasured network confounding. We then propose a generalized method of moments
estimator for causal peer effects, and establish its consistency and asymptotic
normality under an assumption about $\psi$-network dependence. Finally, we
provide a network heteroskedasticity and autocorrelation consistent variance
estimator. Our methods are illustrated with an application to peer effects in
education.
","[{'version': 'v1', 'created': 'Sat, 4 Sep 2021 21:06:06 GMT'}]",2021-09-07,"[['Egami', 'Naoki', ''], ['Tchetgen', 'Eric J. Tchetgen', '']]"
2007.04383,"Azmi Can \""Ozgen","Azmi Can \""Ozgen, Haz{\i}m Kemal Ekenel",Words as Art Materials: Generating Paintings with Sequential GANs,,,,,cs.CV eess.IV,http://creativecommons.org/licenses/by/4.0/,"  Converting text descriptions into images using Generative Adversarial
Networks has become a popular research area. Visually appealing images have
been generated successfully in recent years. Inspired by these studies, we
investigated the generation of artistic images on a large variance dataset.
This dataset includes images with variations, for example, in shape, color, and
content. These variations in images provide originality which is an important
factor for artistic essence. One major characteristic of our work is that we
used keywords as image descriptions, instead of sentences. As the network
architecture, we proposed a sequential Generative Adversarial Network model.
The first stage of this sequential model processes the word vectors and creates
a base image whereas the next stages focus on creating high-resolution
artistic-style images without working on word vectors. To deal with the
unstable nature of GANs, we proposed a mixture of techniques like Wasserstein
loss, spectral normalization, and minibatch discrimination. Ultimately, we were
able to generate painting images, which have a variety of styles. We evaluated
our results by using the Fr\'echet Inception Distance score and conducted a
user study with 186 participants.
","[{'version': 'v1', 'created': 'Wed, 8 Jul 2020 19:17:14 GMT'}]",2020-07-10,"[['Özgen', 'Azmi Can', ''], ['Ekenel', 'Hazım Kemal', '']]"
2107.11695,Amit Verma Dr.,"Amit Verma, Mark Lewis, Gary Kochenberger",Efficient QUBO transformation for Higher Degree Pseudo Boolean Functions,Preprint submitted to Springer,,,,math.OC cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Quadratic Unconstrained Binary Optimization (QUBO) is recognized as a
unifying framework for modeling a wide range of problems. Problems can be
solved with commercial solvers customized for solving QUBO and since QUBO have
degree two, it is useful to have a method for transforming higher degree
pseudo-Boolean problems to QUBO format. The standard transformation approach
requires additional auxiliary variables supported by penalty terms for each
higher degree term. This paper improves on the existing cubic-to-quadratic
transformation approach by minimizing the number of additional variables as
well as penalty coefficient. Extensive experimental testing on Max 3-SAT
modeled as QUBO shows a near 100% reduction in the subproblem size used for
minimization of the number of auxiliary variables.
","[{'version': 'v1', 'created': 'Sat, 24 Jul 2021 22:13:42 GMT'}]",2021-07-27,"[['Verma', 'Amit', ''], ['Lewis', 'Mark', ''], ['Kochenberger', 'Gary', '']]"
1611.06653,Gaorong Li,"Yiping Yang, Tiejun Tong and Gaorong Li",SIMEX estimation for single-index model with covariate measurement error,"25 pages, 7 figures",,,,stat.ME,http://creativecommons.org/licenses/by/4.0/,"  In this paper, we consider the single-index measurement error model with
mismeasured covariates in the nonparametric part. To solve the problem, we
develop a simulation-extrapolation (SIMEX) algorithm based on the local linear
smoother and the estimating equation. For the proposed SIMEX estimation, it is
not needed to assume the distribution of the unobserved covariate. We transform
the boundary of a unit ball in $\mathbb{R}^p$ to the interior of a unit ball in
$\mathbb{R}^{p-1}$ by using the constraint $\|\beta\|=1$. The proposed SIMEX
estimator of the index parameter is shown to be asymptotically normal under
some regularity conditions. We also derive the asymptotic bias and variance of
the estimator of the unknown link function. Finally, the performance of the
proposed method is examined by simulation studies and is illustrated by a real
data example.
","[{'version': 'v1', 'created': 'Mon, 21 Nov 2016 05:22:43 GMT'}]",2016-11-22,"[['Yang', 'Yiping', ''], ['Tong', 'Tiejun', ''], ['Li', 'Gaorong', '']]"
2106.07070,Samuel Greess,"S. Greess (1), J. Egedal (1), A. Stanier (2), W. Daughton (2), J.
  Olson (1), A. L\^e (2), R. Myers (1), A. Millet-Ayala (1), M. Clark (1), J.
  Wallace (1), D. Endrizzi (1), C. Forest (1) ((1) University of
  Wisconsin-Madison (2) Los Alamos National Laboratory)","Laboratory verification of electron-scale reconnection regions modulated
  by a three-dimensional instability","Reviewed and accepted to the Journal of Geophysical Research: Space
  Physics. Accepted on 10 June 2021; in preprint at time of arxiv submission
  (13 June 2021)",,10.1029/2021JA029316,,physics.plasm-ph physics.space-ph,http://creativecommons.org/licenses/by/4.0/,"  During magnetic reconnection in collisionless space plasma, the electron
fluid decouples from the magnetic field within narrow current layers, and
theoretical models for this process can be distinguished in terms of their
predicted current layer widths. From theory, the off-diagonal stress in the
electron pressure tensor is related to thermal non-circular orbit motion of
electrons around the magnetic field lines. This stress becomes significant when
the width of the reconnecting current layer approaches the small characteristic
length scale of the electron motion. To aid in situ spacecraft and numerical
investigations of reconnection, the structure of the electron diffusion region
is here investigated using the Terrestrial Reconnection EXperiment (TREX). In
agreement with the closely matched kinetic simulations, laboratory observations
reveal the presence of electron-scale current layer widths. Although the layers
are modulated by a current-driven instability, 3D simulations demonstrate that
it is the off-diagonal stress that is responsible for breaking the frozen-in
condition of the electron fluid.
","[{'version': 'v1', 'created': 'Sun, 13 Jun 2021 19:02:15 GMT'}]",2021-06-18,"[['Greess', 'S.', ''], ['Egedal', 'J.', ''], ['Stanier', 'A.', ''], ['Daughton', 'W.', ''], ['Olson', 'J.', ''], ['Lê', 'A.', ''], ['Myers', 'R.', ''], ['Millet-Ayala', 'A.', ''], ['Clark', 'M.', ''], ['Wallace', 'J.', ''], ['Endrizzi', 'D.', ''], ['Forest', 'C.', '']]"
2201.05136,Joseph Bakarji,"Joseph Bakarji, Kathleen Champion, J. Nathan Kutz and Steven L.
  Brunton","Discovering Governing Equations from Partial Measurements with Deep
  Delay Autoencoders",,,,,cs.LG cs.CE math.DS,http://creativecommons.org/licenses/by/4.0/,"  A central challenge in data-driven model discovery is the presence of hidden,
or latent, variables that are not directly measured but are dynamically
important. Takens' theorem provides conditions for when it is possible to
augment these partial measurements with time delayed information, resulting in
an attractor that is diffeomorphic to that of the original full-state system.
However, the coordinate transformation back to the original attractor is
typically unknown, and learning the dynamics in the embedding space has
remained an open challenge for decades. Here, we design a custom deep
autoencoder network to learn a coordinate transformation from the delay
embedded space into a new space where it is possible to represent the dynamics
in a sparse, closed form. We demonstrate this approach on the Lorenz,
R\""ossler, and Lotka-Volterra systems, learning dynamics from a single
measurement variable. As a challenging example, we learn a Lorenz analogue from
a single scalar variable extracted from a video of a chaotic waterwheel
experiment. The resulting modeling framework combines deep learning to uncover
effective coordinates and the sparse identification of nonlinear dynamics
(SINDy) for interpretable modeling. Thus, we show that it is possible to
simultaneously learn a closed-form model and the associated coordinate system
for partially observed dynamics.
","[{'version': 'v1', 'created': 'Thu, 13 Jan 2022 18:48:16 GMT'}]",2022-01-14,"[['Bakarji', 'Joseph', ''], ['Champion', 'Kathleen', ''], ['Kutz', 'J. Nathan', ''], ['Brunton', 'Steven L.', '']]"
2105.06318,Tanguy Fardet,Tanguy Fardet and Anna Levina,"Weighted directed clustering: interpretations and requirements for
  heterogeneous, inferred, and measured networks","18 pages, 8 figures, 10 tables (including appendix)",,,,cs.SI physics.data-an physics.soc-ph,http://creativecommons.org/licenses/by/4.0/,"  Weights and directionality of the edges carry a large part of the information
we can extract from a complex network. However, many network measures were
formulated initially for undirected binary networks. The necessity to
incorporate information about the weights led to the conception of the multiple
extensions, particularly for definitions of the local clustering coefficient
discussed here. We uncover that not all of these extensions are fully-weighted;
some depend on the degree and thus change a lot when an infinitely small weight
edge is exchanged for the absence of an edge, a feature that is not always
desirable. We call these methods ``hybrid'' and argue that, in many situations,
one should prefer fully-weighted definitions. After listing the necessary
requirements for a method to analyze many various weighted networks properly,
we propose a fully-weighted continuous clustering coefficient that satisfies
all the previously proposed criteria while also being continuous with respect
to vanishing weights. We demonstrate that the behavior and meaning of the
Zhang--Horvath clustering and our new continuous definition provide
complementary results and significantly outperform other definitions in
multiple relevant conditions. Using synthetic and real-world examples, we show
that when the network is inferred, noisy, or very heterogeneous, it is
essential to use the fully-weighted clustering definitions.
","[{'version': 'v1', 'created': 'Thu, 13 May 2021 14:15:58 GMT'}, {'version': 'v2', 'created': 'Sun, 29 Aug 2021 08:35:15 GMT'}]",2021-08-31,"[['Fardet', 'Tanguy', ''], ['Levina', 'Anna', '']]"
2007.11488,T Deepika,T Deepika,"Analysis and Comparison of Different Wavelet Transform Methods Using
  Benchmarks for Image Fusion","International Conference on Computer, Communication and Signal
  Processing",,,,eess.IV,http://creativecommons.org/licenses/by/4.0/,"  In recent years, many research achievements are made in the medical image
fusion field. Medical Image fusion means that several of various modality image
information is comprehended together to form one image to express its
information. The aim of image fusion is to integrate complementary and
redundant information. CT/MRI is one of the most common medical image fusion.
These medical modalities give information about different diseases.
Complementary information is offered by CT and MRI. CT provides the best
information about denser tissue and MRI offers better information on soft
tissue. There are two approaches to image fusion, namely Spatial Fusion and
Transform fusion. Transform fusion uses transform for representing the source
images at multi-scale. This paper presents a Wavelet Transform image fusion
methodology based on the intensity magnitudes of the wavelet coefficients and
compares five variations of the wavelet transform implemented separately in
this fusion model. The image fusion model, using the Discrete Wavelet Transform
(DWT), the Stationary Wavelet Transform (SWT), the Integer Lifting Wavelet
Transform (ILFT) the dual-tree Complex Wavelet Transform (DT CWT) and dual-tree
Q-shift dual-tree CWT, is applied to multi-modal images. The resulting fused
images are compared visually and through benchmarks such as Entropy (E), Peak
Signal to Noise Ratio, (PSNR), Root Mean Square Error (RMSE), Image Quality
Index (IQI) and Standard deviation (SD) computations.
","[{'version': 'v1', 'created': 'Wed, 22 Jul 2020 15:24:54 GMT'}]",2020-07-23,"[['Deepika', 'T', '']]"
2107.07695,Hao Wang,"Hao Wang, Euijoon Ahn, Jinman Kim","Self-supervised Representation Learning Framework for Remote
  Physiological Measurement Using Spatiotemporal Augmentation Loss","Accepted as AAAI22 paper. Code:
  https://github.com/Dylan-H-Wang/SLF-RPM",,,,cs.CV,http://creativecommons.org/licenses/by/4.0/,"  Recent advances in supervised deep learning methods are enabling remote
measurements of photoplethysmography-based physiological signals using facial
videos. The performance of these supervised methods, however, are dependent on
the availability of large labelled data. Contrastive learning as a
self-supervised method has recently achieved state-of-the-art performances in
learning representative data features by maximising mutual information between
different augmented views. However, existing data augmentation techniques for
contrastive learning are not designed to learn physiological signals from
videos and often fail when there are complicated noise and subtle and periodic
colour or shape variations between video frames. To address these problems, we
present a novel self-supervised spatiotemporal learning framework for remote
physiological signal representation learning, where there is a lack of labelled
training data. Firstly, we propose a landmark-based spatial augmentation that
splits the face into several informative parts based on the Shafer dichromatic
reflection model to characterise subtle skin colour fluctuations. We also
formulate a sparsity-based temporal augmentation exploiting Nyquist-Shannon
sampling theorem to effectively capture periodic temporal changes by modelling
physiological signal features. Furthermore, we introduce a constrained
spatiotemporal loss which generates pseudo-labels for augmented video clips. It
is used to regulate the training process and handle complicated noise. We
evaluated our framework on 3 public datasets and demonstrated superior
performances than other self-supervised methods and achieved competitive
accuracy compared to the state-of-the-art supervised methods.
","[{'version': 'v1', 'created': 'Fri, 16 Jul 2021 04:00:13 GMT'}, {'version': 'v2', 'created': 'Tue, 14 Dec 2021 05:55:43 GMT'}]",2021-12-15,"[['Wang', 'Hao', ''], ['Ahn', 'Euijoon', ''], ['Kim', 'Jinman', '']]"
2012.08025,Navid Constantinou,Navid C. Constantinou and Andrew McC. Hogg,Intrinsic oceanic decadal variability of upper-ocean heat content,,"J. Climate, vol. 34 (15), 6175-6189, 2021",10.1175/JCLI-D-20-0962.1,,physics.ao-ph physics.geo-ph,http://creativecommons.org/licenses/by/4.0/,"  Atmosphere and ocean are coupled via air-sea interactions. The atmospheric
conditions fuel the ocean circulation and its variability, but the extent to
which ocean processes can affect the atmosphere at decadal time scales remains
unclear. In particular, such low-frequency variability is difficult to extract
from the short observational record, meaning that climate models are the
primary tools deployed to resolve this question. Here, we assess how the
ocean's intrinsic variability leads to patterns of upper-ocean heat content
that vary at decadal time scales. These patterns have the potential to feed
back on the atmosphere and thereby affect climate modes of variability, such as
El Ni\~no or the Interdecadal Pacific Oscillation. We use the output from a
global ocean-sea ice circulation model at three different horizontal
resolutions, each driven by the same atmospheric reanalysis. To disentangle the
variability of the ocean's direct response to atmospheric forcing from the
variability due to intrinsic ocean dynamics, we compare model runs driven with
inter-annually varying forcing (1958-2018) and model runs driven with
repeat-year forcing. Models with coarse resolution that rely on eddy
parameterizations, show (i) significantly reduced variance of the upper-ocean
heat content at decadal time scales and (ii) differences in the spatial
patterns of low-frequency variability compared with higher resolution models.
Climate projections are typically done with general circulation models with
coarse-resolution ocean components. Therefore, these biases affect our ability
to predict decadal climate modes of variability and, in turn, hinder climate
projections. Our results suggest that for improving climate projections, the
community should move towards coupled climate models with higher oceanic
resolution.
","[{'version': 'v1', 'created': 'Tue, 15 Dec 2020 00:52:45 GMT'}, {'version': 'v2', 'created': 'Fri, 26 Mar 2021 20:05:04 GMT'}, {'version': 'v3', 'created': 'Sun, 13 Jun 2021 22:53:22 GMT'}]",2021-07-08,"[['Constantinou', 'Navid C.', ''], ['Hogg', 'Andrew McC.', '']]"
2202.08047,Miguel Beneitez,"Gergely Buza, Miguel Beneitez, Jacob Page, Rich R. Kerswell","Finite-amplitude elastic waves in viscoelastic channel flow from large
  to zero Reynolds number","21 pages, 12 figures",,,,physics.flu-dyn,http://creativecommons.org/licenses/by/4.0/,"  Using branch continuation in the FENE-P model, we show that finite-amplitude
travelling waves borne out of the recently-discovered linear instability of
viscoelastic channel flow (Khalid et al. {\em J. Fluid Mech.} {\bf 915}, A43,
2021) are substantially subcritical reaching much lower Weissenberg ($Wi$)
numbers than on the neutral curve at a given Reynolds ($Re$) number over $Re
\in [0,3000]$. The travelling waves on the lower branch are surprisingly weak
indicating that viscolastic channel flow is susceptible to (nonlinear)
instability triggered by small finite amplitude disturbances for $Wi$ and $Re$
well below the neutral curve. The critical $Wi$ for these waves to appear in a
saddle node bifurcation decreases monotonically from, for example, $\approx 37$
at $Re=3000$ down to $\approx 7.5$ at $Re=0$ at the solvent-to-total-viscosity
ratio $\beta=0.9$. In this latter creeping flow limit, we also show that these
waves exist at $Wi \lesssim 50$ for higher polymer concentrations - $\beta \in
[0.5,0.97)$ -- where there is no known linear instability. Our results
therefore indicate that these travelling waves -- found in simulations and
named `arrowheads' by Dubief et al. {\em arXiv}.2006.06770 (2020) - exist much
more generally in $(Wi,Re, \beta)$ parameter space than their spawning neutral
curve and hence can either directly, or indirectly through their instabilities,
influence the dynamics seen far away from where the flow is linearly unstable.
Possible connections to elastic and elasto-inertial turbulence are discussed.
","[{'version': 'v1', 'created': 'Wed, 16 Feb 2022 13:22:53 GMT'}]",2022-02-17,"[['Buza', 'Gergely', ''], ['Beneitez', 'Miguel', ''], ['Page', 'Jacob', ''], ['Kerswell', 'Rich R.', '']]"
1903.05714,Joseph Izraelevitz,"Joseph Izraelevitz, Jian Yang, Lu Zhang, Juno Kim, Xiao Liu, Amirsaman
  Memaripour, Yun Joon Soh, Zixuan Wang, Yi Xu, Subramanya R. Dulloor, Jishen
  Zhao and Steven Swanson","Basic Performance Measurements of the Intel Optane DC Persistent Memory
  Module",,,,,cs.DC cs.PF,http://creativecommons.org/licenses/by/4.0/,"  Scalable nonvolatile memory DIMMs will finally be commercially available with
the release of the Intel Optane DC Persistent Memory Module (or just ""Optane DC
PMM""). This new nonvolatile DIMM supports byte-granularity accesses with access
times on the order of DRAM, while also providing data storage that survives
power outages. This work comprises the first in-depth, scholarly, performance
review of Intel's Optane DC PMM, exploring its capabilities as a main memory
device, and as persistent, byte-addressable memory exposed to user-space
applications. This report details the technologies performance under a number
of modes and scenarios, and across a wide variety of macro-scale benchmarks.
Optane DC PMMs can be used as large memory devices with a DRAM cache to hide
their lower bandwidth and higher latency. When used in this Memory (or cached)
mode, Optane DC memory has little impact on applications with small memory
footprints. Applications with larger memory footprints may experience some
slow-down relative to DRAM, but are now able to keep much more data in memory.
When used under a file system, Optane DC PMMs can result in significant
performance gains, especially when the file system is optimized to use the
load/store interface of the Optane DC PMM and the application uses many small,
persistent writes. For instance, using the NOVA-relaxed NVMM file system, we
can improve the performance of Kyoto Cabinet by almost 2x. Optane DC PMMs can
also enable user-space persistence where the application explicitly controls
its writes into persistent Optane DC media. In our experiments, modified
applications that used user-space Optane DC persistence generally outperformed
their file system counterparts. For instance, the persistent version of RocksDB
performed almost 2x faster than the equivalent program utilizing an NVMM-aware
file system.
","[{'version': 'v1', 'created': 'Wed, 13 Mar 2019 21:14:40 GMT'}, {'version': 'v2', 'created': 'Tue, 2 Apr 2019 20:19:20 GMT'}, {'version': 'v3', 'created': 'Fri, 9 Aug 2019 18:41:24 GMT'}]",2019-08-13,"[['Izraelevitz', 'Joseph', ''], ['Yang', 'Jian', ''], ['Zhang', 'Lu', ''], ['Kim', 'Juno', ''], ['Liu', 'Xiao', ''], ['Memaripour', 'Amirsaman', ''], ['Soh', 'Yun Joon', ''], ['Wang', 'Zixuan', ''], ['Xu', 'Yi', ''], ['Dulloor', 'Subramanya R.', ''], ['Zhao', 'Jishen', ''], ['Swanson', 'Steven', '']]"
2108.10416,Pasquale Tricarico,"P. Tricarico, D. J. Scheeres, A. S. French, J. W. McMahon, D. N.
  Brack, J. M. Leonard, P. Antreasian, S. R. Chesley, D. Farnocchia, Y.
  Takahashi, E. M. Mazarico, D. Rowlands, D. Highsmith, K. Getzandanner, M.
  Moreau, C. L. Johnson, L. Philpott, E. B. Bierhaus, K. J. Walsh, O. S.
  Barnouin, E. E. Palmer, J. R. Weirich, R. W. Gaskell, M. G. Daly, J. A.
  Seabrook, M. C. Nolan, and D. S. Lauretta",Internal rubble properties of asteroid (101955) Bennu,"14 pages, 5 figures, accepted to Icarus",,10.1016/j.icarus.2021.114665,,astro-ph.EP,http://creativecommons.org/licenses/by/4.0/,"  Exploration of asteroid (101955) Bennu by the OSIRIS-REx mission has provided
an in-depth look at this rubble-pile near-Earth asteroid. In particular, the
measured gravity field and the detailed shape model of Bennu indicate
significant heterogeneities in its interior structure, compatible with a lower
density at its center. Here we combine gravity inversion methods with a
statistical rubble-pile model to determine the density and size-frequency
distribution (SFD) index of the rubble that constitutes Bennu. The best-fitting
models indicate that the SFD of the interior is consistent with that observed
on the surface, with a cumulative SFD index of approximately $-2.9$. The rubble
bulk density is approximately $1.35$ g/cm$^3$, corresponding to a $12$%
macro-porosity. We find the largest rubble particle to be approximately $145$
m, whereas the largest void is approximately $10$ m.
","[{'version': 'v1', 'created': 'Mon, 23 Aug 2021 21:16:21 GMT'}]",2021-09-07,"[['Tricarico', 'P.', ''], ['Scheeres', 'D. J.', ''], ['French', 'A. S.', ''], ['McMahon', 'J. W.', ''], ['Brack', 'D. N.', ''], ['Leonard', 'J. M.', ''], ['Antreasian', 'P.', ''], ['Chesley', 'S. R.', ''], ['Farnocchia', 'D.', ''], ['Takahashi', 'Y.', ''], ['Mazarico', 'E. M.', ''], ['Rowlands', 'D.', ''], ['Highsmith', 'D.', ''], ['Getzandanner', 'K.', ''], ['Moreau', 'M.', ''], ['Johnson', 'C. L.', ''], ['Philpott', 'L.', ''], ['Bierhaus', 'E. B.', ''], ['Walsh', 'K. J.', ''], ['Barnouin', 'O. S.', ''], ['Palmer', 'E. E.', ''], ['Weirich', 'J. R.', ''], ['Gaskell', 'R. W.', ''], ['Daly', 'M. G.', ''], ['Seabrook', 'J. A.', ''], ['Nolan', 'M. C.', ''], ['Lauretta', 'D. S.', '']]"
2201.04617,Suprovat Ghoshal,Suprovat Ghoshal and Euiwoong Lee,A Characterization of Approximability for Biased CSPs,68 Pages,,,,cs.DS,http://creativecommons.org/licenses/by/4.0/,"  A $\mu$-biased Max-CSP instance with predicate $\psi:\{0,1\}^r \to \{0,1\}$
is an instance of Constraint Satisfaction Problem (CSP) where the objective is
to find a labeling of relative weight at most $\mu$ which satisfies the maximum
fraction of constraints. Biased CSPs are versatile and express several well
studied problems such as Densest-$k$-Sub(Hyper)graph and SmallSetExpansion.
  In this work, we explore the role played by the bias parameter $\mu$ on the
approximability of biased CSPs. We show that the approximability of such CSPs
can be characterized (up to loss of factors of arity $r$) using the
bias-approximation curve of Densest-$k$-SubHypergraph (DkSH). In particular,
this gives a tight characterization of predicates which admit approximation
guarantees that are independent of the bias parameter $\mu$.
  Motivated by the above, we give new approximation and hardness results for
DkSH. In particular, assuming the Small Set Expansion Hypothesis (SSEH), we
show that DkSH with arity $r$ and $k = \mu n$ is NP-hard to approximate to a
factor of $\Omega(r^3\mu^{r-1}\log(1/\mu))$ for every $r \geq 2$ and $\mu <
2^{-r}$. We also give a $O(\mu^{r-1}\log(1/\mu))$-approximation algorithm for
the same setting. Our upper and lower bounds are tight up to constant factors,
when the arity $r$ is a constant, and in particular, imply the first tight
approximation bounds for the Densest-$k$-Subgraph problem in the linear bias
regime. Furthermore, using the above characterization, our results also imply
matching algorithms and hardness for every biased CSP of constant arity.
","[{'version': 'v1', 'created': 'Wed, 12 Jan 2022 18:43:33 GMT'}]",2022-01-13,"[['Ghoshal', 'Suprovat', ''], ['Lee', 'Euiwoong', '']]"
2109.13792,Shirin Panahi,"Shirin Panahi, Isaac Klickstein, Francesco Sorrentino","Cluster Synchronization of Networks via a Canonical Transformation for
  Simultaneous Block Diagonalization of Matrices","Accepted for publication in Chaos: An Interdisciplinary Journal of
  Nonlinear Science","Chaos 31, 111102 (2021)",10.1063/5.0071154,,eess.SY cs.SY,http://creativecommons.org/licenses/by/4.0/,"  We study cluster synchronization of networks and propose a canonical
transformation for simultaneous block diagonalization of matrices that we use
to analyze stability of the cluster synchronous solution. Our approach has
several advantages as it allows us to: (1) decouple the stability problem into
subproblems of minimal dimensionality while preserving physically meaningful
information; (2) study stability of both orbital and equitable partitions of
the network nodes and (3) obtain a parametrization of the problem in a small
number of parameters. For the last point, we show how the canonical
transformation decouples the problem into blocks that preserve key physical
properties of the original system. We also apply our proposed algorithm to
analyze several real networks of interest, and we find that it runs faster than
alternative algorithms from the literature.
","[{'version': 'v1', 'created': 'Tue, 28 Sep 2021 15:24:02 GMT'}, {'version': 'v2', 'created': 'Tue, 12 Oct 2021 14:08:11 GMT'}, {'version': 'v3', 'created': 'Thu, 14 Oct 2021 22:43:26 GMT'}]",2021-11-10,"[['Panahi', 'Shirin', ''], ['Klickstein', 'Isaac', ''], ['Sorrentino', 'Francesco', '']]"
2202.13184,Amirhossein Kazemipour,"Amirhossein Kazemipour, Maram Khatib, Khaled Al Khudir, Claudio Gaz,
  Alessandro De Luca","Kinematic Control of Redundant Robots with Online Handling of Variable
  Generalized Hard Constraints","8 pages, 10 figures. This work has been submitted to the IEEE/RSJ
  International Conference on Intelligent Robots and Systems (IROS 2022 with
  RA-L option) for possible publication. Copyright may be transferred without
  notice, after which this version may no longer be accessible",,,,cs.RO cs.SY eess.SY,http://creativecommons.org/licenses/by/4.0/,"  We present a generalized version of the Saturation in the Null Space (SNS)
algorithm for the task control of redundant robots when hard inequality
constraints are simultaneously present both in the joint and in the Cartesian
space. These hard bounds should never be violated, are treated equally and in a
unified way by the algorithm, and may also be varied, inserted or deleted
online. When a joint/Cartesian bound saturates, the robot redundancy is
exploited to continue fulfilling the primary task. If no feasible solution
exists, an optimal scaling procedure is applied to enforce directional
consistency with the original task. Simulation and experimental results on
different robotic systems demonstrate the efficiency of the approach. The
proposed algorithm can be viewed as a generic platform that is easily
applicable to any robotic application in which robots operate in an
unstructured environment and online handling of joint and Cartesian constraints
is critical.
","[{'version': 'v1', 'created': 'Sat, 26 Feb 2022 16:56:31 GMT'}]",2022-03-01,"[['Kazemipour', 'Amirhossein', ''], ['Khatib', 'Maram', ''], ['Khudir', 'Khaled Al', ''], ['Gaz', 'Claudio', ''], ['De Luca', 'Alessandro', '']]"
2012.08995,Victor Barbosa Martins,"Victor Barbosa Martins, Markus Garczarczyk (for the The Cherenkov
  Telescope Array Consortium)",The structure monitoring of the MST prototype of CTA,,"Proc. SPIE 11445, Ground-based and Airborne Telescopes VIII,
  114456E (13 December 2020)",10.1117/12.2560930,,astro-ph.IM,http://creativecommons.org/licenses/by/4.0/,"  The Cherenkov Telescope Array (CTA) is the next generation of ground-based
gamma-ray observatory. The observatory will consist of two arrays, one located
in the southern hemisphere (Paranal,Chile) and the other in the northern
hemisphere (Canary Island, Spain), covering the whole sky in the range of
observation. More than 100 telescopes are planned to be in operation for as
long as 30 years, which motivated the development of a continuous condition
monitoring of the individual telescopes. The main goal of the monitoring is to
detect degradation and failures before critical damages occur. Two approaches
are considered: the structure monitoring system, in which the Eigenfrequencies
of the telescope and their damping rates are measured and monitored; and the
drive monitoring, in which the power spectra of rotating components are
measured during telescope movements. The structure monitoring concept system
was applied to the prototype Medium Size telescope (MST) prototype of CTA in
Berlin during late 2018 and in 2019, and the first results are presented here.
The system showed reasonable stability during periods, in which the telescope
structure was unchanged. The system was also capable to detect mechanical
changes, e.g. varying tension in the steel ropes of the camera support
structure. The successful implementation of the structure monitoring system
supports the decision of implementing the system in all future MSTs.
","[{'version': 'v1', 'created': 'Wed, 16 Dec 2020 14:41:33 GMT'}]",2020-12-17,"[['Martins', 'Victor Barbosa', '', 'for the The Cherenkov\n  Telescope Array Consortium'], ['Garczarczyk', 'Markus', '', 'for the The Cherenkov\n  Telescope Array Consortium']]"
2110.13329,Juan de Dios Santander-Vela Ph.D.,"J. Santander-Vela (1) and M. Bartolini (1 and 2) and, M. Miccolis (1)
  and N. Rees (1) ((1) 1SKA Observatory, Jodrell Bank, United Kingdom, (2)
  2INAF Istituto Nazionale di Astrofisica, Roma, Italy)",From SKA to SKAO: Early Progress in the SKAO Construction,"7 pages, 4 figures, presented at ICALEPCS21, Shanghai, China, 2021,
  paper MOAL03",,,MOAL03,astro-ph.IM cs.SE,http://creativecommons.org/licenses/by/4.0/,"  The Square Kilometre Array telescopes have recently started their
construction phase, after years of pre-construction effort. The new SKA
Observatory (SKAO) intergovernmental organisation has been created, and the
start of construction ($\mathrm{T_0}$) has already happened. In this talk, we
summarise the construction progress of our facility, and the role that agile
software development and open-source collaboration, and in particular the
development of our TANGO-based control system, is playing.
","[{'version': 'v1', 'created': 'Tue, 26 Oct 2021 00:07:56 GMT'}]",2021-10-27,"[['Santander-Vela', 'J.', '', '1 and 2'], ['Bartolini', 'M.', '', '1 and 2'], ['and', '', ''], ['Miccolis', 'M.', ''], ['Rees', 'N.', '']]"
2112.03700,Marcel Wolbers,"Alessandro Noci, Marcel Wolbers, Markus Abt, Corine Baayen, Hans
  Ulrich Burger, Man Jin, Weining Zhao Robieson","A Comparison of Estimand and Estimation Strategies for Clinical Trials
  in Early Parkinson's Disease","Manuscript (19 pages, 3 figures, 3 tables) and supplementary Appendix
  (5 pages)",,,,stat.AP,http://creativecommons.org/licenses/by/4.0/,"  Parkinson's disease (PD) is a chronic, degenerative neurological disorder. PD
cannot be prevented, slowed or cured as of today but highly effective
symptomatic treatments are available. We consider relevant estimands and
treatment effect estimators for randomized trials of a novel treatment which
aims to slow down disease progression versus placebo in early, untreated PD. A
commonly used endpoint in PD trials is the MDS-Unified Parkinson's Disease
Rating Scale (MDS-UPDRS), which is longitudinally assessed at scheduled visits.
The most important intercurrent events (ICEs) which affect the interpretation
of the MDS-UPDRS are study treatment discontinuations and initiations of
symptomatic treatment. Different estimand strategies are discussed and
hypothetical or treatment policy strategies, respectively, for different types
of ICEs seem most appropriate in this context. Several estimators based on
multiple imputation which target these estimands are proposed and compared in
terms of bias, mean-squared error, and power in a simulation study. The
investigated estimators include methods based on a missing-at-random (MAR)
assumption, with and without the inclusion of time-varying ICE-indicators, as
well as reference-based imputation methods. Simulation parameters are motivated
by data analyses of a cohort study from the Parkinson's Progression Markers
Initiative (PPMI).
","[{'version': 'v1', 'created': 'Tue, 7 Dec 2021 13:47:58 GMT'}]",2021-12-08,"[['Noci', 'Alessandro', ''], ['Wolbers', 'Marcel', ''], ['Abt', 'Markus', ''], ['Baayen', 'Corine', ''], ['Burger', 'Hans Ulrich', ''], ['Jin', 'Man', ''], ['Robieson', 'Weining Zhao', '']]"
2108.08387,Laura Schaefer,"Laura Schaefer, Vivien Parmentier",The air over there: exploring exoplanet atmospheres,"To be published as article 6 in the ""Geoscience Beyond the Solar
  System"" issue of Elements magazine, v17 No4",,,,astro-ph.EP,http://creativecommons.org/licenses/by/4.0/,"  Atmospheric compositions for rocky exoplanets will depend strongly on the
bulk planetary composition and the orbital position of the planet.
Non-traditional gases may be present in the atmospheres of exceptionally hot
planets. Atmospheres of more clement planets will depend on the abundances of
volatiles acquired during planet formation and atmospheric removal processes,
including escape, condensation, and reaction with the surface. While the
observations of exoplanet atmospheres to date has focused on giant planets, a
series of new space and ground-based observatories over the coming decade will
revolutionize the precision and spectral resolution with which we are able to
probe exoplanet atmospheres. This article consolidates lessons learned from the
study of giant planet atmospheres, and points to the observations and
challenges on the horizon for terrestrial planets.
","[{'version': 'v1', 'created': 'Wed, 18 Aug 2021 20:55:07 GMT'}]",2021-08-20,"[['Schaefer', 'Laura', ''], ['Parmentier', 'Vivien', '']]"
2109.06341,Anna Tenerani,"Anna Tenerani, Nikos Sioulas, Lorenzo Matteini, Olga Panasenco, Chen
  Shi, Marco Velli",Evolution of switchbacks in the inner Heliosphere,Accepted for publication on ApJL,,10.3847/2041-8213/ac2606,,astro-ph.SR physics.plasm-ph physics.space-ph,http://creativecommons.org/licenses/by/4.0/,"  We analyze magnetic field data from the first six encounters of PSP, three
Helios fast streams and two Ulysses south polar passes covering heliocentric
distances $0.1\lesssim R\lesssim 3$ au. We use this data set to statistically
determine the evolution of switchbacks of different periods and amplitudes with
distance from the Sun. We compare the radial evolution of magnetic field
variances with that of the mean square amplitudes of switchbacks, and quantify
the radial evolution of the cumulative counts of switchbacks per km. We find
that the amplitudes of switchbacks decrease faster than the overall turbulent
fluctuations, in a way consistent with the radial decrease of the mean magnetic
field. This could be the result of a saturation of amplitudes and may be a
signature of decay processes of large amplitude Alfv\'enic fluctuations in the
solar wind. We find that the evolution of switchback occurrence in the solar
wind is scale-dependent: the fraction of longer duration switchbacks increases
with radial distance whereas it decreases for shorter switchbacks. This implies
that switchback dynamics is a complex process involving both decay and in-situ
generation in the inner heliosphere. We confirm that switchbacks can be
generated by the expansion although other type of switchbacks generated closer
to the sun cannot be ruled out.
","[{'version': 'v1', 'created': 'Mon, 13 Sep 2021 21:49:18 GMT'}]",2021-10-13,"[['Tenerani', 'Anna', ''], ['Sioulas', 'Nikos', ''], ['Matteini', 'Lorenzo', ''], ['Panasenco', 'Olga', ''], ['Shi', 'Chen', ''], ['Velli', 'Marco', '']]"
2106.07338,Nidhika Yadav,Nidhika Yadav,Neighborhood Rough Set based Multi-document Summarization,"7 pages, original paper not submitted anywhere else",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  This research paper proposes a novel Neighbourhood Rough Set based approach
for supervised Multi-document Text Summarization (MDTS) with analysis and
impact on the summarization results for MDTS. Here, Rough Set based LERS
algorithm is improved using Neighborhood Rough Set which is itself a novel
combination called Neighborhood-LERS to be experimented for evaluations of
efficacy and efficiency. In this paper, we shall apply and evaluate the
proposed Neighborhood-LERS for Multi-document Summarization which here is
proved experimentally to be superior to the base LERS technique for MDTS.
","[{'version': 'v1', 'created': 'Thu, 27 May 2021 00:43:20 GMT'}]",2021-06-15,"[['Yadav', 'Nidhika', '']]"
2012.07480,Aamir Mahmood,"Luca Beltramelli, Aamir Mahmood, Paolo Ferrari, Patrik \""Osterberg,
  Mikael Gidlund, Emiliano Sisinni","Synchronous LoRa Communication by Exploiting Large-Area Out-of-Band
  Synchronization","12 pages, 8 figures, final version to appear in IEEE Internet of
  Things Journal",,10.1109/JIOT.2020.3041818,,cs.IT math.IT,http://creativecommons.org/licenses/by/4.0/,"  Many new narrowband low-power wide-area networks (LPWANs) (e.g., LoRaWAN,
Sigfox) have opted to use pure ALOHA-like access for its reduced control
overhead and asynchronous transmissions. Although asynchronous access reduces
the energy consumption of IoT devices, the network performance suffers from
high intra-network interference in dense deployments. Contrarily, synchronous
access can improve throughput and fairness, but it requires time
synchronization. Unfortunately, maintaining synchronization over the narrowband
LPWANs wastes channel time and transmission opportunities. In this paper, we
propose the use of out-of-band time-dissemination to relatively synchronize
LoRa devices and thereby facilitate resource-efficient slotted uplink
communication. To this end, we conceptualize and analyze a co-designed
synchronization and random access mechanism that can effectively exploit
technologies providing limited time accuracy, such as FM radio data system
(FM-RDS). While considering the LoRa-specific parameters, we derive the
throughput of the proposed mechanism, compare it to a generic synchronous
random access using in-band synchronization, and design the communication
parameters under time uncertainty. We scrutinize the transmission time
uncertainty of a device by introducing a clock error model that accounts for
the errors in the synchronization source, local clock, propagation delay, and
transceiver's transmission time uncertainty. We characterize the time
uncertainty of FM-RDS with hardware measurements and perform simulations to
evaluate the proposed solution. The results, presented in terms of success
probability, throughput, and fairness for a single-cell scenario, suggest that
FM-RDS, despite its poor absolute synchronization, can be used effectively to
realize slotted LoRa communication with performance similar to that of more
accurate time-dissemination technologies.
","[{'version': 'v1', 'created': 'Mon, 14 Dec 2020 12:58:15 GMT'}]",2021-01-20,"[['Beltramelli', 'Luca', ''], ['Mahmood', 'Aamir', ''], ['Ferrari', 'Paolo', ''], ['Österberg', 'Patrik', ''], ['Gidlund', 'Mikael', ''], ['Sisinni', 'Emiliano', '']]"
1610.10006,Paolo Carniti,P. Carniti,"Beam test results for the upgraded LHCb RICH optoelectronic readout
  system",,,10.1016/j.nima.2017.02.038,,physics.ins-det,http://creativecommons.org/licenses/by/4.0/,"  Starting from 2018, the LHCb detector will be upgraded to operate at higher
luminosity and extend its potential for new discoveries. The Ring Imaging
Cherenkov (RICH) detectors are one of the key components for particle
identification of the LHCb detector and the upgraded specifications will
require a redesign of the optoelectronic readout chain. In the present work, we
describe the experimental setup and the results of the tests carried out with a
particle beam to assess and validate the performance of the optoelectronic
readout system.
","[{'version': 'v1', 'created': 'Mon, 31 Oct 2016 16:41:49 GMT'}]",2017-08-14,"[['Carniti', 'P.', '']]"
2103.06733,Simon Carbonnelle,Carbonnelle Simon and Christophe De Vleeschouwer,"Intraclass clustering: an implicit learning ability that regularizes
  DNNs",Published as a conference paper at ICLR 2021,,,,cs.LG cs.AI cs.CV,http://creativecommons.org/licenses/by/4.0/,"  Several works have shown that the regularization mechanisms underlying deep
neural networks' generalization performances are still poorly understood. In
this paper, we hypothesize that deep neural networks are regularized through
their ability to extract meaningful clusters among the samples of a class. This
constitutes an implicit form of regularization, as no explicit training
mechanisms or supervision target such behaviour. To support our hypothesis, we
design four different measures of intraclass clustering, based on the neuron-
and layer-level representations of the training data. We then show that these
measures constitute accurate predictors of generalization performance across
variations of a large set of hyperparameters (learning rate, batch size,
optimizer, weight decay, dropout rate, data augmentation, network depth and
width).
","[{'version': 'v1', 'created': 'Thu, 11 Mar 2021 15:26:27 GMT'}]",2021-03-12,"[['Simon', 'Carbonnelle', ''], ['De Vleeschouwer', 'Christophe', '']]"
2107.07894,Jan Meibohm,"Jan Meibohm, Danilo Forastiere, Tunrayo Adeleke-Larodo, Karel
  Proesmans",Relaxation-speed crossover in anharmonic potentials,"6+5 pages, 3+2 figures, published in PRE","Phys. Rev. E 104, 032105 (2021)",10.1103/PhysRevE.104.L032105,,cond-mat.stat-mech cond-mat.mes-hall,http://creativecommons.org/licenses/by/4.0/,"  In a recent Letter [A. Lapolla and A. Godec, Phys. Rev. Lett. 125, 110602
(2020)], thermal relaxation was observed to occur faster from cold to hot
(heating) than from hot to cold (cooling). Here we show that overdamped
diffusion in anharmonic potentials generically exhibits both faster heating and
faster cooling, depending on the initial temperatures and on the potential's
degree of anharmonicity. We draw a relaxation-speed phase diagram that
localises the different behaviours in parameter space. In addition to
faster-heating and faster-cooling regions, we identify a crossover region in
the phase diagram, where heating is initially slower but asymptotically faster
than cooling. The structure of the phase diagram is robust against the
inclusion of a confining, harmonic term in the potential as well as moderate
changes of the measure used to define initially equidistant temperatures.
","[{'version': 'v1', 'created': 'Fri, 16 Jul 2021 13:30:24 GMT'}, {'version': 'v2', 'created': 'Mon, 27 Sep 2021 14:34:00 GMT'}]",2021-10-04,"[['Meibohm', 'Jan', ''], ['Forastiere', 'Danilo', ''], ['Adeleke-Larodo', 'Tunrayo', ''], ['Proesmans', 'Karel', '']]"
2112.04924,Sylvio Klose,"A. M. Nicuesa Guelbenzu, S. Klose, P. Schady, K. Belczynski, D. H.
  Hartmann, L. K. Hunt, and M. J. Micha{\l}owski","VLT/MUSE and ATCA observations of the host galaxy of the short GRB
  080905A at z=0.122","The Astrophysical Journal Supplement Series, in press",,10.3847/1538-4357/ac2faa,,astro-ph.HE astro-ph.GA,http://creativecommons.org/licenses/by/4.0/,"  Short-GRB progenitors could come in various flavors, depending on the nature
of the merging compact stellar objects (including a stellar-mass black hole or
not) or depending on their ages (millions or billions of years). At a redshift
of z=0.122, the nearly face-on spiral host of the short GRB 080905A is one of
the closest short-GRB host galaxies identified so far. This made it a preferred
target to explore spatially resolved star-formation and to investigate the
afterglow position in the context of its star formation structures. We used
VLT/MUSE integral-field unit observations, supplemented by ATCA 5.5/9.0 GHz
radio-continuum measurements and publicly available HST data, to study the
star-formation activity in the GRB 080905A host galaxy. The MUSE observations
reveal that the entire host is characterized by strong line emission. Using the
Halpha line flux, we measure for the entire galaxy an SFR of about 1.6 Msun/yr,
consistent with its non-detection by ATCA. Several individual star-forming
regions are scattered across the host. The most luminous region has a Halpha
luminosity that is nearly four times as high as the luminosity of the Tarantula
nebula in the Large Magellanic Cloud. Even though star-forming activity can be
traced as close to about 3 kpc (in projection) distance to the GRB explosion
site, stellar population synthesis calculations show that none of the
Halpha-bright star-forming regions is a likely birthplace of the short-GRB
progenitor.
","[{'version': 'v1', 'created': 'Thu, 9 Dec 2021 13:39:43 GMT'}]",2021-12-22,"[['Guelbenzu', 'A. M. Nicuesa', ''], ['Klose', 'S.', ''], ['Schady', 'P.', ''], ['Belczynski', 'K.', ''], ['Hartmann', 'D. H.', ''], ['Hunt', 'L. K.', ''], ['Michałowski', 'M. J.', '']]"
2108.02334,Guilherme S. Couto,"Guilherme S. Couto, Thomas M. Hughes, M\'ed\'eric Boquien, Eduardo
  Ibar, S\'ebastien Viaene, Roger Leiton and Yongquan Xue","VALES VIII: Weak ionized gas outflows in star-forming galaxies at $z
  \sim 0.15$ traced with VLT/MUSE","33 pages, 31 figures, 2 tables, accepted for publication by A&A.
  Comments are welcome","A&A 654, A128 (2021)",10.1051/0004-6361/202141490,,astro-ph.GA,http://creativecommons.org/licenses/by/4.0/,"  We characterize the ionized gas outflows in 15 low-redshift star-forming
galaxies, a Valpara\'iso ALMA Line Emission Survey (VALES) subsample, using
MUSE integral field spectroscopy and GAMA photometric broadband data. We
measure the emission-line spectra by fitting a double-component profile, with
the second and broader component being related to the outflowing gas. This
interpretation is in agreement with the correlation between the observed
star-formation rate surface density ($\Sigma_{\mathrm{SFR}}$) and the
second-component velocity dispersion ($\sigma_{\mathrm{2nd}}$), expected when
tracing the feedback component. By modelling the broadband spectra with spectra
energy distribution (SED) fitting and obtaining the star-formation histories of
the sample, we observe a small decrease in SFR between 100 and 10 Myr in
galaxies when the outflow H$\alpha$ luminosity contribution is increased,
indicating that the feedback somewhat inhibits the star formation within these
timescales. The observed emission-line ratios are best reproduced by
photoionization models when compared to shock-ionization, indicating that
radiation from young stellar population is dominant, and seems to be a
consequence of a continuous star-formation activity instead of a bursty event.
The outflow properties such as mass outflow rate ($\sim 0.1\,$M$_\odot$
yr$^{-1}$), outflow kinetic power ($\sim 5.2 \times 10^{-4}\%
L_{\mathrm{bol}}$) and mass loading factor ($\sim 0.12$) point towards a
scenario where the measured feedback is not strong and has a low impact on the
evolution of galaxies in general.
","[{'version': 'v1', 'created': 'Thu, 5 Aug 2021 01:34:45 GMT'}]",2021-10-27,"[['Couto', 'Guilherme S.', ''], ['Hughes', 'Thomas M.', ''], ['Boquien', 'Médéric', ''], ['Ibar', 'Eduardo', ''], ['Viaene', 'Sébastien', ''], ['Leiton', 'Roger', ''], ['Xue', 'Yongquan', '']]"
2108.08896,Ralph Kube,"Ralph Kube and R. Michael Churchill and CS Chang and Jong Choi and
  Jason Wang and Scott Klasky and Laurie Stephey and Minjun Choi and Eli Dart",Near real-time streaming analysis of big fusion data,,,10.1088/1361-6587/ac3f42,,physics.plasm-ph physics.data-an,http://creativecommons.org/licenses/by/4.0/,"  While experiments on fusion plasmas produce high-dimensional data time series
with ever increasing magnitude and velocity, data analysis has been lagging
behind this development. For example, many data analysis tasks are often
performed in a manual, ad-hoc manner some time after an experiment. In this
article we introduce the DELTA framework that facilitates near real-time
streaming analysis of big and fast fusion data. By streaming measurement data
from fusion experiments to a high-performance compute center, DELTA allows to
perform demanding data analysis tasks in between plasma pulses. This article
describe the modular and expandable software architecture of DELTA and presents
performance benchmarks of its individual components as well as of entire
workflows. Our focus is on the streaming analysis of ECEi data measured at
KSTAR on NERSCs supercomputers and we routinely achieve data transfer rates of
about 500 Megabyte per second. We show that a demanding turbulence analysis
workload can be distributed among multiple GPUs and executes in under 5
minutes. We further discuss how DELTA uses modern database systems and
container orchestration services to provide web-based real-time data
visualization. For the case of ECEi data we demonstrate how data visualizations
can be augmented with outputs from machine learning models. By providing
session leaders and physics operators results of higher order data analysis
using live visualization they may monitor the evolution of a long-pulse
discharge in near real-time and may make more informed decision on how to
configure the machine for the next shot.
","[{'version': 'v1', 'created': 'Thu, 19 Aug 2021 20:22:12 GMT'}]",2022-02-16,"[['Kube', 'Ralph', ''], ['Churchill', 'R. Michael', ''], ['Chang', 'CS', ''], ['Choi', 'Jong', ''], ['Wang', 'Jason', ''], ['Klasky', 'Scott', ''], ['Stephey', 'Laurie', ''], ['Choi', 'Minjun', ''], ['Dart', 'Eli', '']]"
2108.04523,Stavros Tripakis,Stavros Tripakis and Karen Rudie,"Decentralized Observation of Discrete-Event Systems: At Least One Can
  Tell",,,,,cs.FL cs.LO cs.MA cs.SE cs.SY eess.SY,http://creativecommons.org/licenses/by/4.0/,"  We introduce a new decentralized observation condition which we call ""at
least one can tell"" (OCT) and which attempts to capture the idea that for any
possible behavior that a system can generate, at least one decentralized
observation agent can tell whether that behavior was ""good"" or ""bad"", for given
formal specifications of ""good"" and ""bad"". We provide several equivalent
formulations of the OCT condition, and we relate it to (and show that it is
different from) previously introduced joint observability. In fact, contrary to
joint observability which is undecidable, we show that the OCT condition is
decidable. We also show that when the condition holds, finite-state
decentralized observers exist.
","[{'version': 'v1', 'created': 'Tue, 10 Aug 2021 09:07:00 GMT'}]",2021-08-11,"[['Tripakis', 'Stavros', ''], ['Rudie', 'Karen', '']]"
2112.10518,Vishal Kumar,"Vishal Kumar, Supratik Mukhopadhyay, Nayana Majumdar and Sandip
  Sarkara","Comparative study on charging-up of single, double and triple Gas
  Electron Multipliers (GEM)",,,,,physics.ins-det,http://creativecommons.org/licenses/by/4.0/,"  In this paper, a detailed investigation has been carried out to understand
the physics behind GEM charging-up and its effects on gain. Experiments have
been performed on both double and triple GEM with the help of 55Fe x-ray source
and a comparative study of these configurations along with the single GEM
results observed in our previous work, has been reported. The increase in gain
due to polarization of GEM foil dielectric and reduction in gain due to charge
accumulation on dielectric are studied in detail with variation in parameters,
like field configuration and radiation rate.
","[{'version': 'v1', 'created': 'Mon, 20 Dec 2021 13:25:56 GMT'}]",2021-12-21,"[['Kumar', 'Vishal', ''], ['Mukhopadhyay', 'Supratik', ''], ['Majumdar', 'Nayana', ''], ['Sarkara', 'Sandip', '']]"
1706.05077,Hossein Zeinali,"Hossein Zeinali, Hossein Sameti, Nooshin Maghsoodi",SUT System Description for NIST SRE 2016,Presented in NIST SRE 2016 Evaluation Workshop,,,,cs.SD,http://creativecommons.org/licenses/by/4.0/,"  This paper describes the submission to fixed condition of NIST SRE 2016 by
Sharif University of Technology (SUT) team. We provide a full description of
the systems that were included in our submission. We start with an overview of
the datasets that were used for training and development. It is followed by
describing front-ends which contain different VAD and feature types. UBM and
i-vector extractor training are the next details in this paper. As one of the
important steps in system preparation, preconditioning the i-vectors are
explained in more details. Then, we describe the classifier and score
normalization methods. And finally, some results on SRE16 evaluation dataset
are reported and analyzed.
","[{'version': 'v1', 'created': 'Thu, 8 Jun 2017 11:13:32 GMT'}]",2017-06-19,"[['Zeinali', 'Hossein', ''], ['Sameti', 'Hossein', ''], ['Maghsoodi', 'Nooshin', '']]"
2011.11711,Chavit Denninnart,Chavit Denninnart,Cost- and QoS-Efficient Serverless Cloud Computing,"PhD thesis, University of Louisiana at Lafayette (2020)",,,,cs.DC cs.MM,http://creativecommons.org/licenses/by/4.0/,"  Cloud-based serverless computing systems, either public or privately
provisioned, aim to provide the illusion of infinite resources and abstract
users from details of the allocation decisions. With the goal of providing a
low cost and a high QoS, the serverless computing paradigm offers opportunities
that can be harnessed to attain the goals. Specifically, our strategy in this
dissertation is to avoid redundant computing, in cases where independent task
requests are similar to each other and for tasks that are pointless to process.
We explore two main approaches to (A) reuse part of computation needed to
process the services and (B) proactively pruning tasks with a low chance of
success to improve the overall QoS of the system. For the first approach, we
propose a mechanism to identify various types of ""mergeable"" tasks, which can
benefit from computational reuse if they are executed together as a group. To
evaluate the task merging configurations extensively, we quantify the
resource-saving magnitude and then leveraging the experimental data to create a
resource-saving predictor. We investigate multiple tasks merging approaches
that suit different workload scenarios to determine when it is appropriate to
aggregate tasks and how to allocate them so that the QoS of other tasks is
minimally affected. For the second approach, we developed the mechanisms to
skip tasks whose chance of completing on time is not worth pursuing by drop or
defer them. We determined the minimum chance of success thresholds for tasks to
pass to get scheduled and executed. We dynamically adjust such thresholds based
on multiple characteristics of the arriving workload and the system's
conditions. We employed approximate computing to reduce the pruning mechanism's
computational overheads and ensure that the mechanism can be used practically.
","[{'version': 'v1', 'created': 'Mon, 23 Nov 2020 20:30:25 GMT'}]",2020-11-25,"[['Denninnart', 'Chavit', '']]"
2112.02746,Andrew Estornell,"Andrew Estornell, Sanmay Das, Yang Liu, Yevgeniy Vorobeychik","Unfairness Despite Awareness: Group-Fair Classification with Strategic
  Agents",,,,,cs.MA cs.CY cs.GT cs.LG,http://creativecommons.org/licenses/by/4.0/,"  The use of algorithmic decision making systems in domains which impact the
financial, social, and political well-being of people has created a demand for
these decision making systems to be ""fair"" under some accepted notion of
equity. This demand has in turn inspired a large body of work focused on the
development of fair learning algorithms which are then used in lieu of their
conventional counterparts. Most analysis of such fair algorithms proceeds from
the assumption that the people affected by the algorithmic decisions are
represented as immutable feature vectors. However, strategic agents may possess
both the ability and the incentive to manipulate this observed feature vector
in order to attain a more favorable outcome. We explore the impact that
strategic agent behavior could have on fair classifiers and derive conditions
under which this behavior leads to fair classifiers becoming less fair than
their conventional counterparts under the same measure of fairness that the
fair classifier takes into account. These conditions are related to the the way
in which the fair classifier remedies unfairness on the original unmanipulated
data: fair classifiers which remedy unfairness by becoming more selective than
their conventional counterparts are the ones that become less fair than their
counterparts when agents are strategic. We further demonstrate that both the
increased selectiveness of the fair classifier, and consequently the loss of
fairness, arises when performing fair learning on domains in which the
advantaged group is overrepresented in the region near (and on the beneficial
side of) the decision boundary of conventional classifiers. Finally, we observe
experimentally, using several datasets and learning methods, that this fairness
reversal is common, and that our theoretical characterization of the fairness
reversal conditions indeed holds in most such cases.
","[{'version': 'v1', 'created': 'Mon, 6 Dec 2021 02:42:43 GMT'}]",2021-12-07,"[['Estornell', 'Andrew', ''], ['Das', 'Sanmay', ''], ['Liu', 'Yang', ''], ['Vorobeychik', 'Yevgeniy', '']]"
1712.00501,"White, Michael J.","Michael White, Benjamin Hansen, Arkadiy Klebaner (Fermilab)",Cryogenic System for the Cryomodule Test Stand at Fermilab,8 pp,,,Fermilab-Conf-15-684-AD-TD,physics.acc-ph,http://creativecommons.org/licenses/by/4.0/,"  This paper describes the cryogenic system for the Cryomodule Test Stand
(CMTS) at the new Cryomodule Test Facility (CMTF) located at Fermilab. CMTS is
designed for production testing of the 1.3 GHz and 3.9 GHz cryomodules to be
used in the Linac Coherent Light Source II (LCLSII), which is an upgrade to an
existing accelerator at Stanford Linear Accelerator Laboratory (SLAC). This
paper will focus on the cryogenic system that extends from the helium
refrigeration plant to the CMTS cave. Topics covered will include component
design, installation and commissioning progress, and operational plans. The
paper will conclude with a description of the heat load measurement plan.
","[{'version': 'v1', 'created': 'Fri, 1 Dec 2017 21:26:24 GMT'}]",2017-12-05,"[['White', 'Michael', '', 'Fermilab'], ['Hansen', 'Benjamin', '', 'Fermilab'], ['Klebaner', 'Arkadiy', '', 'Fermilab']]"
2104.13911,Przemyslaw Zielinski,Przemyslaw Zielinski and Jan S. Hesthaven,"Discovery of slow variables in a class of multiscale stochastic systems
  via neural networks","26 pages, 15 figures",,,,math.DS cs.LG cs.NA math.NA,http://creativecommons.org/licenses/by/4.0/,"  Finding a reduction of complex, high-dimensional dynamics to its essential,
low-dimensional ""heart"" remains a challenging yet necessary prerequisite for
designing efficient numerical approaches. Machine learning methods have the
potential to provide a general framework to automatically discover such
representations. In this paper, we consider multiscale stochastic systems with
local slow-fast time scale separation and propose a new method to encode in an
artificial neural network a map that extracts the slow representation from the
system. The architecture of the network consists of an encoder-decoder pair
that we train in a supervised manner to learn the appropriate low-dimensional
embedding in the bottleneck layer. We test the method on a number of examples
that illustrate the ability to discover a correct slow representation.
Moreover, we provide an error measure to assess the quality of the embedding
and demonstrate that pruning the network can pinpoint an essential coordinates
of the system to build the slow representation.
","[{'version': 'v1', 'created': 'Wed, 28 Apr 2021 17:48:25 GMT'}, {'version': 'v2', 'created': 'Thu, 6 May 2021 16:56:37 GMT'}]",2021-05-07,"[['Zielinski', 'Przemyslaw', ''], ['Hesthaven', 'Jan S.', '']]"
2108.07542,Jordi Gaset,Jordi Gaset and Adri\`a Mar\'in-Salvador,"Application of Herglotz's Variational Principle to Electromagnetic
  Systems with Dissipation",,,,,physics.class-ph math-ph math.MP,http://creativecommons.org/licenses/by/4.0/,"  This work applies the contact formalism of classical mechanics and classical
field theory, introduced by Herglotz and later developed in the context of
contact geometry, to describe electromagnetic systems with dissipation. In
particular, we study an electron in a non-perfect conductor and a variation of
the cyclotron radiation. In order to apply the contact formalism to a system
governed by the Lorentz force, it is necessary to generalize the classical
electromagnetic gauge and add a term in the Lagrangian. We also apply the
k-contact theory for classical fields to model the behaviour of electromagnetic
fields themselves under external damping. In particular, we show how the theory
describes the evolution of electromagnetic fields in media under some
circumstances. The corresponding Poynting theorem is derived. We discuss its
applicability to the Lorentz dipole model and to a highly resistive dielectric.
","[{'version': 'v1', 'created': 'Tue, 17 Aug 2021 09:59:36 GMT'}, {'version': 'v2', 'created': 'Thu, 19 Aug 2021 10:08:23 GMT'}, {'version': 'v3', 'created': 'Tue, 14 Dec 2021 18:54:48 GMT'}]",2021-12-15,"[['Gaset', 'Jordi', ''], ['Marín-Salvador', 'Adrià', '']]"
2112.14227,Yuwei Lu,"Yu-Wei Lu, Jing-Feng Liu, Runhua Li, Haishu Tan, Yanxiong Wu, Yongyao
  Li","Single-photon blockade in quasichiral atom-photon interaction:
  Simultaneous high purity and high efficiency","9 pages, 6 figures",,,,physics.optics quant-ph,http://creativecommons.org/licenses/by/4.0/,"  We investigate the single-photon blockade (1PB) in the quasichiral regime of
atom-photon interaction that mediates via dissipative environment, where the
effective atom-photon interaction is asymmetrical but achiral. The synthetic
magnetic current in the closed-loop coupling breaks down the reciprocity of
atom-photon interaction, resulting in an asymmetrical and even completely
unidirectional effective coupling between two selected quantum states. As an
example, we couple the single-atom cavity-QED (cQED) system to a strongly
dissipative auxiliary cavity. We find that in the quasichiral regime, the
unconventional photon blockade (UPB) always incorporates with the conventional
photon blockade (CPB) in the condition of maximum chirality. Furthermore, we
show that 1PB in the quasichiral regime combines the advantages of UPB and CPB,
demonstrating the perfect single-photon purity, higher efficiency, smooth time
dynamics as well as lower requirement of modes coupling to achieve UPB. Our
work paves the way for 1PB towards practical applications and reveals the
intriguing quantum-optics phenomena in the quasichiral light-matter
interaction.
","[{'version': 'v1', 'created': 'Tue, 28 Dec 2021 17:22:04 GMT'}]",2021-12-30,"[['Lu', 'Yu-Wei', ''], ['Liu', 'Jing-Feng', ''], ['Li', 'Runhua', ''], ['Tan', 'Haishu', ''], ['Wu', 'Yanxiong', ''], ['Li', 'Yongyao', '']]"
2002.11640,Thomas Gerard,"Thomas Gerard, Hubert Dzieciol, Joshua Benjamin, Kari Clark, Hugh
  Williams, Benn Thomsen, Domani\c{c} Lavery, Polina Bayvel",Packet Timescale Wavelength Switching Enabled by Regression Optimisation,"4 pages, 9 figures, one algorithm, Letter",,10.1109/LPT.2020.2980746,,eess.SP,http://creativecommons.org/licenses/by/4.0/,"  A linear regression algorithm is applied to a digital-supermode distributed
Bragg reflector laser to optimise wavelength switching times. The algorithm
uses the output of a digital coherent receiver as feedback to update the
pre-emphasis weights applied to the laser section currents. This permits
in-situ calculation without manual weight adjustments. The application of this
optimiser to a representative subsection of channels indicates this
commercially available laser can rapidly reconfigure over 6.05 THz, supporting
122 channels, in less than 10 ns.
","[{'version': 'v1', 'created': 'Mon, 24 Feb 2020 21:32:25 GMT'}, {'version': 'v2', 'created': 'Wed, 11 Mar 2020 18:07:35 GMT'}]",2020-04-22,"[['Gerard', 'Thomas', ''], ['Dzieciol', 'Hubert', ''], ['Benjamin', 'Joshua', ''], ['Clark', 'Kari', ''], ['Williams', 'Hugh', ''], ['Thomsen', 'Benn', ''], ['Lavery', 'Domaniç', ''], ['Bayvel', 'Polina', '']]"
2006.02716,Alexandr Grichshenko,"Alexandr Grichshenko, Luiz Jonata Pires de Araujo, Susanna Gimaeva,
  Joseph Alexander Brown","Using Tabu Search Algorithm for Map Generation in the Terra Mystica
  Tabletop Game",,"ISMSI '20: Proceedings of the 2020 4th International Conference on
  Intelligent Systems, Metaheuristics & Swarm Intelligence",10.1145/3396474.3396492,,cs.AI cs.NE,http://creativecommons.org/licenses/by/4.0/,"  Tabu Search (TS) metaheuristic improves simple local search algorithms (e.g.
steepest ascend hill-climbing) by enabling the algorithm to escape local optima
points. It has shown to be useful for addressing several combinatorial
optimization problems. This paper investigates the performance of TS and
considers the effects of the size of the Tabu list and the size of the
neighbourhood for a procedural content generation, specifically the generation
of maps for a popular tabletop game called Terra Mystica. The results validate
the feasibility of the proposed method and how it can be used to generate maps
that improve existing maps for the game.
","[{'version': 'v1', 'created': 'Thu, 4 Jun 2020 09:15:46 GMT'}]",2020-06-05,"[['Grichshenko', 'Alexandr', ''], ['de Araujo', 'Luiz Jonata Pires', ''], ['Gimaeva', 'Susanna', ''], ['Brown', 'Joseph Alexander', '']]"
1604.03060,Christian Baumgarten,Christian Baumgarten,"Old Game, New Rules: Rethinking The Form of Physics","23 pages, no figures","Symmetry 2016, 8(5), 30",10.3390/sym8050030,,physics.class-ph quant-ph,http://creativecommons.org/licenses/by/4.0/,"  We investigate the modeling capabilities of sets of coupled classical
harmonic oscillators (CHO) in the form of a modeling game. The application of
simple but restrictive rules of the game lead to conditions for an isomorphism
between Lie-algebras and real Clifford algebras. We show that the correlations
between two coupled classical oscillators find their natural description in the
Dirac algebra and allow to model aspects of special relativity, inertial
motion, electromagnetism and quantum phenomena including spin in one go. The
algebraic properties of Hamiltonian motion of low-dimensional systems can
generally be related to certain types of interactions and hence to the
dimensionality of emergent space-times. We describe the intrinsic connection
between phase space volumes of a 2-dimensional oscillator and the Dirac
algebra. In this version of a phase space interpretation of quantum mechanics
the (components of the) spinor wave-function in momentum space are abstract
canonical coordinates, and the integrals over the squared wave function
represents second moments in phase space. The wave function in ordinary
space-time can be obtained via Fourier transformation. Within this modeling
game, 3+1-dimensional space-time is interpreted as a structural property of
electromagnetic interaction. A generalization selects a series of Clifford
algebras of specific dimensions with similar properties, specifically also 10-
and 26-dimensional real Clifford algebras.
","[{'version': 'v1', 'created': 'Fri, 8 Apr 2016 11:33:21 GMT'}]",2016-05-18,"[['Baumgarten', 'Christian', '']]"
2202.04589,Paterne Gahungu,"Paterne Gahungu, Christopher W Lanyon, Mauricio A Alvarez, Engineer
  Bainomugisha, Michael Smith, and Richard D. Wilkinson","Adjoint-aided inference of Gaussian process driven differential
  equations",,,,,stat.ML cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Linear systems occur throughout engineering and the sciences, most notably as
differential equations. In many cases the forcing function for the system is
unknown, and interest lies in using noisy observations of the system to infer
the forcing, as well as other unknown parameters. In differential equations,
the forcing function is an unknown function of the independent variables
(typically time and space), and can be modelled as a Gaussian process (GP). In
this paper we show how the adjoint of a linear system can be used to
efficiently infer forcing functions modelled as GPs, after using a truncated
basis expansion of the GP kernel. We show how exact conjugate Bayesian
inference for the truncated GP can be achieved, in many cases with
substantially lower computation than would be required using MCMC methods. We
demonstrate the approach on systems of both ordinary and partial differential
equations, and by testing on synthetic data, show that the basis expansion
approach approximates well the true forcing with a modest number of basis
vectors. Finally, we show how to infer point estimates for the non-linear model
parameters, such as the kernel length-scales, using Bayesian optimisation.
","[{'version': 'v1', 'created': 'Wed, 9 Feb 2022 17:35:14 GMT'}]",2022-02-10,"[['Gahungu', 'Paterne', ''], ['Lanyon', 'Christopher W', ''], ['Alvarez', 'Mauricio A', ''], ['Bainomugisha', 'Engineer', ''], ['Smith', 'Michael', ''], ['Wilkinson', 'Richard D.', '']]"
2106.15656,Wendy L. Freedman,Wendy L. Freedman,Measurements of the Hubble Constant: Tensions in Perspective,"48 pages, 13 figures; accepted for publication in the Astrophysical
  Journal",,10.3847/1538-4357/ac0e95,,astro-ph.CO hep-ph hep-th,http://creativecommons.org/licenses/by/4.0/,"  Measurement of the distances to nearby galaxies have improved rapidly in
recent decades. The ever-present challenge is to reduce systematic effects,
especially as greater distances are probed, and the uncertainties become
larger. In this paper, we combine several recent calibrations of the Tip of the
Red Giant Branch (TRGB) method. These calibrations are internally
self-consistent at the 1% level. New Gaia Early Data Release 3 (EDR3) data
provide an additional consistency check, at a (lower) 5% level of accuracy, a
result of the well-documented Gaia angular covariance bias. The updated TRGB
calibration applied to a distant sample of Type Ia supernovae from the Carnegie
Supernova Project results in a value of the Hubble constant of Ho = 69.8 $\pm$
0.6 (stat) $\pm$ 1.6 (sys) km/s/Mpc. No statistically significant difference is
found between the value of Ho based on the TRGB and that determined from
measurements of the cosmic microwave background. The TRGB results are also
consistent to within 2$\sigma$ with the SHoES and Spitzer plus HST Key Project
Cepheid calibrations. The TRGB results alone do not demand additional new
physics beyond the standard Lambda-CDM cosmological model. They have the
advantage of simplicity of the underlying physics (the core He flash) and small
systematic uncertainties (from extinction, metallicity and crowding). Finally,
the strengths and weaknesses of both the TRGB and Cepheids are reviewed, and
prospects for addressing the current discrepancy with future Gaia, HST and JWST
observations are discussed. Resolving this discrepancy is essential for
ascertaining if the claimed tension in Ho between the locally-measured and the
CMB-inferred value is physically motivated.
","[{'version': 'v1', 'created': 'Tue, 29 Jun 2021 18:09:57 GMT'}]",2021-09-29,"[['Freedman', 'Wendy L.', '']]"
1810.10936,Dennis Lendrem Dr,"Dennis W Lendrem, B Clare Lendrem, Arthur G Pratt, Jessica R Tarn,
  Andrew Skelton, Kathryn James, Peter McMeekin, Matt Linsley, Colin Gillespie,
  Heather Cordell, Wan-Fai Ng, John D Isaacs","Building Reality Checks into the Translational Pathway for Diagnostic
  and Prognostic Models",,,,,stat.AP,http://creativecommons.org/licenses/by/4.0/,"  There has been a significant increase in the number of diagnostic and
prognostic models published in the last decade. Testing such models in an
independent, external validation cohort gives some assurance the model will
transfer to a naturalistic, healthcare setting. Of 2,147 published models in
the PubMed database, we found just 120 included some kind of separate external
validation cohort. Of these studies not all were sufficiently well documented
to allow a judgement about whether that model was likely to transfer to other
centres, with other patients, treated by other clinicians, using data scored or
analysed by other laboratories. We offer a solution to better characterizing
the validation cohort and identify the key steps on the translational pathway
for diagnostic and prognostic models.
","[{'version': 'v1', 'created': 'Thu, 25 Oct 2018 15:44:56 GMT'}]",2018-10-26,"[['Lendrem', 'Dennis W', ''], ['Lendrem', 'B Clare', ''], ['Pratt', 'Arthur G', ''], ['Tarn', 'Jessica R', ''], ['Skelton', 'Andrew', ''], ['James', 'Kathryn', ''], ['McMeekin', 'Peter', ''], ['Linsley', 'Matt', ''], ['Gillespie', 'Colin', ''], ['Cordell', 'Heather', ''], ['Ng', 'Wan-Fai', ''], ['Isaacs', 'John D', '']]"
2203.06396,Andrea Brunello,"Andrea Brunello, Enrico Marzano, Angelo Montanari, Guido Sciavicco","A combined approach to the analysis of speech conversations in a contact
  center domain",,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  The ever more accurate search for deep analysis in customer data is a really
strong technological trend nowadays, quite appealing to both private and public
companies. This is particularly true in the contact center domain, where speech
analytics is an extremely powerful methodology for gaining insights from
unstructured data, coming from customer and human agent conversations. In this
work, we describe an experimentation with a speech analytics process for an
Italian contact center, that deals with call recordings extracted from inbound
or outbound flows. First, we illustrate in detail the development of an
in-house speech-to-text solution, based on Kaldi framework, and evaluate its
performance (and compare it to Google Cloud Speech API). Then, we evaluate and
compare different approaches to the semantic tagging of call transcripts,
ranging from classic regular expressions to machine learning models based on
ngrams and logistic regression, and propose a combination of them, which is
shown to provide a consistent benefit. Finally, a decision tree inducer, called
J48S, is applied to the problem of tagging. Such an algorithm is natively
capable of exploiting sequential data, such as texts, for classification
purposes. The solution is compared with the other approaches and is shown to
provide competitive classification performances, while generating highly
interpretable models and reducing the complexity of the data preparation phase.
The potential operational impact of the whole process is thoroughly examined.
","[{'version': 'v1', 'created': 'Sat, 12 Mar 2022 10:03:20 GMT'}]",2022-03-15,"[['Brunello', 'Andrea', ''], ['Marzano', 'Enrico', ''], ['Montanari', 'Angelo', ''], ['Sciavicco', 'Guido', '']]"
1511.03406,Kimio Kuramitsu,"Shun Honda, Kimio Kuramitsu",Implementing a Small Parsing Virtual Machine on Embedded Systems,An earlier draft for future submission,,,,cs.PL,http://creativecommons.org/licenses/by/4.0/,"  PEGs are a formal grammar foundation for describing syntax, and are not hard
to generate parsers with a plain recursive decent parsing. However, the large
amount of C-stack consumption in the recursive parsing is not acceptable
especially in resource-restricted embedded systems. Alternatively, we have
attempted the machine virtualization approach to PEG-based parsing. MiniNez,
our implemented virtual machine, is presented in this paper with several
downsizing techniques, including instruction specialization, inline expansion
and static flow analysis. As a result, the MiniNez machine achieves both a very
small footprint and competitive performance to generated C parsers. We have
demonstrated the experimental results by comparing on two major embedded
platforms: Cortex-A7 and Intel Atom processor.
","[{'version': 'v1', 'created': 'Wed, 11 Nov 2015 07:44:04 GMT'}]",2015-11-12,"[['Honda', 'Shun', ''], ['Kuramitsu', 'Kimio', '']]"
1903.07136,Alireza Karduni,Alireza Karduni,"Human-Misinformation interaction: Understanding the interdisciplinary
  approach needed to computationally combat false information","21 pages, 2 figures",,,,cs.HC cs.SI,http://creativecommons.org/licenses/by/4.0/,"  The prevalence of new technologies and social media has amplified the effects
of misinformation on our societies. Thus, it is necessary to create
computational tools to mitigate their effects effectively. This study aims to
provide a critical overview of computational approaches concerned with
combating misinformation. To this aim, I offer an overview of scholarly
definitions of misinformation. I adopt a framework for studying misinformation
that suggests paying attention to the source, content, and consumers as the
three main elements involved in the process of misinformation and I provide an
overview of literature from disciplines of psychology, media studies, and
cognitive sciences that deal with each of these elements. Using the framework,
I overview the existing computational methods that deal with 1) misinformation
detection and fact-checking using Content 2) Identifying untrustworthy Sources
and social bots, and 3) Consumer-facing tools and methods aiming to make humans
resilient to misinformation. I find that the vast majority of works in computer
science and information technology is concerned with the crucial tasks of
detection and verification of content and sources of misinformation. Moreover,
I find that computational research focusing on Consumers of Misinformation in
Human-Computer Interaction (HCI) and related fields are very sparse and often
do not deal with the subtleties of this process. The majority of existing
interfaces and systems are less concerned with the usability of the tools
rather than the robustness and accuracy of the detection methods. Using this
survey, I call for an interdisciplinary approach towards human-misinformation
interaction that focuses on building methods and tools that robustly deal with
such complex psychological/social phenomena.
","[{'version': 'v1', 'created': 'Sun, 17 Mar 2019 17:37:39 GMT'}]",2019-03-19,"[['Karduni', 'Alireza', '']]"
2107.03164,Kasper Jensen,Tadas Pyragius and Kasper Jensen,A high performance active noise control system for magnetic fields,The article has been submitted to Review of Scientific Instruments,"Review of Scientific Instruments 92, 124702 (2021)",10.1063/5.0062650,,eess.SY cs.SY physics.app-ph physics.ins-det,http://creativecommons.org/licenses/by/4.0/,"  We present a system for active noise control (ANC) of environmental magnetic
fields based on a Filtered-x Least Mean Squares (FxLMS) algorithm. The system
consists of a sensor that detects the ambient field noise and an error sensor
that measures the signal of interest contaminated with the noise. These signals
are fed to an adaptive algorithm that constructs a physical anti-noise signal
cancelling the local magnetic field noise. The proposed system achieves a
maximum of 35 dB root-mean-square (RMS) noise suppression in the DC-1 kHz band
and 50 dB and 40 dB amplitude suppression of 50 Hz and 150 Hz AC line noise
respectively for all three axial directions of the magnetic vector field.
","[{'version': 'v1', 'created': 'Wed, 7 Jul 2021 11:46:23 GMT'}]",2022-01-05,"[['Pyragius', 'Tadas', ''], ['Jensen', 'Kasper', '']]"
